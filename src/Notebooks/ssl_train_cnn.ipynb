{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ssl_train_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XSqDIK1svI0"
      },
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "# Used for Confusion Matrix\n",
        "from sklearn import metrics\n",
        "# Used for calculating result and accuracy\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        " \n",
        "from sklearn.model_selection import train_test_split\n",
        " \n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        " \n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        " \n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GemIbGss-ow"
      },
      "source": [
        "def get_data(input_shape):\n",
        "    num_classes = 10\n",
        "    (train_img, train_lbl), (test_img, test_lbl) = mnist.load_data()\n",
        "    train_img = train_img.astype(\"float32\") / 255\n",
        "    test_img = test_img.astype(\"float32\") / 255\n",
        "    # Make sure images have shape (28, 28, 1)\n",
        "    train_img = np.expand_dims(train_img, -1)\n",
        "    test_img = np.expand_dims(test_img, -1)\n",
        "    return train_img, train_lbl, test_img, test_lbl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4qbctOftGTJ"
      },
      "source": [
        "def define_cnn_model(input_shape):\n",
        "        model = keras.Sequential(\n",
        "            [\n",
        "                keras.Input(shape=input_shape),\n",
        "                layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "                layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "                layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "                layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "                layers.Flatten(),\n",
        "                layers.Dropout(0.5),\n",
        "                layers.Dense(10, activation=\"softmax\"),\n",
        "            ]\n",
        "        )\n",
        " \n",
        "        model.compile(\n",
        "            optimizer=keras.optimizers.Adam(0.001),\n",
        "            loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "            metrics=[keras.metrics.SparseCategoricalAccuracy()]\n",
        "        )\n",
        "        return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUrtiGiMtHAy"
      },
      "source": [
        "def plot_result(y_test, y_test_pred, test_f1s, test_f1s_avg, pseudo_labels, epoch):\n",
        "    fig, (ax1, ax2, ax3) = plt.subplots(nrows=3, ncols=1, figsize=(25,25))\n",
        "    ax1.plot(range(epoch), test_f1s)\n",
        "    ax1.set_ylabel('f1 Score')\n",
        "    ax1.set_xlabel('# Iterations')\n",
        "    ax1.legend(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], loc=\"lower right\")\n",
        "    ax2.plot(range(epoch), test_f1s_avg, )\n",
        "    ax2.set_ylabel('Average f1 Score')\n",
        "    ax2.set_xlabel('# Iterations')\n",
        "    ax2.legend(\"Average\", loc=\"lower right\")\n",
        "    ax3.bar(x=range(epoch), height=pseudo_labels)\n",
        "    ax3.set_ylabel('Pseudo-Labels Created')\n",
        "    ax3.set_xlabel('# Iterations')\n",
        " \n",
        "    # View confusion matrix after self-training\n",
        "    cf_matrix = confusion_matrix(y_test, y_test_pred, normalize='true')\n",
        "    fig, ax = plt.subplots(figsize=(10, 10))\n",
        "    sns.heatmap(cf_matrix, annot=True, \n",
        "                fmt='.2f', cmap='Blues')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I7gXJtEBKdZ"
      },
      "source": [
        "import sys\n",
        "import time\n",
        "\n",
        "\n",
        "class Stopwatch(object):\n",
        "    def __init__(self, verbose=False):\n",
        "        self.verbose = verbose\n",
        "        if sys.platform == 'win32':\n",
        "            # on Windows, the best timer is time.clock()\n",
        "            self._timer_func = time.clock\n",
        "        else:\n",
        "            # on most other platforms, the best timer is time.time()\n",
        "            self._timer_func = time.time\n",
        "        self.reset()\n",
        "\n",
        "    def __enter__(self, verbose=False):\n",
        "        return self.start()\n",
        "\n",
        "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "        self.stop()\n",
        "        return self.elapsed()\n",
        "\n",
        "    def start(self):\n",
        "        if not self._is_running:\n",
        "            self._start = self._timer_func()\n",
        "            self._is_running = True\n",
        "        return self\n",
        "\n",
        "    def stop(self):\n",
        "        if self._is_running:\n",
        "            self._total += (self._timer_func() - self._start)\n",
        "            self._is_running = False\n",
        "        return self\n",
        "\n",
        "    def elapsed(self):\n",
        "        if self._is_running:\n",
        "            now = self._timer_func()\n",
        "            self._total += (now - self._start)\n",
        "            self._start = now\n",
        "        if self.verbose:\n",
        "            print(\"Elapsed time: {0:.3f} sec\".format(self._total))\n",
        "        return self._total\n",
        "\n",
        "    def reset(self):\n",
        "        self._start = 0.\n",
        "        self._total = 0.\n",
        "        self._is_running = False\n",
        "        return self"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enfq7Dhs-DaA"
      },
      "source": [
        "def self_train_with_pretrain(model_type: str, num_pseudo: int, batchsize: int, epochs: int, confidence: float):\n",
        "    input_shape=(28, 28, 1)\n",
        "    X_train, y_train, X_test, y_test = get_data(input_shape=input_shape)\n",
        "    train_f1s = []\n",
        "    test_f1s = []\n",
        "    train_f1s_avg = []\n",
        "    test_f1s_avg = []\n",
        "    pseudo_labels = []\n",
        "    high_prob_counter = 1\n",
        "    total_pseudo_labelled = 0\n",
        "    total_prelabelled_added = 0\n",
        " \n",
        "    X_train_s = []\n",
        "    y_train_s = []\n",
        "    count = 0\n",
        "    for i in range(10):\n",
        "        for j in range(60000):\n",
        "            if y_train[j]==i:\n",
        "                count+=1\n",
        "                y_train_s.append(y_train[j])\n",
        "                X_train_s.append(X_train[j])\n",
        "                if count > ((num_pseudo/10)-1):\n",
        "                    count = 0\n",
        "                    break\n",
        "    X_train_s = np.array(X_train_s)\n",
        "    y_train_s = np.array(y_train_s)\n",
        " \n",
        "    X_plabelled = np.empty((0,28,28,1))\n",
        "    y_plabelled = np.empty(0)\n",
        "    unlabelled_missed = np.empty((0,28,28,1))\n",
        " \n",
        "    i = 0\n",
        "    #pretrain 600 labelled\n",
        "    if model_type == 'dense':\n",
        "        model_pretrained = define_dense_model(input_shape)\n",
        "    elif model_type =='CNN':\n",
        "        model_pretrained = define_cnn_model(input_shape)\n",
        " \n",
        "    with Stopwatch(verbose=True) as s:\n",
        "            early_stopping = keras.callbacks.EarlyStopping(monitor='loss', patience=30, verbose=2)\n",
        "            reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.2, verbose=2, patience=15, min_lr=1e-5)\n",
        "            callbacks = [early_stopping, reduce_lr]\n",
        "            try:\n",
        "                model_pretrained.fit(X_train_s, y_train_s,\n",
        "                        epochs=epochs,\n",
        "                        batch_size=batch_size,\n",
        "                        shuffle=False,\n",
        "                        callbacks=callbacks)\n",
        "            except KeyboardInterrupt:\n",
        "                pass\n",
        "\n",
        "    print(f\"{num_pseudo} pre-labelled data is training (pre-trained model is ready)...\")\n",
        " \n",
        "    X_train_s = np.empty((0,28,28,1))\n",
        "    y_train_s = np.empty(0)\n",
        " \n",
        "    total_prelabelled_added += num_pseudo\n",
        "    i += 1\n",
        "    epoch = 0\n",
        "    num_new_labeled = 0\n",
        " \n",
        "    while high_prob_counter > 0:\n",
        "        high_prob_counter = 0\n",
        "\n",
        "        epoch += 1\n",
        " \n",
        "        print(f\"Iteration: {epoch}\")\n",
        " \n",
        "        model = model_pretrained\n",
        " \n",
        "        if X_plabelled.shape[0] > num_pseudo:\n",
        " \n",
        "              X_train_s = np.append(X_train_s, X_plabelled[:num_pseudo], axis=0)\n",
        "              y_train_s = np.append(y_train_s, y_plabelled[:num_pseudo])\n",
        " \n",
        "              X_plabelled = X_plabelled[num_pseudo:]\n",
        "              y_plabelled = y_plabelled[num_pseudo:]\n",
        " \n",
        "              num_new_labeled += 1\n",
        "              print(f\"{num_pseudo*num_new_labeled} new labelled data is training...\")\n",
        "\n",
        "              with Stopwatch(verbose=True) as s:\n",
        "                      early_stopping = keras.callbacks.EarlyStopping(monitor='loss', patience=12, verbose=2)\n",
        "                      reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.2, verbose=2, patience=6, min_lr=1e-5)\n",
        "                      callbacks = [early_stopping, reduce_lr]\n",
        "                      try:\n",
        "                          model.fit(X_train_s, y_train_s,\n",
        "                                  epochs=epochs,\n",
        "                                  batch_size=batch_size,\n",
        "                                  shuffle=False,\n",
        "                                  callbacks=callbacks)\n",
        "                      except KeyboardInterrupt:\n",
        "                          pass\n",
        " \n",
        "        y_test_pred = np.argmax(model.predict(X_test),axis=1)\n",
        "        y_train_pred = np.argmax(model.predict(X_train),axis=1)\n",
        " \n",
        "        train_f1 = f1_score(y_train, y_train_pred, average=None)\n",
        "        test_f1 = f1_score(y_test, y_test_pred, average=None)\n",
        " \n",
        "        print(f\"Train f1 Score: {train_f1}\")\n",
        "        print(f\"Test f1 Score: {test_f1}\")\n",
        " \n",
        "        train_f1s.append(train_f1)\n",
        "        test_f1s.append(test_f1)\n",
        " \n",
        "        \n",
        "        train_f1_avg = f1_score(y_train, y_train_pred, average='macro')\n",
        "        test_f1_avg = f1_score(y_test, y_test_pred, average='macro')\n",
        " \n",
        "        print(f\"Train f1 Score: {train_f1_avg}\")\n",
        "        print(f\"Test f1 Score: {test_f1_avg}\")\n",
        " \n",
        "        train_f1s_avg.append(train_f1_avg)\n",
        "        test_f1s_avg.append(test_f1_avg)\n",
        "\n",
        "        num_unlabaled = num_pseudo * 1\n",
        "        if num_unlabaled*(i+1) < 60000:\n",
        "            unlabelled_splitted = X_train[(num_unlabaled*(i)):(num_unlabaled*(i+1))]\n",
        "            i += 1\n",
        "        elif unlabelled_missed.shape[0] > num_unlabaled:\n",
        "            unlabelled_splitted = unlabelled_missed[:num_unlabaled]\n",
        "            unlabelled_missed = unlabelled_missed[num_unlabaled:]\n",
        "        else:\n",
        "            unlabelled_splitted = unlabelled_missed\n",
        "            unlabelled_missed = np.empty((0,28,28,1))\n",
        "\n",
        "        if unlabelled_splitted.shape[0] == 0:\n",
        "            print(\"Whole dataset is observed. Nothing remained.\")\n",
        "            break\n",
        "        unlabeled_pred_prob = model.predict(unlabelled_splitted)\n",
        " \n",
        "        print(f\"Now predicting labels for unlabeled data...\")\n",
        " \n",
        "        high_prob_idx = []\n",
        " \n",
        "        for j in range(unlabeled_pred_prob.shape[0]):\n",
        "            max = 0\n",
        "            pseudo_label = 0\n",
        "            pred_prob = unlabeled_pred_prob[j]\n",
        "            for k in range(pred_prob.shape[0]):\n",
        "                if pred_prob[k] > max:\n",
        "                    max = pred_prob[k]\n",
        "                    pseudo_label = k\n",
        "            if max > confidence:\n",
        "                high_prob_counter += 1\n",
        "                high_prob_idx.append(j)\n",
        "                X_plabelled = np.append(X_plabelled, [unlabelled_splitted[j]], axis=0)\n",
        "                y_plabelled = np.append(y_plabelled, pseudo_label)\n",
        "            else:\n",
        "                unlabelled_missed = np.append(unlabelled_missed, [unlabelled_splitted[j]], axis=0)\n",
        " \n",
        "        print(f\"{high_prob_counter} high-probability unlabelled predictions is labelled and added to next train dataset.\")\n",
        " \n",
        "        print(f\"{unlabelled_missed.shape[0]} unlabelled instances remained to be predict in next iteration\")\n",
        " \n",
        "        print(f\"{X_plabelled.shape[0]} labelled instances are going to be added to train dataset in next iteration.\")\n",
        " \n",
        "        \n",
        "        total_pseudo_labelled += high_prob_counter\n",
        "        pseudo_labels.append(high_prob_counter)\n",
        "        \n",
        "    \n",
        "    print(\"*** Model's Learning is finished. ***\")\n",
        "    print(f\"In the end, {total_prelabelled_added} pre-labelled images and {total_pseudo_labelled} pseudo-labelled images added to train dataset\")\n",
        "    return y_test, y_test_pred, test_f1s, test_f1s_avg, pseudo_labels, epoch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hV7SGgsAXaY",
        "outputId": "1d831b27-0fc8-48e2-c698-fdb528546e8a"
      },
      "source": [
        "#HyperParams\n",
        "batch_size = 64\n",
        "epochs = 100 \n",
        "num_pseudo = 600\n",
        "confidence = 0.95\n",
        "y_test, y_test_pred, test_f1s, test_f1s_avg, pseudo_labels, num_iterations = self_train_with_pretrain('CNN', num_pseudo, batch_size, epochs, confidence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0092 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0089 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0094 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0102 - sparse_categorical_accuracy: 0.9966\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0089 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0105 - sparse_categorical_accuracy: 0.9965\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0097 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0110 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 00043: early stopping\n",
            "Elapsed time: 28.138 sec\n",
            "Train f1 Score: [0.9665     0.97523866 0.92879811 0.94537642 0.94871795 0.94976509\n",
            " 0.9699229  0.93717404 0.92436975 0.90475385]\n",
            "Test f1 Score: [0.964      0.98586572 0.9368171  0.95787362 0.96353364 0.95180723\n",
            " 0.96706743 0.92927308 0.93529721 0.91360477]\n",
            "Train f1 Score: 0.9450616760808211\n",
            "Test f1 Score: 0.9505139814254766\n",
            "Now predicting labels for unlabeled data...\n",
            "560 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "1107 unlabelled instances remained to be predict in next iteration\n",
            "693 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 21\n",
            "10800 new labelled data is training...\n",
            "Epoch 1/100\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 2/100\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0091 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 3/100\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0100 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 4/100\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0106 - sparse_categorical_accuracy: 0.9965\n",
            "Epoch 5/100\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 6/100\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 7/100\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0095 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 8/100\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0096 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 9/100\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0108 - sparse_categorical_accuracy: 0.9962\n",
            "Epoch 10/100\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 11/100\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 12/100\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 13/100\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0103 - sparse_categorical_accuracy: 0.9960\n",
            "Epoch 14/100\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 15/100\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0093 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 16/100\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0103 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 17/100\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 00017: early stopping\n",
            "Elapsed time: 11.628 sec\n",
            "Train f1 Score: [0.96696146 0.97560976 0.92867587 0.94682874 0.94807659 0.95026225\n",
            " 0.97016949 0.93833307 0.92469352 0.9052029 ]\n",
            "Test f1 Score: [0.96496496 0.98631347 0.93693694 0.95887663 0.96296296 0.95175439\n",
            " 0.96649215 0.93117011 0.93746716 0.91233284]\n",
            "Train f1 Score: 0.9454813646673739\n",
            "Test f1 Score: 0.9509271596420199\n",
            "Now predicting labels for unlabeled data...\n",
            "550 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "1157 unlabelled instances remained to be predict in next iteration\n",
            "643 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 22\n",
            "11400 new labelled data is training...\n",
            "Epoch 1/100\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.0120 - sparse_categorical_accuracy: 0.9957\n",
            "Epoch 2/100\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 3/100\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.0091 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 4/100\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.0103 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 5/100\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.0099 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 6/100\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.0097 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 7/100\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.0105 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 8/100\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.0111 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 9/100\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 10/100\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 11/100\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 12/100\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.0100 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 13/100\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.0104 - sparse_categorical_accuracy: 0.9961\n",
            "Epoch 14/100\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.0105 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 15/100\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 16/100\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.0113 - sparse_categorical_accuracy: 0.9961\n",
            "Epoch 17/100\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.0093 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 18/100\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 19/100\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 20/100\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.0101 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 21/100\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 22/100\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.0089 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 23/100\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.0096 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 24/100\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.0090 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 25/100\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.0105 - sparse_categorical_accuracy: 0.9961\n",
            "Epoch 26/100\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.0088 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 27/100\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 28/100\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.0101 - sparse_categorical_accuracy: 0.9966\n",
            "Epoch 29/100\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.0099 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 30/100\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.0103 - sparse_categorical_accuracy: 0.9961\n",
            "Epoch 31/100\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 32/100\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.0090 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 33/100\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 00033: early stopping\n",
            "Elapsed time: 24.570 sec\n",
            "Train f1 Score: [0.967011   0.97474484 0.93070917 0.94620096 0.95004729 0.95067751\n",
            " 0.97002033 0.93877879 0.92542551 0.90672304]\n",
            "Test f1 Score: [0.96603397 0.98720776 0.94011407 0.95783133 0.96300103 0.95076586\n",
            " 0.96912611 0.93078056 0.93796004 0.91297862]\n",
            "Train f1 Score: 0.9460338433349647\n",
            "Test f1 Score: 0.9515799346716214\n",
            "Now predicting labels for unlabeled data...\n",
            "563 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "1194 unlabelled instances remained to be predict in next iteration\n",
            "606 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 23\n",
            "12000 new labelled data is training...\n",
            "Epoch 1/100\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0088 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 2/100\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0097 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 3/100\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0108 - sparse_categorical_accuracy: 0.9964\n",
            "Epoch 4/100\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0090 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 5/100\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 6/100\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 7/100\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0094 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 8/100\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0093 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 9/100\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 10/100\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 11/100\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0103 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 12/100\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 13/100\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0099 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 14/100\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0095 - sparse_categorical_accuracy: 0.9965\n",
            "Epoch 15/100\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0100 - sparse_categorical_accuracy: 0.9962\n",
            "Epoch 16/100\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0089 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 17/100\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0091 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 18/100\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0094 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 00018: early stopping\n",
            "Elapsed time: 13.498 sec\n",
            "Train f1 Score: [0.96846321 0.97477115 0.93198334 0.94722933 0.95036194 0.95176907\n",
            " 0.97163181 0.93932584 0.92548814 0.90754463]\n",
            "Test f1 Score: [0.96748374 0.98765432 0.94134478 0.96044066 0.96448791 0.95394737\n",
            " 0.97020387 0.93169533 0.94018888 0.91377602]\n",
            "Train f1 Score: 0.9468568465249927\n",
            "Test f1 Score: 0.9531222868879009\n",
            "Now predicting labels for unlabeled data...\n",
            "544 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "1250 unlabelled instances remained to be predict in next iteration\n",
            "550 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 24\n",
            "Train f1 Score: [0.96846321 0.97477115 0.93198334 0.94722933 0.95036194 0.95176907\n",
            " 0.97163181 0.93932584 0.92548814 0.90754463]\n",
            "Test f1 Score: [0.96748374 0.98765432 0.94134478 0.96044066 0.96448791 0.95394737\n",
            " 0.97020387 0.93169533 0.94018888 0.91377602]\n",
            "Train f1 Score: 0.9468568465249927\n",
            "Test f1 Score: 0.9531222868879009\n",
            "Now predicting labels for unlabeled data...\n",
            "546 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "1304 unlabelled instances remained to be predict in next iteration\n",
            "1096 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 25\n",
            "12600 new labelled data is training...\n",
            "Epoch 1/100\n",
            "197/197 [==============================] - 1s 4ms/step - loss: 0.0098 - sparse_categorical_accuracy: 0.9965\n",
            "Epoch 2/100\n",
            "197/197 [==============================] - 1s 4ms/step - loss: 0.0109 - sparse_categorical_accuracy: 0.9964\n",
            "Epoch 3/100\n",
            "197/197 [==============================] - 1s 4ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 4/100\n",
            "197/197 [==============================] - 1s 4ms/step - loss: 0.0104 - sparse_categorical_accuracy: 0.9962\n",
            "Epoch 5/100\n",
            "197/197 [==============================] - 1s 4ms/step - loss: 0.0117 - sparse_categorical_accuracy: 0.9963\n",
            "Epoch 6/100\n",
            "197/197 [==============================] - 1s 4ms/step - loss: 0.0089 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 7/100\n",
            "197/197 [==============================] - 1s 4ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 8/100\n",
            "197/197 [==============================] - 1s 4ms/step - loss: 0.0091 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 9/100\n",
            "197/197 [==============================] - 1s 4ms/step - loss: 0.0101 - sparse_categorical_accuracy: 0.9964\n",
            "Epoch 10/100\n",
            "197/197 [==============================] - 1s 4ms/step - loss: 0.0099 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 11/100\n",
            "197/197 [==============================] - 1s 4ms/step - loss: 0.0097 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 12/100\n",
            "197/197 [==============================] - 1s 4ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 13/100\n",
            "197/197 [==============================] - 1s 4ms/step - loss: 0.0104 - sparse_categorical_accuracy: 0.9966\n",
            "Epoch 14/100\n",
            "197/197 [==============================] - 1s 4ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 15/100\n",
            "197/197 [==============================] - 1s 4ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 00015: early stopping\n",
            "Elapsed time: 12.019 sec\n",
            "Train f1 Score: [0.96870567 0.975      0.93142206 0.94711697 0.95097196 0.95258816\n",
            " 0.97201792 0.9391528  0.9260755  0.90829252]\n",
            "Test f1 Score: [0.96790371 0.98678414 0.9415677  0.96003996 0.96502058 0.95547004\n",
            " 0.97026604 0.93353028 0.9395691  0.91414392]\n",
            "Train f1 Score: 0.9471343557070382\n",
            "Test f1 Score: 0.9534295466071736\n",
            "Now predicting labels for unlabeled data...\n",
            "563 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "1341 unlabelled instances remained to be predict in next iteration\n",
            "1059 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 26\n",
            "13200 new labelled data is training...\n",
            "Epoch 1/100\n",
            "207/207 [==============================] - 1s 5ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 2/100\n",
            "207/207 [==============================] - 1s 4ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 3/100\n",
            "207/207 [==============================] - 1s 4ms/step - loss: 0.0091 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 4/100\n",
            "207/207 [==============================] - 1s 4ms/step - loss: 0.0118 - sparse_categorical_accuracy: 0.9964\n",
            "Epoch 5/100\n",
            "207/207 [==============================] - 1s 4ms/step - loss: 0.0096 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 6/100\n",
            "207/207 [==============================] - 1s 4ms/step - loss: 0.0103 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 7/100\n",
            "207/207 [==============================] - 1s 4ms/step - loss: 0.0099 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 8/100\n",
            "207/207 [==============================] - 1s 4ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 9/100\n",
            "207/207 [==============================] - 1s 4ms/step - loss: 0.0101 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 10/100\n",
            "207/207 [==============================] - 1s 4ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 11/100\n",
            "207/207 [==============================] - 1s 4ms/step - loss: 0.0091 - sparse_categorical_accuracy: 0.9966\n",
            "Epoch 12/100\n",
            "207/207 [==============================] - 1s 4ms/step - loss: 0.0102 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 13/100\n",
            "207/207 [==============================] - 1s 4ms/step - loss: 0.0092 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 14/100\n",
            "207/207 [==============================] - 1s 4ms/step - loss: 0.0096 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 00014: early stopping\n",
            "Elapsed time: 12.127 sec\n",
            "Train f1 Score: [0.9668775  0.97507255 0.93234431 0.94769788 0.95189743 0.95322698\n",
            " 0.97194524 0.94010918 0.92631024 0.90889096]\n",
            "Test f1 Score: [0.96651674 0.98721904 0.94050452 0.95856216 0.96402878 0.95547004\n",
            " 0.97077244 0.93411996 0.93950552 0.91343284]\n",
            "Train f1 Score: 0.9474372262748819\n",
            "Test f1 Score: 0.9530132037222808\n",
            "Now predicting labels for unlabeled data...\n",
            "549 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "1392 unlabelled instances remained to be predict in next iteration\n",
            "1008 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 27\n",
            "13800 new labelled data is training...\n",
            "Epoch 1/100\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0093 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 2/100\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0112 - sparse_categorical_accuracy: 0.9959\n",
            "Epoch 3/100\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0112 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 4/100\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0095 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 5/100\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 6/100\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0108 - sparse_categorical_accuracy: 0.9962\n",
            "Epoch 7/100\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0088 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 8/100\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0092 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 9/100\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0104 - sparse_categorical_accuracy: 0.9963\n",
            "Epoch 10/100\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0097 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 11/100\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 12/100\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 13/100\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0095 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 14/100\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0103 - sparse_categorical_accuracy: 0.9965\n",
            "Epoch 15/100\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 16/100\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 17/100\n",
            "216/216 [==============================] - 1s 4ms/step - loss: 0.0088 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 00017: early stopping\n",
            "Elapsed time: 14.956 sec\n",
            "Train f1 Score: [0.96736597 0.97507626 0.93211786 0.94673681 0.95104292 0.95334907\n",
            " 0.97225512 0.93982116 0.92679497 0.90835511]\n",
            "Test f1 Score: [0.96745118 0.98765432 0.94117647 0.96015936 0.96448791 0.95547004\n",
            " 0.97077244 0.93385982 0.9405576  0.91459782]\n",
            "Train f1 Score: 0.9472915240004317\n",
            "Test f1 Score: 0.9536186956128743\n",
            "Now predicting labels for unlabeled data...\n",
            "565 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "1427 unlabelled instances remained to be predict in next iteration\n",
            "973 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 28\n",
            "14400 new labelled data is training...\n",
            "Epoch 1/100\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.0090 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 2/100\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.0092 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 3/100\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.0088 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 4/100\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 5/100\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.0090 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 6/100\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.0093 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 7/100\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.0100 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 8/100\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.0089 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 9/100\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.0102 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 10/100\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 11/100\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.0090 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 12/100\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 13/100\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 14/100\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 15/100\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 16/100\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 17/100\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.0090 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 18/100\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 19/100\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 20/100\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 21/100\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 22/100\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 23/100\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.0096 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 24/100\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 25/100\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 26/100\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 27/100\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.0100 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 28/100\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 00028: early stopping\n",
            "Elapsed time: 25.530 sec\n",
            "Train f1 Score: [0.96706039 0.97522506 0.93335506 0.94792353 0.95187073 0.95277728\n",
            " 0.97276725 0.94036106 0.92759743 0.90832703]\n",
            "Test f1 Score: [0.96745118 0.9876652  0.94251781 0.95847924 0.96448791 0.95447065\n",
            " 0.97130934 0.93537247 0.940495   0.91287129]\n",
            "Train f1 Score: 0.9477264821438258\n",
            "Test f1 Score: 0.9535120081056148\n",
            "Now predicting labels for unlabeled data...\n",
            "550 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "1477 unlabelled instances remained to be predict in next iteration\n",
            "923 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 29\n",
            "15000 new labelled data is training...\n",
            "Epoch 1/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0103 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 2/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 3/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 4/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0088 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 5/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 6/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 7/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 8/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0099 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 9/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 10/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 11/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0097 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 12/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 13/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0099 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 14/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 15/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0092 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 16/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 17/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0089 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 18/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 19/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 20/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 21/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0105 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 22/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 00022: early stopping\n",
            "Elapsed time: 20.695 sec\n",
            "Train f1 Score: [0.96847373 0.97536286 0.93214141 0.94781823 0.9528416  0.95387404\n",
            " 0.97327017 0.93954761 0.92846485 0.90987342]\n",
            "Test f1 Score: [0.9688755  0.98765432 0.94117647 0.9617866  0.96548171 0.95652174\n",
            " 0.97291667 0.93346476 0.94260137 0.91695674]\n",
            "Train f1 Score: 0.9481667904278653\n",
            "Test f1 Score: 0.9547435878384798\n",
            "Now predicting labels for unlabeled data...\n",
            "547 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "1530 unlabelled instances remained to be predict in next iteration\n",
            "870 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 30\n",
            "15600 new labelled data is training...\n",
            "Epoch 1/100\n",
            "244/244 [==============================] - 1s 4ms/step - loss: 0.0091 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 2/100\n",
            "244/244 [==============================] - 1s 4ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 3/100\n",
            "244/244 [==============================] - 1s 4ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 4/100\n",
            "244/244 [==============================] - 1s 4ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 5/100\n",
            "244/244 [==============================] - 1s 4ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 6/100\n",
            "244/244 [==============================] - 1s 4ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 7/100\n",
            "244/244 [==============================] - 1s 4ms/step - loss: 0.0090 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 8/100\n",
            "244/244 [==============================] - 1s 4ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 9/100\n",
            "244/244 [==============================] - 1s 4ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 10/100\n",
            "244/244 [==============================] - 1s 4ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 11/100\n",
            "244/244 [==============================] - 1s 4ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 12/100\n",
            "244/244 [==============================] - 1s 4ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 13/100\n",
            "244/244 [==============================] - 1s 4ms/step - loss: 0.0093 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 14/100\n",
            "244/244 [==============================] - 1s 4ms/step - loss: 0.0090 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 15/100\n",
            "244/244 [==============================] - 1s 4ms/step - loss: 0.0091 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 16/100\n",
            "244/244 [==============================] - 1s 4ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 17/100\n",
            "244/244 [==============================] - 1s 4ms/step - loss: 0.0088 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 18/100\n",
            "244/244 [==============================] - 1s 4ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 00018: early stopping\n",
            "Elapsed time: 18.666 sec\n",
            "Train f1 Score: [0.96788151 0.97537752 0.9344971  0.94798258 0.95405266 0.95442992\n",
            " 0.97316061 0.94109138 0.92826411 0.91107354]\n",
            "Test f1 Score: [0.968      0.98810048 0.94386299 0.96274218 0.96452442 0.95652174\n",
            " 0.97181628 0.93405512 0.94204426 0.91533865]\n",
            "Train f1 Score: 0.9487810938689071\n",
            "Test f1 Score: 0.9547006113573243\n",
            "Now predicting labels for unlabeled data...\n",
            "568 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "1562 unlabelled instances remained to be predict in next iteration\n",
            "838 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 31\n",
            "16200 new labelled data is training...\n",
            "Epoch 1/100\n",
            "254/254 [==============================] - 1s 4ms/step - loss: 0.0091 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 2/100\n",
            "254/254 [==============================] - 1s 4ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 3/100\n",
            "254/254 [==============================] - 1s 4ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 4/100\n",
            "254/254 [==============================] - 1s 4ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 5/100\n",
            "254/254 [==============================] - 1s 4ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 6/100\n",
            "254/254 [==============================] - 1s 4ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 7/100\n",
            "254/254 [==============================] - 1s 4ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 8/100\n",
            "254/254 [==============================] - 1s 4ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 9/100\n",
            "254/254 [==============================] - 1s 4ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 10/100\n",
            "254/254 [==============================] - 1s 4ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 11/100\n",
            "254/254 [==============================] - 1s 4ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 12/100\n",
            "254/254 [==============================] - 1s 4ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 13/100\n",
            "254/254 [==============================] - 1s 4ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 14/100\n",
            "254/254 [==============================] - 1s 4ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 15/100\n",
            "254/254 [==============================] - 1s 4ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 16/100\n",
            "254/254 [==============================] - 1s 4ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 00016: early stopping\n",
            "Elapsed time: 16.558 sec\n",
            "Train f1 Score: [0.96883853 0.97521399 0.93425775 0.94789612 0.95434183 0.95481764\n",
            " 0.97321504 0.94071273 0.92830189 0.91202297]\n",
            "Test f1 Score: [0.96796797 0.98810048 0.94386299 0.96270512 0.96498455 0.95704846\n",
            " 0.9724102  0.93399015 0.94154818 0.91451292]\n",
            "Train f1 Score: 0.948961848706905\n",
            "Test f1 Score: 0.9547131028903879\n",
            "Now predicting labels for unlabeled data...\n",
            "573 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "1589 unlabelled instances remained to be predict in next iteration\n",
            "811 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 32\n",
            "16800 new labelled data is training...\n",
            "Epoch 1/100\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 2/100\n",
            "263/263 [==============================] - 1s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 3/100\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 4/100\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 5/100\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 6/100\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 7/100\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 8/100\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 9/100\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 10/100\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 11/100\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 12/100\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 13/100\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 14/100\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 15/100\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 16/100\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 17/100\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 18/100\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 19/100\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 20/100\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 21/100\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 22/100\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 23/100\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 24/100\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 25/100\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 26/100\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 27/100\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 28/100\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 29/100\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 30/100\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 31/100\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 32/100\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 33/100\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 34/100\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 35/100\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 36/100\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 37/100\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 38/100\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0089 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 39/100\n",
            "263/263 [==============================] - 1s 4ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 00039: early stopping\n",
            "Elapsed time: 42.476 sec\n",
            "Train f1 Score: [0.9677312  0.97508738 0.93497593 0.94771511 0.95512103 0.95402715\n",
            " 0.97326565 0.94112923 0.92827004 0.91193638]\n",
            "Test f1 Score: [0.968      0.98765432 0.94481446 0.96215139 0.96498455 0.95604396\n",
            " 0.9724102  0.93510324 0.94043226 0.91633466]\n",
            "Train f1 Score: 0.9489259106273694\n",
            "Test f1 Score: 0.9547929056555977\n",
            "Now predicting labels for unlabeled data...\n",
            "571 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "1618 unlabelled instances remained to be predict in next iteration\n",
            "782 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 33\n",
            "17400 new labelled data is training...\n",
            "Epoch 1/100\n",
            "272/272 [==============================] - 1s 4ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 2/100\n",
            "272/272 [==============================] - 1s 4ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 3/100\n",
            "272/272 [==============================] - 1s 4ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 4/100\n",
            "272/272 [==============================] - 1s 4ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 5/100\n",
            "272/272 [==============================] - 1s 4ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 6/100\n",
            "272/272 [==============================] - 1s 4ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 7/100\n",
            "272/272 [==============================] - 1s 4ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 8/100\n",
            "272/272 [==============================] - 1s 4ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 9/100\n",
            "272/272 [==============================] - 1s 4ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 10/100\n",
            "272/272 [==============================] - 1s 4ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 11/100\n",
            "272/272 [==============================] - 1s 4ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 12/100\n",
            "272/272 [==============================] - 1s 4ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 13/100\n",
            "272/272 [==============================] - 1s 4ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 14/100\n",
            "272/272 [==============================] - 1s 4ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 15/100\n",
            "272/272 [==============================] - 1s 4ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 16/100\n",
            "272/272 [==============================] - 1s 4ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 17/100\n",
            "272/272 [==============================] - 1s 4ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 18/100\n",
            "272/272 [==============================] - 1s 4ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 19/100\n",
            "272/272 [==============================] - 1s 4ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 20/100\n",
            "272/272 [==============================] - 1s 4ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 21/100\n",
            "272/272 [==============================] - 1s 4ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 22/100\n",
            "272/272 [==============================] - 1s 4ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 23/100\n",
            "272/272 [==============================] - 1s 4ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 24/100\n",
            "272/272 [==============================] - 1s 4ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 25/100\n",
            "272/272 [==============================] - 1s 4ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 00025: early stopping\n",
            "Elapsed time: 28.129 sec\n",
            "Train f1 Score: [0.96862778 0.97537386 0.93574232 0.94780175 0.95545791 0.95393248\n",
            " 0.97383795 0.94128986 0.92886    0.91332209]\n",
            "Test f1 Score: [0.96848424 0.98854626 0.94465649 0.96115538 0.96502058 0.95604396\n",
            " 0.9697286  0.93399015 0.93950552 0.9156746 ]\n",
            "Train f1 Score: 0.9494245988490275\n",
            "Test f1 Score: 0.9542805772458183\n",
            "Now predicting labels for unlabeled data...\n",
            "566 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "1652 unlabelled instances remained to be predict in next iteration\n",
            "748 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 34\n",
            "18000 new labelled data is training...\n",
            "Epoch 1/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 2/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 3/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 4/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 5/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 6/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 7/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 8/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 9/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 10/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 11/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 12/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 13/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 14/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 15/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 16/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 17/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 18/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 19/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 20/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 21/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 22/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 23/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 24/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 25/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 26/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 27/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 28/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 29/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 30/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 31/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 32/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 33/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 34/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 35/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 36/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 37/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 38/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 39/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 40/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 41/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 42/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 43/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 44/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 45/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 46/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 47/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 48/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 49/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 50/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 51/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 52/100\n",
            "282/282 [==============================] - 1s 4ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 00052: early stopping\n",
            "Elapsed time: 62.381 sec\n",
            "Train f1 Score: [0.96827908 0.97545008 0.93596864 0.94941186 0.95574461 0.95507246\n",
            " 0.97433726 0.94111969 0.92975061 0.91437257]\n",
            "Test f1 Score: [0.96796797 0.9876652  0.94291151 0.96218905 0.96402878 0.95766905\n",
            " 0.9697286  0.93392505 0.94092827 0.91712159]\n",
            "Train f1 Score: 0.9499506865570835\n",
            "Test f1 Score: 0.954413506837733\n",
            "Now predicting labels for unlabeled data...\n",
            "564 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "1688 unlabelled instances remained to be predict in next iteration\n",
            "712 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 35\n",
            "18600 new labelled data is training...\n",
            "Epoch 1/100\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 2/100\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 3/100\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 4/100\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 5/100\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 6/100\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 7/100\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 8/100\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 9/100\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 10/100\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 11/100\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 12/100\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 13/100\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 14/100\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 15/100\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 16/100\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 17/100\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 18/100\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 19/100\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 20/100\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 21/100\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 22/100\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 23/100\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 24/100\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 25/100\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 26/100\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 27/100\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 28/100\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 29/100\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 30/100\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 31/100\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 32/100\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 33/100\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 34/100\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 00034: early stopping\n",
            "Elapsed time: 41.617 sec\n",
            "Train f1 Score: [0.96916667 0.97566059 0.93500775 0.95010275 0.95658915 0.95684564\n",
            " 0.97392041 0.94122383 0.93096509 0.91543715]\n",
            "Test f1 Score: [0.96842105 0.98810048 0.94346793 0.96174863 0.96452442 0.95973525\n",
            " 0.97023499 0.93419099 0.94228751 0.91774034]\n",
            "Train f1 Score: 0.9504919021058681\n",
            "Test f1 Score: 0.9550451603427561\n",
            "Now predicting labels for unlabeled data...\n",
            "564 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "1724 unlabelled instances remained to be predict in next iteration\n",
            "676 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 36\n",
            "19200 new labelled data is training...\n",
            "Epoch 1/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 2/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 3/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 4/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 5/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 6/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 7/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 8/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 9/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 10/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 11/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 12/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 13/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 14/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 15/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 16/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 17/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 18/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 19/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 00019: early stopping\n",
            "Elapsed time: 23.567 sec\n",
            "Train f1 Score: [0.97061279 0.97575487 0.93705036 0.94979424 0.95741027 0.95614353\n",
            " 0.97437199 0.94144108 0.93156926 0.91587047]\n",
            "Test f1 Score: [0.97137117 0.98767606 0.94375596 0.96270512 0.96452442 0.95819582\n",
            " 0.971875   0.93405512 0.94154818 0.91857001]\n",
            "Train f1 Score: 0.9510018855147147\n",
            "Test f1 Score: 0.9554276858960309\n",
            "Now predicting labels for unlabeled data...\n",
            "577 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "1747 unlabelled instances remained to be predict in next iteration\n",
            "653 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 37\n",
            "19800 new labelled data is training...\n",
            "Epoch 1/100\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 2/100\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 3/100\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 4/100\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 5/100\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 6/100\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 7/100\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 8/100\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 9/100\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 10/100\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 11/100\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 12/100\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 13/100\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 14/100\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 15/100\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 00015: early stopping\n",
            "Elapsed time: 19.411 sec\n",
            "Train f1 Score: [0.97027884 0.97582025 0.93694871 0.94969123 0.95703831 0.95575061\n",
            " 0.97461929 0.9414791  0.93110098 0.91482543]\n",
            "Test f1 Score: [0.97036665 0.98765432 0.94257238 0.96218905 0.96548171 0.95766905\n",
            " 0.97130934 0.93497537 0.94210526 0.91819534]\n",
            "Train f1 Score: 0.950755276497205\n",
            "Test f1 Score: 0.9552518472549348\n",
            "Now predicting labels for unlabeled data...\n",
            "571 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "1776 unlabelled instances remained to be predict in next iteration\n",
            "624 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 38\n",
            "20400 new labelled data is training...\n",
            "Epoch 1/100\n",
            "319/319 [==============================] - 1s 4ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 2/100\n",
            "319/319 [==============================] - 1s 4ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 3/100\n",
            "319/319 [==============================] - 1s 4ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 4/100\n",
            "319/319 [==============================] - 1s 4ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 5/100\n",
            "319/319 [==============================] - 1s 4ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 6/100\n",
            "319/319 [==============================] - 1s 4ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 7/100\n",
            "319/319 [==============================] - 1s 4ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 8/100\n",
            "319/319 [==============================] - 1s 4ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 9/100\n",
            "319/319 [==============================] - 1s 4ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 10/100\n",
            "319/319 [==============================] - 1s 4ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 11/100\n",
            "319/319 [==============================] - 1s 4ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 12/100\n",
            "319/319 [==============================] - 1s 4ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 13/100\n",
            "319/319 [==============================] - 1s 4ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 14/100\n",
            "319/319 [==============================] - 1s 4ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 15/100\n",
            "319/319 [==============================] - 1s 4ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 00015: early stopping\n",
            "Elapsed time: 20.622 sec\n",
            "Train f1 Score: [0.96934355 0.97554085 0.93650016 0.95121147 0.95721787 0.95740623\n",
            " 0.9745978  0.9420837  0.93179231 0.91536579]\n",
            "Test f1 Score: [0.96893788 0.98811096 0.94581749 0.96465903 0.96498455 0.96083839\n",
            " 0.97077244 0.93445047 0.94333683 0.91658391]\n",
            "Train f1 Score: 0.9511059744063516\n",
            "Test f1 Score: 0.9558491960813393\n",
            "Now predicting labels for unlabeled data...\n",
            "581 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "1795 unlabelled instances remained to be predict in next iteration\n",
            "605 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 39\n",
            "21000 new labelled data is training...\n",
            "Epoch 1/100\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 2/100\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 3/100\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 4/100\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 5/100\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 6/100\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 7/100\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 8/100\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 9/100\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 10/100\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 11/100\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 12/100\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 13/100\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 14/100\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 15/100\n",
            "329/329 [==============================] - 1s 4ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 00015: early stopping\n",
            "Elapsed time: 20.852 sec\n",
            "Train f1 Score: [0.97085595 0.97559887 0.9380719  0.95081698 0.95779974 0.95696294\n",
            " 0.97501482 0.94198718 0.93117694 0.91511667]\n",
            "Test f1 Score: [0.96990973 0.98810048 0.94515975 0.96380764 0.96399177 0.95872317\n",
            " 0.9707419  0.9372549  0.94303797 0.9194831 ]\n",
            "Train f1 Score: 0.951340198899939\n",
            "Test f1 Score: 0.9560210420531196\n",
            "Now predicting labels for unlabeled data...\n",
            "571 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "1824 unlabelled instances remained to be predict in next iteration\n",
            "576 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 40\n",
            "Train f1 Score: [0.97085595 0.97559887 0.9380719  0.95081698 0.95779974 0.95696294\n",
            " 0.97501482 0.94198718 0.93117694 0.91511667]\n",
            "Test f1 Score: [0.96990973 0.98810048 0.94515975 0.96380764 0.96399177 0.95872317\n",
            " 0.9707419  0.9372549  0.94303797 0.9194831 ]\n",
            "Train f1 Score: 0.951340198899939\n",
            "Test f1 Score: 0.9560210420531196\n",
            "Now predicting labels for unlabeled data...\n",
            "563 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "1861 unlabelled instances remained to be predict in next iteration\n",
            "1139 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 41\n",
            "21600 new labelled data is training...\n",
            "Epoch 1/100\n",
            "338/338 [==============================] - 2s 4ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 2/100\n",
            "338/338 [==============================] - 1s 4ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 3/100\n",
            "338/338 [==============================] - 1s 4ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 4/100\n",
            "338/338 [==============================] - 1s 4ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 5/100\n",
            "338/338 [==============================] - 1s 4ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 6/100\n",
            "338/338 [==============================] - 1s 4ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 7/100\n",
            "338/338 [==============================] - 1s 4ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 8/100\n",
            "338/338 [==============================] - 1s 4ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 9/100\n",
            "338/338 [==============================] - 2s 4ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 10/100\n",
            "338/338 [==============================] - 1s 4ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 11/100\n",
            "338/338 [==============================] - 1s 4ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 12/100\n",
            "338/338 [==============================] - 1s 4ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 13/100\n",
            "338/338 [==============================] - 2s 4ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 14/100\n",
            "338/338 [==============================] - 1s 4ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 15/100\n",
            "338/338 [==============================] - 1s 4ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 16/100\n",
            "338/338 [==============================] - 1s 4ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 17/100\n",
            "338/338 [==============================] - 1s 4ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 18/100\n",
            "338/338 [==============================] - 1s 4ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 19/100\n",
            "338/338 [==============================] - 1s 4ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 20/100\n",
            "338/338 [==============================] - 1s 4ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 21/100\n",
            "338/338 [==============================] - 1s 4ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 22/100\n",
            "338/338 [==============================] - 1s 4ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 23/100\n",
            "338/338 [==============================] - 1s 4ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 24/100\n",
            "338/338 [==============================] - 1s 4ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 25/100\n",
            "338/338 [==============================] - 1s 4ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 26/100\n",
            "338/338 [==============================] - 1s 4ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 27/100\n",
            "338/338 [==============================] - 1s 4ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 28/100\n",
            "338/338 [==============================] - 1s 4ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 29/100\n",
            "338/338 [==============================] - 1s 4ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 30/100\n",
            "338/338 [==============================] - 1s 4ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 31/100\n",
            "338/338 [==============================] - 1s 4ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 32/100\n",
            "338/338 [==============================] - 1s 4ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 33/100\n",
            "338/338 [==============================] - 1s 4ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 34/100\n",
            "338/338 [==============================] - 1s 4ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 35/100\n",
            "338/338 [==============================] - 2s 5ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 36/100\n",
            "338/338 [==============================] - 1s 4ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 37/100\n",
            "338/338 [==============================] - 1s 4ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 38/100\n",
            "338/338 [==============================] - 1s 4ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 39/100\n",
            "338/338 [==============================] - 1s 4ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 40/100\n",
            "338/338 [==============================] - 2s 4ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 41/100\n",
            "338/338 [==============================] - 1s 4ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 42/100\n",
            "338/338 [==============================] - 1s 4ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 43/100\n",
            "338/338 [==============================] - 1s 4ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 44/100\n",
            "338/338 [==============================] - 1s 4ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 00044: early stopping\n",
            "Elapsed time: 63.004 sec\n",
            "Train f1 Score: [0.9707085  0.97590003 0.93718388 0.95216138 0.9578168  0.95740439\n",
            " 0.97518001 0.94232932 0.93278343 0.91633668]\n",
            "Test f1 Score: [0.96939288 0.98853616 0.94491928 0.96322068 0.96651211 0.96035242\n",
            " 0.97130934 0.93799213 0.94520548 0.91918691]\n",
            "Train f1 Score: 0.9517804421413041\n",
            "Test f1 Score: 0.9566627368728398\n",
            "Now predicting labels for unlabeled data...\n",
            "552 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "1909 unlabelled instances remained to be predict in next iteration\n",
            "1091 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 42\n",
            "22200 new labelled data is training...\n",
            "Epoch 1/100\n",
            "347/347 [==============================] - 2s 4ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 2/100\n",
            "347/347 [==============================] - 1s 4ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 3/100\n",
            "347/347 [==============================] - 2s 4ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 4/100\n",
            "347/347 [==============================] - 2s 4ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 5/100\n",
            "347/347 [==============================] - 1s 4ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 6/100\n",
            "347/347 [==============================] - 1s 4ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 7/100\n",
            "347/347 [==============================] - 1s 4ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 8/100\n",
            "347/347 [==============================] - 1s 4ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 9/100\n",
            "347/347 [==============================] - 1s 4ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 10/100\n",
            "347/347 [==============================] - 1s 4ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 11/100\n",
            "347/347 [==============================] - 2s 4ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 12/100\n",
            "347/347 [==============================] - 1s 4ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 13/100\n",
            "347/347 [==============================] - 1s 4ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 14/100\n",
            "347/347 [==============================] - 2s 4ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 15/100\n",
            "347/347 [==============================] - 1s 4ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 16/100\n",
            "347/347 [==============================] - 1s 4ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 17/100\n",
            "347/347 [==============================] - 1s 4ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 18/100\n",
            "347/347 [==============================] - 2s 4ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 19/100\n",
            "347/347 [==============================] - 1s 4ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 20/100\n",
            "347/347 [==============================] - 1s 4ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 21/100\n",
            "347/347 [==============================] - 2s 4ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 22/100\n",
            "347/347 [==============================] - 1s 4ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 23/100\n",
            "347/347 [==============================] - 1s 4ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 24/100\n",
            "347/347 [==============================] - 1s 4ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 25/100\n",
            "347/347 [==============================] - 1s 4ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 26/100\n",
            "347/347 [==============================] - 1s 4ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 27/100\n",
            "347/347 [==============================] - 1s 4ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 28/100\n",
            "347/347 [==============================] - 1s 4ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 29/100\n",
            "347/347 [==============================] - 1s 4ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 30/100\n",
            "347/347 [==============================] - 2s 4ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 31/100\n",
            "347/347 [==============================] - 1s 4ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 32/100\n",
            "347/347 [==============================] - 1s 4ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 33/100\n",
            "347/347 [==============================] - 1s 4ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 34/100\n",
            "347/347 [==============================] - 1s 4ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 35/100\n",
            "347/347 [==============================] - 2s 5ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 00035: early stopping\n",
            "Elapsed time: 51.752 sec\n",
            "Train f1 Score: [0.97185334 0.9764846  0.93762247 0.95195788 0.95856259 0.95809904\n",
            " 0.97527938 0.94278846 0.93327488 0.91800507]\n",
            "Test f1 Score: [0.96893788 0.98808999 0.94581749 0.96377171 0.96597938 0.9618995\n",
            " 0.97184567 0.93771457 0.94464945 0.91902633]\n",
            "Train f1 Score: 0.9523927696791654\n",
            "Test f1 Score: 0.9567731963547722\n",
            "Now predicting labels for unlabeled data...\n",
            "580 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "1929 unlabelled instances remained to be predict in next iteration\n",
            "1071 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 43\n",
            "22800 new labelled data is training...\n",
            "Epoch 1/100\n",
            "357/357 [==============================] - 2s 5ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 2/100\n",
            "357/357 [==============================] - 2s 4ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 3/100\n",
            "357/357 [==============================] - 2s 5ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 4/100\n",
            "357/357 [==============================] - 2s 5ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 5/100\n",
            "357/357 [==============================] - 2s 4ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 6/100\n",
            "357/357 [==============================] - 2s 4ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 7/100\n",
            "357/357 [==============================] - 2s 5ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 8/100\n",
            "357/357 [==============================] - 1s 4ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 9/100\n",
            "357/357 [==============================] - 2s 4ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 10/100\n",
            "357/357 [==============================] - 2s 4ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 11/100\n",
            "357/357 [==============================] - 1s 4ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 12/100\n",
            "357/357 [==============================] - 1s 4ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 13/100\n",
            "357/357 [==============================] - 1s 4ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 14/100\n",
            "357/357 [==============================] - 1s 4ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 15/100\n",
            "357/357 [==============================] - 1s 4ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 16/100\n",
            "357/357 [==============================] - 2s 4ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 17/100\n",
            "357/357 [==============================] - 2s 4ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 18/100\n",
            "357/357 [==============================] - 2s 4ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 19/100\n",
            "357/357 [==============================] - 1s 4ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 20/100\n",
            "357/357 [==============================] - 1s 4ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 21/100\n",
            "357/357 [==============================] - 2s 4ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 22/100\n",
            "357/357 [==============================] - 1s 4ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 23/100\n",
            "357/357 [==============================] - 1s 4ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 24/100\n",
            "357/357 [==============================] - 1s 4ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 25/100\n",
            "357/357 [==============================] - 1s 4ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 26/100\n",
            "357/357 [==============================] - 1s 4ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 27/100\n",
            "357/357 [==============================] - 1s 4ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 28/100\n",
            "357/357 [==============================] - 1s 4ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 29/100\n",
            "357/357 [==============================] - 1s 4ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 30/100\n",
            "357/357 [==============================] - 1s 4ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 00030: early stopping\n",
            "Elapsed time: 45.370 sec\n",
            "Train f1 Score: [0.97071828 0.97669223 0.9375     0.95255354 0.95709116 0.95658466\n",
            " 0.97528356 0.94285025 0.93328646 0.91541954]\n",
            "Test f1 Score: [0.96893788 0.98764342 0.94486692 0.96517413 0.96594427 0.95771554\n",
            " 0.97181628 0.93799213 0.94403379 0.91843796]\n",
            "Train f1 Score: 0.9517979682492342\n",
            "Test f1 Score: 0.9562562327399314\n",
            "Now predicting labels for unlabeled data...\n",
            "570 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "1959 unlabelled instances remained to be predict in next iteration\n",
            "1041 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 44\n",
            "23400 new labelled data is training...\n",
            "Epoch 1/100\n",
            "366/366 [==============================] - 2s 4ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 2/100\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 3/100\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 4/100\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 5/100\n",
            "366/366 [==============================] - 2s 4ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 6/100\n",
            "366/366 [==============================] - 2s 4ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 7/100\n",
            "366/366 [==============================] - 2s 4ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 8/100\n",
            "366/366 [==============================] - 2s 4ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 9/100\n",
            "366/366 [==============================] - 2s 4ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 10/100\n",
            "366/366 [==============================] - 2s 4ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 11/100\n",
            "366/366 [==============================] - 2s 4ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 12/100\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 13/100\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 14/100\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 15/100\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 16/100\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 17/100\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 18/100\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 19/100\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 20/100\n",
            "366/366 [==============================] - 2s 4ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 21/100\n",
            "366/366 [==============================] - 2s 4ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 22/100\n",
            "366/366 [==============================] - 2s 4ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 23/100\n",
            "366/366 [==============================] - 2s 4ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 24/100\n",
            "366/366 [==============================] - 2s 4ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 25/100\n",
            "366/366 [==============================] - 2s 4ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 26/100\n",
            "366/366 [==============================] - 2s 4ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 27/100\n",
            "366/366 [==============================] - 1s 4ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 28/100\n",
            "366/366 [==============================] - 2s 4ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 29/100\n",
            "366/366 [==============================] - 2s 4ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 30/100\n",
            "366/366 [==============================] - 2s 5ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 31/100\n",
            "366/366 [==============================] - 2s 5ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 32/100\n",
            "366/366 [==============================] - 2s 4ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 00032: early stopping\n",
            "Elapsed time: 49.075 sec\n",
            "Train f1 Score: [0.97258442 0.97678917 0.93678723 0.95209925 0.95895586 0.95709631\n",
            " 0.97541123 0.94346885 0.93396558 0.91830508]\n",
            "Test f1 Score: [0.96990973 0.98853616 0.94547179 0.96281606 0.96597938 0.96030871\n",
            " 0.97175732 0.93869544 0.94570374 0.92039801]\n",
            "Train f1 Score: 0.9525462975655161\n",
            "Test f1 Score: 0.9569576340722747\n",
            "Now predicting labels for unlabeled data...\n",
            "567 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "1992 unlabelled instances remained to be predict in next iteration\n",
            "1008 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 45\n",
            "24000 new labelled data is training...\n",
            "Epoch 1/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 2/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 3/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 4/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 5/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 6/100\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 7/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 8/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 9/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 10/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 11/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 12/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 13/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 14/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 00014: early stopping\n",
            "Elapsed time: 22.480 sec\n",
            "Train f1 Score: [0.97135221 0.97691735 0.93618753 0.95236528 0.95810753 0.95660821\n",
            " 0.97523745 0.94321741 0.93503989 0.91784415]\n",
            "Test f1 Score: [0.96939288 0.98764342 0.94412879 0.96373572 0.96544611 0.95986806\n",
            " 0.97226583 0.93706981 0.94377299 0.91940299]\n",
            "Train f1 Score: 0.9522877004230803\n",
            "Test f1 Score: 0.9562726588600914\n",
            "Now predicting labels for unlabeled data...\n",
            "570 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "2022 unlabelled instances remained to be predict in next iteration\n",
            "978 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 46\n",
            "24600 new labelled data is training...\n",
            "Epoch 1/100\n",
            "385/385 [==============================] - 2s 5ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 2/100\n",
            "385/385 [==============================] - 2s 4ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 3/100\n",
            "385/385 [==============================] - 2s 4ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 4/100\n",
            "385/385 [==============================] - 2s 4ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 5/100\n",
            "385/385 [==============================] - 2s 4ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 6/100\n",
            "385/385 [==============================] - 2s 4ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 7/100\n",
            "385/385 [==============================] - 2s 4ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 8/100\n",
            "385/385 [==============================] - 2s 4ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 9/100\n",
            "385/385 [==============================] - 2s 4ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 10/100\n",
            "385/385 [==============================] - 2s 4ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 11/100\n",
            "385/385 [==============================] - 2s 4ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 12/100\n",
            "385/385 [==============================] - 2s 4ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 13/100\n",
            "385/385 [==============================] - 2s 4ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 14/100\n",
            "385/385 [==============================] - 2s 4ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 15/100\n",
            "385/385 [==============================] - 2s 4ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 16/100\n",
            "385/385 [==============================] - 2s 4ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 17/100\n",
            "385/385 [==============================] - 2s 4ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 18/100\n",
            "385/385 [==============================] - 2s 4ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 19/100\n",
            "385/385 [==============================] - 2s 4ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 20/100\n",
            "385/385 [==============================] - 2s 4ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 21/100\n",
            "385/385 [==============================] - 2s 4ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 22/100\n",
            "385/385 [==============================] - 2s 4ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 23/100\n",
            "385/385 [==============================] - 2s 4ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 24/100\n",
            "385/385 [==============================] - 2s 4ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 25/100\n",
            "385/385 [==============================] - 2s 4ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 26/100\n",
            "385/385 [==============================] - 2s 4ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 27/100\n",
            "385/385 [==============================] - 2s 4ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 28/100\n",
            "385/385 [==============================] - 2s 4ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 29/100\n",
            "385/385 [==============================] - 2s 4ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 30/100\n",
            "385/385 [==============================] - 2s 4ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 31/100\n",
            "385/385 [==============================] - 2s 4ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 32/100\n",
            "385/385 [==============================] - 2s 4ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 33/100\n",
            "385/385 [==============================] - 2s 4ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 34/100\n",
            "385/385 [==============================] - 2s 4ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 35/100\n",
            "385/385 [==============================] - 2s 4ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 36/100\n",
            "385/385 [==============================] - 2s 5ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 00036: early stopping\n",
            "Elapsed time: 58.782 sec\n",
            "Train f1 Score: [0.97233598 0.97713222 0.93655442 0.95258479 0.95967673 0.95778986\n",
            " 0.97587812 0.94412331 0.93474643 0.91997629]\n",
            "Test f1 Score: [0.97033685 0.98764342 0.9459203  0.96476427 0.96701031 0.9592511\n",
            " 0.97339593 0.94100295 0.94488189 0.92338308]\n",
            "Train f1 Score: 0.953079813655792\n",
            "Test f1 Score: 0.9577590114757557\n",
            "Now predicting labels for unlabeled data...\n",
            "571 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "2051 unlabelled instances remained to be predict in next iteration\n",
            "949 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 47\n",
            "25200 new labelled data is training...\n",
            "Epoch 1/100\n",
            "394/394 [==============================] - 2s 4ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 2/100\n",
            "394/394 [==============================] - 2s 4ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 3/100\n",
            "394/394 [==============================] - 2s 4ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 4/100\n",
            "394/394 [==============================] - 2s 4ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 5/100\n",
            "394/394 [==============================] - 2s 4ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 6/100\n",
            "394/394 [==============================] - 2s 4ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 7/100\n",
            "394/394 [==============================] - 2s 4ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 8/100\n",
            "394/394 [==============================] - 2s 4ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 9/100\n",
            "394/394 [==============================] - 2s 4ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 10/100\n",
            "394/394 [==============================] - 2s 4ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 11/100\n",
            "394/394 [==============================] - 2s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 12/100\n",
            "394/394 [==============================] - 2s 4ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 13/100\n",
            "394/394 [==============================] - 2s 4ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 14/100\n",
            "394/394 [==============================] - 2s 4ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 15/100\n",
            "394/394 [==============================] - 2s 4ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 16/100\n",
            "394/394 [==============================] - 2s 4ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 17/100\n",
            "394/394 [==============================] - 2s 4ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 18/100\n",
            "394/394 [==============================] - 2s 4ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 19/100\n",
            "394/394 [==============================] - 2s 4ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 20/100\n",
            "394/394 [==============================] - 2s 4ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 21/100\n",
            "394/394 [==============================] - 2s 4ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 22/100\n",
            "394/394 [==============================] - 2s 4ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 23/100\n",
            "394/394 [==============================] - 2s 4ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 00023: early stopping\n",
            "Elapsed time: 38.842 sec\n",
            "Train f1 Score: [0.97250313 0.97692079 0.93702072 0.95347114 0.9590192  0.95873016\n",
            " 0.97603929 0.94496515 0.93557961 0.92017343]\n",
            "Test f1 Score: [0.97036665 0.98808999 0.94721826 0.96476427 0.96604938 0.95977961\n",
            " 0.97393118 0.93869544 0.94604505 0.92346173]\n",
            "Train f1 Score: 0.9534422612343263\n",
            "Test f1 Score: 0.9578401559232713\n",
            "Now predicting labels for unlabeled data...\n",
            "572 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "2079 unlabelled instances remained to be predict in next iteration\n",
            "921 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 48\n",
            "25800 new labelled data is training...\n",
            "Epoch 1/100\n",
            "404/404 [==============================] - 2s 4ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 2/100\n",
            "404/404 [==============================] - 2s 4ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 3/100\n",
            "404/404 [==============================] - 2s 4ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 4/100\n",
            "404/404 [==============================] - 2s 4ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 5/100\n",
            "404/404 [==============================] - 2s 4ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 6/100\n",
            "404/404 [==============================] - 2s 4ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 7/100\n",
            "404/404 [==============================] - 2s 4ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 8/100\n",
            "404/404 [==============================] - 2s 4ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 9/100\n",
            "404/404 [==============================] - 2s 4ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 10/100\n",
            "404/404 [==============================] - 2s 4ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 11/100\n",
            "404/404 [==============================] - 2s 4ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 12/100\n",
            "404/404 [==============================] - 2s 4ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 13/100\n",
            "404/404 [==============================] - 2s 4ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 14/100\n",
            "404/404 [==============================] - 2s 4ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 15/100\n",
            "404/404 [==============================] - 2s 4ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 16/100\n",
            "404/404 [==============================] - 2s 4ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 17/100\n",
            "404/404 [==============================] - 2s 5ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 00017: early stopping\n",
            "Elapsed time: 29.658 sec\n",
            "Train f1 Score: [0.97266115 0.97679607 0.93751531 0.95305435 0.95959509 0.9572928\n",
            " 0.97619249 0.94433288 0.93430401 0.92093023]\n",
            "Test f1 Score: [0.97137117 0.98765432 0.94671741 0.96479921 0.96601442 0.95977961\n",
            " 0.97390397 0.93897638 0.94482396 0.92353525]\n",
            "Train f1 Score: 0.9532674385249864\n",
            "Test f1 Score: 0.9577575702378078\n",
            "Now predicting labels for unlabeled data...\n",
            "564 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "2115 unlabelled instances remained to be predict in next iteration\n",
            "885 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 49\n",
            "26400 new labelled data is training...\n",
            "Epoch 1/100\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 2/100\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 3/100\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 4/100\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 5/100\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 6/100\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 7/100\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 8/100\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 9/100\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 10/100\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 11/100\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 12/100\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 13/100\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 14/100\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 15/100\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 16/100\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 17/100\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 18/100\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 19/100\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 20/100\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 21/100\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 22/100\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 23/100\n",
            "413/413 [==============================] - 2s 5ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 00023: early stopping\n",
            "Elapsed time: 40.941 sec\n",
            "Train f1 Score: [0.9717052  0.97730486 0.93684296 0.95340797 0.95896774 0.95772608\n",
            " 0.97594851 0.94497704 0.93539055 0.92133884]\n",
            "Test f1 Score: [0.97088353 0.98808999 0.94586895 0.96218905 0.96494845 0.95876855\n",
            " 0.97390397 0.93879566 0.94438615 0.92269574]\n",
            "Train f1 Score: 0.953360975270898\n",
            "Test f1 Score: 0.9570530039678367\n",
            "Now predicting labels for unlabeled data...\n",
            "570 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "2145 unlabelled instances remained to be predict in next iteration\n",
            "855 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 50\n",
            "27000 new labelled data is training...\n",
            "Epoch 1/100\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 2/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 3/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 4/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 5/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 6/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 7/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 8/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 9/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 10/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 11/100\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 12/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 13/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 14/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 15/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 16/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 17/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 18/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 19/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 20/100\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 00020: early stopping\n",
            "Elapsed time: 36.757 sec\n",
            "Train f1 Score: [0.97250313 0.97707651 0.93607677 0.95299251 0.95896774 0.95734855\n",
            " 0.97568827 0.94568021 0.93537922 0.92181971]\n",
            "Test f1 Score: [0.97134238 0.98764342 0.94647087 0.96218905 0.96544611 0.95982389\n",
            " 0.97339593 0.93879566 0.94377299 0.92284866]\n",
            "Train f1 Score: 0.9533532622112046\n",
            "Test f1 Score: 0.9571728963336282\n",
            "Now predicting labels for unlabeled data...\n",
            "568 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "2177 unlabelled instances remained to be predict in next iteration\n",
            "823 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 51\n",
            "27600 new labelled data is training...\n",
            "Epoch 1/100\n",
            "432/432 [==============================] - 2s 5ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 2/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 3/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 4/100\n",
            "432/432 [==============================] - 2s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 5/100\n",
            "432/432 [==============================] - 2s 5ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 6/100\n",
            "432/432 [==============================] - 2s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 7/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 8/100\n",
            "432/432 [==============================] - 2s 5ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 9/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 10/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 11/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 12/100\n",
            "432/432 [==============================] - 2s 5ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 13/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 14/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 15/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 16/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 17/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 18/100\n",
            "432/432 [==============================] - 2s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 19/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 20/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 21/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 22/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 23/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 24/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 25/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 26/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 27/100\n",
            "432/432 [==============================] - 2s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 28/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 29/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 30/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 31/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 32/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 33/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 34/100\n",
            "432/432 [==============================] - 2s 5ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 35/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 36/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 37/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 38/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 39/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 40/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 41/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 42/100\n",
            "432/432 [==============================] - 2s 5ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 43/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 44/100\n",
            "432/432 [==============================] - 2s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 45/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 46/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9989\n",
            "Epoch 47/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 48/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 49/100\n",
            "432/432 [==============================] - 2s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 50/100\n",
            "432/432 [==============================] - 2s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 51/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 52/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 53/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 54/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 55/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 56/100\n",
            "432/432 [==============================] - 2s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 57/100\n",
            "432/432 [==============================] - 2s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 58/100\n",
            "432/432 [==============================] - 2s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 59/100\n",
            "432/432 [==============================] - 2s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 60/100\n",
            "432/432 [==============================] - 2s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 61/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 62/100\n",
            "432/432 [==============================] - 2s 4ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 00062: early stopping\n",
            "Elapsed time: 118.723 sec\n",
            "Train f1 Score: [0.97276525 0.9770731  0.93794905 0.95444435 0.95961505 0.95764706\n",
            " 0.97647258 0.94628498 0.93578303 0.9223752 ]\n",
            "Test f1 Score: [0.97085427 0.98721904 0.94631829 0.96274218 0.96494845 0.9609246\n",
            " 0.975      0.939379   0.94432773 0.9230005 ]\n",
            "Train f1 Score: 0.9540409649709847\n",
            "Test f1 Score: 0.9574714063122265\n",
            "Now predicting labels for unlabeled data...\n",
            "566 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "2211 unlabelled instances remained to be predict in next iteration\n",
            "789 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 52\n",
            "28200 new labelled data is training...\n",
            "Epoch 1/100\n",
            "441/441 [==============================] - 2s 5ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 2/100\n",
            "441/441 [==============================] - 2s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 3/100\n",
            "441/441 [==============================] - 2s 4ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 4/100\n",
            "441/441 [==============================] - 2s 5ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 5/100\n",
            "441/441 [==============================] - 2s 4ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 6/100\n",
            "441/441 [==============================] - 2s 4ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 7/100\n",
            "441/441 [==============================] - 2s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 8/100\n",
            "441/441 [==============================] - 2s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 9/100\n",
            "441/441 [==============================] - 2s 4ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 10/100\n",
            "441/441 [==============================] - 2s 5ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 11/100\n",
            "441/441 [==============================] - 2s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 12/100\n",
            "441/441 [==============================] - 2s 5ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 13/100\n",
            "441/441 [==============================] - 2s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 14/100\n",
            "441/441 [==============================] - 2s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 15/100\n",
            "441/441 [==============================] - 2s 5ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 16/100\n",
            "441/441 [==============================] - 2s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 17/100\n",
            "441/441 [==============================] - 2s 5ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 00017: early stopping\n",
            "Elapsed time: 34.727 sec\n",
            "Train f1 Score: [0.97268399 0.97698324 0.93716425 0.95396525 0.95988317 0.95746606\n",
            " 0.97646461 0.94650338 0.93601751 0.92302493]\n",
            "Test f1 Score: [0.97134238 0.98808999 0.94691943 0.96274218 0.96697626 0.96035242\n",
            " 0.97390397 0.93990148 0.9449397  0.92552135]\n",
            "Train f1 Score: 0.9540156388500798\n",
            "Test f1 Score: 0.9580689154940801\n",
            "Now predicting labels for unlabeled data...\n",
            "553 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "2258 unlabelled instances remained to be predict in next iteration\n",
            "742 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 53\n",
            "28800 new labelled data is training...\n",
            "Epoch 1/100\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 2/100\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 3/100\n",
            "450/450 [==============================] - 2s 4ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 4/100\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 5/100\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 6/100\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 7/100\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 8/100\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 9/100\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 10/100\n",
            "450/450 [==============================] - 2s 4ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 11/100\n",
            "450/450 [==============================] - 2s 4ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 12/100\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 13/100\n",
            "450/450 [==============================] - 2s 4ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 14/100\n",
            "450/450 [==============================] - 2s 4ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 15/100\n",
            "450/450 [==============================] - 2s 4ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 16/100\n",
            "450/450 [==============================] - 2s 4ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 00016: early stopping\n",
            "Elapsed time: 32.930 sec\n",
            "Train f1 Score: [0.97342026 0.97742008 0.93709257 0.95417834 0.96024727 0.95663173\n",
            " 0.97679539 0.94580251 0.93606228 0.92190541]\n",
            "Test f1 Score: [0.97085427 0.98764342 0.94636925 0.96369965 0.96551724 0.95776193\n",
            " 0.97390397 0.94146581 0.94383202 0.92422732]\n",
            "Train f1 Score: 0.9539555836400782\n",
            "Test f1 Score: 0.9575274885151114\n",
            "Now predicting labels for unlabeled data...\n",
            "568 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "2290 unlabelled instances remained to be predict in next iteration\n",
            "710 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 54\n",
            "29400 new labelled data is training...\n",
            "Epoch 1/100\n",
            "460/460 [==============================] - 2s 4ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 2/100\n",
            "460/460 [==============================] - 2s 4ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 3/100\n",
            "460/460 [==============================] - 2s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 4/100\n",
            "460/460 [==============================] - 2s 4ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 5/100\n",
            "460/460 [==============================] - 2s 4ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9989\n",
            "Epoch 6/100\n",
            "460/460 [==============================] - 2s 4ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 7/100\n",
            "460/460 [==============================] - 2s 5ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 8/100\n",
            "460/460 [==============================] - 2s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 9/100\n",
            "460/460 [==============================] - 2s 4ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 10/100\n",
            "460/460 [==============================] - 2s 4ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 11/100\n",
            "460/460 [==============================] - 2s 5ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 12/100\n",
            "460/460 [==============================] - 2s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 13/100\n",
            "460/460 [==============================] - 2s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 14/100\n",
            "460/460 [==============================] - 2s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 15/100\n",
            "460/460 [==============================] - 2s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 00015: early stopping\n",
            "Elapsed time: 31.410 sec\n",
            "Train f1 Score: [0.97397707 0.97757914 0.93777017 0.95390188 0.96059748 0.95722941\n",
            " 0.97688204 0.94621578 0.93628566 0.92321971]\n",
            "Test f1 Score: [0.97428139 0.98765432 0.94771863 0.96329365 0.96807415 0.95929593\n",
            " 0.97443923 0.94227923 0.9449397  0.92864222]\n",
            "Train f1 Score: 0.9543658335096381\n",
            "Test f1 Score: 0.9590618448971266\n",
            "Now predicting labels for unlabeled data...\n",
            "571 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "2319 unlabelled instances remained to be predict in next iteration\n",
            "681 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 55\n",
            "30000 new labelled data is training...\n",
            "Epoch 1/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 2/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 3/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 4/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 5/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 6/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 7/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 8/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 9/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 10/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 11/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 12/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 13/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 14/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 15/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 16/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 17/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 18/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 19/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 20/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 21/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 22/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 23/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 24/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 00024: early stopping\n",
            "Elapsed time: 51.347 sec\n",
            "Train f1 Score: [0.97351049 0.97693796 0.93893567 0.95466886 0.96080281 0.95758343\n",
            " 0.97668899 0.94611549 0.93516734 0.92298598]\n",
            "Test f1 Score: [0.97237569 0.98810048 0.94716802 0.96384349 0.96551724 0.9609246\n",
            " 0.97441253 0.94192913 0.94526316 0.92598112]\n",
            "Train f1 Score: 0.9543397012761409\n",
            "Test f1 Score: 0.9585515466970801\n",
            "Now predicting labels for unlabeled data...\n",
            "576 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "2343 unlabelled instances remained to be predict in next iteration\n",
            "657 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 56\n",
            "30600 new labelled data is training...\n",
            "Epoch 1/100\n",
            "479/479 [==============================] - 2s 4ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 2/100\n",
            "479/479 [==============================] - 2s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 3/100\n",
            "479/479 [==============================] - 2s 4ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 4/100\n",
            "479/479 [==============================] - 2s 4ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 5/100\n",
            "479/479 [==============================] - 2s 4ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 6/100\n",
            "479/479 [==============================] - 2s 4ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 7/100\n",
            "479/479 [==============================] - 2s 4ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 8/100\n",
            "479/479 [==============================] - 2s 4ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 9/100\n",
            "479/479 [==============================] - 2s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 10/100\n",
            "479/479 [==============================] - 2s 5ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 11/100\n",
            "479/479 [==============================] - 2s 4ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 12/100\n",
            "479/479 [==============================] - 2s 4ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 13/100\n",
            "479/479 [==============================] - 2s 5ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 14/100\n",
            "479/479 [==============================] - 2s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9990\n",
            "Epoch 15/100\n",
            "479/479 [==============================] - 2s 4ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 16/100\n",
            "479/479 [==============================] - 2s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 17/100\n",
            "479/479 [==============================] - 2s 4ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 18/100\n",
            "479/479 [==============================] - 2s 4ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 19/100\n",
            "479/479 [==============================] - 2s 4ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 20/100\n",
            "479/479 [==============================] - 2s 4ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 21/100\n",
            "479/479 [==============================] - 2s 4ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 22/100\n",
            "479/479 [==============================] - 2s 4ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 23/100\n",
            "479/479 [==============================] - 2s 5ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 24/100\n",
            "479/479 [==============================] - 2s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 25/100\n",
            "479/479 [==============================] - 2s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 26/100\n",
            "479/479 [==============================] - 2s 4ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 27/100\n",
            "479/479 [==============================] - 2s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 28/100\n",
            "479/479 [==============================] - 2s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9989\n",
            "Epoch 29/100\n",
            "479/479 [==============================] - 2s 5ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 30/100\n",
            "479/479 [==============================] - 2s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 00030: early stopping\n",
            "Elapsed time: 64.778 sec\n",
            "Train f1 Score: [0.97359184 0.97723214 0.93951283 0.95455294 0.9613307  0.95824654\n",
            " 0.97712252 0.94639556 0.9360063  0.92349265]\n",
            "Test f1 Score: [0.97289157 0.9876652  0.94811994 0.96380764 0.96658098 0.96141125\n",
            " 0.97548252 0.94285714 0.94587493 0.92789657]\n",
            "Train f1 Score: 0.9547484040034748\n",
            "Test f1 Score: 0.9592587736039058\n",
            "Now predicting labels for unlabeled data...\n",
            "578 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "2365 unlabelled instances remained to be predict in next iteration\n",
            "635 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 57\n",
            "31200 new labelled data is training...\n",
            "Epoch 1/100\n",
            "488/488 [==============================] - 2s 4ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 2/100\n",
            "488/488 [==============================] - 2s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 3/100\n",
            "488/488 [==============================] - 2s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 4/100\n",
            "488/488 [==============================] - 2s 4ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 5/100\n",
            "488/488 [==============================] - 2s 5ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 6/100\n",
            "488/488 [==============================] - 2s 5ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 7/100\n",
            "488/488 [==============================] - 2s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 8/100\n",
            "488/488 [==============================] - 2s 4ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 9/100\n",
            "488/488 [==============================] - 2s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 10/100\n",
            "488/488 [==============================] - 2s 5ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 11/100\n",
            "488/488 [==============================] - 2s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 12/100\n",
            "488/488 [==============================] - 2s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 13/100\n",
            "488/488 [==============================] - 2s 4ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 14/100\n",
            "488/488 [==============================] - 2s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 15/100\n",
            "488/488 [==============================] - 2s 5ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 16/100\n",
            "488/488 [==============================] - 2s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 17/100\n",
            "488/488 [==============================] - 2s 4ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 18/100\n",
            "488/488 [==============================] - 2s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 19/100\n",
            "488/488 [==============================] - 2s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 20/100\n",
            "488/488 [==============================] - 2s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 21/100\n",
            "488/488 [==============================] - 2s 4ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 00021: early stopping\n",
            "Elapsed time: 47.336 sec\n",
            "Train f1 Score: [0.97481382 0.97737759 0.93941868 0.95332786 0.96061909 0.95802424\n",
            " 0.97745381 0.94674175 0.93533386 0.92308987]\n",
            "Test f1 Score: [0.97381672 0.98810048 0.9486692  0.96432111 0.96900826 0.9609246\n",
            " 0.97548252 0.94389764 0.94576093 0.92878338]\n",
            "Train f1 Score: 0.9546200566295635\n",
            "Test f1 Score: 0.9598764850964949\n",
            "Now predicting labels for unlabeled data...\n",
            "574 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "2391 unlabelled instances remained to be predict in next iteration\n",
            "609 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 58\n",
            "31800 new labelled data is training...\n",
            "Epoch 1/100\n",
            "497/497 [==============================] - 2s 5ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9991\n",
            "Epoch 2/100\n",
            "497/497 [==============================] - 2s 5ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 3/100\n",
            "497/497 [==============================] - 2s 4ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 4/100\n",
            "497/497 [==============================] - 2s 4ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 5/100\n",
            "497/497 [==============================] - 2s 4ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 6/100\n",
            "497/497 [==============================] - 2s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 7/100\n",
            "497/497 [==============================] - 2s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 8/100\n",
            "497/497 [==============================] - 2s 4ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 9/100\n",
            "497/497 [==============================] - 2s 5ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 10/100\n",
            "497/497 [==============================] - 2s 4ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 11/100\n",
            "497/497 [==============================] - 2s 4ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 12/100\n",
            "497/497 [==============================] - 2s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 13/100\n",
            "497/497 [==============================] - 2s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 00013: early stopping\n",
            "Elapsed time: 29.261 sec\n",
            "Train f1 Score: [0.97408027 0.97773807 0.93896867 0.95397283 0.96109918 0.9560826\n",
            " 0.97719759 0.94658085 0.93582325 0.92306393]\n",
            "Test f1 Score: [0.97332662 0.98765432 0.94781784 0.96465903 0.96804124 0.95947426\n",
            " 0.97545692 0.94285714 0.94687007 0.92857143]\n",
            "Train f1 Score: 0.9544607248235046\n",
            "Test f1 Score: 0.9594728871861233\n",
            "Now predicting labels for unlabeled data...\n",
            "575 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "2416 unlabelled instances remained to be predict in next iteration\n",
            "584 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 59\n",
            "Train f1 Score: [0.97408027 0.97773807 0.93896867 0.95397283 0.96109918 0.9560826\n",
            " 0.97719759 0.94658085 0.93582325 0.92306393]\n",
            "Test f1 Score: [0.97332662 0.98765432 0.94781784 0.96465903 0.96804124 0.95947426\n",
            " 0.97545692 0.94285714 0.94687007 0.92857143]\n",
            "Train f1 Score: 0.9544607248235046\n",
            "Test f1 Score: 0.9594728871861233\n",
            "Now predicting labels for unlabeled data...\n",
            "565 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "2451 unlabelled instances remained to be predict in next iteration\n",
            "1149 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 60\n",
            "32400 new labelled data is training...\n",
            "Epoch 1/100\n",
            "507/507 [==============================] - 2s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 2/100\n",
            "507/507 [==============================] - 2s 5ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 3/100\n",
            "507/507 [==============================] - 2s 4ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 4/100\n",
            "507/507 [==============================] - 2s 4ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 5/100\n",
            "507/507 [==============================] - 2s 4ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 6/100\n",
            "507/507 [==============================] - 2s 4ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 7/100\n",
            "507/507 [==============================] - 2s 4ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 8/100\n",
            "507/507 [==============================] - 2s 5ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 9/100\n",
            "507/507 [==============================] - 2s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 10/100\n",
            "507/507 [==============================] - 2s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 11/100\n",
            "507/507 [==============================] - 2s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 12/100\n",
            "507/507 [==============================] - 2s 4ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 13/100\n",
            "507/507 [==============================] - 2s 5ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 14/100\n",
            "507/507 [==============================] - 2s 5ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 15/100\n",
            "507/507 [==============================] - 2s 4ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 16/100\n",
            "507/507 [==============================] - 2s 4ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 00016: early stopping\n",
            "Elapsed time: 36.664 sec\n",
            "Train f1 Score: [0.97432037 0.97767193 0.93933208 0.95400313 0.96172988 0.95792997\n",
            " 0.97712252 0.94683504 0.93641214 0.92445496]\n",
            "Test f1 Score: [0.9743073  0.98810048 0.9491203  0.96425025 0.96804124 0.96149615\n",
            " 0.97548252 0.94337765 0.948086   0.92956349]\n",
            "Train f1 Score: 0.9549812012235469\n",
            "Test f1 Score: 0.9601825391171228\n",
            "Now predicting labels for unlabeled data...\n",
            "569 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "2482 unlabelled instances remained to be predict in next iteration\n",
            "1118 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 61\n",
            "33000 new labelled data is training...\n",
            "Epoch 1/100\n",
            "516/516 [==============================] - 3s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 2/100\n",
            "516/516 [==============================] - 2s 5ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 3/100\n",
            "516/516 [==============================] - 3s 5ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 4/100\n",
            "516/516 [==============================] - 3s 5ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 5/100\n",
            "516/516 [==============================] - 2s 5ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 6/100\n",
            "516/516 [==============================] - 2s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 7/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 8/100\n",
            "516/516 [==============================] - 2s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 9/100\n",
            "516/516 [==============================] - 3s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 10/100\n",
            "516/516 [==============================] - 2s 5ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 11/100\n",
            "516/516 [==============================] - 2s 5ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 12/100\n",
            "516/516 [==============================] - 2s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 13/100\n",
            "516/516 [==============================] - 2s 5ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 14/100\n",
            "516/516 [==============================] - 2s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 15/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 16/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 17/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 18/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 19/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 20/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 21/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 22/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 23/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 24/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 25/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 26/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 27/100\n",
            "516/516 [==============================] - 2s 5ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 28/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 29/100\n",
            "516/516 [==============================] - 2s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9989\n",
            "Epoch 00029: early stopping\n",
            "Elapsed time: 68.548 sec\n",
            "Train f1 Score: [0.97344689 0.97776456 0.94030216 0.95452299 0.96215567 0.95879743\n",
            " 0.97744998 0.94681022 0.93640505 0.92432432]\n",
            "Test f1 Score: [0.97389558 0.98721904 0.94826768 0.96465903 0.96804124 0.96312603\n",
            " 0.97494781 0.94192913 0.94698163 0.92796821]\n",
            "Train f1 Score: 0.9551979270125326\n",
            "Test f1 Score: 0.959703537984271\n",
            "Now predicting labels for unlabeled data...\n",
            "570 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "2512 unlabelled instances remained to be predict in next iteration\n",
            "1088 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 62\n",
            "33600 new labelled data is training...\n",
            "Epoch 1/100\n",
            "525/525 [==============================] - 2s 5ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 2/100\n",
            "525/525 [==============================] - 2s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 3/100\n",
            "525/525 [==============================] - 2s 4ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 4/100\n",
            "525/525 [==============================] - 2s 4ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9989\n",
            "Epoch 5/100\n",
            "525/525 [==============================] - 2s 5ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 6/100\n",
            "525/525 [==============================] - 2s 4ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 7/100\n",
            "525/525 [==============================] - 2s 4ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 8/100\n",
            "525/525 [==============================] - 2s 4ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 9/100\n",
            "525/525 [==============================] - 2s 4ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 10/100\n",
            "525/525 [==============================] - 2s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 11/100\n",
            "525/525 [==============================] - 2s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 12/100\n",
            "525/525 [==============================] - 2s 5ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 13/100\n",
            "525/525 [==============================] - 2s 4ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 14/100\n",
            "525/525 [==============================] - 2s 5ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 15/100\n",
            "525/525 [==============================] - 2s 4ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 16/100\n",
            "525/525 [==============================] - 3s 5ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 00016: early stopping\n",
            "Elapsed time: 38.195 sec\n",
            "Train f1 Score: [0.97281068 0.97796307 0.94066618 0.95473996 0.96174301 0.95837857\n",
            " 0.97711089 0.9472501  0.93664683 0.92401422]\n",
            "Test f1 Score: [0.97294589 0.98808999 0.94811994 0.96476427 0.96807415 0.96312603\n",
            " 0.97599165 0.94441712 0.94692591 0.92835821]\n",
            "Train f1 Score: 0.9551323501407545\n",
            "Test f1 Score: 0.9600813153954105\n",
            "Now predicting labels for unlabeled data...\n",
            "571 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "2541 unlabelled instances remained to be predict in next iteration\n",
            "1059 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 63\n",
            "34200 new labelled data is training...\n",
            "Epoch 1/100\n",
            "535/535 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 2/100\n",
            "535/535 [==============================] - 2s 5ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 3/100\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 4/100\n",
            "535/535 [==============================] - 2s 5ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 5/100\n",
            "535/535 [==============================] - 3s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 6/100\n",
            "535/535 [==============================] - 3s 5ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 7/100\n",
            "535/535 [==============================] - 2s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 8/100\n",
            "535/535 [==============================] - 2s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 9/100\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 10/100\n",
            "535/535 [==============================] - 3s 5ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 11/100\n",
            "535/535 [==============================] - 3s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 12/100\n",
            "535/535 [==============================] - 2s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 13/100\n",
            "535/535 [==============================] - 2s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 00013: early stopping\n",
            "Elapsed time: 32.383 sec\n",
            "Train f1 Score: [0.97247706 0.97838724 0.93972558 0.95393221 0.96242279 0.95863879\n",
            " 0.97726887 0.94689338 0.9375     0.92494929]\n",
            "Test f1 Score: [0.97294589 0.98808999 0.9486692  0.96425025 0.96910402 0.96312603\n",
            " 0.97543126 0.94280079 0.94863732 0.9288911 ]\n",
            "Train f1 Score: 0.9552195222868851\n",
            "Test f1 Score: 0.9601945841005486\n",
            "Now predicting labels for unlabeled data...\n",
            "580 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "2561 unlabelled instances remained to be predict in next iteration\n",
            "1039 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 64\n",
            "34800 new labelled data is training...\n",
            "Epoch 1/100\n",
            "544/544 [==============================] - 3s 5ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 2/100\n",
            "544/544 [==============================] - 3s 5ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 3/100\n",
            "544/544 [==============================] - 3s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 4/100\n",
            "544/544 [==============================] - 2s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 5/100\n",
            "544/544 [==============================] - 2s 4ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 6/100\n",
            "544/544 [==============================] - 2s 4ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 7/100\n",
            "544/544 [==============================] - 3s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 8/100\n",
            "544/544 [==============================] - 3s 5ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 9/100\n",
            "544/544 [==============================] - 3s 5ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 10/100\n",
            "544/544 [==============================] - 2s 4ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 11/100\n",
            "544/544 [==============================] - 2s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 12/100\n",
            "544/544 [==============================] - 2s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 13/100\n",
            "544/544 [==============================] - 2s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 14/100\n",
            "544/544 [==============================] - 3s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 15/100\n",
            "544/544 [==============================] - 3s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 16/100\n",
            "544/544 [==============================] - 3s 5ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 17/100\n",
            "544/544 [==============================] - 2s 4ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 18/100\n",
            "544/544 [==============================] - 3s 5ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 19/100\n",
            "544/544 [==============================] - 2s 5ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 00019: early stopping\n",
            "Elapsed time: 47.883 sec\n",
            "Train f1 Score: [0.9732665  0.97768853 0.93973742 0.95418589 0.96275957 0.95803184\n",
            " 0.97736329 0.9466838  0.93631579 0.9238965 ]\n",
            "Test f1 Score: [0.97291876 0.98765432 0.94826768 0.96620278 0.96860525 0.96369637\n",
            " 0.97650131 0.94100295 0.9478673  0.92736318]\n",
            "Train f1 Score: 0.9549929126269117\n",
            "Test f1 Score: 0.960007989696565\n",
            "Now predicting labels for unlabeled data...\n",
            "572 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "2589 unlabelled instances remained to be predict in next iteration\n",
            "1011 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 65\n",
            "35400 new labelled data is training...\n",
            "Epoch 1/100\n",
            "554/554 [==============================] - 3s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 2/100\n",
            "554/554 [==============================] - 3s 5ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 3/100\n",
            "554/554 [==============================] - 2s 5ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 4/100\n",
            "554/554 [==============================] - 2s 4ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9989\n",
            "Epoch 5/100\n",
            "554/554 [==============================] - 3s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 6/100\n",
            "554/554 [==============================] - 3s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 7/100\n",
            "554/554 [==============================] - 2s 4ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 8/100\n",
            "554/554 [==============================] - 3s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 9/100\n",
            "554/554 [==============================] - 3s 5ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9989\n",
            "Epoch 10/100\n",
            "554/554 [==============================] - 3s 5ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 11/100\n",
            "554/554 [==============================] - 3s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 12/100\n",
            "554/554 [==============================] - 2s 4ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 13/100\n",
            "554/554 [==============================] - 2s 4ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 14/100\n",
            "554/554 [==============================] - 2s 4ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 15/100\n",
            "554/554 [==============================] - 2s 4ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 16/100\n",
            "554/554 [==============================] - 3s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 00016: early stopping\n",
            "Elapsed time: 40.555 sec\n",
            "Train f1 Score: [0.97271589 0.97803262 0.93963126 0.95435821 0.96230941 0.95808817\n",
            " 0.9777062  0.94614335 0.93684395 0.92419998]\n",
            "Test f1 Score: [0.97243108 0.98852604 0.94881517 0.96665007 0.96969697 0.96316658\n",
            " 0.97647674 0.94302554 0.9480315  0.928     ]\n",
            "Train f1 Score: 0.9550029036708721\n",
            "Test f1 Score: 0.9604819674488677\n",
            "Now predicting labels for unlabeled data...\n",
            "572 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "2617 unlabelled instances remained to be predict in next iteration\n",
            "983 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 66\n",
            "36000 new labelled data is training...\n",
            "Epoch 1/100\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 2/100\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 3/100\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 4/100\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 5/100\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 6/100\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 7/100\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 8/100\n",
            "563/563 [==============================] - 2s 4ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 9/100\n",
            "563/563 [==============================] - 3s 4ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 10/100\n",
            "563/563 [==============================] - 3s 4ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 11/100\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 12/100\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9989\n",
            "Epoch 13/100\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 14/100\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 15/100\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 16/100\n",
            "563/563 [==============================] - 3s 4ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 17/100\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 18/100\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 19/100\n",
            "563/563 [==============================] - 3s 4ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 20/100\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 21/100\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 22/100\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 23/100\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 24/100\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 00024: early stopping\n",
            "Elapsed time: 63.473 sec\n",
            "Train f1 Score: [0.97287824 0.97811197 0.94051316 0.95435821 0.96301382 0.95788142\n",
            " 0.97744616 0.94670092 0.93614785 0.92379261]\n",
            "Test f1 Score: [0.97245869 0.98765432 0.94957184 0.96520875 0.97010309 0.96210873\n",
            " 0.97543126 0.94296952 0.94587493 0.92736318]\n",
            "Train f1 Score: 0.9550844350068234\n",
            "Test f1 Score: 0.9598744313516642\n",
            "Now predicting labels for unlabeled data...\n",
            "582 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "2635 unlabelled instances remained to be predict in next iteration\n",
            "965 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 67\n",
            "36600 new labelled data is training...\n",
            "Epoch 1/100\n",
            "572/572 [==============================] - 3s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 2/100\n",
            "572/572 [==============================] - 3s 5ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 3/100\n",
            "572/572 [==============================] - 3s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 4/100\n",
            "572/572 [==============================] - 3s 5ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 5/100\n",
            "572/572 [==============================] - 3s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 6/100\n",
            "572/572 [==============================] - 3s 5ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 7/100\n",
            "572/572 [==============================] - 3s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 8/100\n",
            "572/572 [==============================] - 3s 5ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 9/100\n",
            "572/572 [==============================] - 3s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 10/100\n",
            "572/572 [==============================] - 3s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 11/100\n",
            "572/572 [==============================] - 3s 5ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 12/100\n",
            "572/572 [==============================] - 3s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 13/100\n",
            "572/572 [==============================] - 3s 4ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 14/100\n",
            "572/572 [==============================] - 3s 4ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 15/100\n",
            "572/572 [==============================] - 3s 4ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 16/100\n",
            "572/572 [==============================] - 3s 4ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 17/100\n",
            "572/572 [==============================] - 3s 5ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 18/100\n",
            "572/572 [==============================] - 3s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 19/100\n",
            "572/572 [==============================] - 3s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 00019: early stopping\n",
            "Elapsed time: 50.316 sec\n",
            "Train f1 Score: [0.97376337 0.97853629 0.93973542 0.95503494 0.96263925 0.96036281\n",
            " 0.97761574 0.94700442 0.93740725 0.92472936]\n",
            "Test f1 Score: [0.97585513 0.98765432 0.94871795 0.96483408 0.96963459 0.96414782\n",
            " 0.97647674 0.94140817 0.9475891  0.9288911 ]\n",
            "Train f1 Score: 0.9556828850903869\n",
            "Test f1 Score: 0.9605208992658163\n",
            "Now predicting labels for unlabeled data...\n",
            "582 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "2653 unlabelled instances remained to be predict in next iteration\n",
            "947 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 68\n",
            "37200 new labelled data is training...\n",
            "Epoch 1/100\n",
            "582/582 [==============================] - 3s 5ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 2/100\n",
            "582/582 [==============================] - 3s 5ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 3/100\n",
            "582/582 [==============================] - 3s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 4/100\n",
            "582/582 [==============================] - 3s 5ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 5/100\n",
            "582/582 [==============================] - 3s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 6/100\n",
            "582/582 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 7/100\n",
            "582/582 [==============================] - 3s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 8/100\n",
            "582/582 [==============================] - 3s 5ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 9/100\n",
            "582/582 [==============================] - 3s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 10/100\n",
            "582/582 [==============================] - 3s 4ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 11/100\n",
            "582/582 [==============================] - 3s 4ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 12/100\n",
            "582/582 [==============================] - 3s 5ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9989\n",
            "Epoch 13/100\n",
            "582/582 [==============================] - 3s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 14/100\n",
            "582/582 [==============================] - 3s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 15/100\n",
            "582/582 [==============================] - 3s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 16/100\n",
            "582/582 [==============================] - 3s 4ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 17/100\n",
            "582/582 [==============================] - 3s 5ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 18/100\n",
            "582/582 [==============================] - 3s 5ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 19/100\n",
            "582/582 [==============================] - 3s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 20/100\n",
            "582/582 [==============================] - 3s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 21/100\n",
            "582/582 [==============================] - 3s 5ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 22/100\n",
            "582/582 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 23/100\n",
            "582/582 [==============================] - 3s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 24/100\n",
            "582/582 [==============================] - 3s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 00024: early stopping\n",
            "Elapsed time: 65.502 sec\n",
            "Train f1 Score: [0.97335672 0.97854269 0.94005227 0.9541224  0.9623725  0.95759877\n",
            " 0.97744616 0.94651331 0.93689914 0.92463842]\n",
            "Test f1 Score: [0.97538925 0.98721904 0.94826768 0.96568871 0.96860525 0.96316658\n",
            " 0.97596656 0.9408867  0.94648478 0.92935323]\n",
            "Train f1 Score: 0.955154238074107\n",
            "Test f1 Score: 0.960102778716165\n",
            "Now predicting labels for unlabeled data...\n",
            "576 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "2677 unlabelled instances remained to be predict in next iteration\n",
            "923 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 69\n",
            "37800 new labelled data is training...\n",
            "Epoch 1/100\n",
            "591/591 [==============================] - 3s 5ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 2/100\n",
            "591/591 [==============================] - 3s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 3/100\n",
            "591/591 [==============================] - 3s 5ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 4/100\n",
            "591/591 [==============================] - 3s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 5/100\n",
            "591/591 [==============================] - 3s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 6/100\n",
            "591/591 [==============================] - 3s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 7/100\n",
            "591/591 [==============================] - 3s 5ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 8/100\n",
            "591/591 [==============================] - 3s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 9/100\n",
            "591/591 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 10/100\n",
            "591/591 [==============================] - 3s 5ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 11/100\n",
            "591/591 [==============================] - 3s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 12/100\n",
            "591/591 [==============================] - 3s 5ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 13/100\n",
            "591/591 [==============================] - 3s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 14/100\n",
            "591/591 [==============================] - 3s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 15/100\n",
            "591/591 [==============================] - 3s 5ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 16/100\n",
            "591/591 [==============================] - 3s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 17/100\n",
            "591/591 [==============================] - 3s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 18/100\n",
            "591/591 [==============================] - 3s 4ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 19/100\n",
            "591/591 [==============================] - 3s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 20/100\n",
            "591/591 [==============================] - 3s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 21/100\n",
            "591/591 [==============================] - 3s 5ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 22/100\n",
            "591/591 [==============================] - 3s 5ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 23/100\n",
            "591/591 [==============================] - 3s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 24/100\n",
            "591/591 [==============================] - 3s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 25/100\n",
            "591/591 [==============================] - 3s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 26/100\n",
            "591/591 [==============================] - 3s 5ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 27/100\n",
            "591/591 [==============================] - 3s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 28/100\n",
            "591/591 [==============================] - 3s 5ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 29/100\n",
            "591/591 [==============================] - 3s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 30/100\n",
            "591/591 [==============================] - 3s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 31/100\n",
            "591/591 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 32/100\n",
            "591/591 [==============================] - 3s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 33/100\n",
            "591/591 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 34/100\n",
            "591/591 [==============================] - 3s 5ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 35/100\n",
            "591/591 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 36/100\n",
            "591/591 [==============================] - 3s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 37/100\n",
            "591/591 [==============================] - 3s 4ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 38/100\n",
            "591/591 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 00038: early stopping\n",
            "Elapsed time: 105.716 sec\n",
            "Train f1 Score: [0.97328435 0.97853629 0.94063778 0.95481853 0.96223345 0.95976074\n",
            " 0.97769485 0.94707207 0.93694323 0.9249092 ]\n",
            "Test f1 Score: [0.97392177 0.98721904 0.9500238  0.96527778 0.968107   0.96361632\n",
            " 0.97596656 0.94280079 0.94814039 0.92988563]\n",
            "Train f1 Score: 0.9555890502430515\n",
            "Test f1 Score: 0.9604959061710303\n",
            "Now predicting labels for unlabeled data...\n",
            "586 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "2691 unlabelled instances remained to be predict in next iteration\n",
            "909 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 70\n",
            "38400 new labelled data is training...\n",
            "Epoch 1/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 2/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 3/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 4/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 5/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 6/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 7/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 8/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 9/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 10/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 11/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 12/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 13/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 14/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 15/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 16/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 17/100\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 00017: early stopping\n",
            "Elapsed time: 48.012 sec\n",
            "Train f1 Score: [0.97410192 0.97817505 0.94045577 0.95452677 0.96258241 0.96030451\n",
            " 0.9782148  0.94656489 0.93700787 0.92433988]\n",
            "Test f1 Score: [0.97441044 0.98721904 0.95007133 0.96630327 0.96966581 0.96414782\n",
            " 0.97754569 0.94054054 0.9480315  0.92814371]\n",
            "Train f1 Score: 0.9556273868777216\n",
            "Test f1 Score: 0.9606079145136974\n",
            "Now predicting labels for unlabeled data...\n",
            "571 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "2720 unlabelled instances remained to be predict in next iteration\n",
            "880 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 71\n",
            "39000 new labelled data is training...\n",
            "Epoch 1/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 2/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 3/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 4/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 5/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 6/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 7/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 8/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 9/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 10/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 11/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 12/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 13/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 14/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 15/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 16/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 17/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 18/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 19/100\n",
            "610/610 [==============================] - 3s 4ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 20/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 21/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 22/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 23/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 24/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 25/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 26/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 27/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 28/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 29/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 30/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 31/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 32/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 33/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 34/100\n",
            "610/610 [==============================] - 3s 4ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 35/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 36/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 37/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 38/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 39/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 40/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 41/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 42/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 43/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 44/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 45/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 46/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 47/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 48/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 49/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 50/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 51/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 52/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 53/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 54/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 55/100\n",
            "610/610 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 00055: early stopping\n",
            "Elapsed time: 159.785 sec\n",
            "Train f1 Score: [0.97345133 0.97846979 0.94084001 0.95529024 0.96256959 0.95843123\n",
            " 0.97804899 0.94667629 0.93666667 0.92418467]\n",
            "Test f1 Score: [0.9748996  0.98721904 0.95007133 0.96623635 0.96863753 0.96316658\n",
            " 0.97754569 0.9421001  0.94736842 0.9286783 ]\n",
            "Train f1 Score: 0.9554628801844766\n",
            "Test f1 Score: 0.9605922932383386\n",
            "Now predicting labels for unlabeled data...\n",
            "575 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "2745 unlabelled instances remained to be predict in next iteration\n",
            "855 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 72\n",
            "39600 new labelled data is training...\n",
            "Epoch 1/100\n",
            "619/619 [==============================] - 3s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 2/100\n",
            "619/619 [==============================] - 3s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 3/100\n",
            "619/619 [==============================] - 3s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 4/100\n",
            "619/619 [==============================] - 3s 5ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 5/100\n",
            "619/619 [==============================] - 3s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 6/100\n",
            "619/619 [==============================] - 3s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 7/100\n",
            "619/619 [==============================] - 3s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 8/100\n",
            "619/619 [==============================] - 3s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 9/100\n",
            "619/619 [==============================] - 3s 5ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 10/100\n",
            "619/619 [==============================] - 3s 5ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 11/100\n",
            "619/619 [==============================] - 3s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 12/100\n",
            "619/619 [==============================] - 3s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 13/100\n",
            "619/619 [==============================] - 3s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 14/100\n",
            "619/619 [==============================] - 3s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 15/100\n",
            "619/619 [==============================] - 3s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 16/100\n",
            "619/619 [==============================] - 3s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 17/100\n",
            "619/619 [==============================] - 3s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 18/100\n",
            "619/619 [==============================] - 3s 5ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 19/100\n",
            "619/619 [==============================] - 3s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 20/100\n",
            "619/619 [==============================] - 3s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 21/100\n",
            "619/619 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 22/100\n",
            "619/619 [==============================] - 3s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 23/100\n",
            "619/619 [==============================] - 3s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 24/100\n",
            "619/619 [==============================] - 3s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 25/100\n",
            "619/619 [==============================] - 3s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 26/100\n",
            "619/619 [==============================] - 3s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 27/100\n",
            "619/619 [==============================] - 3s 5ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 28/100\n",
            "619/619 [==============================] - 3s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 00028: early stopping\n",
            "Elapsed time: 83.758 sec\n",
            "Train f1 Score: [0.97434183 0.97810219 0.94072502 0.95575658 0.96296296 0.96073987\n",
            " 0.97803409 0.94740223 0.93790935 0.92525184]\n",
            "Test f1 Score: [0.9753645  0.9876652  0.95156695 0.96674938 0.97013388 0.96251378\n",
            " 0.97698745 0.93961708 0.94924123 0.93013972]\n",
            "Train f1 Score: 0.9561225966261768\n",
            "Test f1 Score: 0.9609979185687008\n",
            "Now predicting labels for unlabeled data...\n",
            "584 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "2761 unlabelled instances remained to be predict in next iteration\n",
            "839 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 73\n",
            "40200 new labelled data is training...\n",
            "Epoch 1/100\n",
            "629/629 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 2/100\n",
            "629/629 [==============================] - 3s 5ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 3/100\n",
            "629/629 [==============================] - 3s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 4/100\n",
            "629/629 [==============================] - 3s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 5/100\n",
            "629/629 [==============================] - 3s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 6/100\n",
            "629/629 [==============================] - 3s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 7/100\n",
            "629/629 [==============================] - 3s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 8/100\n",
            "629/629 [==============================] - 3s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 9/100\n",
            "629/629 [==============================] - 3s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 10/100\n",
            "629/629 [==============================] - 3s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 11/100\n",
            "629/629 [==============================] - 3s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 12/100\n",
            "629/629 [==============================] - 3s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 13/100\n",
            "629/629 [==============================] - 3s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 14/100\n",
            "629/629 [==============================] - 3s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 00014: early stopping\n",
            "Elapsed time: 42.659 sec\n",
            "Train f1 Score: [0.97369959 0.97802607 0.94120533 0.9555336  0.9625118  0.96084829\n",
            " 0.97777401 0.94796944 0.93706904 0.92475114]\n",
            "Test f1 Score: [0.9748996  0.9876652  0.95147479 0.9652433  0.97013388 0.9630854\n",
            " 0.97698745 0.94094488 0.94764398 0.9288911 ]\n",
            "Train f1 Score: 0.9559388300849163\n",
            "Test f1 Score: 0.9606969569117323\n",
            "Now predicting labels for unlabeled data...\n",
            "572 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "2789 unlabelled instances remained to be predict in next iteration\n",
            "811 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 74\n",
            "40800 new labelled data is training...\n",
            "Epoch 1/100\n",
            "638/638 [==============================] - 3s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 2/100\n",
            "638/638 [==============================] - 3s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 3/100\n",
            "638/638 [==============================] - 3s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 4/100\n",
            "638/638 [==============================] - 3s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 5/100\n",
            "638/638 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 6/100\n",
            "638/638 [==============================] - 3s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 7/100\n",
            "638/638 [==============================] - 3s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 8/100\n",
            "638/638 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 9/100\n",
            "638/638 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 10/100\n",
            "638/638 [==============================] - 3s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 11/100\n",
            "638/638 [==============================] - 3s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 12/100\n",
            "638/638 [==============================] - 3s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 13/100\n",
            "638/638 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 00013: early stopping\n",
            "Elapsed time: 39.202 sec\n",
            "Train f1 Score: [0.97466767 0.97794994 0.94146501 0.95576971 0.96292491 0.96067416\n",
            " 0.97812447 0.94721643 0.93738538 0.92433988]\n",
            "Test f1 Score: [0.97637004 0.98721904 0.95011876 0.96565455 0.96863753 0.96312603\n",
            " 0.97698745 0.94111874 0.94874477 0.92914172]\n",
            "Train f1 Score: 0.9560517549432005\n",
            "Test f1 Score: 0.9607118635829275\n",
            "Now predicting labels for unlabeled data...\n",
            "577 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "2812 unlabelled instances remained to be predict in next iteration\n",
            "788 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 75\n",
            "41400 new labelled data is training...\n",
            "Epoch 1/100\n",
            "647/647 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 2/100\n",
            "647/647 [==============================] - 3s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 3/100\n",
            "647/647 [==============================] - 3s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 4/100\n",
            "647/647 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 5/100\n",
            "647/647 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 6/100\n",
            "647/647 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 7/100\n",
            "647/647 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 8/100\n",
            "647/647 [==============================] - 3s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 9/100\n",
            "647/647 [==============================] - 3s 5ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 10/100\n",
            "647/647 [==============================] - 3s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 11/100\n",
            "647/647 [==============================] - 3s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 12/100\n",
            "647/647 [==============================] - 3s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 13/100\n",
            "647/647 [==============================] - 3s 5ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 14/100\n",
            "647/647 [==============================] - 3s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 15/100\n",
            "647/647 [==============================] - 3s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 16/100\n",
            "647/647 [==============================] - 3s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 17/100\n",
            "647/647 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 18/100\n",
            "647/647 [==============================] - 3s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 19/100\n",
            "647/647 [==============================] - 3s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 20/100\n",
            "647/647 [==============================] - 3s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 21/100\n",
            "647/647 [==============================] - 3s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 22/100\n",
            "647/647 [==============================] - 3s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 00022: early stopping\n",
            "Elapsed time: 68.438 sec\n",
            "Train f1 Score: [0.97418331 0.97833693 0.94200409 0.95599967 0.96322332 0.96050725\n",
            " 0.97803409 0.94778214 0.937593   0.92524945]\n",
            "Test f1 Score: [0.97538925 0.9876652  0.95188185 0.96531219 0.96863753 0.96255507\n",
            " 0.97698745 0.94302554 0.94747899 0.92981583]\n",
            "Train f1 Score: 0.9562913250150556\n",
            "Test f1 Score: 0.9608748895210866\n",
            "Now predicting labels for unlabeled data...\n",
            "573 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "2839 unlabelled instances remained to be predict in next iteration\n",
            "761 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 76\n",
            "42000 new labelled data is training...\n",
            "Epoch 1/100\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 2/100\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 3/100\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 4/100\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 5/100\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 6/100\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 7/100\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 8/100\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 9/100\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 10/100\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 11/100\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 12/100\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 13/100\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9989\n",
            "Epoch 14/100\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 15/100\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 16/100\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 17/100\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 18/100\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 19/100\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 20/100\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 21/100\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 22/100\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 23/100\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 24/100\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 25/100\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 26/100\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 27/100\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 28/100\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 29/100\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 30/100\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 31/100\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 32/100\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 33/100\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 34/100\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 35/100\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 36/100\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 00036: early stopping\n",
            "Elapsed time: 113.448 sec\n",
            "Train f1 Score: [0.97476183 0.97834016 0.94208936 0.95643581 0.96288677 0.96059426\n",
            " 0.97889294 0.948078   0.93739039 0.92477839]\n",
            "Test f1 Score: [0.9758794  0.98721904 0.94971537 0.96520875 0.9691358  0.96418733\n",
            " 0.97859008 0.94244958 0.94681411 0.92903226]\n",
            "Train f1 Score: 0.9564247895786101\n",
            "Test f1 Score: 0.9608231715019026\n",
            "Now predicting labels for unlabeled data...\n",
            "570 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "2869 unlabelled instances remained to be predict in next iteration\n",
            "731 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 77\n",
            "42600 new labelled data is training...\n",
            "Epoch 1/100\n",
            "666/666 [==============================] - 3s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 2/100\n",
            "666/666 [==============================] - 3s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 3/100\n",
            "666/666 [==============================] - 3s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 4/100\n",
            "666/666 [==============================] - 3s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 5/100\n",
            "666/666 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 6/100\n",
            "666/666 [==============================] - 3s 5ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 7/100\n",
            "666/666 [==============================] - 3s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 8/100\n",
            "666/666 [==============================] - 3s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 9/100\n",
            "666/666 [==============================] - 3s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 10/100\n",
            "666/666 [==============================] - 3s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 11/100\n",
            "666/666 [==============================] - 3s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 12/100\n",
            "666/666 [==============================] - 3s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 13/100\n",
            "666/666 [==============================] - 3s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 14/100\n",
            "666/666 [==============================] - 3s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 15/100\n",
            "666/666 [==============================] - 3s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 00015: early stopping\n",
            "Elapsed time: 48.391 sec\n",
            "Train f1 Score: [0.9742819  0.97841298 0.94226366 0.95587751 0.9631597  0.96007966\n",
            " 0.97862595 0.94702199 0.93766416 0.92414376]\n",
            "Test f1 Score: [0.9758794  0.9876652  0.95106888 0.96620278 0.9691358  0.96369637\n",
            " 0.97752222 0.94239291 0.94858342 0.9288911 ]\n",
            "Train f1 Score: 0.9561531273256583\n",
            "Test f1 Score: 0.961103808028241\n",
            "Now predicting labels for unlabeled data...\n",
            "571 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "2898 unlabelled instances remained to be predict in next iteration\n",
            "702 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 78\n",
            "43200 new labelled data is training...\n",
            "Epoch 1/100\n",
            "675/675 [==============================] - 3s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 2/100\n",
            "675/675 [==============================] - 3s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 3/100\n",
            "675/675 [==============================] - 3s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 4/100\n",
            "675/675 [==============================] - 3s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 5/100\n",
            "675/675 [==============================] - 3s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 6/100\n",
            "675/675 [==============================] - 3s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 7/100\n",
            "675/675 [==============================] - 3s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 8/100\n",
            "675/675 [==============================] - 3s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 9/100\n",
            "675/675 [==============================] - 3s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 10/100\n",
            "675/675 [==============================] - 3s 5ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9989\n",
            "Epoch 11/100\n",
            "675/675 [==============================] - 3s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 12/100\n",
            "675/675 [==============================] - 3s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 13/100\n",
            "675/675 [==============================] - 3s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 14/100\n",
            "675/675 [==============================] - 3s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 15/100\n",
            "675/675 [==============================] - 3s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 16/100\n",
            "675/675 [==============================] - 3s 5ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 17/100\n",
            "675/675 [==============================] - 3s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 18/100\n",
            "675/675 [==============================] - 3s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 19/100\n",
            "675/675 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 20/100\n",
            "675/675 [==============================] - 3s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 21/100\n",
            "675/675 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 22/100\n",
            "675/675 [==============================] - 3s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 00022: early stopping\n",
            "Elapsed time: 72.965 sec\n",
            "Train f1 Score: [0.97509611 0.97847941 0.94226366 0.95634267 0.96358495 0.96044175\n",
            " 0.97862595 0.94807692 0.93759832 0.92504447]\n",
            "Test f1 Score: [0.9758794  0.98721904 0.95007133 0.96616915 0.96863753 0.96373626\n",
            " 0.97698745 0.94302554 0.9486911  0.93167082]\n",
            "Train f1 Score: 0.9565554209353577\n",
            "Test f1 Score: 0.96120876233771\n",
            "Now predicting labels for unlabeled data...\n",
            "577 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "2921 unlabelled instances remained to be predict in next iteration\n",
            "679 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 79\n",
            "43800 new labelled data is training...\n",
            "Epoch 1/100\n",
            "685/685 [==============================] - 4s 5ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 2/100\n",
            "685/685 [==============================] - 3s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 3/100\n",
            "685/685 [==============================] - 3s 5ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 4/100\n",
            "685/685 [==============================] - 3s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 5/100\n",
            "685/685 [==============================] - 3s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 6/100\n",
            "685/685 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 7/100\n",
            "685/685 [==============================] - 3s 5ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9989\n",
            "Epoch 8/100\n",
            "685/685 [==============================] - 3s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 9/100\n",
            "685/685 [==============================] - 3s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 10/100\n",
            "685/685 [==============================] - 3s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 11/100\n",
            "685/685 [==============================] - 3s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 12/100\n",
            "685/685 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 13/100\n",
            "685/685 [==============================] - 3s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 14/100\n",
            "685/685 [==============================] - 3s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 15/100\n",
            "685/685 [==============================] - 3s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 16/100\n",
            "685/685 [==============================] - 3s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 17/100\n",
            "685/685 [==============================] - 3s 5ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 18/100\n",
            "685/685 [==============================] - 3s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 19/100\n",
            "685/685 [==============================] - 3s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 00019: early stopping\n",
            "Elapsed time: 62.875 sec\n",
            "Train f1 Score: [0.97429907 0.97863789 0.94258138 0.95570403 0.96319754 0.96131896\n",
            " 0.97863683 0.94892387 0.93864709 0.92647432]\n",
            "Test f1 Score: [0.9758794  0.98721904 0.95011876 0.9670987  0.96863753 0.96536559\n",
            " 0.97805643 0.94244958 0.95033978 0.93220339]\n",
            "Train f1 Score: 0.9568420968643963\n",
            "Test f1 Score: 0.9617368201074423\n",
            "Now predicting labels for unlabeled data...\n",
            "579 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "2942 unlabelled instances remained to be predict in next iteration\n",
            "658 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 80\n",
            "44400 new labelled data is training...\n",
            "Epoch 1/100\n",
            "694/694 [==============================] - 3s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 2/100\n",
            "694/694 [==============================] - 3s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 3/100\n",
            "694/694 [==============================] - 3s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 4/100\n",
            "694/694 [==============================] - 3s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 5/100\n",
            "694/694 [==============================] - 3s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 6/100\n",
            "694/694 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 7/100\n",
            "694/694 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 8/100\n",
            "694/694 [==============================] - 3s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 9/100\n",
            "694/694 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 10/100\n",
            "694/694 [==============================] - 3s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 11/100\n",
            "694/694 [==============================] - 4s 5ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 12/100\n",
            "694/694 [==============================] - 3s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 13/100\n",
            "694/694 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 14/100\n",
            "694/694 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 15/100\n",
            "694/694 [==============================] - 3s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 16/100\n",
            "694/694 [==============================] - 3s 5ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 17/100\n",
            "694/694 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 18/100\n",
            "694/694 [==============================] - 3s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 19/100\n",
            "694/694 [==============================] - 3s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 20/100\n",
            "694/694 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 21/100\n",
            "694/694 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 22/100\n",
            "694/694 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 23/100\n",
            "694/694 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 00023: early stopping\n",
            "Elapsed time: 78.004 sec\n",
            "Train f1 Score: [0.9748559  0.97898032 0.94230926 0.95693069 0.9638451  0.9605287\n",
            " 0.97896879 0.94905736 0.93858653 0.9260325 ]\n",
            "Test f1 Score: [0.97637004 0.98765432 0.95026054 0.96658354 0.97019527 0.96483516\n",
            " 0.97752222 0.94348894 0.95028781 0.93406593]\n",
            "Train f1 Score: 0.9570095156456155\n",
            "Test f1 Score: 0.9621263775945035\n",
            "Now predicting labels for unlabeled data...\n",
            "584 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "2958 unlabelled instances remained to be predict in next iteration\n",
            "642 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 81\n",
            "45000 new labelled data is training...\n",
            "Epoch 1/100\n",
            "704/704 [==============================] - 4s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9989\n",
            "Epoch 2/100\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 3/100\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 4/100\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 5/100\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 6/100\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 7/100\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 8/100\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 9/100\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 10/100\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 11/100\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 12/100\n",
            "704/704 [==============================] - 4s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 13/100\n",
            "704/704 [==============================] - 4s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 14/100\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 15/100\n",
            "704/704 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 16/100\n",
            "704/704 [==============================] - 4s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 17/100\n",
            "704/704 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 18/100\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 19/100\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 20/100\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 21/100\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 00021: early stopping\n",
            "Elapsed time: 72.246 sec\n",
            "Train f1 Score: [0.97465399 0.97864107 0.94314928 0.95652174 0.96394004 0.96070264\n",
            " 0.97871258 0.94883497 0.93886845 0.92596985]\n",
            "Test f1 Score: [0.97294589 0.98765432 0.95061728 0.9670987  0.97019527 0.96430533\n",
            " 0.97698745 0.94452626 0.95018353 0.93253373]\n",
            "Train f1 Score: 0.956999462088547\n",
            "Test f1 Score: 0.9617047779000479\n",
            "Now predicting labels for unlabeled data...\n",
            "566 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "2992 unlabelled instances remained to be predict in next iteration\n",
            "608 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 82\n",
            "45600 new labelled data is training...\n",
            "Epoch 1/100\n",
            "713/713 [==============================] - 3s 5ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 2/100\n",
            "713/713 [==============================] - 3s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 3/100\n",
            "713/713 [==============================] - 4s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 4/100\n",
            "713/713 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 5/100\n",
            "713/713 [==============================] - 3s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 6/100\n",
            "713/713 [==============================] - 3s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 7/100\n",
            "713/713 [==============================] - 3s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 8/100\n",
            "713/713 [==============================] - 4s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 9/100\n",
            "713/713 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 10/100\n",
            "713/713 [==============================] - 3s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 11/100\n",
            "713/713 [==============================] - 3s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 12/100\n",
            "713/713 [==============================] - 3s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 13/100\n",
            "713/713 [==============================] - 4s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 14/100\n",
            "713/713 [==============================] - 4s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 15/100\n",
            "713/713 [==============================] - 4s 5ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 16/100\n",
            "713/713 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 17/100\n",
            "713/713 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 18/100\n",
            "713/713 [==============================] - 3s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 19/100\n",
            "713/713 [==============================] - 4s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 20/100\n",
            "713/713 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 21/100\n",
            "713/713 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 22/100\n",
            "713/713 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 23/100\n",
            "713/713 [==============================] - 4s 5ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 24/100\n",
            "713/713 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 25/100\n",
            "713/713 [==============================] - 4s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 26/100\n",
            "713/713 [==============================] - 3s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 27/100\n",
            "713/713 [==============================] - 4s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 28/100\n",
            "713/713 [==============================] - 3s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 29/100\n",
            "713/713 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 30/100\n",
            "713/713 [==============================] - 4s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 31/100\n",
            "713/713 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 32/100\n",
            "713/713 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 33/100\n",
            "713/713 [==============================] - 3s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 34/100\n",
            "713/713 [==============================] - 4s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 35/100\n",
            "713/713 [==============================] - 4s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 36/100\n",
            "713/713 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 37/100\n",
            "713/713 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 38/100\n",
            "713/713 [==============================] - 3s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 39/100\n",
            "713/713 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 40/100\n",
            "713/713 [==============================] - 4s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 41/100\n",
            "713/713 [==============================] - 3s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 42/100\n",
            "713/713 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 00042: early stopping\n",
            "Elapsed time: 147.763 sec\n",
            "Train f1 Score: [0.97521902 0.97849222 0.94307881 0.95673671 0.96402878 0.9601954\n",
            " 0.97914547 0.9495468  0.93829974 0.92700297]\n",
            "Test f1 Score: [0.9748996  0.98721904 0.94926505 0.96565455 0.97072419 0.9669967\n",
            " 0.97859008 0.94250614 0.95018353 0.93446723]\n",
            "Train f1 Score: 0.95717459288047\n",
            "Test f1 Score: 0.9620506126183059\n",
            "Now predicting labels for unlabeled data...\n",
            "568 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3024 unlabelled instances remained to be predict in next iteration\n",
            "576 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 83\n",
            "Train f1 Score: [0.97521902 0.97849222 0.94307881 0.95673671 0.96402878 0.9601954\n",
            " 0.97914547 0.9495468  0.93829974 0.92700297]\n",
            "Test f1 Score: [0.9748996  0.98721904 0.94926505 0.96565455 0.97072419 0.9669967\n",
            " 0.97859008 0.94250614 0.95018353 0.93446723]\n",
            "Train f1 Score: 0.95717459288047\n",
            "Test f1 Score: 0.9620506126183059\n",
            "Now predicting labels for unlabeled data...\n",
            "574 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3050 unlabelled instances remained to be predict in next iteration\n",
            "1150 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 84\n",
            "46200 new labelled data is training...\n",
            "Epoch 1/100\n",
            "722/722 [==============================] - 4s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 2/100\n",
            "722/722 [==============================] - 4s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 3/100\n",
            "722/722 [==============================] - 3s 5ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 4/100\n",
            "722/722 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 5/100\n",
            "722/722 [==============================] - 3s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 6/100\n",
            "722/722 [==============================] - 3s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 7/100\n",
            "722/722 [==============================] - 4s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 8/100\n",
            "722/722 [==============================] - 4s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 9/100\n",
            "722/722 [==============================] - 4s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 10/100\n",
            "722/722 [==============================] - 4s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 11/100\n",
            "722/722 [==============================] - 4s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 12/100\n",
            "722/722 [==============================] - 4s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 13/100\n",
            "722/722 [==============================] - 4s 5ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 14/100\n",
            "722/722 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 15/100\n",
            "722/722 [==============================] - 3s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 00015: early stopping\n",
            "Elapsed time: 53.918 sec\n",
            "Train f1 Score: [0.97496662 0.97856186 0.94257943 0.95660051 0.9639215  0.96143726\n",
            " 0.97898305 0.94921247 0.93885049 0.9262108 ]\n",
            "Test f1 Score: [0.97538925 0.98765432 0.94981061 0.96713147 0.97016461 0.96635411\n",
            " 0.97912317 0.94291339 0.95078534 0.93419741]\n",
            "Train f1 Score: 0.9571324000545669\n",
            "Test f1 Score: 0.9623523678244181\n",
            "Now predicting labels for unlabeled data...\n",
            "572 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3078 unlabelled instances remained to be predict in next iteration\n",
            "1122 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 85\n",
            "46800 new labelled data is training...\n",
            "Epoch 1/100\n",
            "732/732 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 2/100\n",
            "732/732 [==============================] - 4s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 3/100\n",
            "732/732 [==============================] - 4s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 4/100\n",
            "732/732 [==============================] - 4s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 5/100\n",
            "732/732 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 6/100\n",
            "732/732 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 7/100\n",
            "732/732 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 8/100\n",
            "732/732 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 9/100\n",
            "732/732 [==============================] - 4s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 10/100\n",
            "732/732 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 11/100\n",
            "732/732 [==============================] - 4s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 12/100\n",
            "732/732 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 13/100\n",
            "732/732 [==============================] - 3s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 14/100\n",
            "732/732 [==============================] - 3s 5ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9989\n",
            "Epoch 15/100\n",
            "732/732 [==============================] - 3s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 16/100\n",
            "732/732 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 17/100\n",
            "732/732 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 18/100\n",
            "732/732 [==============================] - 3s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 19/100\n",
            "732/732 [==============================] - 3s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 20/100\n",
            "732/732 [==============================] - 4s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 21/100\n",
            "732/732 [==============================] - 3s 5ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 22/100\n",
            "732/732 [==============================] - 4s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 23/100\n",
            "732/732 [==============================] - 3s 5ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 24/100\n",
            "732/732 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 25/100\n",
            "732/732 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 26/100\n",
            "732/732 [==============================] - 3s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 27/100\n",
            "732/732 [==============================] - 4s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 28/100\n",
            "732/732 [==============================] - 3s 5ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 29/100\n",
            "732/732 [==============================] - 3s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 30/100\n",
            "732/732 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 31/100\n",
            "732/732 [==============================] - 4s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 32/100\n",
            "732/732 [==============================] - 4s 5ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 33/100\n",
            "732/732 [==============================] - 4s 5ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 34/100\n",
            "732/732 [==============================] - 4s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 35/100\n",
            "732/732 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 00035: early stopping\n",
            "Elapsed time: 125.151 sec\n",
            "Train f1 Score: [0.9754509  0.97847941 0.9423391  0.95649313 0.96395857 0.96085538\n",
            " 0.97887862 0.94882079 0.93869329 0.92594476]\n",
            "Test f1 Score: [0.9758794  0.98765432 0.94976303 0.96623635 0.9717804  0.96696035\n",
            " 0.97957046 0.94296952 0.94968553 0.93406593]\n",
            "Train f1 Score: 0.9569913951773195\n",
            "Test f1 Score: 0.9624565291940883\n",
            "Now predicting labels for unlabeled data...\n",
            "581 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3097 unlabelled instances remained to be predict in next iteration\n",
            "1103 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 86\n",
            "47400 new labelled data is training...\n",
            "Epoch 1/100\n",
            "741/741 [==============================] - 4s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 2/100\n",
            "741/741 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 3/100\n",
            "741/741 [==============================] - 4s 5ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 4/100\n",
            "741/741 [==============================] - 4s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 5/100\n",
            "741/741 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 6/100\n",
            "741/741 [==============================] - 4s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 7/100\n",
            "741/741 [==============================] - 4s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 8/100\n",
            "741/741 [==============================] - 4s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 9/100\n",
            "741/741 [==============================] - 3s 5ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 10/100\n",
            "741/741 [==============================] - 4s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 11/100\n",
            "741/741 [==============================] - 4s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 12/100\n",
            "741/741 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 13/100\n",
            "741/741 [==============================] - 4s 5ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 14/100\n",
            "741/741 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 15/100\n",
            "741/741 [==============================] - 4s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 00015: early stopping\n",
            "Elapsed time: 54.776 sec\n",
            "Train f1 Score: [0.97513766 0.97862834 0.94242548 0.9563999  0.96375011 0.96009411\n",
            " 0.97879199 0.94916613 0.93862184 0.92613925]\n",
            "Test f1 Score: [0.97392177 0.98721904 0.95021337 0.96713147 0.97016461 0.96816685\n",
            " 0.97801047 0.94152334 0.95068206 0.9326011 ]\n",
            "Train f1 Score: 0.9569154811575679\n",
            "Test f1 Score: 0.9619634076302279\n",
            "Now predicting labels for unlabeled data...\n",
            "570 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3127 unlabelled instances remained to be predict in next iteration\n",
            "1073 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 87\n",
            "48000 new labelled data is training...\n",
            "Epoch 1/100\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 2/100\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 3/100\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 4/100\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 5/100\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 6/100\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 7/100\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 8/100\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 9/100\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 10/100\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 11/100\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 12/100\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 13/100\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 14/100\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 15/100\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 16/100\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 17/100\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 18/100\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 19/100\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9989\n",
            "Epoch 20/100\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 21/100\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 22/100\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 23/100\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 24/100\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 00024: early stopping\n",
            "Elapsed time: 89.833 sec\n",
            "Train f1 Score: [0.97600936 0.97862834 0.94196283 0.95633548 0.96426429 0.9606599\n",
            " 0.97921792 0.9488723  0.93921106 0.92639594]\n",
            "Test f1 Score: [0.97637004 0.98765432 0.94985809 0.96713147 0.97072419 0.9675646\n",
            " 0.98010471 0.94296952 0.94963274 0.93366584]\n",
            "Train f1 Score: 0.9571557408774348\n",
            "Test f1 Score: 0.9625675510574692\n",
            "Now predicting labels for unlabeled data...\n",
            "579 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3148 unlabelled instances remained to be predict in next iteration\n",
            "1052 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 88\n",
            "48600 new labelled data is training...\n",
            "Epoch 1/100\n",
            "760/760 [==============================] - 4s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 2/100\n",
            "760/760 [==============================] - 4s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 3/100\n",
            "760/760 [==============================] - 4s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 4/100\n",
            "760/760 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 5/100\n",
            "760/760 [==============================] - 4s 5ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 6/100\n",
            "760/760 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 7/100\n",
            "760/760 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 8/100\n",
            "760/760 [==============================] - 4s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 9/100\n",
            "760/760 [==============================] - 4s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 10/100\n",
            "760/760 [==============================] - 4s 5ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 11/100\n",
            "760/760 [==============================] - 4s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 12/100\n",
            "760/760 [==============================] - 4s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 13/100\n",
            "760/760 [==============================] - 4s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 14/100\n",
            "760/760 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 15/100\n",
            "760/760 [==============================] - 4s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 16/100\n",
            "760/760 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 17/100\n",
            "760/760 [==============================] - 4s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 00017: early stopping\n",
            "Elapsed time: 63.455 sec\n",
            "Train f1 Score: [0.97571154 0.97877411 0.9423391  0.9562212  0.96380594 0.96024631\n",
            " 0.97904471 0.94896485 0.93875405 0.92612674]\n",
            "Test f1 Score: [0.9748996  0.98765432 0.94976303 0.96668324 0.97131148 0.96809681\n",
            " 0.98008386 0.94296952 0.95068206 0.93353323]\n",
            "Train f1 Score: 0.9569988558790332\n",
            "Test f1 Score: 0.9625677145495046\n",
            "Now predicting labels for unlabeled data...\n",
            "580 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3168 unlabelled instances remained to be predict in next iteration\n",
            "1032 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 89\n",
            "49200 new labelled data is training...\n",
            "Epoch 1/100\n",
            "769/769 [==============================] - 4s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 2/100\n",
            "769/769 [==============================] - 4s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 3/100\n",
            "769/769 [==============================] - 4s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 4/100\n",
            "769/769 [==============================] - 4s 5ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 5/100\n",
            "769/769 [==============================] - 4s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 6/100\n",
            "769/769 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 7/100\n",
            "769/769 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 8/100\n",
            "769/769 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 9/100\n",
            "769/769 [==============================] - 4s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 10/100\n",
            "769/769 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 11/100\n",
            "769/769 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 12/100\n",
            "769/769 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 13/100\n",
            "769/769 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 14/100\n",
            "769/769 [==============================] - 4s 5ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 15/100\n",
            "769/769 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 16/100\n",
            "769/769 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 17/100\n",
            "769/769 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 18/100\n",
            "769/769 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 19/100\n",
            "769/769 [==============================] - 4s 5ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9989\n",
            "Epoch 20/100\n",
            "769/769 [==============================] - 4s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 21/100\n",
            "769/769 [==============================] - 4s 5ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 22/100\n",
            "769/769 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 23/100\n",
            "769/769 [==============================] - 4s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 24/100\n",
            "769/769 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 25/100\n",
            "769/769 [==============================] - 4s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 26/100\n",
            "769/769 [==============================] - 4s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 00026: early stopping\n",
            "Elapsed time: 97.449 sec\n",
            "Train f1 Score: [0.97633977 0.97883756 0.9416755  0.95604215 0.9636613  0.959819\n",
            " 0.97889294 0.9492451  0.93791652 0.92525969]\n",
            "Test f1 Score: [0.97637004 0.98765432 0.94981061 0.96767777 0.97016461 0.96813187\n",
            " 0.97856769 0.94244958 0.95057834 0.93326693]\n",
            "Train f1 Score: 0.9567689529247628\n",
            "Test f1 Score: 0.9624671759160682\n",
            "Now predicting labels for unlabeled data...\n",
            "585 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3183 unlabelled instances remained to be predict in next iteration\n",
            "1017 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 90\n",
            "49800 new labelled data is training...\n",
            "Epoch 1/100\n",
            "779/779 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 2/100\n",
            "779/779 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 3/100\n",
            "779/779 [==============================] - 4s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 4/100\n",
            "779/779 [==============================] - 4s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 5/100\n",
            "779/779 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 6/100\n",
            "779/779 [==============================] - 4s 5ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 7/100\n",
            "779/779 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 8/100\n",
            "779/779 [==============================] - 4s 5ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 9/100\n",
            "779/779 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 10/100\n",
            "779/779 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 11/100\n",
            "779/779 [==============================] - 4s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 12/100\n",
            "779/779 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 13/100\n",
            "779/779 [==============================] - 4s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 14/100\n",
            "779/779 [==============================] - 4s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 15/100\n",
            "779/779 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 16/100\n",
            "779/779 [==============================] - 4s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 17/100\n",
            "779/779 [==============================] - 4s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 18/100\n",
            "779/779 [==============================] - 4s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 00018: early stopping\n",
            "Elapsed time: 69.041 sec\n",
            "Train f1 Score: [0.97642929 0.97833048 0.94176183 0.95655036 0.9638141  0.95997827\n",
            " 0.97955375 0.94885362 0.93833874 0.92517122]\n",
            "Test f1 Score: [0.9758794  0.98721904 0.94931312 0.96719682 0.97169326 0.96809681\n",
            " 0.97905759 0.94152334 0.95218077 0.93379791]\n",
            "Train f1 Score: 0.95687816434354\n",
            "Test f1 Score: 0.9625958054331358\n",
            "Now predicting labels for unlabeled data...\n",
            "580 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3203 unlabelled instances remained to be predict in next iteration\n",
            "997 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 91\n",
            "50400 new labelled data is training...\n",
            "Epoch 1/100\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 2/100\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 3/100\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 4/100\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 5/100\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 6/100\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 7/100\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 8/100\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 9/100\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 10/100\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 11/100\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 12/100\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 13/100\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 14/100\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 15/100\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 16/100\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 17/100\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 18/100\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 19/100\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 20/100\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 21/100\n",
            "788/788 [==============================] - 4s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 00021: early stopping\n",
            "Elapsed time: 81.050 sec\n",
            "Train f1 Score: [0.97555277 0.97892307 0.94254189 0.95657906 0.96424294 0.9603189\n",
            " 0.97922849 0.94886181 0.94082685 0.9264606 ]\n",
            "Test f1 Score: [0.97441044 0.98721904 0.9487666  0.96713147 0.97128205 0.96809681\n",
            " 0.9790795  0.94204322 0.95183246 0.93587174]\n",
            "Train f1 Score: 0.9573536374566446\n",
            "Test f1 Score: 0.9625733338366178\n",
            "Now predicting labels for unlabeled data...\n",
            "571 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3232 unlabelled instances remained to be predict in next iteration\n",
            "968 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 92\n",
            "51000 new labelled data is training...\n",
            "Epoch 1/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 2/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 3/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 4/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 5/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 6/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 7/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 8/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 9/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 10/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 11/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 12/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 13/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 14/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 15/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 16/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 17/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 18/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 19/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 20/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 21/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 22/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 23/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 24/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 25/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 26/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 27/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 28/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 29/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 30/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 31/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 32/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 33/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 34/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 35/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9989\n",
            "Epoch 36/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 37/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 38/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 39/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 40/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 41/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 42/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 43/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 44/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 45/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 46/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 47/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 48/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 49/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 50/100\n",
            "797/797 [==============================] - 4s 5ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 00050: early stopping\n",
            "Elapsed time: 196.156 sec\n",
            "Train f1 Score: [0.97651091 0.97898346 0.94144511 0.95658609 0.96375011 0.96119674\n",
            " 0.97895809 0.94896485 0.94063128 0.92727119]\n",
            "Test f1 Score: [0.9758794  0.98765432 0.94931312 0.96620278 0.97119342 0.9669967\n",
            " 0.97798742 0.94343335 0.95078534 0.93519442]\n",
            "Train f1 Score: 0.9574297821116347\n",
            "Test f1 Score: 0.9624640266500852\n",
            "Now predicting labels for unlabeled data...\n",
            "585 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3247 unlabelled instances remained to be predict in next iteration\n",
            "953 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 93\n",
            "51600 new labelled data is training...\n",
            "Epoch 1/100\n",
            "807/807 [==============================] - 4s 5ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 2/100\n",
            "807/807 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 3/100\n",
            "807/807 [==============================] - 4s 5ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 4/100\n",
            "807/807 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 5/100\n",
            "807/807 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 6/100\n",
            "807/807 [==============================] - 4s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 7/100\n",
            "807/807 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 8/100\n",
            "807/807 [==============================] - 4s 5ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 9/100\n",
            "807/807 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 10/100\n",
            "807/807 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 11/100\n",
            "807/807 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 12/100\n",
            "807/807 [==============================] - 4s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 13/100\n",
            "807/807 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 00013: early stopping\n",
            "Elapsed time: 51.622 sec\n",
            "Train f1 Score: [0.97636743 0.97891364 0.94111898 0.95566178 0.96369241 0.95982628\n",
            " 0.97884991 0.94892387 0.9403429  0.9264656 ]\n",
            "Test f1 Score: [0.9748996  0.98765432 0.94945678 0.9670987  0.97175141 0.96706915\n",
            " 0.97745149 0.94291339 0.95018353 0.93506494]\n",
            "Train f1 Score: 0.9570162804751794\n",
            "Test f1 Score: 0.9623543318666817\n",
            "Now predicting labels for unlabeled data...\n",
            "582 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3265 unlabelled instances remained to be predict in next iteration\n",
            "935 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 94\n",
            "52200 new labelled data is training...\n",
            "Epoch 1/100\n",
            "816/816 [==============================] - 4s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 2/100\n",
            "816/816 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 3/100\n",
            "816/816 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 4/100\n",
            "816/816 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 5/100\n",
            "816/816 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 6/100\n",
            "816/816 [==============================] - 4s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 7/100\n",
            "816/816 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 8/100\n",
            "816/816 [==============================] - 4s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 9/100\n",
            "816/816 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 10/100\n",
            "816/816 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 11/100\n",
            "816/816 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 12/100\n",
            "816/816 [==============================] - 4s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 13/100\n",
            "816/816 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 14/100\n",
            "816/816 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 15/100\n",
            "816/816 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 16/100\n",
            "816/816 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 17/100\n",
            "816/816 [==============================] - 4s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 18/100\n",
            "816/816 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 19/100\n",
            "816/816 [==============================] - 4s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 20/100\n",
            "816/816 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 00020: early stopping\n",
            "Elapsed time: 80.753 sec\n",
            "Train f1 Score: [0.9764411  0.97841298 0.94189652 0.95665049 0.96376874 0.96128389\n",
            " 0.97929747 0.94922596 0.9395691  0.92650296]\n",
            "Test f1 Score: [0.97538925 0.98721904 0.94891202 0.96623635 0.97122302 0.96749311\n",
            " 0.97959184 0.94389764 0.95063025 0.93512974]\n",
            "Train f1 Score: 0.9573049215416173\n",
            "Test f1 Score: 0.9625722253254951\n",
            "Now predicting labels for unlabeled data...\n",
            "582 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3283 unlabelled instances remained to be predict in next iteration\n",
            "917 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 95\n",
            "52800 new labelled data is training...\n",
            "Epoch 1/100\n",
            "825/825 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 2/100\n",
            "825/825 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 3/100\n",
            "825/825 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 4/100\n",
            "825/825 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 5/100\n",
            "825/825 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 6/100\n",
            "825/825 [==============================] - 4s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 7/100\n",
            "825/825 [==============================] - 4s 5ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 8/100\n",
            "825/825 [==============================] - 4s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 9/100\n",
            "825/825 [==============================] - 4s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 10/100\n",
            "825/825 [==============================] - 4s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 11/100\n",
            "825/825 [==============================] - 4s 5ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 12/100\n",
            "825/825 [==============================] - 4s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 13/100\n",
            "825/825 [==============================] - 4s 5ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 14/100\n",
            "825/825 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 15/100\n",
            "825/825 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 16/100\n",
            "825/825 [==============================] - 4s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 17/100\n",
            "825/825 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 18/100\n",
            "825/825 [==============================] - 4s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 19/100\n",
            "825/825 [==============================] - 4s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 20/100\n",
            "825/825 [==============================] - 4s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 21/100\n",
            "825/825 [==============================] - 4s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 22/100\n",
            "825/825 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 23/100\n",
            "825/825 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 24/100\n",
            "825/825 [==============================] - 4s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 25/100\n",
            "825/825 [==============================] - 4s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 00025: early stopping\n",
            "Elapsed time: 102.493 sec\n",
            "Train f1 Score: [0.97668589 0.97863471 0.94208809 0.95664336 0.96377494 0.96050725\n",
            " 0.97921792 0.9487797  0.93973371 0.92589142]\n",
            "Test f1 Score: [0.97686117 0.98721904 0.9483657  0.96770989 0.97227926 0.96703297\n",
            " 0.97852279 0.94198623 0.95073375 0.936     ]\n",
            "Train f1 Score: 0.9571956975318272\n",
            "Test f1 Score: 0.9626710796681891\n",
            "Now predicting labels for unlabeled data...\n",
            "579 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3304 unlabelled instances remained to be predict in next iteration\n",
            "896 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 96\n",
            "53400 new labelled data is training...\n",
            "Epoch 1/100\n",
            "835/835 [==============================] - 4s 5ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 2/100\n",
            "835/835 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 3/100\n",
            "835/835 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 4/100\n",
            "835/835 [==============================] - 4s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 5/100\n",
            "835/835 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 6/100\n",
            "835/835 [==============================] - 4s 5ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 7/100\n",
            "835/835 [==============================] - 4s 5ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 8/100\n",
            "835/835 [==============================] - 4s 5ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 9/100\n",
            "835/835 [==============================] - 4s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 10/100\n",
            "835/835 [==============================] - 4s 5ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9989\n",
            "Epoch 11/100\n",
            "835/835 [==============================] - 4s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 12/100\n",
            "835/835 [==============================] - 4s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 13/100\n",
            "835/835 [==============================] - 4s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 14/100\n",
            "835/835 [==============================] - 4s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 15/100\n",
            "835/835 [==============================] - 4s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 16/100\n",
            "835/835 [==============================] - 4s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 17/100\n",
            "835/835 [==============================] - 4s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 18/100\n",
            "835/835 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 19/100\n",
            "835/835 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 00019: early stopping\n",
            "Elapsed time: 78.567 sec\n",
            "Train f1 Score: [0.9770163  0.9788344  0.94212717 0.95605662 0.96367375 0.95820922\n",
            " 0.97921439 0.94934274 0.93922361 0.92568139]\n",
            "Test f1 Score: [0.97686117 0.98765432 0.94971537 0.96770989 0.97122302 0.966046\n",
            " 0.97905759 0.94354443 0.95162986 0.93506494]\n",
            "Train f1 Score: 0.956937959205912\n",
            "Test f1 Score: 0.9628506585594898\n",
            "Now predicting labels for unlabeled data...\n",
            "580 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3324 unlabelled instances remained to be predict in next iteration\n",
            "876 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 97\n",
            "54000 new labelled data is training...\n",
            "Epoch 1/100\n",
            "844/844 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 2/100\n",
            "844/844 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 3/100\n",
            "844/844 [==============================] - 4s 5ms/step - loss: 0.0053 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 4/100\n",
            "844/844 [==============================] - 4s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 5/100\n",
            "844/844 [==============================] - 4s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 6/100\n",
            "844/844 [==============================] - 4s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 7/100\n",
            "844/844 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 8/100\n",
            "844/844 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 9/100\n",
            "844/844 [==============================] - 4s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 10/100\n",
            "844/844 [==============================] - 4s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 11/100\n",
            "844/844 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 12/100\n",
            "844/844 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 13/100\n",
            "844/844 [==============================] - 4s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 14/100\n",
            "844/844 [==============================] - 4s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 15/100\n",
            "844/844 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 16/100\n",
            "844/844 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 17/100\n",
            "844/844 [==============================] - 4s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 18/100\n",
            "844/844 [==============================] - 4s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 19/100\n",
            "844/844 [==============================] - 4s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 20/100\n",
            "844/844 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 21/100\n",
            "844/844 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 22/100\n",
            "844/844 [==============================] - 4s 5ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 23/100\n",
            "844/844 [==============================] - 4s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 24/100\n",
            "844/844 [==============================] - 4s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 25/100\n",
            "844/844 [==============================] - 4s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 26/100\n",
            "844/844 [==============================] - 4s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 27/100\n",
            "844/844 [==============================] - 4s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 28/100\n",
            "844/844 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 29/100\n",
            "844/844 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 30/100\n",
            "844/844 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 31/100\n",
            "844/844 [==============================] - 4s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 32/100\n",
            "844/844 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 33/100\n",
            "844/844 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 34/100\n",
            "844/844 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 00034: early stopping\n",
            "Elapsed time: 143.464 sec\n",
            "Train f1 Score: [0.97678691 0.97832725 0.94196283 0.95641447 0.96393386 0.96163265\n",
            " 0.9796334  0.94942197 0.93949491 0.92635495]\n",
            "Test f1 Score: [0.97392177 0.98721904 0.94791667 0.9657228  0.97175141 0.96696035\n",
            " 0.97798742 0.94389764 0.9511298  0.93519442]\n",
            "Train f1 Score: 0.9573963210697152\n",
            "Test f1 Score: 0.9621701308816648\n",
            "Now predicting labels for unlabeled data...\n",
            "590 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3334 unlabelled instances remained to be predict in next iteration\n",
            "866 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 98\n",
            "54600 new labelled data is training...\n",
            "Epoch 1/100\n",
            "854/854 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 2/100\n",
            "854/854 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 3/100\n",
            "854/854 [==============================] - 4s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 4/100\n",
            "854/854 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 5/100\n",
            "854/854 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 6/100\n",
            "854/854 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 7/100\n",
            "854/854 [==============================] - 4s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 8/100\n",
            "854/854 [==============================] - 4s 5ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 9/100\n",
            "854/854 [==============================] - 4s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 10/100\n",
            "854/854 [==============================] - 4s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 11/100\n",
            "854/854 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 12/100\n",
            "854/854 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 13/100\n",
            "854/854 [==============================] - 4s 5ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 14/100\n",
            "854/854 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 15/100\n",
            "854/854 [==============================] - 4s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 16/100\n",
            "854/854 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 17/100\n",
            "854/854 [==============================] - 4s 5ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9989\n",
            "Epoch 18/100\n",
            "854/854 [==============================] - 4s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 19/100\n",
            "854/854 [==============================] - 4s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 20/100\n",
            "854/854 [==============================] - 4s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 21/100\n",
            "854/854 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 22/100\n",
            "854/854 [==============================] - 4s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 23/100\n",
            "854/854 [==============================] - 4s 5ms/step - loss: 0.0032 - sparse_categorical_accuracy: 0.9990\n",
            "Epoch 24/100\n",
            "854/854 [==============================] - 4s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 25/100\n",
            "854/854 [==============================] - 4s 5ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 26/100\n",
            "854/854 [==============================] - 4s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 27/100\n",
            "854/854 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 28/100\n",
            "854/854 [==============================] - 4s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 29/100\n",
            "854/854 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 30/100\n",
            "854/854 [==============================] - 4s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 31/100\n",
            "854/854 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 32/100\n",
            "854/854 [==============================] - 4s 5ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 33/100\n",
            "854/854 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 34/100\n",
            "854/854 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 35/100\n",
            "854/854 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 00035: early stopping\n",
            "Elapsed time: 148.252 sec\n",
            "Train f1 Score: [0.97670146 0.9788344  0.94177133 0.95598519 0.96357247 0.96042742\n",
            " 0.97946368 0.94948685 0.93927977 0.92540852]\n",
            "Test f1 Score: [0.97441044 0.98765432 0.9483657  0.9681592  0.97175141 0.96923077\n",
            " 0.97798742 0.94302554 0.95323174 0.93512974]\n",
            "Train f1 Score: 0.9570931085977697\n",
            "Test f1 Score: 0.9628946288150392\n",
            "Now predicting labels for unlabeled data...\n",
            "588 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3346 unlabelled instances remained to be predict in next iteration\n",
            "854 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 99\n",
            "55200 new labelled data is training...\n",
            "Epoch 1/100\n",
            "863/863 [==============================] - 4s 5ms/step - loss: 0.0031 - sparse_categorical_accuracy: 0.9991\n",
            "Epoch 2/100\n",
            "863/863 [==============================] - 4s 5ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9989\n",
            "Epoch 3/100\n",
            "863/863 [==============================] - 4s 5ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9989\n",
            "Epoch 4/100\n",
            "863/863 [==============================] - 4s 5ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 5/100\n",
            "863/863 [==============================] - 4s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 6/100\n",
            "863/863 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 7/100\n",
            "863/863 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 8/100\n",
            "863/863 [==============================] - 4s 5ms/step - loss: 0.0050 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 9/100\n",
            "863/863 [==============================] - 4s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 10/100\n",
            "863/863 [==============================] - 4s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 11/100\n",
            "863/863 [==============================] - 4s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 12/100\n",
            "863/863 [==============================] - 4s 5ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 13/100\n",
            "863/863 [==============================] - 4s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9989\n",
            "Epoch 00013: early stopping\n",
            "Elapsed time: 55.237 sec\n",
            "Train f1 Score: [0.97718345 0.97854908 0.94181967 0.95630708 0.96416324 0.96025351\n",
            " 0.97974061 0.94947875 0.93899763 0.92545639]\n",
            "Test f1 Score: [0.97686117 0.98765432 0.94931312 0.96716418 0.97122302 0.96706915\n",
            " 0.97852279 0.94302554 0.95378151 0.93519442]\n",
            "Train f1 Score: 0.9571949411994384\n",
            "Test f1 Score: 0.9629809221624314\n",
            "Now predicting labels for unlabeled data...\n",
            "446 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "2900 unlabelled instances remained to be predict in next iteration\n",
            "700 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 100\n",
            "55800 new labelled data is training...\n",
            "Epoch 1/100\n",
            "872/872 [==============================] - 5s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 2/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 3/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 4/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 5/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 6/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 7/100\n",
            "872/872 [==============================] - 5s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 8/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 9/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 10/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 11/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 12/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 13/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 14/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 15/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 16/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 17/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0052 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 18/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 19/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 20/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 21/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0041 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 22/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 23/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 24/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 25/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 26/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 27/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 28/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 29/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 30/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 31/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 32/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0045 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 33/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 34/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 35/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 36/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 37/100\n",
            "872/872 [==============================] - 5s 5ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9986\n",
            "Epoch 38/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 39/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 40/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 41/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 42/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0046 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 43/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 44/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 45/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 46/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 47/100\n",
            "872/872 [==============================] - 4s 5ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 00047: early stopping\n",
            "Elapsed time: 202.348 sec\n",
            "Train f1 Score: [0.97727652 0.97833048 0.94150281 0.95643581 0.96385749 0.96155938\n",
            " 0.97956068 0.94953871 0.93981603 0.92574425]\n",
            "Test f1 Score: [0.97538925 0.98765432 0.94891202 0.96812749 0.97277863 0.9669967\n",
            " 0.97903564 0.94198623 0.95387841 0.93313373]\n",
            "Train f1 Score: 0.9573622164536953\n",
            "Test f1 Score: 0.9627892423940727\n",
            "Now predicting labels for unlabeled data...\n",
            "387 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "2513 unlabelled instances remained to be predict in next iteration\n",
            "487 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 101\n",
            "Train f1 Score: [0.97727652 0.97833048 0.94150281 0.95643581 0.96385749 0.96155938\n",
            " 0.97956068 0.94953871 0.93981603 0.92574425]\n",
            "Test f1 Score: [0.97538925 0.98765432 0.94891202 0.96812749 0.97277863 0.9669967\n",
            " 0.97903564 0.94198623 0.95387841 0.93313373]\n",
            "Train f1 Score: 0.9573622164536953\n",
            "Test f1 Score: 0.9627892423940727\n",
            "Now predicting labels for unlabeled data...\n",
            "343 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "2170 unlabelled instances remained to be predict in next iteration\n",
            "830 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 102\n",
            "56400 new labelled data is training...\n",
            "Epoch 1/100\n",
            "882/882 [==============================] - 4s 5ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 2/100\n",
            "882/882 [==============================] - 4s 5ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 3/100\n",
            "882/882 [==============================] - 4s 5ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 4/100\n",
            "882/882 [==============================] - 4s 5ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 5/100\n",
            "882/882 [==============================] - 4s 5ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 6/100\n",
            "882/882 [==============================] - 4s 5ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 7/100\n",
            "882/882 [==============================] - 4s 5ms/step - loss: 0.0055 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 8/100\n",
            "882/882 [==============================] - 5s 5ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 9/100\n",
            "882/882 [==============================] - 4s 5ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 10/100\n",
            "882/882 [==============================] - 4s 5ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 11/100\n",
            "882/882 [==============================] - 4s 5ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 12/100\n",
            "882/882 [==============================] - 4s 5ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 13/100\n",
            "882/882 [==============================] - 4s 5ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 14/100\n",
            "882/882 [==============================] - 4s 5ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 15/100\n",
            "882/882 [==============================] - 4s 5ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 00015: early stopping\n",
            "Elapsed time: 64.941 sec\n",
            "Train f1 Score: [0.97752527 0.9784762  0.94156003 0.9562639  0.96468975 0.9614792\n",
            " 0.97998643 0.95015227 0.94001226 0.92731278]\n",
            "Test f1 Score: [0.97686117 0.98808999 0.95085066 0.96767777 0.97277863 0.96809681\n",
            " 0.98010471 0.94447174 0.95492662 0.936     ]\n",
            "Train f1 Score: 0.9577458090391826\n",
            "Test f1 Score: 0.9639858112375108\n",
            "Now predicting labels for unlabeled data...\n",
            "227 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "1943 unlabelled instances remained to be predict in next iteration\n",
            "457 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 103\n",
            "Train f1 Score: [0.97752527 0.9784762  0.94156003 0.9562639  0.96468975 0.9614792\n",
            " 0.97998643 0.95015227 0.94001226 0.92731278]\n",
            "Test f1 Score: [0.97686117 0.98808999 0.95085066 0.96767777 0.97277863 0.96809681\n",
            " 0.98010471 0.94447174 0.95492662 0.936     ]\n",
            "Train f1 Score: 0.9577458090391826\n",
            "Test f1 Score: 0.9639858112375108\n",
            "Now predicting labels for unlabeled data...\n",
            "142 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "1801 unlabelled instances remained to be predict in next iteration\n",
            "599 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 104\n",
            "Train f1 Score: [0.97752527 0.9784762  0.94156003 0.9562639  0.96468975 0.9614792\n",
            " 0.97998643 0.95015227 0.94001226 0.92731278]\n",
            "Test f1 Score: [0.97686117 0.98808999 0.95085066 0.96767777 0.97277863 0.96809681\n",
            " 0.98010471 0.94447174 0.95492662 0.936     ]\n",
            "Train f1 Score: 0.9577458090391826\n",
            "Test f1 Score: 0.9639858112375108\n",
            "Now predicting labels for unlabeled data...\n",
            "41 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "1760 unlabelled instances remained to be predict in next iteration\n",
            "640 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 105\n",
            "57000 new labelled data is training...\n",
            "Epoch 1/100\n",
            "891/891 [==============================] - 5s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 2/100\n",
            "891/891 [==============================] - 5s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 3/100\n",
            "891/891 [==============================] - 5s 5ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 4/100\n",
            "891/891 [==============================] - 4s 5ms/step - loss: 0.0089 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 5/100\n",
            "891/891 [==============================] - 5s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 6/100\n",
            "891/891 [==============================] - 5s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 7/100\n",
            "891/891 [==============================] - 4s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 8/100\n",
            "891/891 [==============================] - 4s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 9/100\n",
            "891/891 [==============================] - 5s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 10/100\n",
            "891/891 [==============================] - 5s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 11/100\n",
            "891/891 [==============================] - 4s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 12/100\n",
            "891/891 [==============================] - 4s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 13/100\n",
            "891/891 [==============================] - 4s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 14/100\n",
            "891/891 [==============================] - 4s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 15/100\n",
            "891/891 [==============================] - 5s 5ms/step - loss: 0.0089 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 16/100\n",
            "891/891 [==============================] - 4s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 17/100\n",
            "891/891 [==============================] - 4s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 00017: early stopping\n",
            "Elapsed time: 76.467 sec\n",
            "Train f1 Score: [0.97859532 0.97877095 0.94290375 0.95756382 0.96537539 0.96240465\n",
            " 0.97998304 0.95088283 0.94103216 0.92856539]\n",
            "Test f1 Score: [0.97784491 0.98765432 0.95085066 0.96924603 0.97280657 0.96752889\n",
            " 0.98057743 0.94488189 0.95487933 0.93765586]\n",
            "Train f1 Score: 0.9586077281032171\n",
            "Test f1 Score: 0.9643925896382599\n",
            "Now predicting labels for unlabeled data...\n",
            "36 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "1724 unlabelled instances remained to be predict in next iteration\n",
            "76 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 106\n",
            "Train f1 Score: [0.97859532 0.97877095 0.94290375 0.95756382 0.96537539 0.96240465\n",
            " 0.97998304 0.95088283 0.94103216 0.92856539]\n",
            "Test f1 Score: [0.97784491 0.98765432 0.95085066 0.96924603 0.97280657 0.96752889\n",
            " 0.98057743 0.94488189 0.95487933 0.93765586]\n",
            "Train f1 Score: 0.9586077281032171\n",
            "Test f1 Score: 0.9643925896382599\n",
            "Now predicting labels for unlabeled data...\n",
            "33 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "1691 unlabelled instances remained to be predict in next iteration\n",
            "109 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 107\n",
            "Train f1 Score: [0.97859532 0.97877095 0.94290375 0.95756382 0.96537539 0.96240465\n",
            " 0.97998304 0.95088283 0.94103216 0.92856539]\n",
            "Test f1 Score: [0.97784491 0.98765432 0.95085066 0.96924603 0.97280657 0.96752889\n",
            " 0.98057743 0.94488189 0.95487933 0.93765586]\n",
            "Train f1 Score: 0.9586077281032171\n",
            "Test f1 Score: 0.9643925896382599\n",
            "Now predicting labels for unlabeled data...\n",
            "23 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "1668 unlabelled instances remained to be predict in next iteration\n",
            "132 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 108\n",
            "Train f1 Score: [0.97859532 0.97877095 0.94290375 0.95756382 0.96537539 0.96240465\n",
            " 0.97998304 0.95088283 0.94103216 0.92856539]\n",
            "Test f1 Score: [0.97784491 0.98765432 0.95085066 0.96924603 0.97280657 0.96752889\n",
            " 0.98057743 0.94488189 0.95487933 0.93765586]\n",
            "Train f1 Score: 0.9586077281032171\n",
            "Test f1 Score: 0.9643925896382599\n",
            "Now predicting labels for unlabeled data...\n",
            "0 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "1668 unlabelled instances remained to be predict in next iteration\n",
            "132 labelled instances are going to be added to train dataset in next iteration.\n",
            "*** Model's Learning is finished. ***\n",
            "In the end, 600 pre-labelled images and 57132 pseudo-labelled images added to train dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ptVpUu83tRr-",
        "outputId": "c799cd84-a259-4161-e15a-3ce5e91212bf"
      },
      "source": [
        "plot_result(y_test, y_test_pred, test_f1s, test_f1s_avg, pseudo_labels, num_iterations)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABbMAAAV8CAYAAAABxQJ3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXhb13ku+ndj3hhIggA4iDM1T7Zsy7Zsy7ZkJ2nmJm2GJs1kO8PTc9vTtKe3t703p03b5La3p2mbpu1t0sRxm6RO0qYZ6kx2Ykm2ZMmWHMm25oEzxQkTMQ9773X+WAABkJREUJwkvr/nwQMQAIGFTQAE3vXtbylCCBARERERERERERERrWSm5R4AEREREREREREREdG1MMwmIiIiIiIiIiIiohWPYTYRERERERERERERrXgMs4mIiIiIiIiIiIhoxWOYTUREREREREREREQrHsNsIiIiIiIiIiIiIlrxLMs9gKXg9/tFZ2fncg+DiIiIiIiIiIiIiK7i5ZdfDgohArNdtirC7M7OThw7dmy5h0FEREREREREREREV6EoSv+VLmObESIiIiIiIiIiIiJa8RhmExEREREREREREdGKxzCbiIiIiIiIiIiIiFY8htlEREREREREREREtOIxzCYiIiIiIiIiIiKiFY9hNhERERERERERERGteAyziYiIiIiIiIiIiGjFY5hNRERERERERERERCsew2wiIiIiIiIiIiIiWvEYZhMRERERERERERHRiscwm4iIiIiIiIiIiIhWPIbZRERERERERERERLTiMcwmIiIiIiIiIiIiohWPYTYRERERERERERERrXgMs4mIiIiIiIiIiIhoxbMs9wCIiIhoHnIpYOAFoGc/MPIq0LQd6N4DtN8D2N3LPLibkK4BsSEg0g9E++VxpA/IRIHaVsDbCXi7CsedgFq3NOMSAgj3yOdB3/OA3SOfB10PAi7/0oyBiBaPEEDoEtC7Hxg4Argb5eu7416+1xMREdGqpAghlnsMi27nzp3i2LFjyz0MIiK6GWhZIDoAZOPV/Z4rANSsAUzm+d2voQOXTwA9+2RwOfgioOcAkxUIbAKC50o/t94JdD8oQ82WOwCzdf73GRsGckmgtm15gxMhgHREBshapnCmAiiKPAZKpyvOQ+n0XOh5YHJQ3k+0EFhH+oHJIUDopespZhliq3XyslSo8nYcdTLUri8LuIuHmlbAfB31BMmQDLZ6CofogDy/pgXIJoDspPy56Rb5HOjeI4Mvqzr/+6xWNg4kxgFPM2BzLuxtCyFvW8/Kxzzf19RCjic2DNjcSzeJcSWGAcRHgGxMPj/tnoW9/XxGPt9NJvmeMN/3loVQfE9IjAO+tYszllyq9PqaK5vr+t7rASB2Geg5APQ+B/QekM8vQAbZ6Ujhvd4i39+7HpTv9613Ahb7/O+TiIhoKZX/H19MdjfgWSM/u9ANRVGUl4UQO2e9jGE2ERFRGSGAZLAQYs5yiA0DmOf/TpMVqGufPeD0dlYGT1MVt4Xwuvc5IFMIKRu3y/Bi7V5ZiW1zFSq1D8vgo+cAMPKKHKfNDXTcVwq3G7YUwt7CfaTCQLSvFNpOD3CNfGlMTp8cf11H4bhdjrt4+nrD0mJ4Hu4FIr3TjvtLIe1ScQXkY/V2At7CcV2HPD09kM7EyrZd4RDuLYTiA5Xb0WSRQeBsz4H6LsBRWzmOfFr+bS8Vngujr8rz7bVA1/2FwHqvDPQMHRgpTnockJWcRh4w24H2u0vXbb71+sI2Q5eh6WyPN9IHpIJl27GhtA2nb88rhdHZ+MznY/lpLV3alsXn4dSh7PXlqJn/Y7ya2Ih8rfU+J7dzbEieX5zEmP43XYhJjKJsorQtyrd5cQJGz5Wu6/RVbvPy07OF0cUwfGoyp7/ydPxy6bqKqWyvhM6Z2171lt5r5kvLFSaXpj3O4vMgG5PXu9r7XDX0PDD8i1KIXJw0rJbJWrZtpj/vu2Zum1RY7llRfD6FLsjz1Xr5Gu96UB58a+Vk3sCRsvf6E4AwAIsKtO+S26Drwet/jRMREV2vfFp+Dq74HNdX+rn4f3yxmW1ln71n+TyqepdmHFQVhtkMs4loNcqnS0FE8VDtB4b6bhkMNO9YmBBmroqhZvmHndiIrIwVAlNhcvF0xTFQGTYr0yp2ZztPkdumuJ1yicrxeJpnBlSOaiowBZAYmxk+ZaKVV3P65W17mmTrkMlixW0rsHaPDCG7HgTcgWvfZTEc6TkgA9DwJXm+KyArdovjmf5Ynb7K0NbbKYOi6EDh0F86PT3kcTXI33H6ZNBV3L6KqXAoOw2ldF4yKMOq6bdZEf53lUJBm2v2v7nALOdV+TnHZJYBq7dD3s9CMHRZaRnpK4Ry/ZXh3PSqbtVbep6lQsDAi7IK2WQF2gqB9Nq9c3td5pJA/+HSpMjYSXm+o06GZO7GKh6HJic4igF9+d+qWKleHuC6AmWBd+F1PDkkg7eiqWC/Q4b4xdufvk1s7rLnZae8vsU+8z0uHZ62LesrX7d17aUvMbWtc69kTYWBvoOlkDN4vnD7XqDzfqBztwxCK0LX/spJDMUM1BW+SBWD5BnP1fJjlC7TMoUvg31AcqJybPaamXsB2GtKexgUt310QP4Np8Zjku8t3g75Ja94nYrXtVJ6PZRve0Mvez73XWFctaX3kGoqxKfe//vlJEH588VsL91mMTxXvcDQUfl3CV2U13MFShXL3Xvk333W+zKA8VOlKuj+Q6X3xKbthVB4R3WhcGZy5iTMjOezp7RNY0Py/R4CsLrkXhTdDwJdD8iJy2tVkqWjctzFxzBxRp7vqJUBfzVf0IsTFOV/a3fTjV/NZhil/3nF52x0oGwvnzlQTGWfBQr/j2rbAIut+vHM9vksE62c5Kzvmv+2T0dmTnQBMyfYliK8KW778tdEbEi+zufKZCn9fyl+NnE3Xv9k2VxUTKz2z/656VqcvsLrvbNw3D6/vSgMA0iMXv1/6kKz2MsKF8pCv8Xe9uV74xW3fbRf7h05Z4r8PF3+/6umZWm+z2hZIFrcy69Pjj+fKhWEFMc0322ZmaycbI4OyM97K4WeKz3+xGjlZRZH5TYofu9RFuv/jJD/J8vfg2b7DmavBbyFv8/0opLl9tCn5B5fqxDDbIbZRHQzEmUB6WzVkdM/PNjcMsCa64cmQy9V4dlr5Jfirgfkl+z5Vr2Vjz0VKnw47av8YB7pK1QEl4cuZvnFxWQptY24WjANyNPTw6Hifc8WGNlcs1dULkTF8ZWkI9O+0Bb+dpPDQGBjIbR8SE4qXO8Xh+hgqZJv4oz8QD+j6rh97qFT+RfU8oqLaL/80FjcxkLIL1rFA8p/Llyu1k0LrAvHK6GFxFIor+quCCB6AauzslXI9QbsifHSBEff89V9KVdM8sN0efVt8VDbOrc2D3q+LBCfVvmbmZwWWHSWAgBn/dxeA5nJWSp4++R2nRysfF+BUginOkp7F0ztddBW2DOiEBAW93Qoho3F98KrhY3F6vXpoVKkrzAW/eptcsrf48zWWSrQO6sLFsonVaZvey07S7VSZ3WBf3nF+PRDPj232yg+3ppZJhC9ndcO9yaHSs/v3gPyPQqQz9nuPfJv5t8gK657DsjXQDFo9q2Tf9euB+UEhctXxZivoRiIzbbtnb5S8L7m9vmFo+XiY6VJl4Ej1QW2eq6wu3fZ90OzvTQJUz7JWdch3w+UlfIeLeSEypX2WCjfDopJ7nJeTQskQ5Ovn4rtqVRW4JfvnVAxmTftEB+pvG2rS/4fjI9cY/Km7GBxXPn1lpm2F5OzsH5C+R4zgAxsZtx2V2lCbK5EcU+dac/x4rE+LYB0NVQX5mpZIDmtDYFFrZycLH//8jRXF4xli/83+jGniahq2kmJwvOyYhuU/++ZNvbaVjkpOz1Aj/bLz3HTb8fdICcjF0suIT+rlrPXzAwji6ddfsy9tZuQxQwVz5e+0unpBTiqV36XmStDl/8DZmsRd6X/d6Yq2lVpZRXH09/b4yOofB+1ye8S01+b5QHq1KR7Ydsq5lm+I10liF2sPdHmw2QuTZZP/0znalgZE6TTJwTKT1f1mWUJfOj7cs+sVYhhNsNsIrpZFHdtL7YbqAislUIFXWchiO2sDJ2cvuoD0cREYdfnQqAT7pHnO/2lMKfrQXn70287l5z9w2nxeHqINtXSoQMzvjTXtCxvb1YiuvEZZYFL+V4GU3t/DM+scDNZgba7Cm0eHpA9iq83bKSlIQQwcbZs8uYgkCtb68CzplQB3fWADDKoVFFYrCac/kV/eoiyUtk8hc9B0w9d86+orqjwnuUwvYhginLliUBvpwwAFaWsrc702+5FRVud6cy2yjCs4tBRmqQun1SZPok+295W81UMySs+0xXGUtsGWB3V32Y+XXhelo1/6vTAwrUhM1nl5M2s7Zk651dJO1VRfYXPxFdrXzfVump6cNwpx7kUffJnm4ybre3X9bKoM78DlD/m+awBMWPx7r7KbT99kmTeiq/xK4y9OBFbDFCvFOBfafLRbJtWIT9tO7FFBt2kGGYzzCai62XosjLv8nFZldy6c2nC1Wwc6H+hFF4Xdx8uVnK175JVu8Wq2sX+UBsdKFR8Ffp6Fr+41bYDnffJL0LFD2XTK4CsrmkfyMs+iNW1L+/igkRExarxYhudmuZST3q68ema/B8euiAXS/StW5o2BTeb8jAmPlp9K6fF5KwvBcZz3ZtjIeVSpXAqMVYqMJhvgFtuqu1Cb2lvh2LA6mm+/r2Ypq+DkEvN/XeVQoVw8TPdciyEW2xJEemvfjE5m6v02fR6F2+dDy1b2mNpckg+d4ufk1dau4PpipXnxW0/vYr7WlRv6fuAK7AMr9lkaVI7NiQnHuaqfI+pavZiupKpPW4L76+GXto2N0O7J6J5YJjNMJuIqiWE7Inac0BWJfc9X7lrmM0te6R275F9jAMbF+YDmK4Bwy/L4LpnPzD0kty11eKQocravfI+59JHc7EJAQQvFKq2C7sz21yzVLN0odRHmcEBEREREREREV0Zw2yG2UQrw+hJ4NnPyFYVt74XuO2DspJjpYgOlPqj9j5Xqjqu6yi01NgDtNwOjJ0qVErvK7Xd8DSX+tp275ELWVxJxQIufZW9HSfOFnYjVYA1O0q317br+qt6iIiIiIiIiIhWOIbZDLOJllekH9j3WeDVb8vFKRq2AAOH5WJ+m94K7HxUhsVLWbWbjsggOngR6D8kw+tIr7zM1VDqodld6Ad9JZH+UhV1z365aAsABDbLKuqWO+TujtdaiKi4SIZ/Q+m+nfWL8MCJiIiIiIiIiFYuhtkMs4mWRzIIPPdXwNEvy/5zd38C2P07sj9a8ALw8hPAiW/IYLl+LbDzEWDHry9MiFvsLRi6JEPrisOlyp5u9hrZMqS4wFfD5vkF64YBjL1W6m89cLgUWtvcst3GjMWIrmMhIiIiIiIiIiKimwzDbIbZREsrmwAO/wPwwheAfBK47QPAg38A1LbMvG4+A5z+PnDscWDwCGC2A1vfAdzxiFzc8Gqhsp4vrPo+bTXoSK8Mrct7XEORobGvWy6YWH7wrQfMloXeCnJxntBFwLNmeRYiIiIiIiIiIiK6wTDMZphNtDS0nKy2fu4v5crWm98GPPRHQGDD3H5/7BRw7KvAq9+SfaMDm2W1dvOtpZWmi206iqtOi7JVp00WuZp0RVi9Vh57O65/lWkiIiIiIiIiIlpUDLMZZhMtLsMATn4H2PcZGTZ33g+87tNA66zvO9eWS8rbO/Y4cPl45WXuRrkgo7dTBtTlpz1rFqfCmoiIiIiIiIiIlsTVwmymPkRU1q6jT1Y8x0fkecIoOwhA6NPOKxyGj8te0Y3bgV//DrDu4etrqWFzAbd/SB5GXgHiozK0rmsHbM4Fe9hERERERERERHTjYJhNtBoIASTGZrbpKJ6ODVe264AiW3aYzIBiKjso034uHJw+4Ff+Gdj2LsBkWtixN98qD0REREREREREtKoxzCa6WeTThb7SfUC4t1Bl3VuqttbSldd3N8n2HB33zmzbUbNGBtlEREREREREREQrBMNsooWWiQF9zwPRwUKrDaXUcqPiZ6VU6Vx+nbkQhmy9UR5cxy9XXsfqAuq7AN86YO3D8nRdRyGwbges6kI8WiIiIiIiIiIioiXBMJvoehm6XKTw0rPyMPiS7C29FDxrZEX12r2FyupOwNslj13+6+tbTUREREREREREtIIwzKb5+9HvyxC3vqsyRK3vAtyNN3eQGukHevbJ8LpnP5CZBKAAa3YAuz8JrH0IaNgir1tcPBHiKsfGle7pylwBVlcTEREREREREdGqwTCb5qdnP/DSF2Vg2/8C8Oq3AYjS5Ra1VCk8FXZ3Ajb3coz26ma0+ig/Runn2EgpwA5dlL9b0wJsfpsMr7v2AC7fcj0KIiIiIiIiIiKimxrDbKqeoQM//X9k3+WP7QOsDkDLyh7RFYsO9sl+zr3PAfnkMg96gVidQOdu4M6PygDbv+HmrkAnIiIiIiIiIiJaIRhmU/WOfw0YOwm8+wkZZAOAxQ7418nDdEIAyQkZbufTSznSOZjW6kNMP6/s2FELtO6Uj5WIiIiIiIiIiIiWFMNsqk4mBjz7GaD9HmDLO+b2O4oCuBvkgYiIiIiIiIiIiGgeGGZTdZ7/nKyyfv+32F6DiIiIiIiIiIiIloxpuQdAN5BIH3DkH4Fb3we03LHcoyEiIiIiIiIiIqJVhGE2zd0zfwyYLMDDf7TcIyEiIiIiIiIiIqJVhmE2zU3/YeD094D7fhuoWbPcoyEiIiIiIiIiIqJVZll6ZiuK8kYAnwdgBvBlIcRfTLu8A8DjAAIAwgA+IIQYKlz2lwDeAhnEPwPgt4UQYgmHv/oYBvDTPwQ8a4B7f2u5R0NERERERERERDRvQggYKQ1aKA0tlIEWTEPkjeUeVgXP/S0we2zLPYwVZ8nDbEVRzAD+AcDrAQwBOKooyg+EEKfLrvZXAP5VCPEviqI8BODPAXxQUZR7AdwH4JbC9Q4CeBDA/qUa/6r02reBy8eBd34RsLmWezRERERERERERERXJYSAkciXAuuy4FoLpSEyeunKCqBYVlYDC9fORobZs1iOyuy7AFwUQvQAgKIo3wTwywDKw+wtAH63cHofgO8VTgsADgA2AAoAK4CxJRjz6pVLAj/7NLDmNmD7e5Z7NERERERERESrlhACqePjiB8YklWkCqAoikxIAKBwWlEKpwHApMBkN8N5ZxOct/ihmFdWYEeri5HVkTkfRvpkCLmhuEz6FkOh8lpkKwNrs9cBi88BZ1sDLD4VFp8DFr8Ki9cBxcrXxo1gOcLsFgCDZT8PAbh72nVeAfArkK1I3gnAoyiKTwhxWFGUfQBGIN+q/14IcWa2O1EU5eMAPg4A7e3tC/sIVpNDfwfER4B3fRUw8UVNREREREREtBzywTSi372A7KVJWFvcsDW7ZA4oAAhRcTzVjLXwsxZMI/Ktc4j9pBfu+1rguqsJJseydJ5dcYQQckKAFo2RyiN9Joz0ySAyF6KAZsDkssDeXbeo1dCKwyyD6mJo7XWsuOprqt5Kfef6PQB/ryjKRwA8B2AYgK4oyjoAmwG0Fq73jKIo9wshnp9+A0KILwH4EgDs3LmTPbXnY3IYOPR5YOs7gY57lns0RERERERERCuG0A3o0Sy0cEYeQhno4TS0cAZ6NAvrGjc8D7bCvq7uusJSoRmIHxhCbN8AFIsJde9YB9ddTVBMc79NYQhkzkeQeG4Ikz/qReznA3Dd3QT3vS2w1NnnPbYbmZHVEXu6D4kXR2FrdUPd6oe61QdLvWO5h3ZT0GNZpE+FkD4VQrYnChiAudYO991NULf6YOusreo5TFS0HGH2MIC2sp9bC+dNEUJchqzMhqIobgC/KoSIKoryMQBHhBCJwmU/BnAPgBlhNi2An/8pIAzgdX+y3CMhIiIiIiIiWnJCM6CF0siPyx67+lRwnYYezVa2SDArsNQ7YKl3wNbiQfpsGMGvnIS1RYba6jZ/1eFdtncSke9egDaehnqLH3VvXQtzTfU9dBWTAnVTPdRN9cgNxRF/fhiJg8NIHLwM560BuO9vgW2Nu+rbFULASOZhpLTKqvBpleLF6xbPs/jUZe0FnD4XRvS7F6FHs1C3+6EF05j8YQ8mf9gD6xqXDLa3+WBpcF7XRISR0SB0AbPLuoCjXzrF8c/5+qk8MoUK7NxAHABg8avwPNAGdZsP1hY3q+DpuilCLG3RsqIoFgDnATwMGWIfBfB+IcSpsuv4AYSFEIaiKJ8FoAsh/khRlPcC+BiAN0K2GfkJgL8VQvzX1e5z586d4tixY4vzgG5Wwy8D//wQsPt3gNd9erlHQ0RERERERLRojIwGbSKN/HgK2kRKhtfjKWjhNGCUrmdyWWHxOWAuhNbFg7kQzpaH1UIzkPrFOOLPDUELpmHxOeB+oBWu2xuv2ZvXSOUR/VEvUsfGYK6zo+4d66Buql/Qx6yFM0gcGkby6ChEzoB9fR0897fCvn5mJbmR0eSieYVDvux0xSJ6c6UAto4aqNv8ULf5l6w6XE/kMPlUD1InJmBpUOH9lfWwd9YCALRQWlYSlwexAXUq2L5SECuEgBHPlz13UtDG5XPIiOcAALZ2j3ysW32w+NQleaxzJXRDTtBMpOX4J9LydDAFI6nN6zatLW6oW3wLMiFAq5OiKC8LIXbOetlSh9kAoCjKmwH8LQAzgMeFEJ9VFOVPARwTQvxAUZR3AfhzyDm75wD8H0KIrKIoZgD/COCBwmU/EUL87uz3UsIwu0pCAI+/EQhfAn7rF4CjZrlHREREREREtKoJIZC9GIUWycCxsR6W2tXZGuJKsgMxZM9HqvodI6VNBY96LFe6wKzA4lNhDaiwNDhhbXDC0uCExe+AyV79Du7CEEifCiF+YBD5oQRMbivcu1vg3tU8o2+1EALpExOIPtUDI52H+/5W1DzcDpPNXPX9zpWRyiPx0igShy7DiOdgbXLCsdUvW6iEZGBtJPKlX1BkuwiLX506mD3WssUnC8FlcWHKwmKU5YtS5gZiSJ8MIj+aAgDY2jxQtxeC7UVo81FcOHPyqR4YWR2ePW2o2dt2xf7JeiyL9OkQ0icrW2TI9hg10CPZivC6PNBX7Gb5vCk8f6ALpE+HkB9OAACszS6oW33ysTYuXdCrJ/PQJlJy0qYQXGsTsi0OjFI2aHJbYQkUxu9Tq1oUUbGYYF9Xx1YtdN1WXJi91BhmV+nkfwL/8Qjwts8Dd3xkuUdDRERERES0aglDIHM6hNh+GYQWWds8MhDb6oM14FzGES4fIQSyl6KIPzuIbM9k1b+v2MywNKgyrA44YW2Q4aOl3gHFvPCLxMnxTiJ+YBDZC1EodjNcu5rhua8F5hobtFAake9dRPZCFLY2D+reuW5erT/mPT7NQOrEBOLPD0EbS8HksU4tnlcMNi0BFZb66gLOq8lPpJA+Kauhp8LeFjfUbTLsXYjnthbOIPLdC3K7tnvg/dX1sDa65vz7lYsXRgBN5mgmjxXWgLNswkOFNeCEqcY2a0CthTOFHtJB5PpjgAAsPgcchYptW6vnuntICyGgT+YKleHlleJpGMmyCQlL2YRNwAlLQI7d4ldhUlfq8nq0mjDMZpg9d/kM8A93AvYa4BPPAabFm/0lIiIiIiKi2QldIP3qBGL7B6GNpWCud8CzpxX29hoZrJ0KToXblkbnVKWntdm16JWeQjeQ7Z1E5nwEJpu5FOb51StWui7o/RsCmbNhxPYNIj8Yh8ljg+f+FrjuboJSZQXzcrU/yA0nED8wiPRrQcCkwLGxHpnzEShmBbVv7ITr7uZlWxxPCAGRNxa1Gnw2WjiD9Mkg0q8FkRuUbT6sTU6o2/ywddbA2uCEyTN7UDwbYQgkDl1G7Ok+QCls113Xt12NrA5tIgVLvQMm5/z7YOvxnKz8PhVC9mIUMATMNTY4CqE25jpEAeixQng9IUNrkSurElcthckadWoPA2tAhdnr4OKLtKIxzGaYPXfP/zXw8z8BPvQDoPvB5R4NERERERHRqiI0A8mXxxA/MAQ9nIGl0YmavW1QtwegmCvDJy0qKz0zp0LI9k4CAjDXO6Z61draaxYssBJ5A5kLEXl/Z0JywT+zApQvDqegVL3b4CxUrcoQbXo7jXmNwZABf3z/IPKjKZi9dngebIPrjmv3oF6ptFAa8eeHkTo+Dsf6OtS9fS3MNWwho0WzMtg+WapiBgDFYS6rhlYLFfVOmOsrw9nc5QQi/3kB+aEEHJvqUfeOdUvWl7taRiqP9LkI0ieDyJ6PQOSNa//SNOYaW0WFeHG7mNxW9qu+CsMQOHU5hmfPjmP/+XFEkrlr/9ISeuKRu9Dpn/teBDcThtkMs+cmMQ783e1A1/3A+55c7tEQEREREdEqkx9LIv7cMPKjyap+z+y2wtLogrWx1N/YZL+x9jI1cjqSL44i/vwQjFgO1lY3ava2w7G5fk6BtJ7IIVNshXAxCugCJrcV9rV1pRYIDU7ZA3eO1dNGRkPmXBjpkyFkzoUhcgYUhxnqZtnexL7BCwClheOKC99NyD7L5UG3qcY2s0J0jmHb1EKKBwahhTKwNKjw7GmD89bAorQDoZVFT+SQH01CG0+XPcdSMOKVbTOsfjmJotjMSP1iHCbVgrq3r4V6i/+GCXSNnD61aORcmVzWBZksWi0SWQ0HLwSx7+w4nj03jol4FooC3Npahw7fymrZ9Adv2oTm2pW1YOhSYZi9WsPsA/8LeOELc7++ngOMPPDfXgT86xZvXERERERERGVyg3HE9g0iczoExWqCrat27hXFhR6x+YlURXhq9tphbXTJ0LRRHiwNziVvnXAtRlpD4vBlJA4Nw0hqsHfXwrO3DfZ1dfMO4MpD6NxgHHo0W7rQBFjq1RmVrZYGFSa7BXoyj0yh/UHmQmQqFJf9uf2wd9fOKQwXuoAWTssAciJV1sM3DZEta4PgsMwYh7XBCbPXIavUj44i8dwQ9MkcrC1uePa0Qd3qY4sEgpHKy4mTshYb+fEU9GgWzh0B1L6lG2bX/FuB0M2jL5jEs2fH8ezZcbzYG0JeF/DYLXhgQwB7N3GC2GsAACAASURBVDVgz8YA/O6VWbm/WjHMXq1h9vmfApf2Vfc7XQ8Am968OOMhIiIiIiIqEEIgezGK+P5BZC9NQlEtcN+7Bu5718wrgJoKT8dSyI8VgtOx1MyQu86+oqoYtUgGIqvDsdELz0PtsHfULPh9GDldVk+PpyoqW7VgBjAqq6eNeE62K/HaoW71L3y7EiFgxHKVVdyFcRmJykpbxWyCyOqwddagZm8b7Bu8N0yFLS0fYYhFm+wYi2XwwqUg9Co6gXT5nbijo35RxlMNIQR+MRBFg8eOtvrlr0AemUzj8KVQ+VvQghJC4NxoHM+eHUdPUO7tszbgwsObG7F3YwN2dnph5Z4dKxbD7NUaZhMRERER0Yok8gaMjCYX+VIUKIVjlB1PP+9mqUQVhkD6VAjxA4PIDyUqFu8z2Rc+ZJ4Rck+kIHLV96RdLCanDPFta9xLft9CN6CFMqVQeSIFc519yRaSnK6i0nY8BSOlwbWzEfau2iUdB9F0rw1N4vFDvXjq1cvI69XnaL//xo34jQfXLttkTCKr4VPffQ3fO3EZJgX4pa1NeGx3F+7oWPoJohODUXzlYC9+9NoI9MVKsgtsZhN2rfXhoY0BPLSpEe0rrI0IXRnDbIbZRERERES0zIy0hvTZ8LwX+bI2ueDY6oO6xQfrmusPGrVoBplTIaRPh5Dtj8FcY4c1oMLily0fLAEV1oAKk8e2IGGH0AykTowjfmAI2kQaFp8D7gdb4bq9cc49nFcywxA4cH4CB85PYEdbHR7cEIDXZVvuYS2rZFZDbzCJ3mASfcEkIqk8Hru/Cy11q7MH7EIZDKfw5EsD2NXtw/3rF7YfdCav4wcnLuO14Um01avo8rvR5Xeird4Ju2VltehZbLoh8MzpMTx+sBcv9YXhspnx7p1teM/ONnjmuHeHEMBfPX0OP3jlMj6wqx2ffttWWJa4GvjVoSh+68njGAyn8JsPrUdeN/BvLw5gMp3Hra21eHR3F968vXlRq5Q13cBPT43h8UO9eLk/Ao/dgvfe2YZ37WyFy7Z4e8r43DY4F/H2afEwzGaYTUREREREVdAms9DDGVgCKszu+QeSejyH9OmQDLAvTQKGgLnGBsdWH6yNTkAAEHJ3aHm6dCwKl0EICM1AtncSub6YbAFRZ4e6xQfHVh/snbVQzNcOs4QQyI+mkDkVRPp0CPnLcrdrS6MTjrV10BM52YoimK4I2hW7uRBwq3KBtYATZq+9qkrxbF8MieeHoU9mYW12wbO3Deo2/01RbZ7KafjOL4bx1UO96JlIwmxSoBsCJgW4rd2LhzY1YO/GBmxu9tyULTIyeR2D4RR6CoF1bzA5dXo8nq24rsWkYE2dim99YteqXdTsej316mX84XdeQzyrAQA2NLrx6H1deMdtLXBY5x82j8cz+PqRAXzjSD9CyRxcNjOSuVJvc5MCtHgL4bbPiS6/C51+F7r9brR4VZhvgtdyUTyTx7ePDeGJF3oxGE6jpU7FI/d14j13tqHGUX0LJMMQ+MufnsM/HbiEhzc14Avvv21JAlbDEHj8UC/+v5+cRcBtx+ffdxvu7JTtTqbetw72oieYRFONAx+6twPvv6sddc6Fm4SbTOfx7aODeOKFPgxH02ivd+KR+zrx7p1tcC/Cnjh082CYzTCbiIiIiIiuQggBbTyFdKFSOT+UmLrM5LLA0uCqWETQ2ui8YsithTPydk4FkeuX4bPF54Bjmx/qVh9srZ55h7h6IofM2XBhcb4ooBkwOS1wbKqHusUH+wZvxQKHwhDI9cVkoH46BD2cARTA1l4DdasPji0+nMlk8Zc/OQePw4IOnwsd9Sq6HTa0ChNqkhq0oAy4tYl05UKCVbJ11aBmz83T93hkMo1/eaEfT74kKxxvaa3FY7u78Etbm3BmJIZ9Z8fx7LlxnByOAQCaax3Ys7EBD21qwH3rfNcMsyLJXEVA3BtKonciiXAytxQPb050IRBMZFEeK/hcNnT5XWVhpzzu9LlwfiyOD3z5Rfg9dnzr47vQUONYvsEvEMMQuDyZnqo+L/7NBsIp3NlZj//xho0IeK5/Ybl0TsefPnUKT740iNva6/BX774Vxwdku4YzIzHUu2z49bvb8cFdHVVt11OXJ/H4wT781yuXkTcMPLypAY/e14V71voQS2vyeRdMoDeYmnqMvcEkEoUwHQCsZgW3ttbhw/d24k3bmhas8jid0/Gfx4fw7aODqHPa8NAm+fpZrH7Pg+EUnnihD986OohEVsPODi8e292F129pXJDH9LUj/fjj75/E9pZafPnDdy7I8+JKQoksfu/fX8G+cxN4w5ZG/OW7bpk1pC7uUfKVg704eDEIh9WEX729FY/c14V1DfNvfdQfSuKrh/rw78cGkczpuLurHo/t7sLDmxtvqokPWjwMsxlmExERERFVMLI6MufC0CbS1f2igmv0ea78GdV8Zy1+NSlWJxuV1ckzKpgVBZZ6hwyX/SoUa3VhgzAEcgMy6M2cCkELZQAAtjaPrJxucskQdyyF/FgS+bEURLasUtFlrQi3jZQmg/BhGYRbm11Qt/qgbvPD0uhc8ADXyOnIno/IoPpMGCKtARYTHOvr4FhXh9zlJDJnQzCSGmBW4FhXJ9uUbPbB7JGhxsnhSbz/n4/AZjGjRrVgKJxGrmxlM5vFhPZ6JzrqnejwudBV68BaqwUdVivqq6jeM9faYWtZ+p7Qs8nkddjMJpjmGaiU93sVQuCN25rw6H1X7j07Fstg/7lxPHt2HAcvBJHM6bBZTNjVLfu4bm+tw3A0XQqtC4fJdGkxRLNJQatXRZffhQaPHUpVL6zFoyhAY40D3QEZVnf6XahVr165+nJ/GB/6yktoqnXgmx+/Z1EDvYUihMBEIoveiST6QjKwLp7uC6WQ00qvGdVqRpffhcYaO56/EIRqNeO3X7ceH763c95tHM6NxvGb//YLXJxI4DceXIvfef2GqdsSQuBITxiPH+rFz86MwWJS8LZb1uDR3V3Y1jJ7r3HdEPj5Gdny4UhPGE6bGe++oxUfua8LXX7XnLZHMJGbCrcvBRP46clR9IVSWFPrwIfu7cT77mxHrbP6KmYAGJ3M4F8P9+HfXhpANJXH5uYaZPI6eguL+K1rcE/t8XC9i/hl8jpODEbxxKE+PH16FCZFwZu3N+Ox3V24ta1u3rd7Jc+cHsNvPfkLBDx2PPHIXVgbWPj3xRcuBfHJb55ANJ3Hp96yGR/c1TGn/z9nR2P46sE+fPfEMHKagT0bA/jIvZ1VTR6MRDP4l8N9c34uEl0Jw2yG2URERERE0JN5ZM6EkT4VROZCBNBuou8CCmD2OmBtcMLSoMIaKITMDU6Y1FIFrMgbyFyMyMrms2EYiTxgVmBfWyeD5831MNfMHq4JIWDEcnIRwULArY2nKkJuW7sHaqEC2+JbujYKQjeQ7YtN9cDWo1koDvNUxbZjo3fG4oqnLk/i/f/8Itx2C771iV1o9TqhGwIjk2n0h1KFgwzsij+n86Uwf8/GAB7b3YXd6xa2Z+9CiKZy6A+lKsbeH0qiP5zCRDwLezGk97nQ4XOi01c63VKnzqjCvFK/1w9XGfRkNR1HeyN49uw49p0bnwrnitbUOtBVCIaL1c1dfhdavU7YboK+4kUv9oTwka8eRXu9E09+fBfqV0hv8WhqWjV8Wb/v8pYbNrNJPm/K/kadPhe6A4XJhsLr4eJ4An/61Gk8d34C6xrc+OO3bcH96wNzHo8QAt94cQB/9tRpeBxW/O17d2D3ev8Vr98XTOKJF0rVsHcVqmFfV6iGTWQ1/Psx2fKhP5RCS52KD9/bgffunH/wXKQbAvvOjuMrB3txuCcE1WrGu+5oxSP3daJ7joHtK4NRPH6oFz98dQS6EHjDlkY8trsbd3bKiaLeYFK+ds6O48XeEPK6gMdhwQPrA9i7qQF7Ngbgd898/9Z0A0ORdMXftHi4PJmGEECtasX7727Hh+7pWPQWOCcGo3jsiaPQhcCXP7QTOwutP66Xphv4/M8v4O/3XUSX34W/f9/t2LKmpurbCSay+MaRAXztSD+Cier3xpnvXgJE5RhmM8wmIiIiojnIDsSQeOEyTDYz1G1+2NfWQlnihZoWmh7LFlpehJDtiQKGrJJVt/mgbvXD1u6R5ZVzJubQ57lUWV218oruYvW3SZm1GlzootD+IoX8eFoGy+MpaME0oJfu2+SxwhpwQrGbkb0UhcgZUOzTgt45LuY16xYRAvpkDopZmap4Xk5CCOjhDMy19isurHh2NIb3fekIVKsZ3/z4PWj3XTuQFUJgIp5FXyiFw5dCU0HH+gY3Ht3dhXdeZ8/eagghEEnlp9of9BcqZPsL4XV5VTMANNU40OFzosPnRJvXiVgmXwq5w0lkynqEW0wKWrxqoeWKEzWqBd87fhnD0TQ6fE48cm8n3rVA/V57g0lcHE+grV5FR70Lqm31LLD3wsUgHnniKLoDbjz5sbuvu0/vYDiF/ecnUE3GMZnKl1q4BJOIpmavhi8G1cVJhjV1c+8RLYTAz8+M40+fOo2BcApv2NKIT71lyzVfc5OpPP7gP1/Fj0+O4oENAXzu3bfOuYp9Mp3Hvx8bxFcPlfoU39Ptw49eG0E8q+H29jo8trsbv7R1YdpnTHf6cgyPH+rFD05cRk438NCmBjy2uwv3rvXNmPjSdAPPnB7DVw724lh/BO7iRNE9nVfdRomshoMXgthXmBgaj2ehKMAtrXV4YL0fqZw+NRExEE5BK/t/5HFY0F3WCqdY6b2UCwX2h5L4yFePYjiaxuffuwNv2t58Xbc3HE3jt588jmP9EbxnZys+/fat1/14spqO588Hkcxp175ygWo144ENgSX7X0A3L4bZDLOJiIiI6AqEEMhemkR8/yCyF6NQVAugC4icDkW1QN3ig7rdD8e6uisGgyuNFkrLAPtkELmBOADAElChbvVD3eaDtcW94ippF5LQBbRIphRuT8ig20jlYV9XB3WrH/bu2hvm77nQzo/F8b4vHYHVbMI3P74LnXNoKzCbrKbjqVdG8JWDvTg9EoPXacWv392BD97TgcYFqsaLZfIVVbJ9wSR6Qyn0TiQQy5QCFrNJQUudOhVYd/pcaK+XlbPt9c6rBitCCIzHs+gLysrt/rJq7r5QEvGMhl3d9Xj0PvZ7XWjPnZ/AR//1GDY2evD1j959zRYls0nlNPz/+y/hi8/1VLT7mKvmWkdFFXwx4Gxb4Gr4TF7HVw724h/2XYRmCHzigW78xp61swaOL/eH8d+fPIGxWAa//8aN+Oju7nm1xSkPio8PRvHm7c149L5O3NbuXYiHdE0T8Sy+8WI/vn6kH8FEDpuaPHj0vi68fcca5HQD3z5aCtzb6lU8cm8X3r2zFZ4qF1k0DIHTIzE8e1a283llKAq7xTRjEqJ4ut5lWxH/A8PJHD76L0dxfDCKT71lCx7b3TWv2/nJyVH8/n+8AkMAn33nNvzyjpYFHinR0mOYzTCbiIiIiKYRQiBzNoz4vkHkBuIweazw3N8K193NUEwKMhciSL8WRPp0CCKrQ3GYoW4uBNvrvVX3Z57TmDQDWjAtA9jxFHJjKaSCKTgs5ml9qK9csaxHs8iPytYF1hb3VM9ma8PiLJi1XKKpHE4MRuF12tDqVVdMOLHSXRyP49e+dAQmRcE3P75rzrv/X40QAi/2hvH4wV48c2YMZkXBW29pxmO7u7G99dp9UtM5XfYeLls8r69QKRtMlBY7VBRgTW2hUtbvRJffjS6/DK7b6p3X1Tf3ao8tkzdWVcX0Utt3dhwf/9oxbF1Ti689dtecg0whBP7r1RH8+Y/OYGQyg3fsWIPfft0G1FSxl4XTZlnyv+3oZAZ/8eMz+N6Jy2iudeD/fvNmvPWWZiiKAt0Q+KcDl/DXz5xHS52Kv3vfbdixQH2bdUMs20RMJq/jv165jK8c7MXZ0TjqXTZk8/rUwoCPlrVCWQjpnA67Zf598ZdSJq/jk988gZ+cGsWj93XhU2/ZfNVxT5/gO3U5hmdOj+GW1lp84X23ocM3v8lJopWGYTbDbCIiIiIqEIZA+rUg4vsGkR9Nwlxnh2dPK1x3NM0aUAvNQOZitBRspzUoNjMcm+vh3O6HfYMXpirDECOjFQLrNPITMrjWxlPQwpnSIogKMGlVcCGXR63Tim6/C06reVp7D8xo7WGym+HY7JM9m+tvnl6VQgicHY1P9Uv9xUCkoouJajWjxauipU5Fq1dFi1dFq1f2P27zqvC77TdEsLGYLk0k8GtfOgIhgG9+fBfWNSz8wmP9Idmz99tHZc/eOzu9ePS+Luzd1DDVs7av2NahsIDeyGSm4jYCHju6ij2jA6UWD9eqsKYb19OnRvHfvvEL7Girw788ehdc12jhcuryJP7kB6fxUl8Y21pq8Om3bV2wvsNL5WhfGJ/+wSmcuhzDXV31+O8Prcc/7r+IFy6F8LZb1+Cz79yGmiorlFc6IQQO94TwjSMDUG1mfOTeTi4MCDnR8JkfnsZXD/XhTdua8Oe/sh0jk5lrTvABss/+23e04Hdfv+Gm6qtPxDCbYTYRERHRojAyGrSJUiXxVEuHSCGUnaXPMRQFiqnyZxROzpViN8PiV2EJqLD4VVj9TlgCKkxu6xWrc4VuIHV8HPH9Q9CCaVgCKjx72uDcEZhzX2yhG8hemkT6ZBDpU0EYSQ2wmGB2zr0SUOgCRrKsn69ZkY+hQT4Ga4MTZr+KzxzuwddeHsKbtzfh+QtBpHI6PnB3Oz75ug3wLvFiaboh8NrwJA5emEBWM+Qu2wEXunyuRR1LOqfj0MUgnj03jv1nx3G5EHpua6nBQxsbsGutD8msjuFICkORNIYiaQxH0xiKpBBJVfZMLi7Ydt86Px7cEMCubt+qqrbtCybx3i8dhqYLfPPju7C+0bOo9xfL5PHto3KhuaFIesblXqdVLp7nK7V1KB4vRC9quvH8+LUR/OaTx7Gzw4snHrlr1tdnOJnD554+hydfGkCd04b/85c24j07227Y1i+6IfCto4P4Xz89i0gqD9Vqxp+8fSvevbOVe5qsQl9+vgef/dEZTI/pihN85XukdPnd6PBxgo9uXgyzGWYTERERXRc9kUN+LAVtolBNXAiv9VhZhZBZgcWnwtqgwuxToZiUyqphA1PVw9MXDhRVLhQo0hrywTS0UBrQSr+rOMywBJywFoPugAqLT0WuL4b4c0PQo1lY17jg2dsGdatfjnGehC6Q7ZtE5kwYRmbuiyMpJgXmegesAScsDSos9SoUc2kcQgj88Q9O4V8P9+M3967D/3jDBkRSefzNM+fxjRf74bZb8MnXbcAH7+lYlLYKRSOTaTx/PogDFyZw6GIQ0VR+av6h/M9V57TKyll/ZSjZ5Xdds7pyNoPhFPadk31PX7gUQk4z4LKZsXu9Hw9tasDejQ1omEM/5mRWw3A0jeGIDLeHommcG43jSE8ImbwBu8WEu7t92LMhgAc3BtDtd9204dFAKIX3fukwspqBJz+2CxubFjfILqcbAs+cHsPZ0Rja651Tz43rXeyPbk7fPzGM3/nWCdy71o8vf3jnVFCn6Qa+8eIAPvf0OSRzOj50Twc++fAG1DpvjsrlyVQe3zw6gIc3Ny7KHhN043j+wgRODESn/pd2+JxV9xAnuhkwzGaYTURERFQ1PZZF6tUg0q8FkeuPTZ2v2MywNKiFMNYJa4MKS4NzRii7FIQhoEez0CZSyE+koQXTMnCfSFcG7QBsHTXwPNQGxwbvig0thRD4s6fO4PFDvfjEA934gzdtqhjrudE4PvPD03j+QhDdARc+9ZbN2LuxYUEeTyav48XeMJ47P4HnL0zg/FgCgKwIe2B9AA9s8GP3Oj88DisGI6mpFhHFXaB7g7O3i/BU0b82mzcwHJVVvF1+F/ZubMBDmxpwZ5cXdsvCVJ9l8jpe6g1j/7kJ7D8/jp4J2V+8rV7Fng0NeHBDAPeu8826KNuNaDCcwq996QiSOQ1PfmwXNjfXLPeQiK7qOy8P4ff+4xU8sD6AL33oDrzcF8Gf/NdpnBuLY/c6P/74bVsWfc8CIiJaXgyzGWYTEdFV5EaSMGJZ2LvrFmVBN6IbiR7PIX0yiNQrEzLAFoC1yQV1ux+2Ng8sDU6Ya2+MhfaMrC7D7WAK5lo7bB01K3rcQgj8xU/O4osHevDIfZ34o7dumXW8QgjsOzeOz/zwDHomkrh/vR//861bsKHKcCeayuHSRBLHByI4cH4CL/WGkdUM2Mwm3NnlLQTYAWxq8sx5u822kF86r895TCZFwS2ttXhoU8OCLEw4F4PhFPafn8CBc7ISPJXTYTObcFdXPW5rr6u6fYFJUWA2ydY6JkWBqXCslJ02KYDJpKDeaUOnX/aEXoyWJ8PRNN77xcOIZzR846N3szct3TC+dXQA/9d3XkOrV8VQJI1Wr4r/+dYteMOWxhX9Pk5ERAuDYTbDbCIimkW2bxLxfYPInIsAkD141c31ULf7ZeUme9DRKqEnckifDCH96gSyvZOAACyNTji3+6HeEoC1wbncQ1wV/vrpc/i7Zy/iA7va8We/vO2agU1eN/D1I/34259dQDyTx/vvbsfvvG4DfG771HU03cBQJI1LEwn0TCQrjkPJUuX62oALD2yQ4fWurtXVS7pcVtNxrC+C/efGsf/cBC6MJ5bsvptrHej0yTYt3VPtWpxoq3fOqyp9ZDKN937xCCKpHP7to7uwvZVBNt1YvvFiPz739Hk8cm8nPvZAN3sDEy2hbCqPk88N48yhEeSzc5+UXmlEod2dKGtrV/x56tgoa3+3wrzvj+5G/RrXcg9jWTDMZphNREQFQghkL0YRe3YQud5JmFwWuHe3wNrsRvpkEJnTIRgpDYrNDMfmeqjb/HBs9MJUZbBj5HS5GN5IEvmxFESuig+BZgXuu5thbVqdH1xoaeiJHDKnw0i9NoHspShgAJaACvWWAJy3+GFt5PNvKX3h5xfwuWfO49fubMP/+87tMFVRDRxJ5vD5n1/A1470w2kz4523tWA8lsWliQT6Qknk9dLnfZ/Lhu6AC2sD7qnjzc01WFOnLsbDuuFV+11JCMAQAkbhuPSzPE8IAd0oXT4Rz6K32KYllJw6Xb54pUkBWrwqOn0uOG3mqdsxyu6rdLuln/tCKWRyOr720buxo61uoTcNEdGqJAyBbFqDw3Vz9rFORLJ45dlBnHp+GPmMjtZNXtQEbtzPCArkWiVKYTFyRVEAEyp+VhR5nWoXI18K2/e0QvWszjUmGGYzzCYiWvWEIZA5E0Zs/yDyg3GYamzwPNAK111NFUG10A1keyaRPhlE+mQIRjIPxWqCY1OhYntjPUx2c8Xt6pGMDK1Hi4eUXJSu8C9WsZqgOOYehouMDL69794A5y2BhdkAtCoJ3YAWzkCb6iWdRn4iBS2YhpGQYZnZ54DzloCswG5ycvftZfBPBy7hL358Fr9yewv+6l23VhVkl7s4HsdnfngGL1wMoa1eLQTWbqwNuKaOuejejSGayslgO5REbzCFvsLpnGbM2q6keLr8MofVjN96aB1ua/cu98MhIrqh6ZqB4XMR9JyYQO8rQaRiOfjb3OjeEUD3jgDq19z4CwhHRpM4/vQAzr04CmEIrNvZiNve0I5AG/vT0/JgmM0wm4ho1RKGQPrVCcT2DUIbS8Fc74DnwVa47miEYrl6f2yhC2T7JpF+LYj0yaAM/ywmODZ6YXZZC1XXSYicIX9BASz1DlibXLA0uWBrlseWeoec7Z8jPZZD6OunkRuIw7OnFTVv6Kzq95eLnswj8cJl6OGMXBSwUR7M3uoe/81E5A3kg2lZpT+eghHPyZKPQoWILBeRFSIoVIag7HzFpADmwrFJkYsrmqadX3a5Ec8jH5SLH2oTaWjhDGCUPuuZXFZYAiosfrl4o31dHaw3wRewG9lXDvbiz546jbffugZ/894dVfdnno0Qgn9TIqJlJITAyKVJuOvsqPHfuFWtcyWEgGEImM3Lv/ZMKpbD5EQazhorPD513hPEuYyGgVNh9JyYQP/JEHJpDRa7GR1bffC1uDBwKozRQmu22oCK7h0BdO0IoKmrZt6fe/M5HdGxFDLJ/LWvXEZ121DXqMIyj1Y8oz2T+MVP+9H7ahBmiwlb7m3Gjte3r4rnLa1sDLMZZhMRrTpCM5A6Po74/kFoIRmueva2wXlLQAaC1d6eIZDrj00F20IzYG1yyUOzPLY0OqtuR3K18Ud/cAnJl0Zh3+CF79c2wuRcmbsz6okc4s8PI3n4MkTegMljgxEr9eJVrCZYGp2wNjintpO10Qlzrf2mCdyMjIb8eKoQWhfC64kU9HCm1H9PQelvWOjPh2J/PiFKvfqmjuc5GIsCi0+FNaDCEnDC4ldhCaiw+tUV+xxarf71cB/+6Pun8KZtTfjC+26DZQWEAERENH+GIdBzfALHftyH0FACiknBhjsbcfsbO1DffPO178rndJx9YQQnfj6IWDANV60dNT4H3PUO1Pgc8BQP9fJgWcD1GFKxHCIjSYRHkghfLhyPJJFJlIJgs8WEukYVdY0ueJud8DY54W1yoa7RCessY0kncuh7NYieE0EMng5D1ww43FZ03eJH944AWjd7KwLj5GQWva8E0XtiAkPnIjB0AWeNDV23yuu3bPTCPK14RgiBTCKPyGgSkdEUIiMpRMaSiIykEA9n5r9BFKDG54C3yTX1OIvHDnfl5z8hBPpPhnD86QFcvhCF3WnB9j2t2L6nFc4a7sFFKwPDbIbZREQ3NSEE9FhuqvpVG08hczYCfTILa4sbNXvb4NjiuyGrgxMvjiD6g0sw19nh/+CWFdVHW4/lEH9uCMkXRyA0A/btfnxFT+NgNInXdfvwUKAWXcIEfTyF/Jg8GPGykNtuhrXRKau4GwrHAXVFV3IbaQ35MdkHXRuTz7f8eKoivIdZkZXPxcfUIENla0CtH+ns+QAAIABJREFUalFRIQRgADAMCEMAupj92BAQuoDQDZjdNpjr7Ct2+003HE3j2TNj+NmZcVwcT6DVq6I74KpYBK+t3lnVol/RVA79oRT6wykMhJJTpxXgum8bACZTefSGZF/jnkJ/44FwCl6nFV1+N7r8zsLCfS6sqb1yRdiTLw3gD//zNbx+SyP+8ddvh5VBNhHRDUvXDVw4OoaXf9yP6FgKdY1O3PaGdkRGkjj53DC0vIG1twVwx5s6l6xtQy6jyYB3OInQcALpRB4dW+vRdWsANtVyXbedjufw2v4hvHZgGJlEHo1dNWjd5EUykkU8nEEslEEikpWfU8qoNTYZctc74HBZYbIoMFtMFYeK86zytMlsQiKcqQiuy0Nrm2pBfbML9WtcqG92obZBRSqWQ3Q0NRUax4JpiLICA0+9oyLsHTwdxsjFKISQl3XtkIF089pamObwPzqb1tB/Moie40H0nwpBy+qwqRZ0bPPB3+pGdDyF6GgK4dEksklt6vcsVhPqpoXPzhor5t69WSAZzcnHOSbD8ehYCrpmlLa7x4q6Rnnbnno7Lr48jtBwEm6vHbc+3IYtu9fA5ri+5wTRQmOYzTCbiOimIHQBLZKpCK3zE7IKVpStsq04LLC1ueHZ3QL7Bu8NX/2b7Y8h9PXTEFkd3ndvhHO7f1nHo01mEd8/iOTRUcAQcO5oAHY14RM/OoWjfRHc2laHk8OT0A0Bv9uGvRsb8PDmRty/3g9VF1PBdn4sORUIG2VfSGAxyariQrhdrOq2+NRrtoZZKEa2sIDnqAyu8+MpaKNJ6OUV5zazHFtxrIXw2uJ1zKv6fzUwDIFXhqL4+Zlx/OzMGM6OxgEAnT4ntrfW4XI0jb5gEqFk2XZWgDW1KroKAbEMip1QrRYMhJNlwXUK/aEkYhmt4j4bPHZ0+JwwBK5428WQu/w+UjltajG+YmjdF0ohPO33W70q2rxORFJ59AWTSOdL70U2iwmdPueM2744nsD//P5J7NkQwD998A7YLQtXqUZEREtHzxs4c3gEx5/uRyyYga/FjTve1IG1tzdMTWamEzm88vNBvLZvCLmMjo7tPux8UyeaumsXZAyGbiA6nkZoOIHwZRlch4YTiAVLVb4WmwlWhwXpWA5miwkd231Yv7MRHdt9s1YoX0l0PIVXfjaIM4dHoOcNdN7ix22vb0fzutoZn7cN3UByMod4KIN4OIN4KI14SAbd8XAG2ZQGXTNgaKIieL0am8M8FVjXr3GjvtkFb7MLrjrbNT/va3kdk+NpWQ1drIoeTSI6moKWN1C/xjXVA9vf5r6u7w9aXsfQmUKP7VeDyCTyUD1WWRXe5ER94djb5IRnEYo4DEMgHspMPc5o4bgYpHubXbj9De1Yf2fjjMpxopWCYTbDbCKiZWVkdbn4XKGXb34iDT2SmVGtcTUiZ8hFFfWy/r8em6x6La/sbXDC5Lbe8AH2dHosi9DXziA3GIdnbxtqXt+x5NW3WjiD+IFBJI+NAQJw3t6Amr1tGFEEPvLVlzAYSeNv3rMDb7mlGdFUDgfOT+BnZ8ax/9w44hkNtv/N3nuHyXHed56fqs5hZjr35ARgkCOJQIBEIClSpqSTZa9E5WBLWtv7WN5bW3tr+fa59d2t5L2ztd7dk+9WDhJFSqLoFaldSRYJkYgEMMhpgEGanDtO6NxV9d4f1TODIUBgBsAAQ6I+z9PP29Whuqq6urrq+37f788ks2WRn6eX6+J2jWc6i0/LFEsdFFm9jeoCsprMTy+ADGafA8luKlUin8yW5h3TpexpvRranNZRKBpKdObnShZ5Rga4OezSY1I875+YlPkknVd4+1qMt9pH2HMpSiyVR5bg0UYfTy8P8eSyMIuCM3O7x7LFqYJ3nVG9nRSVJ94hVptliRqvgwa/iwafkwa/k3qfkwa/i3qfE8c7LtJvNu+umH5757wnqSy30xhwTjuv/S6ag7qz+3ohWgjByHj+usJ907feeIaCOn2x/sSSAH/7+Ufn7Aw3MDAwMJimkFMYHclMCZPp0fzt33QdFnvJ0Vty9dpds4vjKhZULh4c5PSve0mP5gk1lvPoc400rva/67lBPlPk/L4Bzr7VRy5dpGapl0efa6SmxTOr8wmhCSYSuelIjcE08cEUyaFpF64kgSfsxFftxl/jwl+jt+V+/ZxruGucqydGuHYyQna8gNlmomlNgCWPhqhf4cdkubmwOdw1xpndvXSciSKbJJZurmTd0/X3LDpFCIGmihni9vRNn3ZV2GYlWs/5szVBPqvM+rufK5omKOYUbAsk6i2fKWK1m98zo/gMHl4MMdsQsw0MDAzmHaEJ1GROL3YXzeridVQXr693syKByWPTXbZzca+a5FJ0w6Rj14l8l0Mk32sIRSP5s2tkToxgX+rF98ll92UbKPEs43v7yJyKgASuR8OU7azD7LVzvn+ML33/OEVV428//yibmnw3vL+oahzvTrCnPcJblyJ0xdIALKss4+nlYT6ytpqllTcfcqsVVH1/mnTjx7KIgqp3hAj0iI0ZOdOlaU3oj83O6DPNZERI2IllUrSeYwHP9yN5ReXC4DjZgoomBJrQL84m76uanvmtp57ojyfSBfZdjnKkM05B0Sizm9nREuTp5WF2Lg3icc49k1GU5tsdT5MtaNT7nFR77Pcka3py3l0lB7bTaipFkjhxWu/+d6ZqgsHRLF2xNKPZIs+sCBtCtoGBgcEsEEKQnSiSHJqMUZhuU9d3PssSrgrr7NMZgFxaQbludJ+z3Hqd81d3/fqqpkXuQlbh/P5+zr7VR3aiSPUSD48+10jtstmPBCzkFC6+Pcjp3b1kxgtUNlfwyG800LBKF8KnROvrs6AH0ySH0yiF6RMbl8eGv9qFryRY+6vdeKucsyoCqGmCwaujXD0xQsepCPm0gtVhpnl9kCWPhqhdqq9Pd1uc07t7GLo2hs1pZuX2GtbsqsVVYZv9RjYwMDC4Awwx2xCzDQwMHmK0vELuUoLshTjqXNwqopTZq+p5vGiTOb3a9PQ72uuR7OZSAbrSLVCKY/Db55QbbDATIQTpo0OM/o9OzD47/s8txxK+N64YrVBy0EdLHRGxLMVYluJgCmQJ96Yq3DtqMZcuYPZejvAvfngKr9PKC7+zkcWh2WVAdkRTvFXKST7RnUAT8Fizny9sbeQDK8KYHnLheKHQl8iw70qU/ZcjHO6Ikymot3/TO2j0O3lqeZinloXY2OQzcqENDOaZQk6ZGtKfHs3jKLNSEXJQEXDc08Jr72Uy4wUutw6Tuy4y6HbIJpnmdUGC9fcn6/j9iKYJOk5FuNw6jDKH/xOlqDE6kiGfuS5j2GbCG3bqBf3C0znDFUHHuzqL3w2hCSaS027n5KR4PJyZKXJXWPFWuoj1TZDPKNSv9PHIbzRSvdgzp8+buW568cSTb/SQSuTx17gwmeUbPttVYZ0hrOvxGs575vRVVY3+9iTXTozQeSZKIadid1uwOc2MRbK4fTbWPVXP8m1VRq6ygYHBfcMQsw0x28DA4CFDTRfJtSfItsXIXUuCIpDdFixzHAooyXp0g2SSwCS/Y1rSpycfN0mYPbaScO1Adr3/oj4WEvnuMeIvtSMKGt5/tgRb0+xzF0VBRYnnKJac85MuenVs5oW9qfR9WmvLcD9Wjem66uY/Od7LN15rY1llGd/74kZC5fY7Wo9EusArJ/p48UgPA6NZajwOPvdYA88/WofXdWfV1IUQdETT7Lsc4UhHnJwy+4tmkyxT73PQHHCzKORmUfDWRfwWArFUnn2Xoxy4EkUAi4IuFgXdNAddNAfcN8RsvBu5okprZ5z9V6Lsvxyls+Sgr/M52NkSYtviAF6nBZMsIUkS+uFAKk1P35dLsS8Oi4mqCrtxHDAwuEcIIcili9flz+am75emrxf83onba6Mi6KA86KAi6KAi6NSF7qDjoRCoEoNpzr7Vy+WjI6iKNqecWE3VEAJqWjysfbqexlXvzaLSDwKlqHLpyDCnf93LeDRLecCO2zv7cwbZJOEJOWfkDLu98x/zdTN3dHIoTZnPzoYPNhBqKL9nn6WqGleODtN2YFDPhL6ukKG3avbRJ/cCpajSeyHB1RMjZMYKrHyimkWPhDAZndEGBgb3GUPMNsRsAwODhwB1okD2QoxsW5x85yhouhjpWOnHsSqAtaHcuPB6n6GM5Ym/1E6xb+KO5yHZTZiDTiwBvRNCd9I7sQRu7qAXQvDXb17lP711le0tQf7mMxtw2+5eBFFUjTfbI7xwuJsjnXFsZpnfXFfDF7Y2sqL69heMuaLKkc44+y5F2Hs5Sm8iA0Bz0IVvDnEWBVWjOzaziKDdItMU0MXhRUH3lFjcFHDhugfrPlc0TXB+YIw9l/Q88rP9YwAEy2zYLTL9ySzXn97VeBw3LHtz0E243EZnLM3+y1H2X4nS2hknr2jYzDKPLfKzoyXIjpYgTQGXIUgbGDwgVEWj/3KSjlMRus7qRcSux2IzUea3U+Yr3fzTrbPCSnaiyFg0w1gky1g0q7exLNnxmZ2XjnIrnpCD+hU+mtYG8VU/mN+9EIKha2OcebOXfEahYbWf5rVBPGHnHc+v/3KSM7/uo/dCHJNFZtmWStY+VYe3cvYd/PmsHgtxbk8fqWQeT9jJ2qfqWLqlck7F8x4m8pkibQcGpuI4Qo3lbHi2nqa1wQXdQWxgYGBgsDAwxGxDzDYwMHifoiRzZNviZNtiFHrHQYA54MCxShewLTV3V4nbYOEjihqZ81FEYfbh0JJJwuzXheu5FMssqhrfePU8/3iyn48/Uss3f2v1vMRGXBoe54XDPbx2up9cUWNTk48vlSJIrs9G7k9m2Hs5yt5LEQ53xMgVNewWmW2LAuxcFmLX0iC13rkLIEII4ukCHZEUHdE0ndEUHdEUnbE0fYnMjESdynI79X7ndOHBUtHBBp8Tj/PejU4YyxY5eDXKnksR9l+OEk8XkCRYX+dh19IQu5aFWFFVjixL5IoqXTG9uGFHNFVafn090tcN7baaZQqlglGLgi52tITYsTTI5iafkeVsYPAAUYoqfe26gN19LkY+o2Cxm2hcHSDcWD5DsLY5zXd0nCnklGlxO5phPJol1p8i0qN3jpYH7DStCdK4NkD14grkeXZlCk3QfT7GqTd6GO4cx+624PbaiPWlAPBWOmlcE6BpbZBwU/ltxVBV0bh6YoQzb/YR70/hKLOwemctq3bU4HDf2agf0B3aHaeinHmzl0jPBHaXhVU7ali1o8bIEC6RHs1z5q0+LhwcoJhTqV/hY/2zDbMucmhgYDA3or3d2JwuygPBB70o72mEppE+cgRlePhBL8oMyp5+GlPF7Efgvp8wxGxDzDYwMHifoeUVkj+9SvZcDABLpWtKwDaHncbFwhyZLGR3L4rIvV9J5RX+4IenOHAlyh89tYR/+fSSed/PRjN6BMkPjvTQn8xSXWHnU5vqSeUV9lyKcDWiixz1PidPLguxc2mQLc3+eRVi84pKTzxDR0QXtzuiKXrjGXoSGaITMzPpy+xmXeD2Oan3uWjwOwmV2ZjtZhMCroyk2HspwsneJKomqHBY2NES5MllIba3BPHNIYpFCMHIeH5KnO+OZ2gKuNjREqTOd2euR4OHCyEEnaejZCcK1K/0Ux5wPOhFWhCMx7J0nY3RdS5KdqKIJ+zUYxHCjql4BPttoreKBZXetjgdp6N0n4tRzKvYnGaa1gRYtCFE7XLvrIq63S3psTzd52J0nYvR355EVTRsTjMNq/00rQlSv9J3TyNJVEXj6vERTu3u1SMc/HbWf6CeZVursFhNTCRydJ2N0X0uysDlUTRN4Ciz0Lg6QNPaALXLfTOc0bl0kQsHBzi3t5/MWAFftYu1T9XRsil8T7ff9Q7yrnMxZJNEy6ZK1j1Vh7/GfU8+Qy1qjEWzjEYyjI5krmuzZCdmn/cNYHOY9f1yat/U98+KoBOL7d5sl+RwmtO/7uVy6zBCEyx+JMT6ZxqMnHEDg3lCKRQ49MpLnPjFa5itVh5//vOs/40PI8uGIWEuiGKR8V/9ivjf/h35q1cf9OLcQPMvfo5t8eIHvRgPBEPMNsRsAwOD9xHFaIb4ixdRolnKdtbheiSM2RAU7ohkusDLx/t4qbWHWCrPxkYfWxf72bYowKqaCqMQYYnIeI4vff84l4Yn+ObHVvH8xvr7+vmqJnirfYQXjnRz6Foci0liU5NvypHcvEBiMDIFhb5Elp54mt5Ehp6SyN2XyNCfzFBU7+yca0VVObuWBdm1NMS6Oo/R6WLwQMhniux96TIdpyJTj3krnTSs8tOwyk/VYs+cMojfywghiPZO6AL22SjxAT1f3lftojzgYCySYSyaRbvuN29zmmeK3GG9WN3oSIaO0xF62uIoBQ2720LzuiCL1gepWep9oNu0kFPoa0/oYvL5GPm0gmyWqF3qpWmtLmyX+e4sF7+Q02M7zr6lx3b4a9xseLaexY+E3tUFns8q9LbF6TobpactTiGnYrbI1C730bjaT7w/RfuRIZSCRt1yL+uerqduhW/+O15HMpzb0zf92St8rNpeg6Ns9p2NxbzCWCQ7Q7SeiOdmREY5yixTgvRcXeDZVJHRkQxjkQyp5MyOV7fXNkPkrgg55lRYsJBTuHhwkM6zUUxmmeVbq1j3dD0VQePc1MBgvhjuuMqvvvNtEgN9rH7qWdLJBJ2njlO1eCnP/N7XCNQ1POhFXPBo2SyjP32VxD/8A8XBQWxLFuP/8pdxPvoos3ae3AfMwSCS5f7l5i8kDDHbELMNDAzeJ2TbYiT+8QqSWcL3qeXY76KC+sPMxcFxXjjczc/ODJBXNLY0+1hWWU5rZ5xLw6Uh1nYzW5r9bFscYNtiP4uCCyOyRdMEQ+M5umNpumJpumNphsdzVHscLAq6aA66WRR0z8mxe7PPiKby9MQzdMfT/Kc3r5LMFPjOZzawa2noHq7N3BkczVLusNyTnO77iaoJBkezJNJzc9NVVtgJ32FxTQODe8VQxxi7/76NzGiBzR9tpmltgN4LCXraYgxcHUVTBBabibrlPhpW+alf6cftfX9FLqhFjf4rSV3YPRslPaZH/VQt9tC0VncJVwSnRzhoqsZ4PFcSEGeKlO8UE53lVprX6wJ29RLPvEd63AmaqjHcOUbn2RhdZ2OMR7OAntmtC6EOKsJOvOFJQdSJzXHjcTo7UeDc3n7O7+snn1GoXuJhw7MN1K+cm+isKhqDV0enHPGpRL7kjg6z7un6e+aOngu5tJ4RfX5vP5nxuR3rJzHbTHhCDrxhJxXXu6jnKDDfimJendoXxyIZRkem3d+3KiB6K2xOM6t31rJ6Zy3O8js//zAwMLg1qlKk9dWfcPS1V3B5vDz7z79G47pHEEJw6dB+9n7/u+QzGTZ/7BNs/tjHMZkfThH0VqhjYyR//GMSP3gRNZHAsW4d/q9+FffOHUjywvv/fZgxxGxDzDYwMHiPIzTB+O4eJvb1Yal14//sCsye95dQMN8UVY3dF0Z44XA3x7oT2C0yH1tfyxe2NrCscrrAYHQiz+GOGIevxTnUEaM/qV+wh8ttbF0UYOsiXeCu9syf42gyDqIrlqY7np4WruNpeuIZ8sp0PrbNLBMutzM8npvKPwbwOC16ob+Ai0Wh6bbe58RikskrKn2JLL2J9FRMRl/JTdybmPkZ4XIbf/f5jayufTjz2gwMHiSaJhiPZfGE7n8UjKYJTv6qm+O/7KbMZ+OZ311FuGlmQdZCTmHgcpKeCwl6zsemhFp/rVt3ba/0U+ZfWB0yQhMIIRCafrzVNAFCX1/9OabayQiR3otxijkVs82kF0lcE6Bhtf+O8peLeZWxqC4iOiusVDZXvKcK4gkhSAylGbwyqov0JaF+PJ6D653EpaKSk27iVDxH++EhlKJG09oAG55toLL57v9XJpfH4bYuCCFVLerCv6rOvpaF2SJTEXTirLA+sI5zIQS5dJHRkSzF/OxFbUmSCDeV39P4mYcNIQTRni6uHW/FUVZGsL6JQH0jdve96ZQpFvIkBwcYj0XRVAWhaVM3TdNKx8PSY6L0mKaBEEiyjCTJeivLSLKELJtKj0tIsoxceg5JQmL2+6+3qhp/7f0d7fdeJtrbza++822i3Z2s2P4ku774VWxOFxO/+hVaNovriSco2m3s/f53uXRoP/7aep79vT+iasnSO/7MQm8vmWPH0PL527+4hGQyYamqwlJXj6W2Btn67sflVDLBcMdVmEdd0u5y469vwJzOknjhBUZffhktk8G1YzuBr3wFxyOPLAjDksGNGGK2IWYbGBi8h1HTRRIvXyJ/dRTXpko8H1mEZHmwvcaqJohM5OhPZulPZuhPZBkez7Gx0cdvrK7EZl44WW2xVJ6Xj/XyUmsvw+M56nwOPr+lkU88WkfFLFxOvfEMhzpiHLoW40hHnHjJWWszy5hkCVmSkCWQp+6XpiUJkywhSWCSJYTQt5sQAlUINDGd1a2WRBP9cYGiCpTrqgxaTTL1fieNfhdNASeNARdNfheNAReV5XZkWULVBAPJLB2x1HSec6m9PsvZLEt4nFbi6fzM4csWEw1+J3W+6WKGdT4nDX4XtV7HvBR6NDAwuDXZiQK7//4C/ZeSrNpRw+P/bAmm+3T8TyVz/PofLjJ4dZSWTWF2fGop1ps4ba9nUlTsaYvT2xZn6NqYLhS/x3GUW2laU8poXnZ/sqvfiyhFlfFo7saM55EM2Ykiskli6eZK1j9Tj7fS9aAX18DggTMei9L+9j7aD+4l3t97w/Nl/iDBhkYC9Y0EG5oI1jfhrapGNt38GJRNTZDo7yMx2E98oI9E6TYWjcyrWHg3+GrqaNmyjZYtjxOoazBExZugqSrHf/4qh1/5IXa3m6e/8i9YsvExlGSSoW/8Gam9e6dea1+9GvfOHcSqwxzY/QtSyTgbfuN/4vHnP4fFfvuOZS2fJ3P8BOmDB0jtP0Chu/vuFl6SMFdWYq2txVJfh7WujoLPS99Eks7Oqwx2XLlv+6atqOLOFfBXVVPz5NNUbtyEv7YBm9OoG7NQMcRsQ8w2MDB4j1IYSBF/8SLqRAHvRxfj2lR5x/PKFJQbCtTdCiF0IXhKsE5m6U9m6UtmGBzN3pD/67KaSBdU/C4rz2+s49Ob66n13ruTg6Kqzelc59LwON8/3M0vzg5RUDWeWBLgC481smtZ6I6zsDVNcHlkgsMdcSITuZIYDVrJ2aeVBGlREqgnBWtVCGSpJGxPCt6yLnqb3imCy7oIXl1hpzHgotHvotrjuKv87rFska4pcTtFZDxPtcdBg39atA66bcYFhIHBAmLo2ihv/N0FcukijasDdJyKEGoo49mvrJr3woudZ6LsebEdVRHs/FQLS7dU3dF88lndtZ1LF+/xEt4dkiQhy0DpWEzp2Ku7DCm1+jHb7rYQrCtDeg85pxci+UwRIcDuMoa8Gzzc5DNprrQeov3gXvra20AIqluWs/yJXSx97HHUYpFobzfRni5ivd1Ee7tJDPShqSoAJosFf209wfomPJVVTMSjJAb7SQz0kxkbnfocs8WKt7oGX3Utvpo6/LV1VIQqMVksyCUXtXwT17VIpckcO07m0CGKgwNYKqsw19VirqnBXF2NuaYGye0GxEx3d8nhPWuEYPDqJa62HqK//QJCaHiramjZso0lm7cRamy+b+el+UyGzFgSt9d/W8E3e76NxAsvkD54UHevzxJLZSWhP/lj3Dt2zGnZEoMDvP4332bo6mVaNm/jqS//Ac7yCtJHjzH49a+jJpOEvv51nJs2ktq3n9S+fWTPngUhEOEQ15Y2cXUsRnkgyDP//I9oWLPuhs8oDgyQOniQ1P4DpFtbEdksktWKc/Nm3Nu349q2DZNn9qNoRLFIcWCQYl8vhb5+in29jPb20pOMMGiWGHXp27gsm6cqW6TS7sY0T9+1QJAaHiLlclBoWUzK7SIRHUa5zmle5g8SqKvHX9dAoK4Bu3thFa2tW7EKq+PhFNwNMdsQsw0MDN6DpE+OkHztGiaXGf9nV2Ctu7M/1u5Ymu8f7ua/newnNYdho+8k4LZR63WUbk7qfHpb63VQ43FgNcm8fS3Gi609vNU+AsCTy0J8dksD25cE5zyEuqBonOxJcuBqlP2Xo1wcGp/zMjutJn57gx4lsji0sE5MDAwMDG6GEIKzb/Vx5NUO3H47H/zqKoJ1ZXSeifLWC+1IEjz9xRU0rgnc889WCiqH/ts12g4MEKwv45nfXYkn/HBeQBkYGBjcK1SlSNeZU7Qf3EvHyaOoxSLeqmqWP7GL5dt24qm8dYehqhRJDPRPidyTQnd6NInd5cZXU6cL1jW1U/fLg0Fk+fajSIQQFLq6SO3dS2rvPjKnT4OqYvJ6sbW0UBwYoDg4CNcJt3J5OdaGBqz19Xrb2IC1oQFzMAhmM5LFgmQ2T90wm28pTKdHk1w73sqV1rfpu3geoWl4wlUs2bKNls3bCDcvvithu5jLMRYdYTwaYSwyzFg0wnhkZOqxXGpi6rUuj5eKcBWecCWeUlseDGO5cpX0y6+QO3UK2eWi7Nlnkd2zHGEiIH3wIIXubtxPPkn4T/8N1rq6W79F0zj9+s85+OMfYLZYeOp3f5+lW7eDqhL9zneI/3//FWtDAzXf/ivsK1bMeK8Sj5M6cJDUvn2k336bGCrn60KkbRaW1Dez88t/gCk5RurAAVIH9lO41gGApbYW9/btuHdsx7lpE7Lj7jrOxyLDXGk9xJWjhxi+dgWAYH0ji1pWUO8P4ZpIU+jtQ4lG59WdbV28CN9nPoM5oJ83CU1jLBoh3t9DrLeHeH8vsb4eEoP9qMWF1fkO8MW/+puHNo7HELMNMdvAwOA+o8Sz5C4lKAykMPvsWCpdmCtdmH3227q7hKIx+otO0q1D2Jor8H16GaY5ZnIKITh0Lc73DnWx53IEsyzx4TXVbFscYC6EcIfkAAAgAElEQVSass9lpdbrpMbjwGGd/bDqgdEsPz7ay8vHe4mlCjT4nXx2cwMff7QWj/Pd16U3nmF/Sbw+0hEjXVAxyxIbGrxsbvJhn8PQbp/LyofWVFFuN1xgBgZ3SzZVoOtMDG+Vi3BT+Xsq33e+EUIw0jVOecBx13m9+azCnhfa6TwTpXl9kCc/v3xGEb2xaIbXv9tGrC/Fhg82sPkjTfesWGB8IMXuv79AYjDNug/Us+WjzZjMRryQgYHBjQhNI9feTvrtQ2SOH0d2u7E1N2FtasLa1Iy1sRHTbIW+69CyWQo9PRQ6O8l3dVHo7EIdH6f8ueco/9Bzt8zeBUgl4nScPDYnh7DN6STU2Iy3uuZdxV+hqkzs2UPyRz9C5PK4HtuCa+tWHGvXIllufp6ZS6WIdHdw5ehhLh85SG5iHEdZOcu27WD5EzupXNSCJEkoySSZI0dIHzlC5vgJtGx21suumGTs4Ups9XVYauuw1NVira/HUluLORh8VwFYFApkTpxgYt8+Uvv2U+zVI05sy5bh3rmDsp07sa9ejVSKM9EKBYr9AxR6uvXvp6eHYk8PhZ5eXeiezfa+TtyWzGawmLHWN+B+fBuuxx/HvnIlkiyTGR/j2vFWrh49RG/bWTRVpTwYYsmmrZQHQ6iKgqYoequqqEqx1CqohTzFWIz8yAjFRIKc1UxaaORyM7ep2WKlPBiiIhSmPBimIhTGWeEhlYgzOjKk34aHSCXiM9+nCco9XvxLluJvbKJxzQaqWpbOrtOgUCDxgx8Q/Zv/FxQF/5e/jP8rX75BMBZCEOvtZu/3v0vfxfM0b9jIB776h7i9PooDAwz8ydfJnj5NxW//FpXf+Aay69a/M1EokDl5ktG33uLksUNcs8tYFBV/KossyVgCfmxV1djq6rB4vbpz32TGZNZvssmMbDYhSbM/H8hOjNFx4igjndcACDcvKTnut+KtrJ71fO43mqoyOjJMIZt50IsyA39dPRbrw1kryxCzDTHbwMBgnhGKRr57jNylJLnLCZSoftIkuyxomeJ0QSSzjCXsLN1cmCv11lQq+KOO5Yn/sJ1C7wTu7bVUPNuIZJq9aJQtqLx2eoDvH+7iykiKgNvKpzc38NnN9YTK738Brryi8nrbMC+19nC8O4nNLPORtdV8bksDa+s8ZAoKrZ1xDlyJsf9KlK5YGoBar4MdLUG2twTZushPmSFIGxg8EMbjWc682Uf724MoRd2VZXOaqV/ho36Vn/oV/gVRcO1BkRhMc+DlywxcGUU2S7RsDLPmyTqCdzCSJto3wevfbSMVz/HYby1i7VN1NxUilKLKwVeucvHgIDUtHj7wuytxVdz5RY4QggsHB3n7H69itZt4+osrqF/pv+P5GcwPWj6PMjyMuarqtoKewc1RU2kKXV0Uujop9PXhXL8e52OPGRFbs0SJx0kfOkTq7bdJHzqMGteFPtuSJWiFPMW+/hnuXXMohLW5GWtTI7amZqxNTdiamzBXVqLEYtOCdVc3hc5OCl1dujA6iSRhqaoCs5liby8mvx/v88/j+eTzWEKhG5av/9IFfv7tb82I2pgLZpuNYH0jocZFhJqaCTUuwusLkP75z0m8+BLFvj4sNTWYAn5y59tA05CdTuyPPoq6bjWZyhCjhZzunO7tZiIW1edrsbJo4xZWPLGLhjXrkRSFzMmTZI4cIXX4MPmL7QDIZWU4N23C5PXMfqGLCsWhIQr9fShDwzNEZclux1pXOy1y19Uj2ayk3z5E+tAhtHQayWbDtWUL7l07cW/fjqV67kKjVihQ7Ouj0NODmkggFAVRVPRWKcKM6enHtEKBfPslchcuAGDyeHBt3Yrr8cdxPb4NSyhENjVBx/FWrhw9RM+5M2jqzBGmkiQjm0zIgKSqSMUikqYhCz2OxZbN4cjlcRRUKoIhfCtXE3rsMXyPb8dc9u7FNQv9/SRffJH4T39KqlhAWbEcsXED2fIyxqIjjI0MMToyjNA07O4ymtY9QtOGjTStfeS2RTuLIyNE/q//m/Ff/hJLdTXhb/wppo2P0tt2lu5zp+k5d5pUIo7V4WDXF77Kyp1PI0kS42/sZujf/ltQVSr//M+p+PCH5vxdCSEYOHSQgz9+gXSxgLCY0TSt1DFQ6iBQ1Bu2851QtXhpyVm/lYrQncdkGjzcGGK2IWYbGBjMA+p4ntzlJNlLCfJXRxEFFcwStmYP9qVeHEt9mAMOtIKKEslQHM5QHElTHMlQHE6jjRem5iXZTFgqXSjxLKKg4v1nLTjXBGe9LIOjWX5wpIeXj/cymimysrqcL21r4sNrqubkZp5P2ofGeam1h9dOD5ApqDQFXAwksxRUDbtF5rFmP9tbguxoCdIUcBkXlwYLnr6LCS4dHaLMa8db5cJb6cRb6cJiWxi/ubshPpDi9O5erhwfQQJaNoVZtbOW8ViW3gtxei4kyJaOYaGGMupX+WlY6SfU+HC4tgs5hRP/1M3ZN/uw2E1s/FATY5EM7UeGUAoa1Us8rH2qjsY1gdtuDyEE7YeHOPDjK9jdFp798kqqFt9ezLjUOsT+H17G6jDzzJdXUtPindM6JIfTdJ6J0nEqSrR3gvoVPp764oqHunPiQSKEQE0kdFGor59CXy/Fvn59ur8fZWQEhCgJep/A8/wnsYRvFPQedoSqUhwcLInWXVPu3kJXlz6U/R3Yli7F96UvUvHcc0hGJ8EMRKFA5swZ0gffJnXo7SnR1eT14tq2Ddfj23Bv26ZHS1ASNXt7yXd2TgnU+W59+2sT0zEOyPIM0VtyOrE1lVzdzU36/eZmrA0NyHY7QggyR46QePElUvv2gdlM+Qc/iO9zn8WxZg1CCM69+Sv2fO+/UhEK89wffp0y/+xjmDJjo0S6O4l0dehtd+eUM1MSAneugM/ppnrTY9R94FkwyYxcbmf41Emivd2MZlNopXNWSQjKrXYC1bWE16yncuUqqpYsQ/T0kD58mMyRI2ROnEQUCmCx4Fy3Dte2rbgee0x3JptvXWT3VmiFgh4J0t9PoVc/fhT6+yj26scQkdHXyRwK4d65E/fOnbge23LXURJ3i5JIkD50mPTbB0kdOowaiwH6b9P1+Dbcjz+O45FHUIWGUiggxsbInjhB9shRsq2t+rERsNTX43rsMV0Q37wJk8eDKBTInj9P+uhRMq1HyZ4+jSgWwWzGsXo1zi2bcW3egmP9OiSrlezJkyReeIGJt/aALOv72Re+gGP1qhuWO5dO0XPuNJ2njtN1+gTZiXEkWaa6ZTnNGzbSvGEj/tr6d+mULtL531/j8o9+wHAxx7hTNxzZXW7qV6+jYc16Fj2yCZfHi5bNMvKtv2D0lVewr1lDzV/95W0jSu4WIQSaqgvbk0L3XHRDk8WC3XVrUd/AYDYYYrYhZhsYvCcRmkBN5kCAaRbxHPdjeQr9E+QuJchdSlAc1F3Epgor9mU+7Et92BZ7kGcZx6FlirqwPZKeEroR4P3YYizh2w/NFEJwsifJ9w518/qFYYQQPLuyki9ta2Jjo3fBisETuSKvnR7g1xdHWFZZxvaWIBsb5xYhYmDwINFUjWO/6OLk6z3YHGYKORWhTZ9PuX02vJXT4ravyokn7MJRZlmwv8tJhq6NcuqNHrrPxzFbZVY+XsPap+so880c2SE0QbRvQhe22+KMdI1PFXerW+GjYZWf2mVeLDYTUqnIqSRTKqq3sLfBrRBC0HkmytuvXCWVzLNsaxVbP7YIR5kuguXSRdoPDXFuXx+pRJ7ygJ3VO2tZvq16RlzIJMWCyoEfXeZS6zB1y7184HdWTs1rNsQHUrz+3TbGIhm2/OYi1n+g/l3/K4UQxPpSdJyO0HkmRnJI/w8LNZSxfFs1Kx+vfuD/sw8TWj5P8kc/JnPyxJRorWVmDm02h8O6o7LkrDSHQqT27NUFPZNpWtBbu/bBrMQ9RmgaufPnmXhrD6m9eygODILFckP+rmQxg/nGx5RojEJPjy4UlpArKqaF0qYm3SXc3Iw5XMnEG2+Q+P73yF+9hjkUwvu5z+L9xCcwVcy+0NlCRghB/tIlUvv3UxwcApOMJJugVOwPWUYyySDJpedkkE0gQe7CRTKtrfo+aTbrouvjj+txECuW66+dw3Ko8bjeudCpu6/N4dCUaG0OhWb9v1Do6SH5ox8x+tNX0VIprGvX0L64nsvX2mla9wjPfe3rdyyiCSHInj5D/PvfZ+TAPsYdNnIrl5MO+onFIzc4vh1l5QQbmgg2NOEr9+CKxbFcuESu9ShqMgmAtbkZNZFAHdXfa1uyRBdbt23F+cgjt42IuFdMdpap4+NYGxsX7P+w0DTyly/r7v+3D5E5dQqKRSSHA+cjj6BEIuSv6NnLpooKnI89hmurLmBba2tvO38tlyN7+jTp1qNkWlvJtrWBqiJZrZirKin29GKqqMDz/PN4P/NpLOHwrJZb01SGr12l89RxOk8fJ9rdCUB5MEzzhkdpXr+RMn9gyn3df7GNYj6HbDIRrPDiudqNfyxF0/OfJPT7vz+1X+QuX2Hgj/8VhWsd+L/yZYJf+9q7xtoYGLwfMcRsQ8w2MFjQCEVDiWcpjmR0B3M0izKSoRjLgFI6RpklLAEH5pATS8g53QYcSPOY6SlUQb5rjGxbjOyFONpEAWSw1pdjX+bDscyHOey8byeFQgjaBsZ5/cIQr7cN0xFNU24386lN9XzusQZqvUahLgOD+SQ9lmf3311g8Oooy7dV8cTzLciyxFgkS3IkTXIoQ3I4TXJYb5XCtPvM5jJT5rPrTl1JQpZBkiRd4L3+vjQ9DfrvXmiTrbhhWtPQq9YLcLgteK4T0b2VrtuKo0IIetrinHqjh6FrY9hdFtY8WcvqHbXY3bO7aMqlivS2x+ltS9BzIU4udesCOpPrLEsSyBKyBDanhYbVfprXBalu8WC6R1nQ94rRSIaDP7lC74UE/ho3Oz7V8q4Oak3V6Dob4+yePoaujWGxmVi+tYrVu2rxhPTj9OhIhte/e574YJqNzzXy6Iea7sjVXsgp7H3pEtdORGhcE+CpLyzH7tK/N00TDHeM0nk6RueZKBOJHJIE1Us8NK8P0rQ2eENHhcH8IoQgtWcPI3/xHyj29U05UCdjAPS2DktNDbL95t9NobeX5A9/xOhPf4qWSmFfswbf5z5H+bPPvOfcxVouR/rIEVJ79jKxby9qNAYmE85HH8W+bClCUW8eV1AsTj9eeszk9c4QrK1NTZi8t+7cF0KQfvsQie/9A+nDR5CcTjy//dv4vvD5WYljCw0tlyPd2kpq7z5S+/ejDA+DJGHy+fQIClXVHZaqitA00LSpFlWdmo+ltnbKFevcsgXTbaIT7jdqKs3Qyz/i17/6GQmzxJKJPFs+/DF8zz+P2T+3mCRRLDK+ezeJF35A7tw55PJyvJ/4ON7PfEaPOSmRSiaIdHcgSTLBhiZcnpvvW5OCbPrwYdLHjmH2eKfc15MudoPZoaXTpI8d04XtY0cxBQJ6Z8BjW+fcqXIz1FSKzIkTZFqPkr92jbKnn6Liox+9a7f6RDxG1+kTdJw6Ru/5syiF/NRz3qpqGtasp2HNBupWrMbmdKLEYkS+/R8Ze/VVzOEw4f/lX6OOjTHyF/8BubyM6r/4C9zbtt3VMhkYvBcxxGxDzDYwWDAo8Sz5nnGUSJZiRBevlUQWJvUeCUxeO5agA3PYiSXoBAmKkawudEcyU27tydeb/Q7MQQeWsBNzcFLsdiDb7myonlA0ctdGybbFyF2Mo2UUJIuMvcWLY1UA+1IvsvP+9YqrmuBEd4I3LozwxoVhBkazmGSJzU0+Prymmt9cX43TeufDEg30i1kEhivxAaBpAon3xrbvu5Tg139/gWJeZcenl7JsS9UtXy80QWo0T3JoWtxOj+YRgpIILabu3yhYl+4LkGUJSeIGoVsqPS7L+n0kSI/mGR3OTOVbg+6W1l3izlIciu4ad3lsXDsZ4dQbPSQG07h9NtZ/oJ7lW6vvKipFaIJI7wTDHWOoqgZC/57F9et7k3WfSOTovRhHKWjYnGYa1wRoXhekfoUP8xwK0N5rlILKyTd6OP1GL7JZYvNHmlm9s2bWhRcjPeOc29PP1RMjaJqgcXWAmhYPx37Rhckk84HfXUH9irvLqBZC0LZ/gLf/8Souj41NH25i6NooXediZCeKmMwydcu9NK8P0rgmgGOORYUN7g35jg5Gvvkt0ocOYV28iMpvfAPX1q13PD81lWbsv/+M5IsvUejuxhQM4P3kJ/E+/zzmwOxjFuaCEo+TOXaMdOtRCl1dunu8uhpLTTWW6ppSW41se/ccdyWRILV3HxN795A+dBiRzSK7XLi2P0HZk0/i3r79gbijc5cukfje9xj75T+BplH2zDP4v/TF2zrf1YkJioODFAcG9ZiHwUHURByTx4s5FMIcDmMOBbGEQphDIWTnvTUeFIeHSe3bT2rfPtKtrYhcDtnpxLVtG+5du3Bvf2LW+8Ok0H03cRf3g8Erl/gf3/4m+UyanTuexXvkOOm330ayWnFt24bsmF0n3aQbWxkextrQgPfzn8Pzm7953xzTBu9/ioU8/RfOkx5NUrdy9S3zo7NnzjD8v/8f5C5eBMD1xBNU/8W35txBY2DwfsEQsw0xe14QQizYIUoGCwehCQq94+TaE2TbEyiR0hBaWcIcsGMJOnXROqQL0eag47YxHaKo6u7tkritt1mUeBbU6WOaqcKGOeSY6eQOOTG5bhSitYJK/kqSTFuMXHsCkVeRbCbsy304VwWwtXhnHR9yLygoGoc7YrxxYZjdF0aIpwtYzTLblwR4dmUlTy8P43UZYsTdUMyr9F9K0H0uRndbHCWvUrtcj0eoX+HH7X04q0bfD1LJPL0X4/S2xelrT6CpgoqQE0/YgSfkxBMu3ULOWTuD5xNNE5z4ZRfH/6kbb6WLD35lFb7qhXuhKzTBRDKnC+jXCenJ4cwMx7Qk6UY9X7WLDc/Us3hj+IG7oYsFlb6LCTrPROk+FyOfUTBbZRpW+mleH6RhdeCmcR2TTHYgjEYyjI1kGB3JMhrJMDqSAYmp/UpvHXjCLlwe67uez3Sfj3HwJ1cYj+VYsjHMtt9ejMtzZ8eG9Fietv0DtB0YIJcqUtlczjNfXnVPndEjXeO8/rfnSSXyWOwmGlf5aVoXpGGVH6t9YYtT72fU8XFi3/kOiR/+CNnhIPiHf4j3U5+8Z8PFhaaRPnSIxIsvkj5wEMliofy55/B+9rPYV664K/eiOjpK+vhxMkePkTl6lPzVqwDILhe2xYtRYjGKw8MzXL0ApkBgSti21tRgrq5GZDJM7NlL9vRpEAJzZSVlT+7C/eRTODdtXDCFLYsjIyRfeonkyz9Bm5jAsWEDvs9+Ri9EOClaD04L19r4+Iz3SzYbZr8fJZlEZLM3zF92u28QuE0+P7LDjmS1IdmsSFYrss02NS3bbEiTN6sVZWiIiX37SO3bT75dz7K21Nbq4vXOHTg33p/tmRwa4Oybr2O2WPHV1OKvqcNbXYPVPn85zOf37Oatv/8b3D4/H/2T/5VgQxMA+c5Oki+9RLr16IxCiLfDUl2N9zOfwb1zx107fQ0M7hahqoz97GeIooLnEx839kmDhxpDzDbE7HtGKq+w73KE3RdG2HspQqjcxr/+4DKeWRE2hG2DKbS8Qu5Kklx7gtzlBFpaAVnC1lSOfbkf+xKPHg9yj0UToWoo8VwpqiSjR5WURG9xnUtRdlmmRW6fQxfbryQRRQ3Zaca+wq87sBd75jXC5J2k8woHrkR5/cIwe9ojTOQVXFYTu5aF+OCqSnYuDeG+Q7f5fJJLFUkOpxmLZfFVuQjWlS1Yl+14PEvP+Tjd5+MMXE6iKhpWu4m6FX6sDhO9FxKkR/WhgP4aNw2r/DSs8hFurrgjkW9SWBuPZWc4ZW//xusculrJ1Squc++WXL2TjlfZJFG92IMnvDBjZlRVY6RzjJ5SBEW8PwWAy2OjYaUPi8OsC4+RLOPRrL5uJWwu83Xio95WLaq4Y0FxrmTGC/z6Hy7QfynJ0i2V7PjU0nkv8Kjlcoz/8p9IvvITTC43lf/uf8NaX39P5p1NFaaiUMaiWaoWe2hc5V+Qv1lV1Ri8PErnmSidZ6JkxgvIJonaZV6a1wXxVbkYi2UZvU60HotkZkS7mK0ynrCTimAp2qMkcl//e5x8zfUit8tr59yePrrOxvBWOtn+yRZql/nuyXopRZVYX4pgfRmmefiPyWeKxAfThBvKMVmMi+AHiVBVRl99leh//GvUZBLPxz9O8F/+EWbfvdmXbka+s4vkD3/I2GuvTeUdW0IhzFVVWCorsVRVYg6X2soqLJVhTD7flGAyNez+6DHSR1vJt18CIZDsdpwbNuDcsgXX5k0zitUJRUGJRKbE3UKpnZwuDg5BUe9Isy1fTtmuXbifehL7ihUL+vpBTaUZe/WnJF74AcWBganHZacTS01NyZFecqNfN23y+ZAkSS+ilkqhRCJTt+LI9H1lZIRiNIISjU1tnzkhyzg3bMC9Sy/mZ21uvm/bM9bXw9HXXuHy4YPIJhltMq6kRJk/iK+mdkrg9tXU4auuxVnhueNlVJUie1/4O87u/iUNa9bzoa99HUdZ+b1aJQMDAwODBYYhZhti9l0Rmcjx5sUIuy8Oc/hanIKq4XdZ2bUsxOneJB3RNBsbvfzpc8vZUO990Itr8IBQkrmS+zpOvnMMVIHkMONY6tUF7BYv8i3cdPOJ0ATqaF4XuCMZPZs7qmd0i5yCXGbFsVIXsG1NFUim+5d/3RFNs+9yhL2XIxzrSlBUBV6nhQ+sCPPsykq2LQ4siMKIQghSyfwNLs/kcJrsxMwLMGe5lYbVfhpXB6hd5n2gbkBNE4x0jdN9PkbP+RjxAb3gWUXQQeOaAI2r/VQt9kwJSkIIEoNpetr0onbDHWNomigJ3j7qV/ppWOmfIaSqisZEPMdoJMN4LMtYVBdkx6JZxmM5VGUOIvZdUhFy0Lj6xvV6EKRH8/RciNN7IU5fe5JCVkGWJSoXVZQ6Cfz4ql03XNSqqsZELDflph2NZBkdSTM6kp3qaAAI1pfRsNpP05rAvHWgDFxOsvvvL1DIKmz/VAvLt1bf88+4nkJfH8kfv8zYT3+KOjaGdfEilJEIqCrhP/szKn7rYw9E+BGaRu7CBdJHWhH5/O3fMPVGgdBU0ARoKkLV9FabzGvVnxOaCqqGORgk8M+/etPh3UITjHSP03E6SufpCOOx3NRzkixRHrDfxHXtxFVhu2HfuJV7ezyemyrmabbKbPxQE2ufqnugv6X3MkJRUOIJRLFw+xdPIWEO+N81L/pu0HI5lGgUkcuh5QuIQh6Rz6Pl84h3mZbMZiwNDXoGc13drDOpM6dOM/Lv/z25CxdwbNhA+M++gWPlynu+Tu+GOjHBxO7dFHp6KQ4PoQwNUxwZQRkenlEgEUCyWDBXViK7XLrzWlWRLBYc69bh3LIZ1+bN2NesuWOnr9A0XbBFzLqg2kJCKArZ06eRnE6sNTXIFRX39FgsNA1tYgJRKMzYL/V98eb7pVxWhnvbNkyem+f2zxeR7k5aX32Zq0cPY7HZWffsh3jkQ7+J3e1mdHiYxEAficF+4gN9+v2Bfor56eO13eXGOylwV9fqIndNLRWhMLL87ue7mbFR/se3v8XApQs8+pHf4olPfQHZ9ODPjw0MDAwM5g9DzDbE7DnTGU2x++IIuy8Mc7pvFCGg3ufk2ZVhnllZyYZ6LyZZQlE1XjnRz7d/fYVYKs9zqyv5+rPLaAos3OHXBvcGoQkK/RO6+7o9TnFYjw8xBx3Yl/twLPNjbSi/b8LwnSCEQMsoyA7zfXMlZgsqrZ1x9pYE7L6EPvx0ScjNrmUhdi4NsqnRh/keu9aVosq1ExF9qP0sEQJSk1EFIxmU/PQQYpvLjK/SNVVozlvppDzgINozTvd5XcAs5FRks0Rti5eGksBaHpj9sFNN1ZhI5KbE4dRofjorfRZMJHP0tiXIpYtIskT14oqp5fBWzu4YVcgq9F1K0NsWp+c613agzo3dZWEskiWVzM0YzWq2magIOKgIOigP6m1FwIHFPreLrqlsZFkqFQyczE6ezkqefK6YV+lrT9B9Pkb/5SSaIqYc541rdAH+dkUAJxGaID2Wv05IzpAZn4MQJQTJkQyxvpL7usKqR7es8lO7zHfLiIhbz1YQe+U1uv7L90lWtBCv3cioFEAg4SizlET8ALXL774DRWiCk693c+znXVSEnHzwq6vw18xP8SuhaaTffpvkD39E6sABkGXKnn4a76c/jXPTRpShIQb/zZ+SOXaMsmeeofLP/x1m7/x3HGuFApnWVibe2kNq716USOTOZiTLYDLpwo/JpLs/ZVlvTaYZ95WREazNTdT+5/+CrbnpXWcphCA+kCaVyFERclAecNwzsVlVtKlOqUCtG7fXKI54M4SqoiYSFKccp1GUaHSmAzUaQY3F5zTc/3pMfv+087W6evpWcsLerCCdmkqVIiAGZsZBlG5qLHZ3K24yYamtwdbUfGOhwZIbtzgyQuQv/4rxn/8cczhM6E/+hPIPf2jBOJCFEPp3NzyMMjxMcWgYZXiI4vAI6ugo9lUrcW3ejGP9+nnpUDB4bzJ07TKtr/6EzpPHsDqcbPiNj7DhuY/e1hkthGAiHiMx2F8St/tKQnc/mbHRqdeZLBa8ldUlcbtuOrKkqprEQD8/+8v/k9z4OM/83tdY/vjOeV5bAwMDA4OFgCFmP6Ri9sXBca6MTMz69QLB1RFdxL4W0UWI1TUVPLNCF7Bbwu53PRFP5xX+9mAn3z3QSUHR+OyWBv7wycX43Ubm7PsJLa+Sv5okOxkfkiqCDLbGCuzLfdiX+7HMQax8WOiJp9l7KcLey1FaO+PkFQ2HxcS2xX52LA2xsyVInW9+4iGyEwXaDgxwfl8/2Qld1J3L5bSzwloqGDctWnu1OwIAACAASURBVHsrXTjKLLe8MFdVjaFrYyVHdHxKRPdWuWgsubYrm8tRFTElHE07mjOMRbNMJPJTDknQ833nIgZYnWbqV/poXB2gfoUP210W7ZwU0HpLbmOlqFEecFARmhasy4MOnOXvnr97PyjkFPovJek5r2eBZ8YKIEFlU/mUmO+vcZNPK9Pu55GMfj+SvTGmwSLj9NiYyyq5Kmy6gL3Sj7/mRvf1XFFTaYb//M8Z//nPcW7ahHVRM5mjx0j1jZDwrSAeXk/ctxwFK7IJalq8Jed9YE4dKKDHirz5vQv0tSdp2RRmx6eXzsvoAnVsjNFXXyP58o8p9vRiCgTwfuITeJ7/xA3ORaGqJL73PSL/6T9j9nqp+tY356WqvTo6Smr/fib27CV98CBaJoPkdOJ+/HHcT+7CvWPHvArp6SNHGPhXf4woFKj61jcpf+aZefssg9sjhECJRCh0dZHv7KTQ1U2hq4tCZyfFkZEbMpJBF6DNodB0FnBQvy/Z5iCKaipKNDozl3ho6IZRAXJ5OZbqasyBAEo8rmcXj43NeI1ktWKpqpqOgqiuxhwKIzsdpexhG7LNimS3T9+fyiXWp7V8vrTuneS7uvT7nZ0UenpmLJNcXo61qZH81WtQLOL73d8h8JWvvGcKyalKkaErlwnUN2K/SUfB/UIIQXZinER/H2arlXDzYiMz9h0MXmkn2tNFRbgKX1UNZf7AvG2j/vY2Wl/9CT3nTmN3l/HIcx9l3Qc/jN119/tILpUiMTgtbk+6usdGRhCidB4i6Z34bp+fj/7xnxFuXnzXn2tgYGBg8N7AELMfUjH7L9+4zP+z99qc3mOSJbY0+3hmRSVPrwhT45mbCBCZyPHXb17lJ8f7cFhM/P7ORfzOtiYc97FwnsG9RRnNTRVvzHeM6vEhdjP2pV4cy316fMgsRMLoRJ6DV6McuBJleDxHvc9JY8BFk99FY8BFo9+1YPcTVROc6Uuy91KUo126GD1bRjNFehO6kNsUcLFzaZBdS0NsavLNa3xIYjDN2T19XG4dRlU0Glb5Wft0HbVLvQ9EaB0dydDTFqf7fIzBK6NomsBkkVHfkSNtc5qnHc2B65zNQcdN4wIMbo3QBNG+CX3bn4sR6dE7OM0WeUZm8FxjGu4nuYsXGfif/xWFvv+fvfuOb6u+9z/+0pYseUjeO3EcZ+84g5BNIAESRoBS2tL2li6g45au23VbblsKt/RHy733198tHbRll1GgQIGQvfdOvPfUsKw9zvn+/pBxYkZiO3bshO/z8dDj2JLOOV/Zkmy9z+d8vo1k3HsPGV/8IpqeU4tjHR0E9+wluHs3vt17cXYbcKZPxZU5g6A5E4BUux5Lcv8PZHS5osQigsUfG8/kK/OG/PUSPnkSz5NP4n3lVUQ4jGX2bOyfuIOUVavO274gfOIEzd/6NtHqahyfvpPMb3wDrenCDhpHm5rwb9iAb8M7BPfvB0VBn5mJbcUKklcsJ2nBggvex0DEWltp+trXCR85QvpdnyPz61/v7csrnZ9QVWItrcTb20CjTbx2362AP7sSXqtLzFvRUy2vdHcnQuvaWqI1tYnQurY20XO5hyYpCeOYYkxjSzDk56PPTkxc9+4Edvr09H634Bjw4xICxeU6qwdzT8jd3ELc6USXkY7x7Arunq916enDFvK9+7OO1tb0Cfz1GRlkfu2rQ9bn/mJoPHGUDb//v7iaGtBoteSVTaJkdjkls8tJLygalv8bVFWhu7MTd0sj7qZGXM1NvdW7Yf+ZYpyk1DTGzpzD2FnljJkxC1PSpXFwYKgJIWg6cZSdzz9N4/EjfW7TGQykZediz83HnpvXZzmYHtVCCBqOHWbXC0/TdOIYSalpzLnuRmZefS1Gy/DPzRGPRvG0tfQG3NFwiPJ160lKSR32fUuSJEmjhwyzP6JhtjsQxRsa2GQiDquRVMuFz6xe1eHjwTdO89aJdrJTTNy3agLr5xSgk0HUiAjHFEx6bb/+mRVCEGvyEzrhInzSTawt0WNYn2HBPNGBeZID05iU807eGIkr7K/zsKXSyZaKTk60JmZ6T7caKU5PosEdwunvW2WVk2JmTEYSYzOsFKcnAu7E10kXvW+00x9hS0UnG08nAnhvKIZOq2FGQWr/XyNCkCS0zClLZ/mk7GFvvyOEoOmkh0MbGmg47kZn0DJhQQ4zVhTiyB09H/4ioTiNJ9y0VndhsRn7tOMwWy/8/Uf6cAFvhPpjiQkYk9PPhNfJGeZBTXA5nIQQeP76BB0PPYTO4SD/l/9JUnn5OdeJtbYS2L2b4O49dBw4TYeSjTttAqqu/wGbTokwrmMjGQU2TGXjMZWVYR6fWOpS+/9BWunuJlJdTbS6mkhlFZHqaiLV1cRbW9GYzaSuXYv9E3dgnjix39sEUEMhOn75MJ4nnsBUVkbef/4n5gll/V8/HCa4bz+B7dsJbNuW6I8LmMaPx7ZyBckrVmCeOnVEKyHVaJT2Bx6g66mnSZo/n/xfPYw+PX3ExjNUhBBEKioJbN1C8OAhdD2VxYnwtWeZk9OvQFgoCrGmpsTzqqqaaHUVkapqIjU1iFDogsapz8vFNGYsxpKSRBuNsYmv9dlysu8LpaoKXW1tuBrrcTbV42psQKvX9+kfnJaTg05/cf4WBro8bPnrHzixdSMpmdksXH87Xe1t1BzcS2ddDQApmVmMnVVOyey5FE6ZjsHY/4Nb71ZZe9vb6GpvxdPa0lt962lpJn5WL3VLSur7+iiHfd3UHNxH3aH9hAN+tDod+RMmM3Z2OSWzynHkF1z2z0khBPWHD7DrxWdoPnUCa5qduWtvZvy8hXR3duBpbcHT1oKntRlPSzNd7W2oSrx3faPFgj03H7MtOdGbW1V6lokJGz/o63gkgs/Vic3uoHzdeqatvAbDQM6ukCRJkqQhIMPsj2iYPRrsrnHx89dPcbixiwnZySwc1/8PoxoNZKeYKXIkJS7pSaSYZdDVH4lK4i42ne5g0+lOjjZ7GZOexMpJ2aycmEX5WAeG9wRXQhWEjrvwbW4k1uQHLRiLU7BMSsc8yYEh89yVGEIIap0BtlR0sqXSya4aF8Gogl6rYU6xnSVlmSwty2Rybkqi/y/gC8eodwWpdQaocwaodQWodwWpcwZwBc58wNFoIDfFnKjgzrAyJj2pN+gudAxN0K2qgiPNXjae6mDT6Q6ONHsRAjJspt5q6ivHZ/Q7yO7qCLL1mUoajrvQG7TYc6048hKX9DwbjjwrNrtpSD6ExWMKlXvbOfR2I+6WAJYUI9OX5TNlST4W2/BUyUnScFK6umj5wQ/wv70B27Jl5D7w8wG3t0gcmGsidOgQajh8/hXeXS8SJVpTTbiigkhFJWp3d+9t+uxsTGVlmMrGYy4rw1RWhj4zk2h9fSJIrKrqDRXP7jGtMZsTfXVLx2GZNp3UdWsHFIx/EP+WLbR87/uoXi+Z930Dx513fmAALYQgUllJYNt2Atu3E9y3DxGJJCZ3mzsH29KlJK9cibGw8ILGMxy6XnyJth//GF1aGgW/fgTLzJkjPaQBU/x+Ajt3EtiyBf/WbcTb2gAwjhmDGgwS7+zs21Nao0Gfmfn+/tApKWeeZ9XVRGtq+kzip8/JwTRuHKbScRjHjcOQl5+4QVUQigI9QRXvTsJ59mScqoLWYkmE18XFaC2yXdiFEqpKt7MTV1MDzsZ6nI2J4Nrd3NgnwE3Nyk7MD+Hq7L1Oq9ORmp1Len5Bn2DXkVeIKWloqmJVVeHIW2+w7ek/E4tEKF+3nvk33donsPS5ndQe3EfNgb3UHz1EPBJBbzRRNHV6b7idkpGFEo/T7ezoCazb8Ha00dXWircj8XX07IMrGg2pmVln+iLn9UwEmF9wzt7LqqLQUnmK2gN7qTm4D2dDXeLnl51DyaxySmbNpWDyNPTDdGbASBBCUHNgD7teeIa2qgps6RnMu+EWpi2/+pyPU1UUup2ddLU2425toasn6I4EAmh0OrQ9Z2dotNoP+Tpxn4JJU5iy9KrL6mcqSZIkXVpkmC3D7BElhOC1o238ekMFbd7+BwqqAH8k3ue6tCQDRY4kCt8NuM+65Kaah3zSPEhUGDe6g/gjCgV2C+nWke2H+2Fc/ghbKjvZeKqTLZWddAVjaDUwp9hO+RgHJ1q72VHtIhpXSTbpWTIhk6smZbF0XAamii58m5uId4bQp5uxLSkgaVrGOduHdIdjVLb7qerwcbjJy5aKTpo8iQ8sxelJLBmfyZKyTBaOS8dmGvgp4t5QjHpXoCfoDlLnCiQuzgCe4JkzDjQayEu1MDbDypiMRMidMoCzC2KKyr46D5srOnEHomg0MKswjeUTslg2IYspeWfC9/6IRxX2v1HPgTfr0em1TF9eQDyq4m7x424JEPCe+RBrNOsSAXeuFUeeDUe+lZT0RIggVJGYoFIVCPVDvlcFLVVdvf2w0/NtzFhZSFl5NjrD6KqylaT+Ch44SPM37yPe6STrvm/g+PSnR+w9VwhBvL2dSEUFkYqKRMBdWUW0qgoRe/+ZT5qkpESgeFaoaCotxZCfPyyVznG3m9Yf/BD/O+9gvWIhuQ88gCE7m7jbTWDHTgLbthHYvj0RmALG0nHYFi3CeuWVJM2de0mEluGTJ2n6yleJtbeT/W/fxf7xj4/Kv8Hv6j14sGUL/i1bCR44APE4WqsV66JF2JYsxrp4cW9fdBGNEmtre/9khe+202hrg/iZ/4UMeXkYS8dhGleKqTTx/DKWlKBLTh6ph3zJUBWFUzu2ULl7B6r6/n7fQyXk9eJsaiAWPhPi2tIzyCgsJr2giIzCYjIKinAUFGI0J16D0XAIT0tzT+/gRP9gV3MjXW0tqGf1JrfZHRRMnkZp+ULGzprTu/5AtFVX8vZj/0N7TSVFU2ew8nNfxpFXcM514tEoTSeOUnNwHzUH9+JtTxyUsabZCXq9Z/obk2h5kZqVQ1p2DqnZOaRl5ZCanUtadg4pWdkDquz+MN3Ojt6gveHYEeLRCHqTibzxE8kaO47ssePIGluKPSf3gt57Y+Fw7wEJd2sz8Wjkg6uZFeV91c1arRZ7bl7i915YjCOvoF/BsFBVKvfuZNcLz9BZV0NqVjbzbryVyUtWojfIoh5JkiTpo0OG2TLMvmR1h2M0uoM0uoM09F5CNLqDNHmCxJQzz1+dVkNOipkCu4V8u4WCtMQyPy2JfLuFvDQzJv0HV/BG4yqNnkRFcK3z3dA0EaC2dIU4aw46koy6DwzUCx1JFNgtF60dRp9K4opOjjR19VQSG1lalsXyiZksLs0k9axAOhCJs73KyYaTHWw72cEVAcHtGMlGizdZj2VxPmMWFaA966CANxSjqsNHRbufynY/lR0+Ktv9tHWfOTBhNepYOC6DpWUZLCnLpDh9eFtaeIMxanuC7TO/r8TX3eH4+TfwHvYkA0vLMlk+MYvF4zNxWAdXhVJ7xMnWZyrwucKML89m0fpSrGl9P7SFAzHcLQHcrQHczX7crQFczQHCgYG1BDrbSPfD/qgR8Tihw4cTAaFGm2i5827/2fctExeNXo8+Oxt9ZuZl/zuKu92o3d0YCgoG1OtYqCqu3z1G529+gyEvj/xfPYxl2rRhHOngiXg8USVbUUG8sxPjmDGYxo1Dn3thwcmgxiIEXc89R/sDv0BjNGLMzyd84gQAutRUkq5YiO3KK7FecQWG3NyLOrahoni9tHz7O/g3byb1hnXk/PjHwxbE9/ZBrqlGDQT6v140SnDffvxbt/ZWX5vKyrAtXYJ18WKSZs1CM4ggSiiJyRAVrxdjQcElM5ngaKLEY5zYspE9Lz1HV3srKZnZQzJ53Ycx26ykFxT3hpjpBYWD3p8Sj+PtaOudIM/VWE/d4QOEfN3oDAaKp82kdN5Cxs2Zf95+wmG/n23P/IXDb72GNTWNZXfexYQrlgyqn7K7pYmaA3txNtSRkpGZCKuzckjNycGW5rio74OxaITG40eoPbiP1soKnA21KD0HgAxmC1ljSnrC7UTI7cgvRKvr+796PBbD3dzYt5K+qaE3tAfQ6vQYTKb3VTJre/rOa7VaNJoztynxeJ+WHxqNlrTcPDIKi3oObCSeI2k5uej0elRV4fTObex+4RlcTQ3Yc/OYf9PHmLhoKTo5b4AkSZL0ESTDbBlmX5YUVdDqDdFwVtjd7AnR5AnR3BWivTvcJ4QGyEo29QTcFlIsBhrdicC62dM3sE4x68/0bc6wMjYjCZvJQJMn2Gd/De4g4fdMYJfT0xrFbjWgYXhCq7iqcrChC1dPJfHMnkri5f2oJFaDMfw7W/Fvb0YNxulMNfCULsaz7sSp9IUOC/PGpNPeHaayw0d795m+1maDlvFZyYzPsjE+O7Esy04m324ZFf3QhRB0BWMEov0PtDWaxEGQCxm/tzPEtmcrqDvqwp5rZentZeRP6H9LhERPyRjuFj8+dwSNNjGud5darQbNuxcNie97bk9ON5N6nhYw0oWLtXcQ2LYV/5atBHbsQPX5zr/SB9CmpGAqLT1TuVtaiqm0FH1W1iUbcgtFIXz0KP6eStTw8eOJtgkGA8bCQowlYxM9d8f29N8tKXlfi42400nLt79DYMcOktesJvf++2Wl6QBF6+po+4+foobD2K5chHXRIsxTpvROlnmpE6qK87e/xfnof2EqK6Pg0d9c0AR7QlWJNTf39DOvItrTviNSU4M4a9LDgdBarVivWIh1yRJsixdjyMkZ9PikCxePRjm26W32/P05fM5OsktKWXDz7YybM29Ee8JfKFVRaD59gqo9O6ncuxOfsxONRkv+pMmML19IaflCUjKzeu8vhODk1o1s/usfCHV3M3P1dSy67ZOX7USKSjyGq6mRjtpq2mur6aitpqO+hngk8f+s3mAko3gMmcVjCft9uBob8LS1JNrwkGjzYs/N7zkY0VNJX1hManYOWu3A3k+VeJyutpY+rWacjfV0tbX2VrPr9HrseQXEIxG62ltJLyhi/s0fY8LCKwe8P0mSJEm6nMgwW4bZH0kxRaXNG6bJE6LJE6S5K0RzT9Dd3BXCG4pRaE/q04M5EVxbsScZ+j1ZYqc/cibcdoV6Qu4A3aGBVwj3l0YDE3OSB1RJrHRH8W1rJrCrFRFVME90kLysANOYRKjU6g3xzqkONpzs4FBjF/lpFsZn2xiflUxZz7LAbhlQy43LXTymcPDNBva/UY9Gq2HedWOZvrJg1E2kJw2ciMcJHTqEf8tW/Fu3Ejl5EgB9VhbWJYuxLV6CccwYEGpvP1pU9Uwf2rOXQkXE4sRaWohUVSZCs6oqlK6u3v1pk5MxjRt3VvuAUiyzZqGzDX3YEKmtJXLyJPqcHAz5BegzMwYc7MRdLgLbtiXC/e3bE49Fq8UyfTrWJYsxZOcQrasjWldLpKaWaEMDnNWWQ+dw9Ibc+txcPE8+herzkf2975F2262XbLAvDT//1q00f/NboKpk3nsP2nP02e1DCOJOJ5HqqkRv85paxFm91PXZ2Wdegz0HnAbU11yjwVhY2K/JG6XhFYuEOfL2P9n3yvP4PW5yyyay8ObbGTNzzmX33iKEoKO2mqq9O6ncsxNXUwMAWWPHMb58ITnjJ7D7xWdoOnGM3NIJrLzrbrLHjhvhUV98qqrgaWmho7aqN+DubKjDbLP1htXpPe1f7Hn5wz4BZywawdPSfFbIXU8sEmHm1dcyft4Vl/TBFkmSJEkaKjLMlmG29BEjFJW4J4LiChF3h4k2+Qke6gBVYJmeSfKyQoy5l2dFzsVSdzTRUqTbGaZ0bhaL1pdis8uZ3i9lH1h9rdeTNGtWIsBesgRTWdmQhSFxl6tn0sBKotXVvRMIKm534g4GA9bycmzLlmFbvmzQE/QJVSV0+DD+d97Bt+EdojU1fW7XmEwYCgowFORjLCjEUFiAsaAAQ2EhhvwCdDbrWdXXiXA/fOwYCIEuPT3RwmLJYmyLFqFLS/vgMcTjxJqaiNTWEq2pJVJbQ7S2jmhNDYrHg3HcOPJ/9SvME8oG9RgvFd6OdsIB/0cyTBpK0aYmmr/6td52KgOhz8npDav7BNcp/QzFpVErGgpy6M3X2Pfqi4S6vRROnsaC9bdTOGX6ZRdifxhPazOVe3ZStW8XrRWnADBbbSz+xGeYtvxqGZJKkiRJknTJkGG2DLOly5AaVVDcYeLORGAdd4WIu8LE3WGUrjCc1f1EY9SSNDOL5CUF6DNG/4Rfo1m3M8S25yqpPezEnpPE4tvLKJzoGOlhSRdAxOO0fv8HeP/+dyBRoWldfCW2JUuwLlx40dtdxN1uIqdO4d+2Hf/GjURra4HE5H3Jy5ZhW7YMy8yZ5+xHrUYiBHbuxL9hA76Nm1CczkQwXz6X5BUrSZozm7jLRbSxkVhTM7HGRqJNTcQaG1H9/j7b0tntoKooXm+f6mvb4iWYp0y+4HBE8XrR2myXTTuMD9JeW83el5+nYuc2NFoNt/7o5xRMnDLSw7qkCUUh1tp2/jueRZeaItvXXIbCAT8H33iFA6+9TNjvo3j6LBasv/0j/xrze9y0nD5BweRp5+2nLUmSJEmSNNrIMFuG2dIoIuIqcWeIWFuAWFuQWHuAWHsQMYCJC4XK++6vTdKjc5jRp1vQp5vRO3qW6Ra0yf1rmyJ9uK72IIc2NHJqZysaDZRfN5YZKwvR6WWV06VMxGI0f+vb+N54A8dnP0vqjTcMafX1UIjW1eHfvBnfpk0E9+6DeBxdamqiL++ypdiuvBJdaipxjwf/5s34N7yDf/t2RDCY6OG7ZDHJK1ZiW7rkvNWnQghUr5doYxOxpncD7iaEEsd6xRVYr7gCvb3//eA/yoQQNBw9zN5Xnqf+yEGMliSmX7Wa6n27iASDfPIXj5DsyBjpYUofQUII/B4XXa0teNpa8LS2oMRjpGXnYc/Nw56bT0pG5vsmyRttVEXh0D9fZcdzTxIJBiiZM48FN3+M3NIJIz00SZIkSZIk6QLJMFuG2dIIEKpA8YSJtQcTwXXPMt4Zone2Sa0GfaYFQ3YSWuvA+vPpUoxnAmuHGW3S8Pb3+6hqrfZy6K0Gag53otVpmDA/h/LrxpLskC1FLnUiFqP5vm/ie/NNsr77HdI/85mRHtJ5KT4fge3b8W/chH/LFhSPB3Q6TCUlRGpqQFHQZ2djW7E8UYE9fx5a2cP3olIVhYrd29n78vN01FZjtTuYvWYdM1atwZRkxdXUwBPfv4+MgiJu+/Ev0Bvke7c09IQQhLq9uFube0Pr3vC6raV3MjwAncGAVqcnFg71XqfV6UnNzsGek9sbcKflJMLuZMfA++wPteZTJ9jw+/+hs6GOMTNms/iOz5A1pmRExyRJkiRJkiQNHRlmyzBbukiEEESqu/BvbyFS3YWInun1obObMORYMWRbMeQkYcixos+woPkIVfZ2O0McfLOBzkYfKelmUjItpGRYSM1MXKypJjT9nGBSqIKAN0q3M4i3M0S3M9yzDJGUYqRosoOCSQ5SMy0DrrJVVUHdYScH36qnraYbU5KeqUvzmbasAGuqaTAPXRplRDRK0ze+gf/tDWR/799w3HnnSA9pwISiEDpyBP+mzYSOHMYyYwbJK6/CPHXKqKosH0qqqnDgH38na+w4iqbOGOnh9BGLhDm+aQP7/vEi3vY27HkFlK+9mUmLl78vsK7cvYOXf/Vzpi6/mqu/+JXL9vd1KXI1NVCxaztV+3ah0WjJKCxKTAzXc7E50kf178vT1sKel56jcvcOIsFA7/VanY7UrOwzoXROHmm5eThy87Glp6PRaAl6u/C0NuN5T/jd1dpCPBbt3ZbeYCR/0hRmrV5Lyay5FzXYDnq72PLEHzm+eQPJ6Zks//TnKZ23cFT/TiRJkiRJkqSBG3VhtkajWQ38GtABjwkhfvGe24uBPwCZgBv4pBCiqee2IuAxoBAQwLVCiLpz7U+G2dJwEzGF4MFOfNubibcH0VoNWKZnYMy1oc9JSlRemz68v+3lztMWYP8b9VTsaUejhZyxqfg9YXzuCEI98x6k02tJyTCTkmEhJdNCas9SA3idIbo7Q73LblcYJXbmYIFGqyHZYSI53UK3M4TPFQYgOd1M4WQHhRMdFEy0Yz5HBXwsqnB6ZyuH3m7E2xkiJcPMjJVFTLoiF4NpdJ9u3R+KP0CsuWlA6+jS0tBnZo54Fd5QUqNRmr/+r/jfeYfsH/wAxyc/MdJDkvpBicd47dGHqdi1DYDJS1aw9FOfG/FesCFfN4fe/AcHX3+FkK+b3PETKL/hFkrnzD/n62bb039h94vPcNVddzNj1bUXccTS2YQQOBvrqdi1jYpd23E3N4JGQ/6ESegMRlyN9QS6PL33NyVZSS8oIqOw+EzIXVQ84s9DV1MDu198llPbt6DT65mwaAlZxWMT4XVuHikZWejO0Wf/XISq4nO76OppSeJuaaJi51b8HjdpObnMWr2OqctWYrQkDfGjOkNVFY689QbbnvkzsXCYOdffxMKbb8dglmdJSZIkSZIkXY5GVZit0Wh0QAWwCmgC9gIfF0KcOOs+zwGvCiEe12g0K4DPCiE+1XPbJuBnQoi3NBqNDVCFEMFz7VOG2dJwUbwR/LtaCexuRQ3GMeRasS3KJ2lGJhrD5RP+DVZng4/9r9dRfagTvUHLlMX5zLyqCJs9Ud2sKCp+d6RPSO11hhIV1p0hYhGlz/YMJl2fkDs100JKhpnUTAs2hxmdLvEzF0Lg7QzReMJN40k3zac9RMMKaCCrKDkRbk9ykFOSik6vJeSLcnRTE0c3NxP2x8gak8KsVUWUzMpE289K8dEusGcPzd+4LzER4EAZDBiyszHk5WHIzcWQn4chLw99bm7iurw8tKbhrVgXqoridqPPuLAew2o0SvNXvop/82ayf/RDHHfcMUQjlIZTLBrhlV89QO3BfSy+4zNEQyH2vvw3jElWlt95F5MWL7/olZl+j5t9r7zA4bdfJx6JOszV/QAAIABJREFUUDK7nPJ168mf2L/KeFVVeOmh/6D+yCFu+9HPyZ84+YLGE4uE2fm3p/B73KRm5ZCalU1aVg6p2TnY7I7L6oDUhRJC0FFXQ+Xu7VTs2o6ntRmNRkvBpCmMX7CI8fOuwGY/M7FvyNeNq7EBZ2N978XVWE84cGay1KTUNObdcCuzr113UZ+LHXU17H7hGSr27MBgNDHj6muZe/1NWNOGt7e9Eo9TuXs7B157mdaq0xgtSUxdvopZq9eSlp0zpPtqrTzN27//HzpqqymaOp0Vn/0y6QWFQ7oPSZIkSZIkaXQZbWH2QuDHQohrer7/NwAhxANn3ec4sFoI0ahJfCLwCiFSNBrNZOB/hRBXDmSfMsyWhlq00YdvWzOho04QAvOkdJKvzMM4NlWe6gq0VnWx7/V6Go67MJp1TFtewIwVhViS+9+7VwhB2B/D25no4ZmSYcEyyIksVUWlvc5H40k3jSfctNd1I1SB3qQjqyiZ9rpulJjKmOkZzFpVRG7p5fN7FELg/uOf6Hj4YYxFRWTcew+a/vboFaB43MRaWom1tCQura3E29tBVfvcVZeejiE/n+SVK7F/7DZ0aWlDM/5YjO7XXsP5v78jWl2NdfFiMu+9B8uMgbeYUCMRmr76VQKbt5Dz4x9jv/1jQzJGaXhFQ0Feeug/aDx5jFV33cP0q1YD4Gyo483/fZTWytMUTZvJqrvuIS0nd9jH0+3sZO/Lf+PoO2+iKgqTFi2lfN16MorGDHhb4YCfJ773r0RDoQuaELKrrZWXf/VzOutrSU7PxO92IcRZba70elIys0nNznlf0G3Py8dgvPzbJwkhaK+pomL3dip3baervRWNVkvh5GmULbiS0vIFAwqAhRAEujy9wXbtof3UHzlI2YIrueZLXx3WKmWAtqoKdr7wNDX792C0JDFr9VpmX7tuRCrEWytPc+D1l6nYtQ1VVRk3Zx6z16yjcMr0C/pbGvJ1s/Wpxzn6zptY0+ws+9TnmHDFksvm77MkSZIkSZL04UZbmH0LiaD6rp7vPwXMF0Lce9Z9ngR2CyF+rdFobgaeBzKAxcBdQBQYC7wNfFcIobxnN2g0mi8AXwAoKiqaU19fP7wPTLrsCUUldMyFf3sz0QYfGpMOa3kOtoW56NMtIz28ESeEoOmkh32v19FS2YXZZmDGykKmLSvAZBncqc3h06fxPPUUKAppt30My7SpQzLWSChO82kPjSfdtFZ7yS5OZuaqIuw51iHZ/mih+AO0fv/7+P75T5JXrSL3gZ+js9kueLsiFiPW3kGspZl465mgO1JVTejgQTRmM6k33oDjzk9jKhk7qH2okQjeF17A9djviTU3Yyorw7ZkMV3Pv4Di8WBdspjMe+/FMn16v7fXdO9XCGzdSs79P8F+222DGtdHjRCCE1veobO+lmkrria9oOii7j/k9/HCA/9Oe00Va+75BpOuXNZ3fKrK4bdeZ+tTf0KNKyy89Q7mXHfjoNspnEtXext7XnqW45vfAWDK0hXMu+HWCw7QnY31PPn9+8goLB7UhJDV+3fz+n/9Co1Gw5qv3EfJrHKUeIxuZyfe9ja8HW14O9rxtrfR1ZH4PhI400tZo9Fiz80jc0wJmcVjySoeS2bxWKx2x4BCw7Dfj6u5EXdLI+7mJtzNjXR3dqC+58DXuZgsSRTPmM24OfPIHjvugqvJVVWh+dQJqvbspGrfLro7O9DqdBRNncH4+YsoLV8wZOGvEIK9Lz/Ptqf+jD03j3X3fW9YXi9Np46z+4VnqDt8ALPVxuxrb2DWmrWYrRf+3n6h/G4Xh996jcNvvU7I101GYTGz1qxj0uJlAzpgIlSVoxvfZOuTjxMJBpi9Zh0Lb7kDU9LwHiCQJEmSJEmSRo9LMczOA/6LRGC9BVgPTAWuAn4PzAIagGeA14QQvz/XPmVltjRQajBG3BUm7g4llq4wkSoPijeKLt2M7Yo8rHOy0ZovjT7YQohhq2SKhuM0nfKw//U6Oup9WFONzLq6mMlX5g2qz7RQFPwbN+L+818I7tmDxmwGrRYRDGKePh3HJ+4gefXqYW9rcamLVFfT9JWvEq2rI+u++3D8y2cvSjVb+HQF7j8/TvcrryKiUWxLl+L4zKdJWrCgX/tX/AG6nnkG15/+iNLpxDxjOhlf/BK25cvQaDSogQDuJ57E/Yc/oHR1YVu6lIx77z3ngQ41HKbp7nsI7NxJ7k//g7T164fyIV+2XE0NvP3Y/9B08hhoNCDEgFtpXIhAl4fnf/ZD3C1NXP/171JavuBD7+tzO3nnD/+Pqr07ySwaw6ovfoXc0glDMg53SxO7X3yWk9s2odXpmLbiasrXrSclI2tItg9QsXs7r/zqAaatuJpVX+jfhJCqqrDj2SfY/eKzZI0dx7pv/BupWf1r7xD2+/F2tNHV3oqzsZ7O+lo662vp7uzovY8lJZXMnmA7q3gsmWNKcOTlE/B4cDc34m5p6gmvm3A3NxH0dvWuqzMYEr2as3PQ6vr/d9LvcdNacQohVGx2ByWz51EyZx5F02b0OwyNR6PUHz1I1d5dVO/bTcjXjc5goHjaTErnLaS0fCEWW3K/xzRQjceP8OqvHyIWDnP1F7/CxEVLL3ibQggajx9h1/NP03jiKJaUVOZefxMzr7522CvAByMejXJq+2YOvP4ynfW1mJNTyBhAsB/0duFuaSJ/4hRWfu7LZA7irAdJkiRJkiTp0jbawuzzthl5z/1twCkhRIFGo1kAPCiEWNpz26eABUKIe861TxlmS+8lhEDxRom7QijvhtbucG9wLcLxPvfXJhsw5NqwLcjFPNGB5jx9lEOHDxNtaMC6cOEF9/gdLKWrC9+GDXS/9jrBvXtJXn0N2d/+dr/HI4QgGorj90Twd0UIeCL4PWH8XZHEdZ4IAU840YsaSMkwM/uaYiYuyEU3iH7hSnc3XX97Hs8TTxBrbkafm4vjE3eQdsstoNPhfenveJ58kmhtLTq7nbRbb8V++8cw5OUNeF+Xu+433qD1e99HY7GQ//DDWBfMv+hjiLtceJ56Gs9TT6G4XJgmTMBx552kXH/dBx6IULq6cP/lr7j/+ldUr5ekhQvI+OKXSJo/7wODPcUfwPPEE4lQ2+vFtmxZItSeOqXP/dRQiMa77ya4aze5P/85aTfdOGyP+XIRi4TZ9cIz7HvlBYyWJJZ84rOMmzufw2++xsE3zprkcN16xs2dj1Y79JOjdjs7+NtPf4jP7eTGb/6Q4ukz+7Ve5Z4dvPOH3+Lv8jBr9fVc+bFPDTrsczbUseuFZzi9axt6o5EZV61h7vU3YXOkD2p757Pt6T+z+8Vnueque5ixas057xvs9vKPXz9Ew7HDTFtxNSs++yX0xv63cfowYb+fzoba3nC7o64GV1MDSiz2gfc325Jx5BfiyCvAkV9Aes/XKVlZg35eBLu91B7cR83+PdQePkAsHEJvNFE8fSbj5synZHb5+9qBRIIBag7spWrPTmoP7ScWCWO0JFEyu5zS8oWMnTn7ooa+freLVx55kJbTJ5i1Zi1LP/kv6PQDq7iHxAGLyt072ffK87RVV2K1OyhfezPTV66+JCY+TJyxdYwjb79BwOPu93oanY7Ji5czeckK2VJEkiRJkiTpI2q0hdl6EhNArgSaSUwAeYcQ4vhZ98kA3EIIVaPR/AxQhBA/6pk88gBwlRCiU6PR/BHYJ4T473PtU4bZEoBQBdG6bkInXIROulBc4TM3ajXo7SZ06Rb0DjP6dDN6hwV9uhmdw4zW2L8P5SIWo/PR/8L1u99Bz2vLPHUqtiVLsC1dgnnqVDS6oQ9+3qX4fIkA+/XXCezYCbEYhoICLLNm0f3GG2gtFrL+9euk3XbbB44jGo5zbEszp3e10e0KE3/PBIxoICnFiC3NhM1uxmo3YUszkZadxJhp6Wh1Aw+xIzU1eP76V7pe+jsiGMQydw6OT91J8soVaN7TKkAIQXDnTtxPPon/nY0A2FYsx3HHHSQtXHhJf+iNNjTg37iRaHMztkWLSFqwYMDV5yIep+PhX+H+4x+xzJxJ/q8fwZCdPUwj7h81EqH71Vdx/+lxIpWV6NLTsX/849g/fjv69HRiHR24//Q4nqefRgSD2FauJOMLn+93T2zF78fz1ydw/fGPqF4vtuXLybj3HixTpqAGgzR++W6Ce/eS98DPSb3hhmF+tJe+moN72fD739Ld2c6UpVex5JOf7dOGIRYJc3zTBvb940W87W3Yc/OZu/YmJi9eMSRhKoCnrYXn/uP7RINBbvruj8mfMGlA60eCQbY9/TiH3nwNmyOdFZ/9InnjJ/Z7/W5nB3te+htVe3diMFuYdc11zLn+pmHvRayqCi89eD/1Rw+fc0LIlopTvPLILwh1e1n5uS8zbfnVwzsuRcHd0kRnfS3ulmaSHemJ8LqgEEtyyrC+78ZjMZpOHKV6/x6q9+/G5+wEILd0AiVz5mG2JVO1dyeNx4+iKnGsaXbGzZ3P+PKFFE6dPqgAeago8ThbnvgjB177O7llE1n79e+SnN6/g8mxaITjmzaw/9UX6WpvJS07lznX38TUZVcN2etMkiRJkiRJkkazURVmA2g0mmuBRwAd8AchxM80Gs39JILpl3takTwACBJtRu4RQkR61l0FPAxogP3AF4QQ0XPtT4bZH11qVCFS2UXohIvwKRdqIA46DebSNMwTHOizLOgdFnSpJjS6C/tAHm1ooPmb3yJ85Ahpt95C2i23ENi5E//mLYQOHwZVRWe3Y118JbalS7EtWjQkk+Qp/gD+jRsTAfbWrYhYDH1eLimr15CyZg3mqYl2AJGaGtp+cj/B3bsxT59O7o//HfPkRFgSDsQ4srGJI+80EgnGyRufRmZRMja7CWtPcG2zm0hKNaIbRGD9XkJVCWzbhvvPfyGwbRsag4GU667Dceenesd0PrHmZjzPPEvXc8+heDwYS0qwf/zjpN5045D0hR5uIh4ndOgQvo0b8W/cRLSmBgCN0YiIRtEmJWFdsoTklSuxLV2CLiXlnNuLd3bS/I37CO7di/0TnyD7O99GM4pCj3cPRLgef5zA5i1ojEaS5s8nuHs3Ih4n5dprSf/85zFPKBvU9hW/H89f/oLrj39C7e7GtnIlqtdL8MAB8h78Balr1w7xI7q8+NxONv3pd1Ts3o4jv5Cr7rqbwsnTPvT+qqJQuWcHe19+nvaaKpJS05i9Zh0zVl2L+QJef86GOv72sx+iKgrrv3c/2SWlg95WS8Up3vrfR3E2DnzODJPVyuw165i1Zt2wtqR4r7A/MSFkLBLmkw880qcKXAjBoTf/wabHHyM5PZ213/ge2WPHXbSxjTQhBM6Gut5gu62qAoC0nFxKyxcyft5CcksnXHCf7aF2eudW/vl/f43eZOL6r32boqkffqAu2O3tcwZETmkZ5evWU1q+YFjOgJAkSZIkSZKk0WrUhdkXmwyzP1oUf5TwKTeh4y4iVV2ImIrGrMMy0YF5cjrmCXa0pqHtde19+WXafnI/6HTk3n8/Kauv6XN73OMhsH0H/i2bCWzZitLVBVotlpkze6u2jcXFib60/SBiMQLbt9P92uv4t2xBRCLos7NJWX1NIsCeMeMDq+WEEHS/+irtv3gQxePBcvtnaC67nuM7O4hFFMbOyGDO6jFkjz13cHq2aFMT4aNHUcMRRCyKiMYQsRgiGv3gZSxG6OBBonV16DIzElW6t9026HYsaiSC7403cD/xJOEjR9AmJWEsKUEoCigKQlVAUc/6Xk0sz/peo9GATgc6LRptz1KnT4QiOh0anRa0ukQ1u0GPITcPY3Fx4jImsdQ5zj9ZmuLzEdi6Fd/GTQS2bEHxesFgwFo+F9uy5diWL0OfnU1w9258b2/A984GlE4n6PVY583DdtVKkleswJDTty9u8MABmr/2dRSfj9z7f0LqunWD+lleLJGaGtx//jP+dzZiW7qU9M/fhbFoaCZKU3w+3H/5C+4/PY7q95P30EOkXn/dkGz7cqQqCof++SrbnvkrQlFYsP525q69qd8VrYlevkfZ+8rz1B3aj8FkZvpV1zBl2SocefkDqoxtq67k+Z//CL3BwC0/+OmQTJ6nxONU7N7eZ8LD89EbjYyftxBT0shMCOtsqOPJH3yTjKJibvv3xISQsXCYN//3UU5t30zJ7HLW3HPfBR00uBwEujxEggHsufmj/qwcV1MjLz/8MzytLSy6/VPMW7e+T+je1d7G/n+8yLGNbxOPRhK96deuJ3/S8PemlyRJkiRJkqTRSIbZMsweMUII1GCcuDPRk9qYb8OQNfR9K9VgjMD+DkLHnUTru0GALtWEebIDy5R0TGNTE4HkEFP8ftruv5/ul1/BMmcO+f/50Hl7OAtFIXzsGP7NW/Bv2UL42LFB71+XmUHK1deQcu0aLLNm9bsirauuk52/+Sd1vgxUrZ4xBYL5n11ARsH5KxCFohA6fAT/xo34N20kUll17hX0ejQGAxqjsWdpwJCbh/32j5FyzTVDWj0cOnqMrmefJdbRfiaUPjuc7gml+1yv1YEQiXBbVRCK2jf0fm/4HYsSbW4m1tQMypk2LFqbDWNREcYxxRiKizEWJUJurc1KYMcO/Js2E9y3D+JxdHZ74iDG8uVYr1z0oZXkQlUJHzmCb8MGfG+9TbSuDki0rkm+aiXJK1cS2LWb9gcfxJCXR8Gjv8E8YWgmvbvUKT4f8U4nppKxIz2UUautqoK3HvtvOmqrGTNzDiv/5cukZfdvAsEP0lFXw75XX+TU9s2Jg0RaLWnZuTjyC870Ve7prWy29n3ON508xosP/gSzLYVbf/izCxrH5aBi1zZe+T+/YNrKa5h7/c28/PDPcDU3sujWTzD/pttGXfWxdH7RUJA3/9+jnN65lXFz57P67n+lq62Vva+8QOWu7Wi0WiYtXkb52puH5ECOJEmSJEmSJF3KZJgtw+xhp0aVRGD97qUzsYw5Q4jQWZMpasAyNYPkFUUYcy+86k3xR/Fva8G/swURUTDkWDFPSccyOR1DnnVYK5pChw/T/M1vEWtuJuOeu8n44hff1+O5P+JOJ/5t21Cczv6vpNFgnjqNpLlzBtSDu6s9yP5/1lOxqw00UFpmJHfb79Ed3Yl10SJyfvTDRIX4eyj+AIHt2xMB9ubNKB4P6PUkzZmDbfkyrPPno7XZzgqse5YGw2UbuohYjFhzM9GGBqJ19UTrz1xizc2gqn3ubxpf2lN9vRzLjOmD6p0eqalJVGxveJvw4SO919uWLyfvwV+ctxWJJAGEfN3seO6JRE/pNDvLP/MFxs9fNGTvl93OTppPHsPV3IS7pRF3cxOe1hZU5czfAmuavTfYtqY52PP3v5GSkcktP/wpyY6RmTR3tNn61OPseek5dAYDBrOF677yTcbMmD3Sw5IugBCCg6+/zOa//gGDyUwkGMBoSWLG1dcye/XaYZtcVJIkSZIkSZIuNTLMlmH2sAjsayN4sIO4M4Ti7du2XJdqRJ+ZhD7DcuaSZiJ4uBP/jkTwbJ7kIGVFEcbCgfcjVbqj+LY0EdjdioirWKZlkLysEGPe8J92LRQF12O/p/PRR9FnZZL/y1+SNHvwAYMQgrqjLrraggNaT6vToNNr0Oq16HovGnR67VnXJb6PhhWObGyken8HWr2WyVfmMWtVEckOM0JR8Dz5FJ2PPIKIxUj/4hdI//znUTo78W3chH/jRoJ79iBiMbSpqdgWL8a2fBm2xYtlePohRDRRvR2tr0fxdJE0dw7GwsIh3UesvQP/xnfQGE2k3njDZXvQQBo6gS4P+159kcNvvkY8GmXm6utYdNunMCUN/dky76UqCt6ONtwtTbiaGnG3NCUuzY1EAgGyxoxj/fd+QlLqhc8jcLlQVYV/PPIQwW4va+79BikZWSM9JGmINJ86wfZn/0rJrLlMW7n6orwGJUmSJEmSJOlSIsNsGWYPuVhHkPZH9qNPt2AsTO4bWmdY0Bo/vOpUDcbw72jBt70FEYpjKrOTsqIQ05jU8+437gnj29xEYF8bqIKkmVkkLyvsd+sSxR8gfPw44aNHiLW0YMjLO6slRBFas/ncj7u9nZZvf4fg7t0kr1lN7k9+ckGBrrPJz9ZnKmip7Br0NvrLYNYxbWk+M1YWkZTy/tYesfYOOh78Bd2vvY42ORnV5wPAOGYMtuWJfs5Js2cPqvpckj7KhKri97ixJKegH4FJOX0uJ3tfeZ6jb/8TJR5nwhWLmX/TbWQUvv8sjItNCEHI143ZZpMT3EmSJEmSJEmSJEmADLNlmD0MnH86TqTWS8635qKzDS6cUSNx/Dtb8W9tRg3EMI5NJWVlIaZxae873T3uDNG9qZHggQ7QgHVONslLC9CnWz50+yIaJXy6gvCxo4SOHCV09AjR6hroec6fHdi+S5+Tc2Ziv7Mm9zMUFhLYto3W730fNRYj5/vfJ/XmmwZ9Wn44EGPPyzUc29KMKcnAghtLGF+ePaBtqIpAiauJZUxFiasf+L0SFwghKJzkwGw9/2Rs/m3b8b7wAuapU7EtX4ZprOw5LEn9EY9G8bS14G5OtNZwtzTham7E09JMPBrBYDJTPH0mJXPmUTKrHGuafVjH4+1oY89Lf+PYprcBwaTFy5l/463Yc/OHdb+SJEmSJEmSJEmSdCFkmC3D7CEVrvLgfOwYqWvGkLz0wlsnqFGFwJ42fJubUH1RjEXJJK8owjzBTrwjSPfGRkKHO0GnwTorA+v8THQ2HeLdSflUFRFXUIMBIidPJoLrY0eJnDiJiMUA0DkcWKZNwzxtGpbpiaXebkfx+YjWNxCtr0v0Oq6v7+1/rHSdVS2t0YAQmCdPJu/hXw464FVVwYltLez+ew2RYIypywqYd/3YfoXMkiQNn0CXh/ba80xmejaRWCcRVidCa29He+/BMjQaUjKySM9P9IVOy87D2VhP9YE9+F1O0GjIHVdGyZx5jJszj4yiMUPWs9rd0sSel57jxNaNaLVapi6/mvJ160nNGtgBM0mSJEmSJEmSJEkaCTLMlmH2kBGqoOPRg6ihODn3zUVjGLo+vSKmEtjfhm9TI0pXFDXkQmO2gxIjVruZaNVbiIj3vNvRJCVhmTwZ8/TpieB66jQM+XkDDooUr7fP5H7apCTsn/wE2kG2CWip7GLrsxU4G/3kl6Wx+GNlpOcPf49vSZI+nKooHHj9ZXY8+wSxSHjA6+sMBhy5+djzCxPBdV4BjvxC7Ll5GEzvb1skhKCzvpbq/bup2b+HtupKAJIzMimZnQi2C6dMR28Y+AGuzoY6dr/4LKd3bkVvMDL9qtXMXXuTnFBRkiRJkiRJkiRJuqTIMFuG2UMmsLcNz/OVOD4+kaQZmUO+/dCRI7T95KfEfcmYp1yDzqFBn+JCaxSg1aHR6xJLnRZ0OjQ6HWi1aHR6NEYjpgllmMaNS1w/Svg9EXa8UEXl3nZsdhOLbhnPuNmZQ1aFKUnS4DSfPsmGx/6bzoY6SmaXU752PTpj/0Nkiy2FlKysC+r17Pe4qTmwl5oDe6g/cqi3HUnRtJlYBzAZos/VSe2h/RjMFmZecx1zr7tRTqYoSZIkSZIkSZIkXZJkmC3D7CGhRhTafrkPvd1E5pdnDGkYG/d46Pw/j9D13HPoMzPJ/u53SF6z5pIOfOMxhcMbGtn3ej1CEcy6pojZ1xRjOMfkmJIkDb+Qr5utT/6Jo++8iS09gxWf+QKl5QtH/P0mFo3QePwINfsTwfZAKsV1BiOTl6xg9rXrsNiSh3GUkiRJkiRJkiRJkjS8zhVm6y/2YKRLl29Loqd16icnDVnoI1QV7wsv0PHLh1F8Phyf/jQZ996LzmYdku2PlMaTbjY9eZruzhAlszJZtL6UlIwPn6xSki513Z0dHNv0NpGAf9j2oTcaKZo6k4LJU9DpB96GQ6gqxzdvYPMTfyQS8DN37c0svOXjGM2j47VpMJoomVVOyazykR6KJEmSJEmSJEmSJI1KMsyW+kXpjuDf0oRlWgam4pQh2Wb45EnafnI/oUOHsMyZQ86PfoR5QtmQbHukCCE4+FYDO1+sxp6dxLqvzaRwkmOkhyVJw6a9tpp9r7zA6Z1bQYDRMnzBcCwSYc/f/4bRYmHM9NmUzJnH2FlzSUpJPe+6zoY63v79/9B86gR5EyZz1V13k1k0ZtjGKkmSJEmSJEmSJEnS0JNhttQv3n/WI1RB6uoxF7wtxeej89e/wfPkk+jS0sj9xQOk3nDDiJ/if6HiUYWNT5yiYnc7pXOyWHHnJAwm2VJEuvwIIag7fIB9r7xAw7HDGMwWZq9Zx+xrbyAlY+h76b8rFgnTcOww1fv3UHNgLxW7t4NGQ+74CYybPY+SOfPIKCzu814SDYfY+ben2P+PlzBZbVz9pa8ydelVaLRDN3mtJEmSJEmSJEmS1H/hcAudzrfp7j4Mw9n9WAMajR4NWjRaPRqNDg26xLL3ogeNDq1GB4yuz4l5ebdhNMoCyfeSPbOl84q2+Ol49CC2K/NJu65k0NsRQtD96qu0P/gQisuF/eO3k/m1r6FLPX9V5Wjn90R4/bdH6GjwMX9dCXNWF1/y4bwkvZcSj3Fq+xb2vfICzsZ6bHYHs9asY/pVqzFbbRd1LEJV6air6Qm299BeUwVASmYWJbPLGTd7HrFIhI2P/w6fq5NpK65m8R2fwZI8NGeWSJIkSZIkSZIkSf0jhCAQqKCz8y06nW/h8x0DwGTKQasxDt9+URFCec8lDqgIEe+9brSaP/8NbNbxIz2MESEngJRh9qAJIXA+dpRYa4Ccb85FmzTwPrUAQlFovPtuApu3YJ4+nZwf/QjL1ClDPNqR0Vbj5fXfHiUWUVj1uSmMnZ4x0kOSpCEVCQY4/NbrHHz9ZfweNxmFxcxdezMTFy0ZVO/q4eB3u6g5uJeaA3upP3KIeDQCQEbRGK763N3kT5w8wiOUJEmSJEmSJEn66BBCwes5vJNzAAAgAElEQVQ9SKfzLTo73yIUqgcgJWUWWZmryMhYhdU6+ILJoZLIRd8Nt0d6NH1ptQY0mtFVLX6xyAkgpUELn3ITqfaSurZk0EE2gOeppwls3kLWt76J47OfvWxO8T+5o5VNT57CZjez7uszSc+7uNWpkjQQsUgYb0d7v++vxGKc3LaJo+/8k2goRNHUGVz9pa8xZsbsUXfmgc2RzvSVq5m+cjWxaITG40eI+P2ULVyMTi//1EmSJEmSJEmSJA03RYng8ezoCbDfJhZzodEYcNgXUlR0F5kZV2EyZY30MPtIfLZNtByRLg3yE770oYSi4n2tFn2GBdv83EFvJ97ZSecjj2BdtAjHv/zLqAvBBkNVVHY8X83hdxopmGjnms9PxWwdHRWqkvRBPK3NPPfTH+Bzdg5oPY1Wy4SFi5l7/U1kl5QO0+iGlsFoomRW+UgPQ5IkSZIkSZIkacTFYt0Eg1UEAlUEgtXEY92oIoqqvnuJ9H4t1CiKGkG8e72IMZCm1ooSRFUj6HQ20tOXkpm5ioz0Zej1ycP3AKWPHBlmSx8qsKeNeGeI9E9NRqMffCV1+4MPISIRcn74g8siyA4HYrz52DEaT3qYsaKQK9aPQ6u7PCrNpcuTs6GO5376A4Sqsvruf0VvNPV73dzSMlIyR9eRc0mSJEmSJEmSJKmvWMzz/9m78/i4qvv+/6+5d/YZzYy20b7bkmzwBt7wBgZssCExEEy2lqRLSEKBJG3TJt+mSb/pkvbXNEmbkBBoE0KTbwtm38zuYGxjbLziRYu1b6ORNJp9v/f+/hh5bGEbbFmybDjPx+M+7pVm5t4zY1kzet/P/RzCkWNEIq1EIseIRjIBdiJ54upcSTKh1zuRJBOSZBxbMtt62YZkzEPSnfieTjKgO4dJESXJSF7ecnJzlyJJZ/93pyCcCxFmC6elxtMEX+vCWOPEPHviM6dGdu4k+PzzFNx9N8bq6skb4HlQ0ip7XuqiZZcHZ4GFvDI7+WU28kvt5JZY0RvOfGnJSH+YF3/xHuHRONfe2cisZaUXcOSCcO48ba088U/fRW8wcPt3f0B+ecV0D0kQBEEQBEEQBEE4T4oSp7v7PxkdfZtI9BjJ5HD2Nlm2YrXWkZe3HJttBjbbTGy2GZjNZaKdhnDJE2G2cFqhLT2okTSum2omXE2tJZN4/u/3MVRUkH/XlyZ5hBPj7QryxiNHGemLUNbgIhpK0rulBzWduWxGJ+lwuS3klZ4IuPPKbDgLLHQeGuHV/zqM3iRz659fQXGtc5qfjSB8sN6mwzz1z3+H2e5g49/+I66i4ukekiAIgiAIgiAIgnCefL7tNDV/h1isG0fOXPLzV4+F1jOwWWdiNpd8bCcOFD76RJgtnCLtixPa3od1gRtj+cT7Go38+mGSHR1UPPhLJLN5Ekd47tIphd0vdLLvlW4sOQbWf3UONfMKgUz/a783xkhfGF9/hJG+MEM9Idr2ebOtofRGiXRKpbAih/VfnYM9d3qfjyB8mM6D+3jmX/+BnIJCNn7nH8jJL5juIQmCIAiCIAiCIAjnIZkcobX1n/AMPo3FUs2CBb8lL/eq6R6WIFxQIswWThF4uRPQ4bihesL7SPb2MvyLX5Czdi32Vasma2gT4mkP8MYjRxn1RGlcVsKK22dgsp6YrFGSJfJKbOSV2MY9LpVQMuF2fxhfXwS9UWLh+mr0RnFJjnBxa939Ni/85F/IKy3n9u/8A1ana7qHJAiCIAiCIAiCIEyQpmkMDDxB67EfoCgRqqvvobrqbmRZ9KUWPn5EmC2Mk+gOEjswRM7qCvSuif9SHPzHfwJJoujb35rE0Z2bVFJh17PtHHi9B5vLxM33zqPqsvyzfrzBJFNU46CoxjGFoxSEyXV02+/ZfP+PKKqdwW3f/r9Y7GLWaEEQBEEQBEEQpobf/y6dXQ8QiRzDZHJjMhWdWIwnbZuKkWVxhfNERCLtNDV/B7//HZzOhTQ2/gN228zpHpYgTBsRZgtZmqYReKEDyW4g55ryCe8n9MYbhLdswf3Nb2IoKZnEEZ69/lY/bzxylMBQjMtWlrLsthkYLeLHXbhw0qkUnfv30HP4IBoakiQjyZlFJ8lIsnSa78mY7XYqL5+H1XHuPdkPvv4Srz50P+WzLuPWv/ouRot1Cp6ZIAiCIAiCMBkCiQAPH36YJl8TX577Zea750/3kAThrGiahs/3Fp2dP8cf2I3BkEdu7lUkk8OEQkcYHt6CqsZOeZxe78gG2zk5l1FYsAaHY67o7XwGqpqgs+uXdHb+Alk209jwj5SW3iFeL+FjT6dp2nSPYcotXLhQe/fdd6d7GBdcojNAsid01vdX/AnC2/tx3ToD+5KJhdBqNErbzTcj2+zUPPkEOoPhwx80iZLxNDufbue93/fiKDCz+g8aKW/Mu6BjED6+lHSankMHaNrxFsd2v00iGkFvMiHr9aiKiqYoKEoaTVU/eEc6HaUzG6m9YhG1VyyioLL6Qydi3fPCM/z+kYeonn8ln/zzb2MwiaoHQRAEQRCEk2maxruD77KpeRPBVBCjZMQoGzHJJgySAaNszH7PIBuy2xa9hRVlKyi2Tc5k2tFUlN8d/R2/PvRrwqkwTpOTQCLA52d9nnsX3IvVIAoShIuTpqkMDb9KZ+fPCYUOYTIVU1X5JUpLP40sW066n4aihIknPCQTXhIJD4nEIImx7XjCQzh8FE1LYzS6KSy8nsKCNeTmLkWSjNP4DCeHoiQIBN7FN7oDn28b8fgAVmsVVmstVksNVmsNVms1Fkv1GduEjI7uoqn5O0SjbRS5b2bmzO9gMhVe4GciCNNHp9Pt0TRt4WlvE2H2R1fg5U5CW3rO6THGKgeFd81FJ39wcHYm3n/7ESMPPUTV736L9corJ7SPiepp8rHlv5sI+eLMvaacJRtqMZpFNbYwtVRVoa/pCM07ttKyczuxUBCjxcrMxctoXLaSisvnIevH/xxqmoamqqiKgqoqmbWioKkqwWEvHfvepX3vuwy2twKQk19I7RULqb1iMRWXz8VgNI3b1ztPPsr2x37LzMXLWH/fN9Ff4JNIgiAIgiAIF7OUmuLlzpd55PAjHPUdJdeUS5m9jKSaJKmMLWPbKTVFUkmiaMq4fUg6iavLr2Zj/UaWlS5Dls59Hp2UkmJTyyYePPggI/ERrim/hnsW3EOZvYyf7P0JjzY/SqmtlO9d9T2WlS2brKcvCOdNVdMMep+nq+sBIpFWLJZKqqq+QknxrRMOn1OpACMjv2do6FVGfG+iKFFk2U5B/jUUFq4hP/9q9PpLo2WipqmEw034fNvw+bbjD+xGVRPodHqcjgVYrNXEYt1Eo+0kk0MnPVKH2VyWDbczYXcVXu9L9A88htlcTmPD98nPv3ranpsgTBcRZn9Mw2wtpaIpH1IB+j46o4xOmliQnTh2jPZbbsX5iU9Q+oN/mtA+JkLTNPa+3MXOp9txui1ce+csSmeICe+EqaNpGgOtzTTv2Erzzm1ERn3oTSbqrlxC47JVVM+7Ar3x/CsKwqO+sWB7N10H95FKxNEbjFTOmUftFYuoWbCQ/S+/wO5nn2D2ytXc8NWvI8liglJBEARBEATItPF4ovUJfnf0d3ijXmqdtdw5+05uqr0Js/6Dr2JTVCUbcI/ER3iu7TmebH0SX9xHmb2M2+tv55YZt1BgKfjQcSiqwgsdL/Dz/T+nL9zHwqKFfO2Kr53SVmTP4B7+bsff0RnsZEPdBr656Js4Tefeeg4glAzxXNtzPHXsKeLpOKvKV3F1+dUsKFqAQRKFD8LZUdUEAwNP0tX1ILF4NzZbPdVVX8XtXo8kTV7hmKIkGB3dwdDQKwwNv0Yq5UOnM5CXexUFhWsoLFhz0VUlx+P92fDaN7qDVMoHgM02k7zc5eTlrcDlWoxebxv3uHQ6RDTaSTTakVliHdltRYkAoNPJVFb8CTU19yLLH90rNdJqmjZ/G6p2brnVx0mNs+ZD368+qkSY/TENsy8kTdPo/sIXiTc3U7f5RfR5F6a1h6pqvPVoC4fe7GPmoiKu/cNG9EYR5gmTT9M0hro6aNqxleYdbxEcGkQ2GKiZv5DG5auoXbAIg3nq3mTSqRS9R96jfd9u2vfuJjDoyd42b806rvvjr6KTRO80QRAEQRCEnlAPvzv6O55sfZJYOsaSkiV8YfYXWF62HOk8es2mlBSv97zOpuZN7PLsQq/Tc23ltdzRcAeLixef0hZO0zTe6HmDn+37Gcf8x5iVN4uvXfE1lpUuO2MLuYSS4IEDD/DrQ7/GZXLxN0v/hjVVa85qfJqmcXjkMI81P8ZLnS8RS8e4LP8yXCYXuzy7SKkpcgw5LC9bzqryVawsW4nLfHEVAWmaRigVwhvx4o16iSkxriq56oK3XlHVFNFoO+FwM+FwE+FIE+FwMwa9k0L3jbgLb8Rur5+UYylKAr9/J6Oj72Cz1VFQcC0GQ+6k7BsyFdDDI1sIBvaj08lIkunEIh/fNiJJJuSTbguFjtDd/Z8kkoM4HPOorrqbgoJrp7xfs6YpBAL7MsH20KvE4t2ADqu1GrutEbv9xGI2l31oO8YzUdUEsVgfsXg38Xg/qhJDVRMoagJNTaKoCdRxSzK7nUgMEot1AWA0usnLW0Ze7gry8pZhMhVN8HlrJJNDRKPtmExFWK01E9rPpeLt/rf5l13/QlugbbqHclF7esPT1LnqpnsY00KE2SLMnnKBZ5+l/6/+muK/+ztyP/PpC3LMdFLh1V8doX3/EAvWVHLVrXUTrioXhDPx9ffStH0rzTu24uvvRSdJVM9dQMOyVcxYtBST1fbhO5lkmqbh6++lfe9uTFYrc669YcIf4gRBEARBED4q9nv388iRR3i9+3UkncT6mvXcOftOGvIaJv1YHYEOHm95nKePPU0wGaTKUcXG+o1sqNuAy+zinYF3+I+9/8HB4YNUO6q5Z8E9rKlac9Zh+tGRo3xvx/c46jvK9ZXX83+W/B8KraevTI2morzQ8QKbmjdx1HcUi97C+pr1bGzYyGX5l2Xv8/bA22zt3cqbPW8yEh9B0knML5zPqvJVXFNxDbXO2nP6TKmqaUZGtpBOB9Hp9Oh08mnWmW0VSKoKcSVJIBllJBFgKBZgKDbKYGwUT2yIwegwg9FBYunxEwfaDXZurr2ZjQ0bqc+dnAD5uEyAOHxSYJ0JrSORY2haCgCdzoDNNgO7rYF4oh+/fzegYbXOwO2+Ebd7HXZbwzm9domEN9NiY/h1fL7tY5Ml6gANnU7G5VxEYeEaCgrWYLGUnfPziscHGBp+jeGhVxn1v4OmpZFlOwCqmkTTkme1n1zXUqqr7yY398wnYKaSpmlEIi0MD79OMPQe4XATsVh39nZZtmO3N5wUcDdgtzWg19vRNI1UaoRYrGds6SYWH1vHukkkBoHT52GSZM4G/KcuRgwGJy7XYvJyl2OzzRR/i52DnmAP//ruv7KlZwvl9nLumnvXhK9A+ThYUrIEm+HCZw4XAxFmizB7SinBIG3r1mMoK6P6f//nglSHxiMpXvz5QQbaA6y4fSbzrquY8mMKF04sFGSkp5vhni6Ge7rQNJWCiioKKqrIr6jC6pjaN7uAd5Dmt9+iacdWhjrbQaejYtblNC6/mhmLr5ry4wuCIAiCIHyUBBIBjowcIa2mUTWVtJZZK6py6raauf1cpNU0r3S9wsGhgziMDu5ouIPPNn4Wt9U9Rc/ohHg6zqtdr/JY82PsH9qPUTJS56rjqO8oRdYi7p5/N5+s+yT6CbRkSKkpHjn8CD/f/3NMehPfXPhNbplxSzY4a/Y181jzY7zQ8QKRVISZuTO5o/4Obqq9iRzjmXsNq5rKkZEjvNn7Jm/2vMlR31EAyuxlXFNxDaW20uy/k6Iqp26rCXKTzZSm9mPWQhN74U43LnRoyKAzZKqEZROgJ5gMEU6F0dAwy2acJid2g31SAsRkciTbHgLAZCw6KRydhd3egNVaM64vdCLhZWjoFbzezYz6dwEqFks1bvc63O4bybFfdtoq/VD4MENDr+MZeoV4pClzfJ0dD26Oxg3sDYapshiYa1Gplv3YCWYea6zE5lpOSdE6yvIWY5BPbROjaRrRaFu2mjkYOgiA1VpLYeFaCgvW4HDMzVZVa5qKqqbeV3k8ftEbXOTYG8/7NZ5s6XSESKQle+Lh+ImIdPrEz6LJVEI6Hcy27Tjx/WIs5goslgrMlkoslgqslkpM5lL0sg1JMqHTGUQ4PQUiqQgPHXyIR448gl7Sc9fcu7hz9p0Y5Ut/wk9haogwW4TZU8rz/b9n9H//l+pNj2G57LIpP17IF+e5/9hPYDjG9V+czcyFE7uMR5h+yXiMkd5MaD3S08XwWIAdGT3pA6XVBjpIRE58ELG5cskfC7ezIXd5BUbLxC8/DI/6aNm5jaYdWxloyXy4LJnZQOOyVdQvXYE9L3/iT1QQBEEQBOFjKJqK8tujv+XhQw8TSk1e6Hk6FTkV/OHsP2RD3YYL3pLiuJbRFjY1b2Kvdy8b6jbw6cZPY5JNH/7AD9EZ6OR7O77HXu9elpYsZU3VGp459gwHhw9ikk3cUH0DG+s3Mq9w3oRCOE/Ew9berWzt3crOgZ0klMQp95F0EgadjiU2hdU5cXJllb6UgW1RJwHsWGQTFr0Ji2zEojdilo1YZCMm2YBJNmCWDJhkPSbZgMNgxWGwkGMwY5H1aCe1b1BPau9wvNUDZFq89Ef66Qv3EklFMUh6SmyllOeUn1fVol6fcyK8tjVgNI5vl6lpGp6Ih7ZAG+3+dsKpMLJORpZkZJ2MXothS7ZiiR/BkGhHh4qqz0exzkO1ziMcHyAd3ocj1YlFl0DVoCspcTgmczgu401nnkdFTgUl9hKiqSjeqJfB6CBqYoBGc4I5FoVqo4qkg+G0jmPJHIakMjRzNW45Rok2iFvrw6Jlwu+YXEzU1EDKchk6YwlG2YhJNqGX9CiactqTRyeftDh+u0E2UOWoospRRWVO5UXdt1fTNBKJgbGAu4lIpA2DMXcsuM6E1mZzObJ84Z9DUkmSUBIfeILpo0zVVJ5vf56f7PkJQ7EhPln3Sb52xdcuyMlG4dImwmwRZk+Z2KHDdG7cSO7nP0/xd/5myo833Bvi+Z8eIJVUWf/VOZTVT14vMeHCaN21g0O/f42Rni4C3sHs9/VGE/nlFeMD6soq7LmZEDky6stWamfD795u0okTH7YdhUUUVFRidbqQJBmdLCPJEpKsR5JlJGnsa0lG0uuRJAlVVek8sJeeI++BplFYVUPDslU0LluJ0118wV8fQRAEQRCEiUqpKVpGW9jv3U+zr5kqRxVLSpbQmNc4ocrgiUoqSTa1bOLBgw/ii/tYXbGazzR+BpvBhl6nR5ZkJJ2EXqdH0knIkjxuW9bJ59zbOseYc179sC92qqayqXkTP977YyKpCNWOau5ouINP1n1yUi/RPx68nRzY6rQ0AwOP09n1AInEAA7HfGqq7yE//5oLXsGqaRq7PbvZ1LKJ17pfI62mWVi0kI31G7m+6voJV3kqqkJfuI/2QDtt/rbsuiPQQTQdPat9WCWNORaF+ZY09WYVeeylias6+lQnIUMNBtt8ip31lOeUZwJsW8kZ/29qmsZoYhRv1Isn0EJgdCuE92FNdyOhomg6ZJ2GokFnysThmJGDUR3D6XO7suFsldhKsuF2taM6uy6xn/k5TDVN00goCWLp2LgloSQosZVQbCuett8LnYFOHm95nGfaniGcCvPphk9z19y7yDNfmPnFLgYHhw7yL7v+hYPDB5lTMIdvLf4WcwvnTvewhEuECLNFmD0lNEWh89OfIeXxULf5ReScqT3T2Nvk48UH3sNk0XPzPfPIL7NP6fGEyRWPhHnjVw9wdNvvcbqLKK6rzwbWBRVVON1FSNK5Td6pqSoB7+ApIXc8GkFNZyoNNEVBVRRUVUFNK2inmSk5t6SMxuWraLhqFfnlomWNIAiCIFwq0mp62kKUi4E/7ufA0AH2D+3nwNABDg0fyvYbdpqcBBIBINNzeGHRQhYVL2JxyWLqc+unJOBJq2mea3uOXxz4BQORARYXL+a+K+5jXuG8ST/WRClKAq/3RWy2OhyOSy9UGY4NMxgZZHb+7CkPkhUlTn//o3R1P0gi4cHpvIKa6vvIy1txUbRhGImN8PSxp9nUsom+cB+5plxWV64+p2p4f8JPu7+djkAHSfVEH2m3xU2tq5Y6Vx21ztrM4qol15SLoimZRX3f+qTtZMpP2P8OTmsp5YXXjrVMmRzpdIiRkTfxB/bidMwnP/8aDAZH9nZN00iraRJKgqSaJKlklrSaPu3JI70uU+Rz8okmWScTS8foDnbTFeyiM9iZWQcy65OvtNBLeipyKqh2VGdfrzpXHTXOGix6y4SeYygZoj3QTrv/xMmFQDKQCatTJ0LruBJHPc3fd8dZ9BZqnDXUOeuoddVmx1ZmL5uS946UkuL17tfZ1HJiktjVlauxG+w80/YMZtnMFy//Il+Y/YULfgVJd7CbbX3bMuOS9JTYSiixlVBqL81s20twGB0fvqOzMBQd4id7f8Kzbc9SYCngG1d+g5trb/5In3AUJp8Is0WYPSWaH3ic7k2v4br1Fmzz56KTdEiyDknSjd8eW0uyDpfbis117m/kLbs9vP7wUVxFVm6+Zx45eRfvJU7CqboO7uelB35CZNTH0ts+w5Jb70DWT9PZe1VFVdUT4baqYrLZLooP5IIgCIIgfLikkuSNnjd4qvUpdg7spMZRkw1pFxUtwmV2TfcQp4SqqXQEOtjv3c/+of3s9+6nM9gJgKyTacxrZL57PvML5zPfPZ9iWzHDsWF2e3azy7OLXQO76A5lJk5zmpwsKlrEouJFLClZcs4T/51ubK91vcbP9v+MjkAHl+dfzn1X3MfSkqUXzWcsTdMYHHyOtvYfEo/3AZCXu4Lq6q/ici25aMZ5MVCUGH19/0NX94Mkk0O4XIupqb6X3NyrLsrXSdVUdvbv5LGWx9gzuAftDJP6nY5Nb8uE1s66bABb66qdtFDvo0jTNHxxH13BrmzQ3RnopDPYSXewO9vzXoeOUntpNkA+eW03ZgrT/HE/bYG2cdXw7f52vDFv9ngm2US1o5o8cx4WvQWLwZJZv2+x6q3ZbYNkoC/SR7u/PbvfweiJq4INkoFqZ3Um5B47UVHnrKPKUXXanuQfpifUk50Q1hf3UWYv41MzP8WtM2+lwFIAQHugnZ/u/Smvdb9GnjmPr8z7CrfPvH1CxzsbsXSM3Z7dbOvbxva+7dnf/+X2cmRJZiA8MO4EDmROfJbYSyi1lVJsK6bUXkqxtficrnho87fxq0O/IqWmuHP2nXxp7pc+thMYCudHhNkizJ5Umqqx+4UOdr/QOaHH5+SbKa51UlLnpLjOSX6ZHUk684eifa92s+OJY5TOdLH+q3MwWafml70w+VKJOG/9v9+w76XnyCstZ909f0Fx3czpHpYgCIIgCOcokAhkwwar3sqi4kUUWgsv6BiOjR7jyWNP8lzbc/gTfkpsJVxXeR0dwQ72Du7NViQ35DZkwu3ixVxZfOWUh1LhZJj2QDsdQztJpbzkO6+k1FFLqb10Qj1SVU2lP9w/rt1Bu7+dtkAbkVRmDhGXycX8wvnMc89jfuF8Liu47KwqID0RTzbY3uXZxUBkAIB8cz5XFl1JrauWcnum/UF5TjmFlsIPDC81TWNH/w7+fe+/c9R3lDpnHfcuuJdrK6+9qEJPv/9dWo/9E8HgAez22dTV/QWRcAvdPf9FMjmM07GA6uq7yc9ffV7jjsW68Xo3EwwdIj9vFW73OvT66b2aNJ2OEI/3oqqJTC9qJX7KRH+KGkcd61udTofweJ4hlRohN/eqsRB7ybQ+B+HSkVJSdIe6T/nd1RnoHF/5bnWTVtP44ifmSrLoLadUUNc56yi1lyKf4xW8pxNOhukIdGT7nx//HdsX7sueAJF1MpWOymw1fp0rc5Kj2lF9Ss/wlJrizZ43eaz5Md4eeBtZJ3N1+dVsbNjIstJlZ6xCPjB0gB/v+TF7BvdQkVPBfQvuY2312vOuWtY0jY5gB9v7trOtbxvvet4lqSYxy2YWlyxmeelyVpStoNJRCWTea3xxHwPhAfoj/QyEBxiIjN8OJoMTGsvqitV8c+E3qXCIq56FiRNhtgizJ00ilua1Xx+h8+AwxZ6dLPv0bBzr16GpGqqioaraGbeVtIqvL8JAWwBPm59IIPNmZjDJFNU4KK7LBNxFNU5MFj2aqrH9iWMceL2HuivcXP9Hs9Abzv9NTLgwPMdaePH+HzHa38uCdZ9g5ee+iME4eZfXCYIgCIIw+UZiI9k/8E+ulBuJj5xy3xpnDYuLF7OoOFPhOxV9QKOpKC91vsQTrU9wcOggeknPtRXXctvM21hasjQbcKTUFIeHD2eCWs8u9nv3k1ASSDqJxrxGlhQvYVHxIua752M32CcUWAYSgdO+NkpygBsdKa6wKkg6UDUYSOloT8h4FCsxQxk51ipKbKXjLucutZUSTUfH7et4j964Es8et8BSQJ0zUzF6WcFlzC+cT5Wj6rzDYk3T6A33Ziu393v3MxAZGHfJvlk2U2Yvy4bbx/v8ltvLGU2M8tN9P2XP4B7K7GXcPf9ubqq5aVJCp8kSjXbR1vaveIc2YzIWUVv355QU34pOlxmjoiQYGHicru5fEo/3Ybc3Ul31Vdzuddn7fPgxOvB6X8Lr3UwofBgAgyGfVGoEWbbiLryRkpLbcbkWX9CAX1Fi9PT8hq7uX5JOn30gpdMZyc1dQk31Pbhcp80QBOGcHe9J3uZvy4bJekmfDYvrnHUU2YqmpQ1FLB2jM9B5Sr/0nlAPiqYAmSrzMntZprLcVYsOHc+2PctwbJgiaxGfqv8Ut824jSJb0VkdU9M03up7i5/s/Qmto63MypvFN678BleVXnXWjw8kAvSGe+kOdvV56cUAACAASURBVLNncA/b+7fTF85cdVLrrGV5WSa8vrLoyglPRBtOhvFGvaTU1Fk/xqq3ihBbmBQizBZh9qTwDUTY/MB7BIdizHP34XrsB9Rv34Y+99wnYdQ0jdBIHE97IBNutwcY6Q2jaYAO8kvtGC0yA8cCzF1dzoqNM9F9QPW2cPFQ0mneeepRdj75KLbcPG78ytepmjt/uoclCIIgCML7DMeG2da3jfeG3suGC6OJ0eztdoN93OX3xy/F9sf92dB47+De7ORoM1wzWFKSCY0XFi2c8KR0mqZxcPggT7Y+yeaOzcTSMWqdtdw28zY+UfeJbGieSAzhD+zG6ZiP2Vw6bh9JJcmBoQPZoPbg0MHsH+M6dJlL0g3W016efvz7Vr2VpJrMVhcOxYay+7foLcx1lXK1NUyJ1olOZyC36DaczsV4R3cSDh2AeDuSljlmWDXQkZBojau0J2T6UzpUxn+2LbIWnXIpfnVOKTZZRlEiKGocm7UGSZq64oCUkqI/0k9vqJeeUE923RPObB+vfj8u35zPl+d9+QMvldc0Ba/3JfyB3Ug6I5JkQpLNSJIJWcqsM98zZbdlyYzRWIjZXDahADiVCtDZeT89vY+g0+mpqvoyVZV/giyfvketqqYYHHyOzq4HiEbbsFiqqa76MsXFtyBJp15eH4m04fVuxju0mXC4CQCHYwFu9424C2/EbC4jGNxH/8DjDA6+gKKEsZgrKSm5jZKST53y8zqZVDVFf/9jdHT+jGTSS37+akqKb0WWrUiSMfvaZ17n46/58e8Z0YmetoIAZN5HuoPd2ffH4+1QOoOdKKrCyvKV3FF/ByvKVkz4JJ6iKrzY8SI/3fdTBiIDXFVyFV+/8uvMzp9NSk3hiXiyv4t7w72Z9dhyct9yq97KkpIlrChbwfKy5ZTZyybrZRCEaSPCbBFmn7e2fV5ef/goeqPEjXfNIf6XX0TOyaHqt/89acdIxtIMdgazldu+gSjzrqtg/vUVF9VlisKZjfT1sPlnP2KwvZVZK1dz7R99GbNNTNQpCIIgCOcjkopg1VvP+/NQWk1zcOgg2/q2sa1vG0d9RwHIMeYwwzVj3CXVdc463Fb3hx4zpaY4MnIkExoP7GKfdx9xJY4OHY15jSwqXoTb6j7rMUbTUV7pfIVj/mNY9BZurL6R22bexrzCeeh0OhQlxtDQq3g8T+Eb3Y42VjV3Ikhch8Vy6h/xsXSM/d79HPUdJZKKEEvHiKai2UnEoumTtk/6vqyTMz10nbWZ18hVS6XFTmzocQYGnkCnkygr+zxVVV/BZCwYd0xVTROJNOMP7CHg34M/sIdEItPWA52RpKEMnd6JTdZj0gFaDEWJkk5HUJQoihKB9/X+tVpraGz8AbmuRWf9mk4WTdMYiY9kA+60muaG6hvOOImZpikMDr5AR+f9RKPHkGUboKEoceDME7adTK934ci5jJycy8lxXE6O/TIslsoz/lyqaoq+vv9He8d/kE4HKCm5nbrab2AynW21pMrQ0Kt0dt1PKHQYk6mYqsovUVr6aWKxnmyAHYm0AuB0XonbvQ534Q1nDKgVJYZ36GUGBh5ndPRtQEde7jJKSj5FYeENyPLkzAWkaSqDg8/T3v5jYvFunM6FzKj7pqiuFoRJllbTxNKxCbWROpOEkuDRpkd56L2Hsm20vFFvtjIcMn2+y+xlmatkTmoHVZ5TTo2jZsp6bwvCdBFhtgizJ0xVNXY9186ezV24qx2s+/LlGCPDtF2/Bvdf/zX5f/TF6R6icBHQVJV9Lz/PW797GL3JxJov/Rn1S1dM97AEQRAE4ZIVTUXZ3LGZTS2bODxyGJfJNT5sHgucCywFHxg4e6Netvdt562+t9jZv5NQKoSsk5lXOI+V5StZUbaChtyGSSscSCpJ3ht+j12eXez27OaA98ApE0x9mLkFc7lt5m3cWHMjNoMNTVMYHd2Jx/M03qGXUZQIZlMpxcUbyMu/moB/D96hFwmFMi0eHDlzMwGjex0Wy+Rd6pxIeOns+gV9ff8LaJSWfprq6q9iNhWf9T7i8f5MuB3YQyCwl3Q6gl5vQ5aPL1b0sg157Hv649/X29DUNB2dPyUe76Ws7HPMqPsr9PrJCVP8/nfxDr2E07GAgoLVZ6xgPhuqmmbQ+zydnfcTjbZjs9VTU33PWOsOCU3T0LT0WL/mE72alWwv5ziKGice7ycUfI9Q+DDhcAvaWJW7Xu8g53jAnXMZjpzLsViqGB5+nWNt/0I02kFu7jJmzvg2OTmzJ/QcNE3D53uLzq5f4PfvQpJMqGoC0OFyLcJdeCOF7hvO6d8eIBbrZcDzFAMDTxCP9yDLdoqKbqa4+BYcOXMmFGxrmsbIyO9pa/8h4XATdnsjdbV/SX7+NaIgSBAuMaFkiP8+8t90BjvHBdYVORUUWgovqjZOgjDVRJgtwuwJiUdSvPqrI3QfHmH28hJWfaYB2SDh+81vGPzBP1P3yssYKyune5jCNBsd6OO1//w53YcOULNgIWu/fB/23MnvmSkIgiBcOkLJEAeHDlJkLaLCUTHhXo0fR82+Zja1bOL59ueJpCLMcM3g+qrrGY4N0+5v55j/2LgJmXKMOePagMxwzcAgG7ITQDWPNgPgtrhZUb6CFWUrWFqydFIryj5ISkmRUBJnfX9JJ2UrfcPhZjyep/EMPksi4ckEf+71FBffgsu16JR2CMcn3xv0biYUeg+AnJzLcRdmgm2rtWpCzyGZHKGr65f09v0WTUtTUvwpqqvvOW0F+FRTlCht7T+mp+dhTCY3jQ1/T0HBtRPeXzB4kPb2HzPi2wpIgIokmcnPvxq3ex0F+avPegJDVU0zOPgsHZ33E4t1Yrc3UlN9L4WFa8+7dYWqJgiHWwiFDhEKHSYYOkQ43IymZU6USJIZVY1jtdYxc8a3JzXI9fvfxeN5Gru9kcLCGzCZzn/iU01T8ft30T/wOF7vS6hqDJ1OxmadkQ3pM5Xos5HlM0/sOerfTVvbvxII7MFiqaS25hsUFd0sWoUIgiAIlzwRZosw+5yN9IV58YH3CPvirPpMPZetPPFhvevOL6CMjlL73LPTOEJhuo16+nnnyUc58tYW9AYj19z5p8y57gZRASIIgvAxpWkae717ebL1SV7pfCU7gZ0OHaX2Uqod1VQ5qqh2jq0d1RTbiqdlsqfJFEwG6Qh0kGvKpcxeNqGqqVg6xsudL7OpZRMHhw5ilIysrV7LxvqNLHAvGPfeerzVw/snIWwPtOOL+7L30+v0zHfPZ0VZJsCuz62flvdoRYmNtcs4+/sPDb3CgOdpwuEj6HQyeXmrKCm+hYKC68+6cjUW68U7tBmv9yWCwf0A2O2zKci/Br3ejk6nR6eTx9b6k76W0UkGpLHb/IG99Pb+BkWJU1y8gZrqeyccik+mQPAAR49+i0ikhSL3zdTX/y3G97U5+SCh0FHaO37C8PBrGAy5VFXeRVnZ5wiFjuAdehGv92WSSS+SZCQvbxVF7vUUFFx72kpwVU3h8TxDZ9f9xGLd2O2zqam5h8KCNVMaqqpqkkjkWCbgDh/BZquntGQjknRpXWqfTocYHX2bYOgQodAhgsFDpFLHJ1yVsNnqyMm5HEfO5eTkXI7dPotYrIu29n9jZOT3GI1uamruvSSfuyAIgiCciQizRZh9TlrfHeSNR45itOhZ9+U5FNeemLwnPTpK6/IV5N/1Jdxf//o0jlKYLn7PADuffJQjb72BLOuZt3Ydiz55OzbXuU8EKgiCIFz6hmPDPNv2LE+1PkVnsBObwca6mnWsqVyDP+GnM9hJZ7CTrmAXnYHO7GSBACbZRKWjkmpHNXWuOq4supL5hfMx6yenh+xkSqtpuoPdtIy2jFsGIgPZ+xglIzXOmnFtQGpdtVTkVKCX9Kfss83fxqaWTTzb9iyhZIhqRzW319/OhroNuMyucx6jL+6j3d9ONB3lCvcV2I3TM29FKhVkePh1vEObGRl5K1s9ey5ycuZQUnwLRUU3n1NIezrxeD9e70t4vS8SCO47x0frKHLfRE3Nfdhsdec1jsmmqkm6un5JR+fPkWUr9TO/Q3HxLR940iIcaaWj4z/wel9Er3dQWfmnVJR/4ZTqa01TCQT2jvWIfolEwoNOZyQ/fyXuwnUUFFyHLFvweJ6io/PnxOM95ORcRk31fRQUXCeKG86DpmkkkoOEgmPh9ljInUwen4BUB2jo9Q6qqr5CRfmdH1i9LQiCIAiXIhFmizD7rKiKys6n29n3ajfFtU5u/PLl2JzjLwv2P/00A9/6NtWbHsMyZ840jVSYDn7PADufepQjWzMh9tw161i8QYTYgiAIH0dpNc32vu080foEW3u3omgKV7iv4NaZt7K2au0HTAinMRwbHhdudwW76Ax20hPqQdEUDJKBuYVzWVy8mEXFi5hXOA+jbDznMQaTQVpHW7Oh8/FJFC16C1bD2FpvPe22RW9hMDpIi+9EaN3mb8v2ftbr9FQ7q6nPrac+t546Vx2j8VHaA5k2IO3+dvoj/dmx6CV9NrCvc9aRa85lc8dm9nr3opf0rKlcw8aGjSwsWnjJhoCZAPtVBr2b8fm2oWkpTKYS3O4bsVqqz35HOolc12JsthlTMk5VTaFp6bFFQT2+rSonfT9zm6alMRhyJ7Xv9lQIR1ppavo/BAJ7yc9bRUPDP5zSAiUa7aCj46d4Bp9Flq1UVPwRlRV/gsHg+ND9a5pKILhv7ITAZhKJAXQ6AwaDi2RyiJycOdTW3Ed+/upL9uf3UpBIDGaC7eAhdJKe8rI/wGBwfvgDBUEQBOESJMLsj2mYvfOZNvZs7jrnx12+qowVd8xE1p96WWDvvfcRO3iQGVveQCdd2pcFC2fHP+jhnace5fCbryPJMvOuX8eiDbeLvtiCIAgfQ93Bbp469hTPHHuGodgQeeY8NtRt4JaZt1DrrM3eT9NUkslhjMbCsw63IqkIewb3sNuzm12eXTT5mlA1FZNsYl7hPBYVL2Jx8WLmFMzBIJ+4lD6tpukOjVVM+05fMe0wOnCZXMTSMaLpKLF0DFVTz2pcBZaCbGh9fKlx1nxowB5NRekIdNAWGGsHMtbvui/ch4ZGRU5Ftgo735J/VmO52KRSAYaGX8Xr3YzPtx1NS2E2lWYnX3Q45onevReIpqn09v2WtrYfAhp1tX9JefkfEI8P0NH5Uzyep9DpDFSU30ll5ZcwGif2OU7TVILBg3i9LxKNdVFW9lny864WIbYgCIIgCJNKhNkf0zC7p8lHf6v/nB5TWJ5D7YLTT2qixuO0XLUM5y0bKPne9yZjiMJFLOD1sPPJxziy9XV0ksTc629k8Sdvx553af7BLQjCR8Ph4cOk1BT1ufVnrP69GCmqQpOviUAiwIKiBVj0l9Yl4e963uUXB37BLs8uJJ3EirIV3DbjNlZVrMIw1qNV0zTC4SN4Bp9jcPB5EokBbLZ6Sopvpaj4k5hNxed0zGAyyB7PHnZ5drHbszs7kaFFb2F+4XwKrYUc8x+jzd+WnWBQ1snUOGuYmTszGzw35DbgtrpP6TudUBLZYDuaihJNR4mmotnAu8BSwEzXzEkPmmPpGN6ol4qcimnrF65pGsnkEOHwUULhJlLJESTJhCSbkSQTsmRGksxIsglZMmW2x76WJBOh4CG8Qy/i8+3IBNjmMtyFN+J2rx8LsEWwOV3i8X6amr/DyMibWK0ziMW60Ol0lJV9nqqqr2A6z5YtgiAIgiAIF4IIsz+mYfZkC23ZQu9X76bioYewr1wx3cMRpkjYN8KOTb/j8JtjIfZ1N7J4gwixBUGYfr87+jv+edc/AyDpJGocNczKn8WsvFnMzp9NY17jtPUIPp3eUC9vD7zN2/1vs8uzi0AiAGT6Kl9ZdGVmYr7yFdQ4as4r/NM0hcHBF+joehCzuZj6Gd+etN6+zb5m/n3vv/NW31u4LW4+3fhpNtRtoMhWlL1PNNoxFmA/RzTajk6nJy9vBU7nFQwPbyEY3AfoyMtdTnHxLRQWrkWvt53zWPxxP+8OvpsNt0fjo9nQuiGvgfrcemqdtRNqSfJRlpkkr41w+CjhcBOhsXUqdWKySEkyo6oJ4Oz/LjCby8YqsNfjyJkrAuyLiKZpDA4+S1fXL3G6FlJdffc5n0wSBEEQBEGYTiLMFmH2pBj4278luPkl6ndsR2cUfyh+1KSTSfa88DTvPPUYqpJmznU3sviW28nJExU8giBMv18f+jU/2vMjrqu8jg11GzjqO8rRkaMcGTmCN+bN3q/KUcXsvNmZkDt/Fo25jdgMZx+c6nS6007UdzqaphCP92EyFSNJRgKJALs8u3i7PxNg94Z7AXBb3VxVchVXlV5FrimX7f3b2da3jfZAOwBl9jJWlK1geelylpQs+dCK85SaojPQSYuviUHv8+RGd+DQRRlI6ciVwSTpyC26jbn1f3NW/XBPpzfUy/377+eF9hewG+386Zw/5XONn8tOzBiP9zPofYHBwecIhQ4DOlyuxRQV3Yy78MZxLQyi0Q4GPE/j8TxNPN6LLFspLFxLSfFt5OYuRaeTJzRG4QRFiZNMDpFIekkmhojFe7PhdSTShqalAJAkIzZbPXb7LHLsjdjts7DbGzAYXGiahqalUNUEippAVeKoanzs6/jY10kUNY7FXEZOzhwRYAuCIAiCIAhTQoTZIsw+b5qi0LrqamxLFlP2ox9N93CESaRpGm17dvH7Rx4iMOhhxqKlXP2Hf4qrSFTwCIJwcXjgwAPcv/9+1lWv4x9X/mO2rcVxw7HhbLB9POQ+efK9c2XRW3CanLhMLpxGJw5Tpt+y0+TEaXTiNDlxEEIe/i1KrA0NCb9qpDueYiClY1S14HbN57KS1VxVtvKMldf94X629W1jW9823hl4h2g6ikEycEXRFawsW8ny0uXkmnOzPaCPL+3+Y8wxx1nrSFFk0BhWzPQbr8SRu4rm4T04wltYYkuRxIChcCPXzP4bjGMh9IfxxX08ePBBHm1+FFkn8/lZn+ePL/9jnCYnyaQP79BLDHqexR/YDUBOzhyKiz6B270es7nkA/etaSr+wB48A0/iHdpMOh3CZCyiuHgDxcW3YLc3nPs/1kUgnY4QjbZjtVaj1+dM+v4VJUYguJ9EYpBkwksyOUwi6SUxtp1MekmnQ6c8zmQqxm5vGAusG8mxz8JiqUY6y5M1giAIgiAIHyeKoqAoynQPYxy9Xo/0MZ2vToTZIsw+b9G9++j63Oco/eEPcd5803QPR5gkI709bPnNg3Qd3EdeWQWrv3gX1XMXTPewBOFjSVEVDo0cYlvfNnZ7dqNqKla9FavBeub12LbT5GROwZxp6787VTRN46f7fspD7z3EJ+s+yfeXfR9ZOrsqXn/czxHfEVpHW0kqybM+pqIphJIh/Ak/wUQQf8JPIBkgkMgsaGnWOlJc70gTVeH1kAG7pKPeZqfYoGFU/Rxv1aDTyVgs1dhsM7HbZmKzzcBmq8dqrT0lUEwpKfZ697K9bztv9b3FMf+xU8bmthRwXZ6DefpezKofg7mGmXXfoNi9btwke96olxeOPgDDj1JpiONJG4g4b2Ld7K9TkVNx2ucdSUV45PAjPHz4YeJKnFtn3MpX5n2FPIORoaFX8Ho3M+p/G01TsFrrKCr6BMVFN2O11pz1azvudVbiDA+/jsfzNCO+rWhaGqu1Dpu1FrOlAoulAos5szaby5Hlswvjp5KmacTjfdk+05nK56PEYt1Apuo5L28Vbvc6CguuO69gW1FiDI/8Hq/3RUZGfo+iRLO3SZIZk9GN0VR40roQo9GNyZRZm80lGAyu837OgiAIgiAIHxWpVIpgMIjf788ugUAgux0KhbjYMtK7774bt9s93cOYFiLMFmH2efP+8IeM/OYR6ndsR86Z/Koj4cKKR8K8/fj/sP/l5zGYzCzb+Dnmrb0JWS+qtQThQhqODbOjfwfberexY2AHgUQASSdxef7lWPSW7IR00fSJyelSauq0+2rIbeDeBfeyqnzVR+LSf03T+Ld3/43fHPkNn5r5Kb571XenPaz3+/dw+Oi3iMfaMeeuhvyNaLKNeYXzyDFm3hsVJU402kEk0ppdwpHWscBTBY63epg5rmLWbp+FweDMHssT8bC9bzuRVISZuXUUKh0M9T1MNNqB3d5ITc19FBasGRdiv19aSbO95d8JDvwaKzH2R2V6jEu4qeFOrqm4BoNkIKWk2NSyiV8e/CW+uI/rK6/n7jl/iDXRPBZg70TTFCyWStyF6ygquhm7fdak/owlk8MMDj6Pz7edWLyHWKwHVY2Pu4/R6B4fcFvKsVqqsdsb0esnv0+6osQIR1oIh44SjjQRDjURjjSdVAGtw2KpGvu3a8RqrSEQ2It36CUSCQ86nZH8/JW4C9dRUHDdWbV7UZQow8Nb8A69xPDwFlQ1hsGQh7vwBgoKrsNiqcJkKkSW7R+J/+OXgkAgwODgIDNmzPjYVkUJwnRQVZXe3l6ampoYGRlh6dKl1NRM7OSpIAgXr/7+fvbv34+qqlN2jFgslg2sw+HwuNt0Oh0OhwOXy4XT6cTlcmG8yFrqLliwAJvt3Oea+SgQYbYIs89b27r1GEpKqPzVf033UITzoKoKh7a8xrb/fYRYKMica9ey4jN3YnU4P/zBgiCct7Sa5r3h93ir9y229W3jqO8oAPnmfJaXLWdl2UquKr0Kp+nM/ydTSmp8yJ2K0hZo48GDD9IT6mFu4Vy+tuBrLC5ZfKGe1qRTNZV/3vXP/E/T//DZxs/yrcXfmtYgO52O0N7+I3p6f4PJVExj4z9QkH/NOe1DURJEo+2EI82Zit5QZiK+VGokex+TqSQbjtpzZpFjn0UgeIDOzp+NhdizqKm590ND7FOPHedI20/w9D6MqqV5PSizL1nEtdXr2Nq7ld5wLyuK5/HFqnkYYgfx+98ZC7CrcLvXU+Reh90++4IFqJqmkUwOEx8LtmOxbmLxXmKxHuKxHuKJAU6eqNBirsSe04jd1og9J3NywGyuOKvxKkqUSOTYSUsrkcgxYvGe7DFk2T7WrqMxe/LBZqs/7SSWmqYSCO7D630Jr3czicQAOp2BvLwVFLnXUVCwZlywnU5HGBnZwqB3MyMjv0dV4xgM+bjdN+AuXIfLtVi0BZkmTU1NPP3008TjcfLz81m5ciVz5sxBlkWPd0GYCqlUivb2dpqbm2lubiYSiSBJEmazmWg0ypw5c1i7di05orBKEC55mqbxzjvv8MorryDLMgaD4cMfNEEmkwmXyzUusD6+7XA4xPv6RUyE2SLMPi+J9nba199E0d9+h7zPf366hyNMUF/TEd54+Jd4O9oobZjNtV+8i6LaGdM9LEG4JO3z7uPIyJGzvn9aTXNw6CBvD7xNKBlC1snMK5zHirIVrChbQUNew3mHtSk1xTPHnuEXB36BN+placlS7ltwH3MK55zXfs9VWk2jQ3fW7UDeT9VUvv/293mi9Qm+MPsL/MXCv5jWKtQR3zaamv6GeLyX8rI/pK7uLye1EjiRGMq2qzjeuiIabUfTTvTrm2iI/X7x+ACtx/4/vN5niWlmnh7VKLW6uSYvBy3aBKhYrTW4C9fhdq/Hbm+8KCuAVTVJPN5PNNpOaGySw8zr1smpAfSJiQ51OilbKX88uI7He7P71emM2Kw1WG0zxirn68eC8fIJve6aphIMHsDr3YzXu5l4on8s2F5OXu4y/IF3GRl5E1VNYDQWUFh4I0Xudbhciy7aSTF9Ph8tLS1IkkRDQwNO50fvZHg6nea1115j586dlJSUsGjRInbt2oXH48HlcrF8+XLmz58/pX94C8LHRTQapaWlhebmZo4dO0YqlcJoNDJz5kwaGxuZMWMGsiyzbds2tm/fjizLrF69msWLF4sASpgUyWSSjo4OBgcHmTNnDrm5uRf0+JqmEY1GCYVCBIPB7NpoNFJTU0NxcfFH7sqgaDTKM888Q3NzMw0NDWzYsAGr9YMnPxc+nkSYLcLs8zL80EMM/duPmLHlDQwlHzy5k3DxSEQjDHd3MdzTRfehA7Ts3IY9L59Vn/8jGpdffVEGFIJwsVM1lYcOPsT9++9H49zePwsthSwvW86KshUsLVn6gdXX5yOhJHis+TEeOvgQo4lRVles5p4F91CfWz+h/WmaRjgVxhf3ZZaYj5H4yImvx5aRWOZ7gUQAp8nJDdU3cFPtTcwrnHfWQb2iKnx3x3d5tu1ZvjTnS9y74N5p+12VSgVoPfZPDAw8jtVaQ2PjD8h1Lbogx1aUBJFIC+FwE0ZjPvn515xXiP1+/sAeWlr+nlDoPQCs1lrc7rEA29Zwyb4/KEqUcLjlfT2tm1GU919SasRmq8VmzYTWxxeLpXLKqqA1TcsE20NjwXa8D6PRPVaBvR6X68qLMsDWNI3+/n6am5tpamrC6/WOu72kpITGxkYaGxtxu92X7M/OcT6fj8cff5z+/n4WL17M2rVr0ev1aJpGa2srW7dupbe3l5ycHJYtW8aVV1550V2OLAgXu9HRUZqammhubqarqwtN08jJyaGhoYHGxkaqq6vRn6b14cjICC+++CJtbW243W5uuukmqqqqpuEZCJc6v99PS0sLra2tdHR0kE6nAZBlmWXLlrFixQpMJtOkHS8cDtPZ2TkurD55/UETDprNZmpqarJLQUHBJf1e29PTw+OPP04oFGLt2rUsWbLkkn4+wtQSYbYIs89L52c+i5ZKUfPE49M9FOE00skkI309jPRkguvh7k6Ge7oJjQxl72O0WFlw4ydYfMvtGM2WaRytIFy6IqkI39n2HV7rfo2bam/iLxf+JQbp7CvzHEbHBf2wFklF+O2R3/Lw4YeJpCKsq1nHn83/Myodlae9v6ZpjMRHaPO3ccx/jDZ/W2YJtGUmPjwNh9FBnjmPPHMe+ZZ88sx55Jpz6Qp0saVnC3ElTqmtlPW167mp5v9n777D4zrrvP+/zzRNuujongAAIABJREFU0aiOmtWLVdzk3p3ENU6cCg4kS9ksDyHAhuVHllCWnhDKsuyGQPYHT1hYQgIhhTTbcYljx13uJZZs9d779Hbu5w9JE8tVkiVLtu/XdZ1ris45c8/YmtF8zvd873XkRF/6bBC/6uc7u7/Du9Xv8tjMx3i08NELn5OzktbWTQgRwGCwnbPEYjDYRq2XcGvrFs6W/gC/v5O0tC+QmfEVtNrR+1IzEQih0tm5l7CweCyW3Bv2i4QQamjSRoEg3JKL0Zg6rq07+iaSbMRoTBrVgxSjJRAIUFNTEwqbent7URSF9PT0UNgUCARCAXd9fV91e3R0NPn5+eTl5ZGWljYmlWRCCBwOB+3t7aHF4XCQn5/PlClTrqpS8/Tp07z99tsoisK9995LQUHBRR+/qqqKXbt2UV1djdlsZtGiRcybNw+jcfwnKZWkiUgIQXNzM2fOnOHMmTO0tLQAEBcXFzoYlpSUNKT3DCEEJSUlbN68md7eXgoLC1m9ejXh4aM/d4I0Mbjdbo4fP87x48dRFAWbzTZoiY2NveKZMsFgkPr6+lCAPXBgNjo6mtzcXHJzc4mOjmbHjh2cOnWK8PBwVq1axYwZM67qs6yjo4N9+/Zx/PjxUGCt0+mIiIjAarVe8tJqteJyuaiqqqKyspKqqip6evr+FrdaraFgOysr67o5Q0pVVfbt28f27duJjIzkgQceIDk5ebyHJU1wMsyWYfaIBdraKLvlVmxfeYy4L395vIdz3bB3tNNcXkowGEAEgwSDQdRgADUQRFWDqIHAR/cFVdRgAIbxu6iqKj2tzbTX1dLd1IgQfRMmaHU6YpJTsaWmE5uaji01nbi0DKy2uBs2qJCka6G2t5av7vgqVT1VPD7ncT4z5TPXze9Uj7eHP374R14qeQm/6ue+nPv4VMGn6PR0Xja0thqs5ETlkB2VTbo1nVhTLLHGWGJMfeF1dFg0eu2lvzw4/U7er32fjVUbOdB4gKAIkhudy7qsddyRcQdJ4R+d6eMP+nli1xNsr93O43Me55+m/dNHP/N309KygabmN+jtPQ4MvO4XvmdqNGEY9LGDgm69IRaNMvTg0u4oob39PazhUyko+ClW69QhbytJ1yuPx0N5eTlnzpyhrKwMr9eLTqcjJyeH/Px8Jk+efMnJh+x2e6jHbWVlJcFgELPZTG5uLvn5+WRlZQ27ejkQCNDV1TUotB5YvF5vaD29Xk9YWBgOhwOr1crcuXOZO3fusCZK8vv9bN26lUOHDpGcnMz69euHdJp5bW0tu3btory8HKPRyPz581m4cOGYnSodDAY5ffo0drsdrVaLRqO5YDn/fp1OR0pKimyJMsG1t7dTVVVFTEwM8fHxhIePzySvPp+PlpYWWlpa0Ov1xMfHY7PZRvT/JxgMDjoo1tPTg6IopKamhg56xcbGXtVYP/jgA/bv34/BYGDFihXMnTt3zNsxBAIBfD4fqqr2fZdT1YsuAz8TQpCQkDAm7wvBYJCGhoZQVfFQaLVaYmJixu3/2HA0NTVx8OBBTp06RSAQICUlBaPRSHt7O93d3YPWjYqKGhRu22w2IiMjqa+vp6ysjLKyMjweDxqNhrS0tFCAHRsbe8HrUFdXx+bNm2loaCApKYm1a9cO+wyAxsZG9uzZQ0lJCRqNhsLCQubMmUNMTAxGo3HYr70Qgq6urlCwXVVVhcvlAiAmJobMzMxhtUdRFIWkpCTS09OvSbsep9PJG2+8QXl5OVOmTOGee+6RB4ClIZFhtgyzR6zrlVdo/v4PyHzrLYx5IztF/WYihODU+1vY+aff4/d6hrydRqsd9odaRFw8sSnp2NLSsaVmYEtNJyoxCe1FTsuTJGnk9jbs5YldT6BRNPzHrf/BwqSF4z2kEWl3t/P8yed5pfQVAupHX3wiDBHkROWQFZUVCq+zI7OxmUbvNMYOdwdbqrewqWoTJ9pOADAnYQ7rstZxa8qt/Gj/j9hVv4tvzf8Wnyr4FKrqo6PjA5qa36C9/X2E8BNuySMx6WMkJtyDXh+D39+Fz9f+0eIfuN4x6NLv70SI4XzRM5OR/s+kpf0fNMOovJek64kQgtbWVioqKigvL6empiYUQg9UX2dlZQ07xPJ6vaFQvLS0NBSKD2fCNlVV6e3t5dzvKFar9YJqPJvNFtpveXk5RUVFVFRUoNVqmT59OgsXLiQxMfGyj9XR0cGrr75Kc3MzixcvZuXKlcP+Yt/Y2Mju3bspKSlBr9czf/58li5disk0emfC1dXVsXHjRpqbm4e9bXh4OAsXLmTu3LnjFh6oqsrx48fp6Ohg2bJlMsTo53a7+eCDDzh48CCqqobuN5lMxMfHEx8fT0JCAvHx8cTFxY3q/ymHw0Fzc/OgpaOjg/OzAUVRQiH7uUtMTMwFvysDv/9nz56ltLQUj8eDTqcjOzub/Px8cnNzh3WgaSja2trYtGkTVVVVJCUlsW7dOlJSUka8P5/PR3d3Nz09PXR3dw+63tPTg91uH/Y+dTodM2bMYMGCBSQkJIx4bANcLhfHjh3j4MGDoWrd4QoLCwuFvucuMTExF23xcq34/X6Ki4s5dOgQ9fX16PV6pk+fzrx580g6p92p3++no6Nj0IHOgdt+v3/QPs1mM5MnTyY3N5fs7Owhvf+oqsqHH37Itm3bsNvtTJ06ldWrVxMVFXXJbYQQVFZWsnfvXiorKwkLC2Pu3LksXLhw1CctVVWV1tbWUOV2TU0NPp9v2PsxGo2D+tOPZmuVAdXV1bz++uu4XC7Wrl3L3LlzJ/yBFGniGNMwW1GUdGCyEOI9RVFMgE4IMfx3+TEkw+yRq3v0i3grKsjetlW+6VyBs7uLrb97lsqjh0ibVsjSBz+LwWRCo9X2L7q+S50OjUaLRqdFq9WhaDTytZWkUdTr62VDxQbq7HWszVzLDNuMy/6Oud21ff2DHcWYzVn9/XNzsJgn82ZtEc+ceJ7JUZN5ZvkzpFhH/gVpomh0NLKvcR8p1pRRD62Hos5ex6bKTWys2khVT1Xo/u8t+C5rJxXQ1PwGLS0b8Ps70etjSUy8l6TE+/sn8JPvlZI0Ui6Xi8rKSsrLy6moqAiFMnFxcaEK7NTU1FGrbByozCwtLQ1VkA1VZGTkoIBlqF+w29raKCoq4sSJE/j9ftLT01m4cCF5eXkXPK+TJ0+yYcMGtFot999/P7m5V1e00dLSwu7du/nwww8xGo0sXbqUBQsWXFVVtNPp5L333uPYsWNYrVbWrl1LTk7OBdWfl6oMdTqdHDp0iIqKijENVi6nqqqKzZs3h1pLREZGcu+995KVlXXNxjDRBINBjhw5wo4dO3C73cyePZtFixZht9tpbW0dtJwbUEVERITC5KioqEtW5F/sfrvdPii4PjeUjYyMJCkpicTExNDi9/svGEtnZ2co7NZqtcTFxYWC7YaGhtCZGSaTKXRmRnZ29pj3lRdCcPr0abZs2YLdbicvL29Ywb/H4wkF1m63e9DPNBoNkZGRREZGEhUVRWRkJCaT6ZKv+fmv+8DYTp48SSAQIDMzkwULFpCbmzvs99rW1tbQ+1sgECAjI4O5c+cO6/f53BB44LK3tzf0c0VRiI6ODr33JiQkkJmZSURExLDGOlxdXV0cOXKEo0eP4nK5iI2NZd68eRQWFg7r31JVVex2O+3t7XR1dZGYmMikSZNG/Lnm8/nYu3cve/fuBWDx4sUsWbJk0GeSqqqUlJSwZ88empqaxuUAoqqqw6rQP//MCbfbjVarJTMzM3TmxNV+Tqiqyu7du9m5cycxMTGsX79+0AEJSRqKMQuzFUV5BPgCECOEyFYUZTLwWyHEyhHvdAzIMHtkVKeT0kWLiX7oQRK+/e3xHs6EVnZoP9t+92v8Hg/LPvUws26/C+UGm3VYkiYyIQQn20/y6tlX2VK9BU/Qg06jI6AGyI3O5YHcB1iXtQ6r4aM/zFTVT23dH6iqehZF0WGzrcDtrsHpLCcYdIbW8xBGQtRMrOF5WCyTCbfkYrHkoNdfujrjRiCEoNd+koaGv+B0lmO1TiMychaRETMxmdKvOlgWQlDScZqdla+QY3Bg9ZzG5SpHozFgs60iKfFjxMQsG9fexpI0XgZOKa6pqaGmpobW1lYsFkuol+b5/TXNZvMFv5MDp6APhNcNDQ1AXyVWVlYWOTk5ZGdnXzf9NofD7XZz9OjRUOViVFQU8+fPZ9asWWi1Wt59912OHTtGWloaH//4x0f1NWhubmb79u2UlZVhtVpZvnw5hYWFw6r4VlWVo0eP8t577+Hz+Vi4cCG33nrriKvmGhsb2bt3L8XFxWg0GmbOnMnixYuvqs3DlXR2drJt2zZKSkqIjIxk9erVREZG8uabb9LR0cG8efNYvXr1qAWdHo8HvV5/TU6Zvxrl5eVs2bKFtrY2MjIyuP322y8Z8Agh6OnpuSBUbmtru+yEcZeiKApxcXEkJiYOCq+HGhb6/X7a2touGE9vby9RUVGh/tepqanj8u/g9XrZuXMnJSUlF1SYX45erw+F1QOB9cCl1WodlQN8Lpcr9J7U29tLdHR06D3pcoGnqqqUlZVRVFREZWUlOp2O6dOns2DBgiueeTJUXq/3girngbB74P9ZfHx86DMjLS1tVFoXqapKRUUFhw4dorS0FEVRyMvLY968eWRmZo55y5jh6Onp4b333hvUT3vKlCmcPHmSffv20dnZSUxMDEuWLGHGjBnXVWunYDBIXV1daB6Mrq4uAFJSUkLBdlxc3LD2abfb+fvf/05VVRXTp0/nrrvuGpOqb+nGN5Zh9nFgPlAkhJjVf98pIcT0Ee90DMgwe2R6t2yl4atfJe2FP2GZP3+8hzMheV0udvzp/3J653vEZ2Zz52P/SmzKxSdXkyRp9Nl9djZUbuDV0lcp6yrDrDOzLmsd63PXk2ZNY1PVJl4rfY2SzhJMOhNrM9byQO4DpBmCnDn7HRyOM8TFrSF38vcxGvu+TNb11vHdD76Mx13JAxlLmBIejdNVdkHIrdfHYjZnnrNkYDZlYjKlX9eTBQYCTlpa3qah4a/YHafRas2Eh0/B4SgJPX+9PiYUbEdEziLCOgOd7tKnDgsRxO2uxensex0d/ZcuVwWq2tf/NjJyLkmJ9xMffyd6/dhWAEnSRCOEoL29nZqaGqqrq6mpqQlVTppMJhITE3G73djtdpxO5wXba7XaQUF3MBikqqoKr9eLoigkJyeHgojk5OQJFRKMpWAwyNmzZykqKqKmpga9Xo/FYqG7u5tly5Zx2223jVnoVl1dzbZt22hoaMBms7Fq1Sry8vKueCCwoaGBjRs30tjYSEZGBnfeeSfx8fGjMqbzJyObMmUKS5cuZdKkSaOyf+gLlXfv3s2BAwfQaDQsXbqUxYsXh8Idn8/H+++/z4EDB4iOjua+++4bdj/ac7W1tbFv3z5OnDhBVFQU69evH9XnM1ra2trYunUrZWVlREdHs2bNGvLz80d0YDgYDOJ2uy/Zp/li9w+0LhmLkM3n86HX6+XZU0MQDAY5c+YMRUVF1NbWYjAYmDlzJvPnz8dms4XW83g8HD9+nKKiIrq6urBarcyfP5/Zs2ePequWS1FVlZaWFioqKqioqKC2tpZgMIhOpyMjIyP0mWKzXf4Mv2AwSFdX1wWBeVtbGx6PB4vFwuzZs5k7d+6EP7h6bj9trVZLMBhk0qRJLF26lPz8/Ov+s3WgBdlAxXZjYyPQN1HmcP7fdXR04Pf7WbduHTNnzpTvDdKIjWWYXSSEWKAoyjEhxCxFUXTAUSHEjBHvdAzIMHtkGr/5TRw7P2Dy3j0osg/zBepLPuTd5/4Le3sb8+97gEXrH0Sru36OwkrS1fKrfnq9vfT6eunx9uDyu8iLySPWNHaVXtDfm779FK+Wvsrmqs14gh4KYgp4IO8B7sy8E4vecsH6xR3FvFr6KturN7DCYmdZeABVG0F+3o9IS7ontO7+xv08sesJhBD84pZfsDh58aD9eL1NOJylOJ1luJyVuNzVuFxV+Hxt5zyigtGYPCjgNpsziYiYOaFDWrvjDA0Nf6G5+S2CQQfh4fkkJ3+KxIS70emsCBHE4Syjp+covT3H6ek9hstV2b+1hvDwvFDArdNZzwmty/pD649OlTaGTepr5WKZjMUymaio+ZjNIw8zJOl6MxASDFRe19TUhFpxhIeHk5GRQXp6Ounp6dhstkFfkAOBAA6HA7vdTm9v76DLgetCiFDYkJWVNaq9dq9XTU1NFBUV0dzczKpVq8jJyRnzxxRCUFJSwvbt2+no6CA1NZVVq1ZdNLx1uVy8//77HD58mPDwcNasWcP06dPHJASw2+0UFRVx6NAhvF4vWVlZLFmyhKysrBE/3kBf7O3bt+N0OiksLGTlypWXbE9QXV3Nm2++SXd3N4sWLWLFihXDClrr6urYu3cvZ86cCfUkLi8vx+l0smbNGubPnz8hAhSXy8UHH3zAoUOH0Ov13HLLLSxYsGBc+xJLE0NjYyNFRUV8+OGHBINBcnJymD17NjU1NRw7dgyfz0dqaioLFiygoKBg3M868Pl8VFdXh8726ejoAPra1GRnZ4fO9Dm/wruzs3NQT3iLxRJqY5KRkUFBQcF19fugqiqnTp2iqqqKGTNmkJmZOSHea8ZCT09PaHLn83uRX47BYGD58uWjdiBWunmNZZj970A38FngK8CXgWIhxHdGvNMxIMPs4RN+P6VLl2G97TYm/fxn4z2cCSXg97PvlRc59M7fiYxP4I5//leS8wrGe1iSdFkOn4Pttdupd9QPeRshBK6AKxRYh5b+2+6A+4JtNIqGmXEzWZW+ipVpK5kUPnrVUXafnY2VG3m19FVKu0ox6UzcmXknD+Q9wNTYqVfcvq1tKyVnf4DP18aHfhsvtjjQaM3cmXkn63PXc6TlCP955D/Jiszi2eXPkhqROuSxBQJ2XK6+YHsg4B5YgkEHAIqiJzZmGfHxd2CzrZoQwXYw6KG1dRMNDX+hp/cYGk0YCfHrSE7+ByIirlxJ4fd309N7nJ6eY/0B9/HQ84X+0Dp8MhZzDpb+9iwWSw46XfhYPzVJmpAcDgcHDhzgyJEjod6sUVFRoeA6PT2dmJiYG/aL8c0qGAxy/Phxdu7cid1uJzc3l5UrV5KQkICqqpw4cYJt27bhdruZP38+y5cvvya9Vj0eD4cPH+bAgQM4HA4SEhJIS0sb1K88IiLiiv8fq6ur2bx5M83NzaSmprJ27VqSk5Ov+Pher5dt27Zx+PBhbDYb991332Un7xNCUF5ezp49e6ipqcFoNDJ//nwWLFiAxWLB6XTy5ptvUlZWRn5+Pvfee++4HcgJBoMcPnyYnTt34vF4mD17NsuXLyc8XH7+SYM5HA4OHz7M4cOHcTgcaDQapk2bxoIFC4b0ezReurq6QpMID5wJNECj0RATE3PBBJOxsbHy4KokSUM2lmG2AnweWAMowBbg9+JqZ5UcZTLMHj7ngSJqH36Y5F8/S8Tq1eM9nAmjrbaad3/9H7TVVjN95e3c9tnPYzDKD2RpYgqqQYqainir4i3er30fT9Az7H2YdCYiDBFEhEX0XQ4sYRdeN2qNHGo5xPba7ZR1lQFQEFPAyrSVrExbSXZU9pADGlWo1NnrKO4o5nT7aYo7iznVdipUhb0+dz3rstZdUIV9MR5PE6WlP6KtfRvh4QXk5z9NhHUGH7Z/yGtlr/Fu1buhYH51+mp+vOTHmPXmYb9WFyOEwOfvwOkso6N9By2tm/B6m8Y92HY6K2lo/CtNTa8TCPRgNmeRnPwPJCXef1W9wIUI9rVjUT1YzNkytL6BCCFobm4mLi7uuqqgmig6OzvZt28fx44dIxgMUlBQQEFBAenp6RP+tGpp9Ph8PoqKitizZw9er5fCwkI6Ozupq6sjNTWVdevWjVof3OHw+/2cPHmSY8eO0dbWNiiU0uv1FwRSNpuNmJgYHA4H27Zto7i4mIiICFavXs20adOGfTCmoqKCt956C7vdzpIlS7jtttsGvc8Eg0FOnz7N3r17aWlpISIigkWLFjF79uwL+rAKIdi/fz/vvfceVquVBx544LIB+VC53W7cbjderxev14vP57vs9ebmZjo6OsjMzOT2228fl39X6foSCASorq4mISHhmk7SOhoG5mhwuVzYbDaio6PHvZJckqTr35iE2YqiaIHTQoj8EWy7FvgVoKUv/P7ZeT9PB/4AxAGdwKeFEPXn/DwCKAbeFEI8dqXHk2H28DX/5Cd0/+0VcvfvQ2MenVDneiWEIODzcmLrJva8/AJhlnDWPPovZM+RfcSliamsq4x3Kt5hQ+UG2txtWA1W7si4g7uz76YwrvCaVPzV9tayvXY722u3c6LtBADpEemhYHuabRoape+0eSHER8F1x2mKO4op7ijG4e+r8DVoDOTF5DHdNp17su9hSuyUIT0HIYLU179IReV/IkSArMx/ITX1c2g0g09jtvvsvFv1LmHaMO7JvmdMXx8hBL29x2ltffecYNtAbMxS4uPvIC5uNTrd2HyBESJIe/v71Nf/mc6uvSiKnri4NaQk/wNRUQtkJah0Wfv372fLli0kJSVx//33y1NHh6ipqYm9e/dy+vTpazbxnjTxuVwu9uzZQ1FREWFhYaxevZrCwsIJ0W9VCIHD4bjoZHDd3d2D1tVoNGi1WpYuXcqiRYuuajJHj8fDli1bOHbsGPHx8dx///3ExsZy/Phx9u3bR3d3NzabjaVLlzJt2rQrHlSrr6/ntddeo7e3l5UrV7Jo0aJhv74DPdePHj1KeXn5Fdc3GAwYDAbCwsKwWCwsXrx4SH3SJUmSJEm60FhWZr8FfEUIUTuMbbRAKbAaqAcOAQ8JIYrPWedVYIMQ4k+KoqwA/kkI8Zlzfv4r+oNuGWaPPiEEFStXEZaXR+r//9/jPZwx4fO4KT2wF7e9F5/Lidflwtt/Gbrt/ui22j+Tc868haz+wlcwR4xeFdXZzrP87ODPqOypvPLK54gMiyTOFEecOY54Uzw2k414c/xHt802TDpZNX6z6HB3sKlqE+9UvENJZwk6RcfSlKXck30Pt6bcikE78i+YV6vV1cqO2h1sr93OoeZDBESAeFM8CyctpMXZQnFnMXZf30Rneo2evOg8psROYUrsFKbappKkh66OHfT0HAVA0ehQFB0aRY+i6FAULYpG33+fLnS9s3M3vb0niIlZRn7eU5hMQ28bci0IodLbe+KSwbbNthy9PvqqH8fv76ax8RXqG17C46knLCyRlORPkTTpE4QZbFfegXTTO3v2LH/9619JT08PVW2uWrWKBQsWTIjwbaIRQlBdXc2ePXuoqKjAYDAwb948Fi5ceN1V20ljy+12o9VqryoEvpZ8Ph+dnZ2hgNvv9zN//vxRPbugtLSUt99+G5fLRVhYGG63m5SUFJYuXUpubu6w3nPcbjdvv/02JSUlTJ48mfvuu29Ik5h1dnZy9OhRjh07htPpxGq1MnPmTGJjYwkLCyMsLCwUWg9cNxgM8v1QkiRJkkbRWIbZu4BZwEEgNLW6EOKey2yzCPihEOL2/tvf7t/mp+escxpYK4So629l0iOEiOj/2RzgCWAzMFeG2aPPc+YMVffdT9KPnyJq/frxHs6o83s9vP6T79Nwpv/4iaIQZjJjMJsJM1sI6780mD66bTBbiE1JI3vO6E0m4wl4+N3J3/G/H/4vEWERrEhbgYah/REsEHR7u2l3t9PqaqXN1YbvnMnVBlj1VuLMfYF3ojmRpPAkkixJJFoSQ5cy8L5++YI+dtTt4J2Kd9jTsIegCDIldgr3ZN/DHZl3EGOMGbR+T+8J7PbTw3qMsLAErOEFhIUljcr//R5vD7vqd7G9djuHWw6THJ7M1NipfcF17FRyonLQabT09p6krW0rbe3bQpMMWiyTURQ9QgT6FjWAKvz9t4MI4UdV+38m/BgMcUzO+TcSEu6e8FVRA8F2S+smWlvfxettAhQirNOJiV1GbMwtREQUXlBVfjl2xxnq6/5Ec8vbqKqHqKgFpKZ8FpttFRqNbBMhDU1TUxN/+MMfiIuL4+GHH8bn8/H2229TWlpKRkYG9913H1FRI29NcyNRVZWzZ8+yZ88eGhoasFgsLFy4kLlz58oeoZI0DC6Xi+3bt+NyuVi4cCFpaWkj/hwXQnDo0CG2bNmC2Wzm4x//OBkZGResFwgEOHv2LEeOHKGyshJFUZg8eTJz5swhJydHtkyQJEmSpGtsLMPsWy92vxDig8tss56+oPrz/bc/Ayw4N5RWFOUvQJEQ4leKonwMeB2wAV3A+8CngVXIMHtMtD33HO2/eY7Ju3ehs91YVXvBQIC3f/k0lccOc8c/P072nAUYjEaUa1xJcbDpID/a/yNq7bXcm30vX5/7daKMV9OnVtDr66XN1Uaruy/cbnO3hS5bXC00O5tpc7UhGPw7HxUWNSjgTrIkkR6Rzi0pt6DVyD/cJ6oebw9feu9LnGo/Rbwpnruy7+LurLvJic65YN1AwElF5S+or//ziB9Pp4vEGl5AuLWA8PB8rOFTsFhy0GhGp5pMVX10dRXR1r6N9rb38PpaUBQd0VELsMWtJs62CqMxaVj7FEJM+BD7YvqC7ZN0dO6is2MXPb0nABWtNpyYmMXExPSF2ybThT1AVTVAW/s26utfoLv7IBqNkcTEe0lJ+SzW8GF3BZNucr29vTz//PMoisIjjzwSqioWQnDs2DE2b96MoijccccdFBZemxZGE43H46G9vZ3GxkYOHjxIe3s70dHRLF68mJkzZ6LXD/0AlCRJY6epqYlXX32Vrq4ubrvtNpYtW4ZGo6Gjo4MjR45w/PhxXC4XkZGRzJo1i1mzZsl+9pIkSZI0jsYszO7feQIwr//mQSFE6xXWH0qYPQn4DZAJ7AI+DkyjL8Q2CyH+XVGUh7lMmK0oyheALwCkpaXNqampGfmTvMlUfuxjaIwmMv51zYsPAAAgAElEQVTy0ngPZVQJVeXd5/6Tkj07Wf3IY8xYtfaaj6HH28MvD/+SN8rfINWayvcXfZ+FSQuv2eP7VT+trlaaHE00OZtodjbT5PzoeqOjEVfABcDiSYv52bKfEW28+jYH0uhqd7fz6LZHqeqp4sklT3JHxh2XPPDQ1XWA4pJv4fHUkZLyj6SnPYKiDLUqV8XtrsPhOIPdUYLDUYLDcRZV7ZtIUlF0WCw5hIfnEx5egDW8AJ0uor/Nh7av5YeiR9HoPrqu6NBo+q4Hg246OnfR1raVjo4dBAJ2NBoTsbG3EBe3BlvscvR6+UXS7++hs2sfnR276Ojc3V+1DWZzZijYtlhyaWl5i/qGl/B6mzEaU0hJ+TSTkh64qgkdpZuXz+fjj3/8Ix0dHXzuc5+76ORlXV1dvPHGG9TW1pKfn8/dd989pFP4rzeqqtLb23tBD+H29nYcDkdovcTERJYuXUpBQYGs4pSkCcjr9bJhwwZOnToVqs6urq5GURTy8vKYM2cO2dnZsl2IJEmSJE0AY1mZ/QngF8BOQAGWAU8IIV67zDZXbDNy3vrhwBkhRIqiKC/1P4YKhAMG4L+FEN+63Dhv1srsHm9PqA/tUEV2+6hfvY74J75O7P/5P2M0smtPCMGO//2/HNv8Dksf/CwL7v/ENX/8LdVb+OnBn9Lj7eEfp/4jXyz84oRr8SGEwO63s7lqMz8/+HOijdH88rZfUhhXOC7jqeyu5OWzL9Pj7WFu4lzmJcwjPSL9pqz+G9DsbOaRrY/Q4mrhmeXPsHjS4ouud241tsmURkH+z4mOvvpJS4UI4nJV43CUhAJuu70En++yxzEvS6+PxmZbSZxtNTExS9FqjVc9zhuVEAKXq7KvartzN11dRaGDCwAx0UtJSf0sttjb6JuiQpKGT1VV/va3v1FaWspDDz1Ebm7uZdfdv38/77//PkajkXvuuYe8vLxrONrRo6oqXV1dtLa20tLSMii0DgQCofWMRiM2m+2CJTY29qb+fJKk68HAmSWbNm0iPDyc2bNnM2vWLNnPXpIkSZImmLEMs08AqweqsRVFiQPeE0JcMvlS+koCS4GVQAN9E0D+gxDi9Dnr2Oib3FFVFOVpICiE+P55+3kY2Wbksp49+izPn3p+WNv8Y0kc695sIuvdTYRlZo7RyK69fa/+hf2v/YU5d93PrZ/+3DX9stnkaOLHRT9mV/0upsZO5YeLf0h+zMQ/3b+4o5jHdz5Oi7OFr8/7Ov+Q/w/X5HUTQrCvcR9/Lvkzexv2YtAYsBqsdHg6AIgzxfUF24nzbrpwu663js9v/Ty9vl6eW/kcsxNmX3S986uxc7K/jlZrHtOx+XwdOJylBANOhOjvZR3qXx1ADfW59odug0J01HwiI+fIHs4jFAx66ek5jN1RjC12BRZL9ngPSboBbN26lX379rF27VoWLhza2UMtLS38/e9/p6WlhVmzZrF27VrCwsKGtK0QAp/Ph8/nC02kNpbv60IIHA5HKLRubW0NLeeG1lFRURcNrS0Wy03zuSNJN6pgMIiiKLIKW5IkSZImqLEMs08JIaafc1sDnDj3vktsdyfwDKAF/iCEeFpRlCeBw0KIt/tbkfwUEPS1GflnIYT3vH08jAyzL6uko4TSrtIhr3+09ShTnnyVQiWV/He3jOHIrq2j777Djv/9HVNvW8XtX/zqNfsCGlSDvHz2ZZ49+iwCwWMzH+NTBZ+6rvpQ93h7+O7e77Kzbidr0tfwo8U/ItwQPiaP5fK72FC5gRdLXqSqpwqbycaDeQ/yQN4DRIdFU91bzaHmQxxuPsyhlkO0u9uBmyfcruiu4JGtj+BX/fx29W+ZGjv1gnXGqhpbkqTrg9frRafTXVWLiyNHjvDOO+8wb9487rzzzmG9nwYCAXbu3MnevXuJjIxk3bp1mM1mnE7noMXlcl1wXzAYHLSvsLCwSy4Gg4GwsLBh96O22+2hANvtdofut1gsJCQkEB8fT3x8PAkJCcTFxWEwjM6cAJIkSZIkSZIkDc9Yhtm/AGYAf+2/65PAKSHEN0a80zFws4bZw1XfdJaulffReu9CVv70j+M9nFFRsnsHm37zS3LmLeTur30bzTXqYVneVc4P9v2Ak+0nWZK8hO8t/B7J4cnX5LFHmxCCP57+I88efZZUayq/vO2X5EZf+pTz4Wp2NvPXM3/ltdLX6PX1MiV2Cp8u+DRrM9ai1148qBBCXDbcXpayjNvTb2d+0nx0N0DFb3FHMY9uexSdRsfzq5+/6CSP41GNLUnS+PH7/bS0tNDQ0BBaOjo6iIyMZMmSJcyaNWvYYW9FRQUvvfQSWVlZPPTQQyMOxWtra3njjTfo6uq64Gc6nQ6LxRJazGZz6LrBYMDn8+H1ei+6nP+z4TIYDKHAeiC0jo+PvyH7fEuSJEmSJEnS9WysJ4D8GLC0/+ZuIcQbV7XDMXCzhtnBnh6CdseVV+zn2PUBLU8+xQtfncJPv/T6GI7syjob6yk9sJeknDzSpheOqNK28ugh3vzFU6QUTONj3/ohumtUYbWjdgff3P1NjFoj35z/Te7MHF5l20R1qPkQ39j1DRw+B99f9H3uzr57xPsSQnCi7QQvlrzIezXvIRCsTFvJZ6Z8hplxM4f9ep0bbh9sPsiehj04/U6iw6JZmb6StRlrmZsw97qqih9wrPUYX37vy1gNVn6/5vekRaQN+rmsxpakG5+qqrS3t9PY2BgKrpubm1FVFYDw8HCSk5NJTEykoqKC+vp6wsPDWbJkCXPmzBlShXFbWxu///3viYyM5HOf+xxG49X1rvd6vZSVlaHX6wcF16PVQkRV1Ququa9Ep9PdEJ/HkiRJkiRJknSjG8vK7EygSQjh6b9tAhKEENUj3ukYuFnD7NZnnqHjt78b1jbeaDMPf9HP+5/cSYwxZoxGdnGqGqTy6GGOb9lAzcljoftjJqUw8/Z1TLllJWHmoVWa1pd8yOtPf5/Y1DQe+N5Phrzd1RioYH7myDNMjZ3KsyueJc4cN+aPey21u9v5xq5vcKj5EOtz1/Ot+d8iTDu0nqg93h7OdJ6huKOYbTXbONV+CqvByvrJ63kw/0EmhU8atXF6Ah72Nu5lS9UWdtbvxB1wE2OMYXX6atZmrGV2wmw0ysTvkbi/cT9f3fFVEswJPL/meRItiQgRxONpwOWqwumqpK7uT7IaW5KuMZ/PR2NjI/X19XR2dmIymS6oNB64vFJ1tKqqobYb5186nc5QiO3z+YC+6uJJkyaRnJwcWiIiIkIhrRCCqqoqdu3aRXV1NWazmUWLFjFv3rxLBtROp5Pf//73+Hw+HnnkEaKiokb3BZMkSZIkSZIkSRqGsQyzDwOLhRC+/tsGYK8QYt6IdzoGbtYw2336NN6zQ++ZDdCYZOCTpd/iycVPcv/k+8doZIO57b2cen8rJ7ZtoretlfCYWApX38mUW1ZQX/IhxzdvoKn8LHqjiSm3rGDW7euITUm75P5aqyt55UffxhwVzYM/+jnmiMgxfw6+oI8n9z/JWxVvsTZjLU8teQqj7uqq2iaqgBrgN8d+w/98+D8UxBTwy9t+Sao1ddA6He4OSjpLKOkooaSzhOKOYhocDaGfZ0Vm8VD+Q9yTfQ9m/diGr+6Am931u9lcvZnd9bvxBD3EmeJYk7GGtRlrmRE3Y8IF20IIdlS9yX8f+gH51mg+kXkrwt+Cy1WN211L/1suAGZzJvl5P5HV2JI0RoQQdHZ2Ul9fH1qam5sZ+PvJbDbj8XhCVdLnMxgMg1ppaLXaQWH1ub2bz2cymYiOjiY5OTkUYNtstiFPWFZbW8uuXbsoLy/HaDSycOFCFixYgMlkCq3j9/t54YUXaGpq4uGHHyYlJWUYr44kSZIkSZIkXf+CQrCtvZd6r+/KK19DH0uIJkZ//bdOHYmxDLOPCyFmnnffCSFE4Yh3OgZu1jB7JIQQrHl9DQUxBTy74tkxfayWynKObdnA2b27CPh9pE6Zzsy1d5Ezd+EFva2by0s5vnUjZ/btIuj3kzZtBjNvv4vsOQsGrdvV3MjL3/8GGp2Oh578dyJs8WP6HAA6PZ18bcfXONp6lC8VfokvFX7ppjiNeWfdTv5tz7+BgMdmPUaPt4fizmJKOkpocbWE1ku1pjIldgoFMQUUxBZQEFNAtDF6XMbs8rv4oP4DtlRvYXf9bnyqj3hzPPGmeIIiiF/1E1ADBEWQgBoIXferfoJq330CQXZUNtNt00NLZmTmVbcwEUKlofFlGhtfptdRhnJOYK3RGDCZ0jGbMzGbMjCbMzGZMzGbMzHoY2+K/2+SNFJCCIbzt47f76ehoWFQeO1yuYC+YDo5OZmUlBRSU1NJTk7GYrEghMDr9V50gsPzrwcCgQt6RV/suslkuqqJHM/V0NDArl27OHv2LAaDgfnz57No0SLMZjN///vfOXXqFA888ABTp144sawkSZIkSZIk3aiCQvBWazf/Vd1MmWv4c7KMtQ/m55NnuTELJa9kLMPsbcCvhRBv99++F/gXIcTKEe90DMgwe3iePvA0b5a/ya4Hd2HSma68wTAE/H7KDuzh2NaNNJWeQR9mZMotK5i55k5saRlX3N7V29NXxb11E/aONqyxcRSuvoPpK28nGPDz8ve/id/j5pM/+jmxyalX3N/VKu8q57H3H6Pd3c5TS57ijsw7xvwxJ5J6ez2P73ycks4SFBQyIzNDgfWU2CnkxeQRYYgY72FelMPnYGf9TnbU7sAVcKFTdOg0OrQabd+lokWv0aNVtIPuD6pBSrtK+bD9Qxz+vp70Fr2FqbFTPwq446YTbx76gRSXq4qSM9+hu7uIgD6VfZ1NhJnS+ceZ3yDGWoDRmIiiXH/9viVpvJWUlPDWW2/h8XhGtL3NZiMlJSUUXsfFxQ25Knoiam5uZvfu3Zw+fRq9Xk9qaiqVlZWsWLGCW265ZbyHJ0mSJEmSJEnXREAVvNHaxTPVLVS4veRbjHwtI4Fl0VYmUqlYhE6L9iYtXhvLMDsbeAmYBChAHfBZIUT5iHc6BmSYPTz7Gvfx6LZHeXb5syxPWz4q+xRCcOjt1zmy8U1cPd1EJ01i5u13MfXWlYSZLcPenxoMUnH0IMc3b6D2wxNodTpM1gi8bjef+P5PSMyePCrjvpzd9bt5YtcTmHQmnl3+LNPjpo/5Y05E/qCfyp5KUq2pY94yZCJRhUp1bzWn2k5xqr1vKe0sJSACACSYE5hum05uTC5CCDxBD96AF0/QgyfgwRv04g26yFIrmaGtJojCTnc873b0sCR5Kf9123+N+sEkSbpZCCHYs2cP27dvZ9KkSeTm5g55W61WS2JiIikpKYPacdxI2tra2L17N6dOnaKwsJB7771XnuEhSZIkSZIk3fACquD1li6eqWmmyu1jisXI4xmJ3BkXiUb+PTyhjFmYfc4DhAMIIRxXvbMxIMPs4fEH/dzyt1tYnb6aJ5c8OSr7PLLxTXa+8HsyCmczZ919pE+fiTJK1W0d9bUc37qR6hNHWf3IV0ibNmNU9nspQgheLHmR/zj8H+RF5/HsimdJtCSO6WNK1wdPwMOZzjOhcPtU2ynqHfUAGDQGwnRhGLVGjDojk/Qqq4wNxGldNIg4TiszQRdJqjWVL8z4AgatYZyfjSRdnwKBAO+88w4nTpxg2rRp3HvvvVechPFm5Xa7MRqNMsiWJEmSJEmSbmh+VfBqSye/qm6hxuNjeriJxzMSuN0mQ+yJ6nJh9oi6iCuKcjdwUghR03/X48DHFUWpAb4qhKga2VCliUCv1bMseRkf1H9AUA1edS/g6hNH+eDPfyBn3iLuefzboxZiD4hNSWPl5740qvu8FL/q5+kDT/N62eusSlvF00ufvqmqkaXLM+qMzIyfycz4j6YS8AV96DS60CSTquqlqvo5amp+h04XSV7ev7Mibq0MkyRpFDidTl5++WXq6uq47bbbuPXWW+Xv1mXcqJXnkiRJkiRJkgTgU1Vebe7iVzUt1Hp8zLCa+NPkTNbERsjvCdexkU6J+TSwEEBRlLuATwMPAbOA3wK3j8ropHGzPG0571a/y8n2k8yKnzXi/XQ1NbDhVz8nNjWNOx57fNSD7OESQnC26yzvVLzDibYT2Ew2Ei2JJFmSSLAkkGRJItGciM1kuyDE7/H28PjOxznYfJBHpj/CY7MeCwWU0s1DVQNoNEN/6zy3wrqn5yjFJd/G5SonMfF+cid/B71+fCbDlKQbTUtLC3/9619xOBysX7+eadOmjfeQJEmSJEmSpIvwq4KgEBi119f36QaPj91ddmrcPhZGhbMg0nLdPYeJ5KzTw1+bOgiOQseIi1EFbOnood7jZ6bVzNOTk1klQ+wbwkjDbCGEcPVf/xjwP0KII8ARRVG+PDpDk8bT0uSl6DQ6dtTuGHGY7XW5ePMXP0bRaLnvie9iMI5fBVizs5mNlRvZULmB8u5ydBod023Tqe6pZn/jflwB16D1dYqOeHM8iZbE0PJezXs0OZv4ydKfcHf23eP0TKTx4vE2U139HI2Nr6DTRWCxTMZimUx4/6XFMhmDIeai2wYCTior/5O6+j9hDEtiZuEfiI299Ro/A0m6cZWWlvLaa69hMBh4+OGHSUlJGe8hSZIkSZIkSecRoq9f8Q/LG+kOBMi3mCi0mii0mimMMFNgMWKYQJNtd/gC7O12sKfLzu4uO1Vu30c/rGnBpFFYFBXOitgIlsdYyTKFyaB0iHZ09PLI6Wp8qsCoHbvXLN9i4ue5qayIscp/mxvISMNspb9PtgtYCfz3OT8zXvWopHFnNViZlzCP9+ve52tzvjbsX3pVDbLp17+gq6mB9d/5MZHx176ntNPvZFvNNjZUbOBg80EEgsK4Qr674LvcnnE7UcYooO8D1e630+RoosXVQrOzmSZnU+jyRNsJttZsJTosmj/c/odBLSSkG5/P10lNzW+pb3gRIVQSE+9HQcHhLKO5+U2CwY+mCtDrY/vC7fDJWCy5WMw5BINOzpb+EI+nnpSUz5Cd9XV0uvBxfEY3h97eXux2O5MmTZJ/tNzAhBAcOHCArVu3kpCQwEMPPURkZOR4D0uSJEmSJEk6T4XLwzfP1rOn28Esq5mHomM4aXezsa2Hl5o6ATAoCgXhRgqtZmZazcywmsizmNBrrs3f845AkP3dDvb0B9inHR4AwrUaFkWF83CyjWXRVtKNBvb3ONnR0cvOTjvfLWsAINVoYHmMleUxVpZGW7Hqrq5l643qhYZ2vl1WT57ZyJ9nZJFslPNFScMz0jD7GeA40AuUCCEOAyiKMgtoGqWxSeNsedpyflL0E6p6qsiKyhrWtnv/9iKVRw+x4nNfHPMJGc8VUAPsb9zPO5XvsKN2B56gh5TwFL5Y+EXuyrqLtIi0C7ZRFIUIQwQRMRHkxeRddL+qUBFCXHX/cOn6EQjYqa39A7V1fyAYdJGUeB+Zmf+CyZQaWkcIgdfbhNNZhsNZhtNZjtNZRlPTG4NCbrM5izmz/0ZU1EXnLpBGUXNzM/v37+fUqVOoqkpmZiZr164lISFhvIc2ZC6Xi+rqauLj47HZbOM9nAkrGAyyceNGjh49Sn5+Ph/72McwGOQfwpIkSZIkSROJJ6jy69oWfl3TilGr8LPcFD4zKRZtf8GJEIJaj48Tdjcn7C5O9Lp4s7WLFxo7AAjTKEwNN5Fo0GPUajBpFExaDSaNZtCl8dz7NRpUwC8EAVX0XQox6Pa513sDQQ50OzlmdxIQfY85L8LCtzITWRZtpdBqRndeoL4qNoJVsREA1Li97Oi0s7Ozl9db+sauU2BuhIUVsRFMDzfhEwJ3UMWtqv2X599W8fRfBgToFQWdoqDXKOiU828rg24LQej5Xe45B4RAFXBnXCSfTIy55kU/qhA8WdHIb+vaWBkTwe+mphMuA39pBBQxwt40iqIkA/HACSGE2n9fEqAXQtSO3hCv3ty5c8Xhw4fHexjXnWZnM6tfW81XZ3+Vz0///JC3O7P3AzY++wumr7yd1Y88dk3eIBsdjbxY8iKbKjfR4ekgwhDB2oy13J19N4VxhbIyUxqyYNBDfcOfqan5HX5/F3Fxa8nK+v8It0we8j4GQm6Hs5SAv4e4uLVotWFjOOqbmxCCyspK9u3bR0VFBXq9nlmzZhEVFcXu3bvxeDzMnj2b5cuXEx4+MaviXS4XZ86cobi4mMrKSlRVBSAhIYGpU6cyZcqUGyrY9nq9VFdXU1FREXq+cXFx2Gy2QculJih0uVy88sorVFdXs3TpUlasWIFmAp2SKkmSJEmSJMHuTjvfLK2n0u3l/vgofpSTTHyY/orbqUJQ4/Zxwu7iuN3FSbubLn/gvOBX4BulXssaYGaEmWXRVpZGhTM30oJphL2wfarK4R4XOzr7qrZPOdyXXT9Mo5wXzCtoUQaF0X71nGBaCPzqR+H1AIX+wFtzTtCtKOg0DLrtUlWq3T4WRlr4WV4K+ZZr0w7WFVR5rLiGTe09fC7ZxpM5yRccIJCkcymKckQIcdGKwBGH2dcTGWaP3Cc3fBKdRsdLd740pPVbKst5+QffJCErmwe+9zRa3ZU/qK5Gi7OF5089z+tlrwNwW8pt3JV9F8uSlw2aeE+SrkRV/TQ2vUp11W/w+lqIiVlGdtbjRERcuzMLpOEJBAJ8+OGH7N+/n5aWFsLDw1mwYAFz5szBbDYDfaHnBx98wKFDh9Dr9dxyyy0sWLAAnW6kJyaNnosF2FFRUUyZMoXc3Fyampo4ffo09fX1wPUdbKuqSnNzMxUVFVRUVFBbW4uqquh0OjIyMjAYDLS1tdHZ2UkwGAxtZ7FYLgi4w8LCePPNN+np6eGee+6hsLBwHJ+ZJEmSJEkThSoEDV4/6jAyjjCNhhi9dkL1ab4RtPn8/LC8kddbusgwGfhZbgq3xUSM+uMEVIFH7Qu3XeeE3G5VRcNFwt1zqpq1ioJeAZ1GIUzRjFmw2ur1U+n2XqSaXMGo0YQq1EdCCEFQgKIw5P2oQvByUydPVTRiDwb5Umo8X8tIxDyGE1m2eP189lQlJ+1unpqczOdT4sbssaQbhwyzZZg9Yr898Vv++/h/8/4n3sdmunx44uzu4sV/+xoKCp/+6X9hjowas3G1u9v5n1P/wytnX0EVKvdPvp8vzPgCiZZr35tbur4JEaS55R2qKn+F21NLZOQcsrP+lejoBeM9NOkS3G43R44coaioCLvdTlxcHIsXL2b69OmXDKnb2trYunUrZWVlREdHs2bNGvLz86/5WRuXC7CnTp160R7fPT09FBcXU1xcTF1dHdAXbA9sM5bBdiAQwO124/P50Ov1oWUoBwN6e3tD4XVlZSUulys09pycHLKzs0lLSxu0r2AwSHd3N+3t7YOWtrY2PB5PaD2z2cyDDz5IWtqFraMkSZIkSbr5HOh28L2yhitWwV6KVash1qAjRq8jVv/RZd99WmL1Omx6HVadFpNWg7k/kDRqFHkW8DlUIXipqYMfVzT1VeKmxfMv6QkjrnKWxk67L8BTFY38rbmTFKOen0xOYY1t9OeeKXG4+fTJSjr9QX47NZ3bx+AxpBuTDLNlmD1iZzvPsv6d9fxg0Q9Yn7v+kusFA35eefI7tFZV8OCT/05CZvaYjKfL08UfT/+Rl8+8jC/o4+7su3l0xqOkWFPG5PGk0SeEQAg/Gs34V853dR2ktPSHOJxnCQ+fQnb2vxIbc6v8g3QM+Hw+2traaG1tpaWlhdbWVjo6OjAYDJjN5ssuJpMJs9mM2+2mqKiIo0eP4vP5yMzMZPHixeTk5Az536y8vJwtW7bQ1tZGRkYGa9euJTFxaAfBnE7noPF7vV40Gg1arRaNRjPo+vmXiqJQXV09KMAeqLIeziSVlwq28/PzMZvNlx3DuZdCCNxuNy6XK7Q4nc5Bt10uF16v96Lj0Gg0g8JtvV6PwWAIXe/u7qa1tRXoq67Ozs4mOzubrKwsrFbrkJ7ruYQQuFwu2tvb6erqIjMzU070KEmSJEnXmaJuBy83d7Is2srdcVGjMqlfvcfHUxWNvNXazaQwPV9KjSdiGD14PapKpz9Ahz9Apz9Ih2/get+lV71yXjJQZWvSfBRyD1TfLooK59OTYok1jP9ZgWOt2OHmG2frONzrYlGUhX/PTWWyxTjew5KuYH+3g2+erafU5eFOWyRPTU4etQkZd3T08sjpasK1Wl6YkckMq3lU9ivdHK5pmK0oSrgQwnHlNa8dGWaPnBCCO/5+B9lR2Ty38rlLrrPt+d9wavsW1n31G+QvvmXUx9Hj7eGF4hd4sfhF3AE3d2bdyZcKv0R6RPqoP5Y0dlyuKj48/TUcjrPYYm8lMfE+YmOXX/N+0l5fO+XlP6O5+Q2MxhRysr9BfPwdKIqsGLhaqqrS1dUVCnwHLjs7Oxn4vNHpdMTHxxMbG0sgELggQL3c55KiKEybNo3FixeTlJQ0ojEGg0GOHDnCjh07cLvdzJ49mxUrVoT6afv9/kHB+8BzcDg++mgzmUxYLBaCwSCqql7y8lwjDbAv5WLB9kjpdLpBBxAsFsug23q9nkAggN/vx+fz4ff7L1jOvd9kMoUC7ISEBNnPWpIkSZJuYlUuLz+ubGRjWw96pa8XcHKYnkdT4/hUUiyWEUwA5wqqPFfbwnO1fQfP/zktni+nxWPRjt5kckIIXEGV9v5gu8MXwBlUcQ20tLjcZH5BlZ5AkFMON0aNwvqEGD6fahu1/sTOYJBjvX1nvZkHwnOt5qPrmrFrmwHgCAQpd3kpc3koc3o46/LwXkcvkTotP8hO5hOJ0bJA6DriU1V+V9fGf1Y3oygKT2Qk8vmUuKs64PSnhnb+rayefIuRP0/PYtIoBeTSzeNah9m1QogJdd6vDLOvzs8P/pxXzr7C7gd3Y9ZfeCTt/7F35+FVlefex79rz2OGnXlOSMKQEGRUwAmpKGqrqK2l2qrVaqu1tUc7vmqt7bHaUdtjrW2tp0u6r1sAACAASURBVKNa7alWERxQFGcEBQJJIAKZ53nP03rePxIiFNBAEhLw/lzXvva01rPuHTFZ+7effT/vPbeKlx56gBNXfIZTP3fFmB7bF/Hxt+q/8Zftf8Eb9XJWwVlcP/t6ipPGZ+a3GB9KKVpbH2fHzh9iMFhITz+Hrq4XiUQ6MZncpKedQ0bm+SQnnTSugbJScZqbH2XX7p8TjwcpyL+GwsLrMRqPzqIXx7Ndu3axfv16mpubicViw497PB4yMjJIT08nIyODjIwMkpOTDxlu6rpOOBw+IODeG3JXVFSM2YzcYDDIK6+8woYNGzCZTEyZMoWuri66u7uHA3Wj0Uh6evpw/XuvXS7XR56gK6XQdX34YrFYxu2kfm+QfKhg/WAh+95Afm9YLW84hBBCCDGWeqIx7qlr40/N3ZgNGjfkp/Pl3DRe7/Nxf0MHb/X7STIZuSInlatzUke0MKBSin939PGjXS00h6NckJ7ErcXZ5E3SoKzGH+SPTV083tZDSFecnuzmmrw0lnrcGA7z3Ks3GuOF7gFWd/bxco+X0EfMGjdr2vCMcbvRgNNoINlkGm6nsrd9isdsInX4MdNwD3GlFJ2RGDsDocHg2h+iduh2Szg6fByjBkV2K6cku/l2USYe8/E/C/14VR8Mc0ttM2u7Byhz2vjptDzmJzoPa4y4UvxoVwsPNHZyZkoCD5QV4DqCD6yEGPMwW9O0mw71FHCLUspz2IOOIwmzR2dD6waufv5q7llyD2cWnLnfcw3btvLPO2+laPY8VnzrNrQxmn0XioV4uOZhHtr2EP3hfs7IO4Ovzv4q0zzTxmR8cfREo31U19xCZ+ezJCctpKzs59hsWSgVp6f3TdranqSz83nicT9WayYZGZ8iM3MFbtf0Ma1jYGArNTu+j9dbSXLyYqZNvQOnc8qYHuPjqK2tjRdeeIFdu3aRlJTE9OnTh0PftLQ0LJbJ+cZiX11dXaxdu5aOjo4DgmuPx4NxDGf4CCGEEEIc78K6zkNNXdxb3443FufSrBS+XZR5QFi9qd/P/Y0drB6asX1Jpoev5KdR4jh4a4qt3gC31jazod9PhcvOj0pzWJjkOhovadS6IzH+3trNQ01dtEWiFNutfCkvjUsykz90NnlbOMqarn7WdPbxep+PuIJsq5lzUhP5REoCVoN20FnhAf3AmeO+WJyeoXYqPdEYfbH4IY/rNhrQNBiIffBNQ6fRQInDSqnDRqnDRolz8Hah3SILaB5HlFKs6ern1tpmWsJRLs3ycMJhtAd5sXuA57sHuConlR+W5IzrNwTE8W08wuwQ8DMgdpCn/0spNX4r/x0BCbNHJ6bHOP0fp7Mkbwl3nnLn8OP9HW387f/dhCMhkUv/+xdYHaPvf6SU4tm6Z7ln0z20+ls5JecUbph9A+Wp5aMeWxx9vb1vsb3qZiKRLqZMuYmC/C+haQeerMXjQTq71tLe9hTdPetRKobTOZXMzBVkZnwKmy37iGuIRvvZtfuXNDf/HYslldLSW8hI/6TMQh2l/v5+XnrpJbZs2YLNZuO0007jxBNPHNHCgEIIIYQQ4vijlOKpzj7u3NVKQyjCGR433y/OZobrw78FuTsQ5oHGDh5r6yGsK85OTeD6vHROHAqqOyNR7t7dysOtPXjMJv7flCxWZnkwHoPn8xFdZ1VnP79r7GCLN0iiycjns1P4Yk4quUOzy/cEwqzu6md1Zx+bhlqJlDisnJuayDlpScx228fkvUxUV/TFPmihsjfk3tszPKYYDq9LHFayrfJNvo8TXyzOz+raeLCpk/hhxIZGDe4oyeFLuWnjV5z4WBiPMPsN4GtKqU0Hea5RKZV3+GWOHwmzR+97r36PV5tf5eVLXsZkGAyrHr3923Q11nPZnb8kOStn1MfY2rmVn77zU7Z0bmG6Zzrfmv8tTsw6cdTjiqNP16Ps3nMv9fW/w24vYGb5PSQkzBrRvpFIDx0dq2lr/zf9/e8C4HaV43aX43LPwO0qw+Wajsn04bMwlFK0tT1J7ft3EY32kpd7OVOmfAOT6fAXnxMfCIVCvPbaa7z11lsopTjppJM49dRTsdulVYsQQgghxMfVO/1+fvB+M5sGAsxw2ri9JJslnoTDGqMzEuWhpi7+1NxFbyzOggQni5NdPNTUSVDX+VJuGjcVZh7WAo+TlVKKjQMBft/YyTOdfWganJmSQEMwQrU/BMAsl51z0xI5Ny2JqbKQopgg3licYFz/6A2H2I0G3MfB/6Ni4o1HmD0N6FZKdR3kuQylVPvhlzl+JMwevefrnufmV27mobMfYkHmAnpamvnf//oyp33+KhZ86qJRjd3mb+Ped+/lmd3PkGJL4etzv84FxRdgNMgvwGPR3kUevd5KsrMuobT0Vkymw+uztVcw2EBb21P09b2D11dFNNoz9IyG3V6A212G2zUDl7sMt6sMqzUdAJ9vJzt23k5f3wYSEuYwfdoPcbvLxugVfjzFYjE2btzIK6+8QjAYpKKigk984hMkJU2qL+IIIYQQQoijRCnF7mCYu3e38XRnHxkWE9+ZksVnM0c3a9ofj/Noaw8PNHbSGIpwZkoCPyjJPmT7kWNdYyjC/zZ18c/2HqbYrZyblsjy1ETy7daJLk0IISbMh4XZR/p98FuVUl/QNO1GpdSv9n1isgXZYmycnHMyFoOFdY3rWJC5gOrXXgZNY8bJpx/xmIFogIe2PcSft/8ZXelcU3ENV1dcjdN8ZMGnmFiDizz+k521P0TTzFTM/A3p6ctHNabdnk9R0Q3D44cj7fi8VXi9VXh9VXgHttHRsXp4e4slFYejmP7+TRiNLmZMv4usrE+P66KSxzulFFVVVaxdu5be3l6KiopYtmwZ2dlH3vpFCCGEEEIcO+JK0RSKsNMfojYQHlwE0D943ReLYzcY+GZhJtflpeEcgxmZTqORq3PTuCI7ldZIdNIu7jhW8mwWvl+SzfdL5PxaCCFG4kjD7HmapmUDV2ma9hcGF34cppTqOfhu4ljlNDs5Kesk1jWs45vzvkn1a+vIL5+Fy5Ny2GPpSufpXU/z63d/TUewg3MKz+Eb875Btkv+eB+rotF+anbcSkfHapKSTqK87Oej6nN9MJqmYbNmYrNmkpq6dPjxWMyL11uN17cdn7can7+GrKxPUzzlZiyWSbUW7YTSdZ3W1la8Xu+I94lGo7z11ls0NzeTnp7OZZddRklJifTKE0IIIYQ4TjWHImwc8FM7FFbX+kPsDoYJ6R98ozvVbKLUaeX89CRKHTY+lZ5E5n8s7jgWTAbtuA+yhRBCHL4jDbMfAF4EpgCb2D/MVkOPi+PMGfln8Oqbr/LOey/S397GwotWHvYYm9o38dN3fkpVdxWzUmfxiyW/YHb67HGoVhwt3d3rqa75f0QinRRP+RYFBdccdJHH8WIyuUlOPpHkZOmv/p/6+/vZtWsXu3btYvfu3QSDwcMew+12c/755zN79mwMskq5EEIIIcRx66mOPm6srieoKzQGZwyXOmyc5nFT6rBR6rBS6rSRbJYFv4UQQkycI/orpJT6NfBrTdN+q5S6boxrEpPUktwl/JAf8vaL/8ZktlB64uIR7+uP+rnjjTtYU7eGDEcGd516F+cWnYtB2j8cs0KhFnbW3kln57M4HEXMn/f4iBd5FAfX3d3N7t27cblcJCYmkpiYiMPhGPFM6HA4TH19/XCA3dU1uKyB2+1m2rRpFBcXk5KSclgzq1NTUzGbx36mjRBCCCGEmByUUvyirp2f17WxIMHJf0/NYarDht0o79WEEEJMPqP6SFWC7I+XNEcaszwVBF6so3z+qVgdjhHt1+Jr4YaXbmB3326uP+F6rpx5JXaTfZyrFeNF16M0Nv2JPXt+jVJxpky5iYL8L2EwyAIlRyoYDPLKK6+wYcMGdH3/laJNJtNwsP2fl4SEBCKRyHB43dDQgK7rmEwmCgoKmDt3LsXFxaSnp0trECGEEEIIcYBAXOcbNQ081dHHZzKT+fm0PKzybTwhhBCTmHw/SByWU6JlBMJvkb1gZK1BtnRu4esvfZ1oPMr9Z97P4uyRz+YWk09v7wZ27Pw+fn8tqSlLmTr1+9jteRNd1jErHo+zceNGXn75ZYLBIHPnzmXx4sVEIhH6+/sPuNTW1uLz+Q46VkZGBgsXLqS4uJj8/HyZTS2EEEIIIT5UazjCFZV7qPQGua04m+vz0mQChBBCiElPwmxxWJJ3R+gxx6lN7GbeR2z7zO5n+P7r3yfDmcF9y+9jSqK0Uj9WhSNdvP/+3bS1PYHNlsOsit+RlnbmRJd1TKutreW5556jq6uLwsJCli9fTmZm5vDz2dkHX0AzFosxMDBAf38/AwMDaJpGUVERbrf7aJUuhBBCCCGOce8NBLiycje+uM6fK4o4KzVxoksSQgghRkTCbDFikWCA9i3b6Mo30Ni6npUzLz3odrrSuX/z/fxu6++YlzGPe5fcS5It6ShXK8aCUnGamx9h1+6fE4+HKCy4jsLCr2I0jn+bGKUUfr+frq4uEhIS8Hg8Y36MSCTCpk2bMJvNFBQUkJqaOu6zUTo6OnjuuefYtWsXHo+HlStXMm3atBEf12Qy4fF4xuXnIYQQQghxPIvpime7+nmsrYcCu4XPZnqY6R5Z68TjyZPtvXyjpoE0i5lVJxQzwyUtIIUQQhw7JMwWI1a74U1ikQg5J87l722r8EV8uCyu/bYJxoLc+tqtPF//PBeWXMhtC2/DbJR2B0ebUopYrJ9wuJ1wuJ1IpBujyYHFnILZnIzF4sFkSkT7kAU4Bwa2UrPjNrzebSQnL2La1DtwOovHvNZ4PE5vby9dXV0HXEKhEABGo5ElS5awePFijEbjmBy3ubmZf/3rX3R3dw8/5nA4yM/Pp6CggIKCAjIyMsbseH6/n3Xr1rFp0yYsFgtnn302CxYswGSSX8NCCCGEOH5EdJ26YITaQIhaf4j3A2F2BkJYNI2vFWRwVkrCUW9l0R+N8XBrD39s7qQpFCXTYublHi9/aOqizGnjs1keLspIJs1y9N63tIWjbPEG2OIN0BWJMTvBwUmJTqbYreP289GV4md72rinvp2FiU4enFlEqkXORYUQQhxbNKXURNcw7ubPn682btw40WUc8/555230tbUw+5br+OJzX+Rnp/+M5YXLh5/vDHTytZe+RlV3FTfNu4kryq+QnmsjFIn0EIl0jnh7hSIa7SUS7hgOrMORvbc7iETa0fXIR4xiwGxOwmz2YLF4BkNus4dwxEJbaw0m8wYs5lRKp95CRvonx+S/pa7r1NXVsXv37uHAuqenZ79FD10uF6mpqaSmppKWlobH42Hz5s1s376d7OxsVqxYQXp6+hHXEI/HWb9+PevXr8ftdnPBBReQmJhIfX09DQ0N1NfX09fXB4DFYiEvL4+CggLy8/PJyck57F7UsViMDRs28MorrxCJRJg/fz5LlizB6XQe8WsQQgghPs6UUmzzBXmhe4Ct3gDnpSWxIj0Zs0HOO48mXyxObSBMbSDE+/7Q8O26YJjYPm8xc6xmSh026kNh9gQjzE1w8L2iLE71jH+LtN2BMA82dfJoWw+BuM6iJCfX5qZxVmoiA7E4T3b08Y/WHjZ7Axg1+IQngc9meTgzJWFMF0HsGA6ug2zxBtjqDdAeiQFgAFwmAwOxwfPhFLOJExOdnJjo5KREJzPddixjUIs/Hufr1Q0809nP57I8/GRq7piMK4QQQowHTdM2KaXmH/Q5CbPFSPh6e/j9dVdy0oWfYeFnLuWMx85gUfYifnLaTwCo7q7mhpduwBvx8pNTf8IZ+WdMcMWTn65H6e5+hZbWx+nuXodS8SMey2h0YLVmYLVkYLVmYLGmD90fvLZYUojHA0SivUQjPUSjPUSiPYOBeGTwOhrtIRjsJB7vB6CleRodHQuZOXMB8+bNIy0t7Yjr6+npYfPmzWzZsoX+/n4MBgMej2c4tN73YrPZDjrG9u3beeaZZwiHw5xxxhksWrTosGdNd3Z28sQTT9DS0sKsWbM455xzsNsP/Fplf3//cLDd0NBAR0cHMDhDPCsrC6vVOuJjdnd309fXR0lJCWedddaognghhBDi4yoQ13mt18sL3QOs7R6gNRwFIN1ioiMSI89m4av56azM9GAzSkA3FpRS9Mbi1AXC1IUi1AXD7AmGqQ8O3u4YCmMBTBoU2a2UOmyUOm2UOqyUOAavnabB87WornisrYdf1rXRHI5ycpKL703JYn7i2H7Ar5Ti1V4fv2/qZG33ABZNY0VGEtfkplFxiJYiO/whHmvr4Z9tPbRHYiSbjFyYkcwlmR5OcNs/clKHUoqArtMbjdMbjdEWjlLpC7J1KMDe++9VA0odNma57cxOcDDLZafcbcdhMPB+IMyGfj9v9/vY0O+nLjg4McVu0JiTMBhsn5joZH6iE7fp8M6BW0KDCz1u9wW5vSSba3NloUchhBCTm4TZEmaP2qZnnuTlvzzIlb/8LSk5edz2+m282PAir3z2FdY3rud7r32PRGsi9y29j2meaRNd7qTm979PS+s/aWt7gkikC4sljazMC3EnVDB4ijsyZnPSUHidjsnk+ugdPoRSitdff521a9eSnZ3FZz5zET09A2zatImamhp0XSc/P5958+ZRVlY2otnJ4XCYqqoqNm/eTH19PQDFxcXMmTOHadOmHfYMZwCfz8czzzxDdXU1OTk5rFixYkQhu67rbNiwgbVr12I2m/nkJz9JeXn5iI8bCARoaGigoaGB5uZm4vGRf/BgsVhYtGgRpaWlI95HCCGEENAUirC2e4AXugZ4vc9LSFc4jQaWeNwsS0ngEykJpJhNrO0e4N76dt4dCJBuMfHlvHSuyE7BdZiB35GKK0VTKEJtIEyiycj8BMcxFxQOxOKs6exnVyA0HFzXBcPDs4X3yrKaKbBZKHJYKbJbKXEMBtiFduuIZ8aH4jp/a+3m3rp2uqIxlqUk8J2izFH3rg7Gdf7V3svvmzrZ4Q+RajZxRU4KV2Snkm4d2XlnTFes7/XyWFsPa7r6CeuKaU4bF6UnYzNq9Ebj9ERj9ERjw8F1b2zwOqTv/75aA0ocVk5wO5jltnOC28FMl3043P8oHeEoG/r9wwH3Nl+QuBqcyZ1ns+A0GnAYDdiHrh2GoWujAYfROHzfoMGv6tsJxnUeKC/kEykJh/mTFUIIIY4+CbMlzB61v373RjRN4/N33QvASw0vceO6G1leuJxn656lIrWCXy/9Nan21AmudHKKxby0d6ymteVx+gfeQ9NMpKacQVb2Z0jxnI7BMHG96mKxGE8//TRbtmyhvLycFStW7Bc0+3w+Nm/ezLvvvktPTw82m40TTjiBuXPnkpGRsd9Yuq5TX1/P5s2bqaqqIhqNkpKSwuzZs5k1axaJiaNfJV0pNTxLOxKJsHTpUhYtWoThEF+T7O/v58knn2TPnj2UlpZy/vnn43aP/9dahRBCiLHQF42xuqt/KEybmBnHbeEor/Z6Wd/r5bVeH33ROElmIwkmI4mmwesk0/73E82DtxNNRsyHEeyGdcXrfT5e6Oqnyj+4dkaBzcJZqQksS0nkpCTnQds/KDW436/r21nf6yPJZOTq3FSuzk3DYx6b86ywrrN7qP9zrT/M+4EQtYEQuwLh/YLM2W4H1+WncV5qEqZJ3vqkJRThD02d/LWlG19cx6gNBqVFdisFditFdguFdisFdgsFNiv2Mfw36I/F+WNzF79p6KA/Fuf89CS+XZRJiePg39Lbl1KKrmiMWv9ga5Maf4h/d/TSE41T7rJxTW4aK0b5/0x/NMZTnYNtSDYOBAAwapBkMuExG0k2m0g2G0k2DV57zCY8Q4+lWczMcNrG9AMVfyzOuwMB3ur3sScYIRCPE4jrBOOKgD54e/ii68T3eZtfYLPwl1lTmOb86J+tEEIIMRlImC1h9qh0NzXyp5uvY8nl1zDvvAuAwYUeT3v0NELxEMsLl/Ojk3+EzSQnR/tSStHX9w6trY/T3rEGXQ/icJSQnf0ZMjNXYLVMfPDv8/n4xz/+QWNjI0uWLOH0008/5Eyivf2u3333XaqqqtB1ndzcXObNm0dubi7bt29n8+bN9PX1YbFYmDlzJrNnzyYvL29cZif5fD5WrVpFTU0Nubm5rFixgtTUD36mSikqKyt55pln0HWd5cuXM3fu3GNuppQQQoiPL10pLt2ym5d7vZzgtvPQzCJybJZxP+5ALM6bfT7W9wwG2LWBMAAes5FTkt1kWc0MxOIMxOL0Rwev+/bej8UZ7bsLowYnJjpZlpLIspQEShyHtyDeuwN+/qe+gzVd/TiMBi7PTuEreelkjmB2rjcWpykUoSUcpTkUGV7I8P1AiPpghL3zlDUGQ9/BthpWpjpslDis1PhDPNDYye5gmHybhS/npbEyy4NzjBaUHivVviD3N3bwRHsvCjg/LYlr8tKY5XIc9QC+Pxrjt42d/L6pk1Bc55JMDzcXZZJns6ArRePQrPfBxSRDw7d7Yx98U85hNHB6sptrctNYlOQc8/O9zkgUs6aRYDJiOEbOJSP6B+F2qsUk/bGFEEIcUyTMljB7VF579K9sePJxvvzAn3EmJQ8//vfqvxPTY1xedrkEhPtQStHS8ij1DX8gGKzHaHSRkfFJsrM+Q0LCCZPmZ9XW1sYjjzyC3+/nwgsvPKy2G36/ny1btrBp0ya6u7uHHy8qKmLOnDlMnz4di2X832wrpdi2bRurV68mGo2ydOlSFi5cSCgUYtWqVVRVVZGXl8eFF16Ix+MZ93qEEEKIsXRPXRs/2dPG57NSeLKjF6vBwO/LCzg5eWy/YRTWdTb1B3i118urvV7e8waIq8FevQuTXJya7Oa0ZBdlLvtHBnm6Uvjj+gfhdjRO7DDebxg0mOmykzQGs6mrfUHuaxgMbE2axsosD5/PTiEQ12keCqybQhGah4Lr5nDkgLYaFk1jisO6X2hd6rQxxX7oWcpxpXiuq5/7GzrYOBAg2WTkypxUrspNJc1y+G3WYLDf9O5gGM/QrN8jsXf2+m8aOljX48VhNHBZlodrctPIt498PZDx0hmJcl99B39q6UJXUOqwsicYJrjPrPcUs4lSh5WpTtvwf5NSh41sq3nSnGMLIYQQYvQkzJYw+4gpXefBr19DclY2n77lRxNdzqQXjnRRXf1durvXkZgwh5ycy0hPX47ReOAigxNpx44d/N///R9Wq5WVK1eSk5NzROMopaivr6e9vZ1p06aRlJQ0xpWOjNfrZdWqVezYsYOcnBz6+/sJBAIsXbqUxYsXH7IFiRBCCDFZvdbr5ZLNu7gwI5n7ZuTzfiDMF7ftYU8wzA+Kc/hSbuqow7v2cJS797TyZHsfQV3HAMxJcHBqsptTk13MTzx4S49jTX0wzG8aOni0tYfIf7z38ZiN5FgtZNvM5Fgt5Ngs5FjN5Nos5NjMpFvMGEfxc97Q5+P+xg6e6xrAatC4JNPDV/LSmeI4dHjsj8ep8oXY5guyzRug0hdkhz9EeCjUzbCYKHfZqRjqwVzhtpNvsxzyg4aYrni6s4/fNnSw1RckzWLiSzlpXJ6TQvIYtWAZSy2hCL9u6KAhGN5vQclSp23MWsYIIYQQYnKTMFvC7CPWVLOdf9z+Hc756k2UnbZ0osuZ1Lq61lFV/R3icS8lxd8lN3fyzVhXSvHGG2/wwgsvkJWVxec+9zkSEo6PRWCUUmzdupU1a9aQkJDARRddRGZm5kSXJYQQQhy2jnCUT2zcQZLJyLPzpg4vGOeNxfladT3Pdg1wcUYyP5uWh+MIegKH4jq/b+rkV/XtRHTFZzM9nJmSwKIkJ4nHcVi4t/d3msU0HGAfrfYf7wdCPNDQyePtPUR0xTmpiVyfn06h3co2X4Bt3uBgeO0LsisQHm7VkmwyMtNtZ6bLTpnLTm80RqUvyDZvkJ2B0HBfZLfRQLnLPrxthdtBjtXM4229/K6pg6ZQlBKHlevy0rk4Y+L6rwshhBBCjISE2RJmH7G1D/6G7etf4rrf/w2LbXLNLp4s4vEgte/fTXPz33C5plNedg8u19SJLusAsViMVatWsXnzZsrKylixYsVRaQVytEUiEUwmk8zGFkIIcUyKK8VnNu/ivQE/q+dNZYZr//MvXSnurW/nZ3vaKHfZeWhm4YhbRCilWNXZzw93tdAYirA8NYHbi3Mo+pBZwmJsdUai/LGpiz81d9G3T89ngFybmZkuOzNdDiqGQukPa58RiuvU+ENs9wWHAu4A230hgvr+rVJOSnRyfX46y1ISjpl+z0IIIYT4ePuwMPv4nXohRi0ei7Ljzdcomb9QguxD8Hq3s237TQQC75OfdzXFxTdjMEy+N4R+v59//OMfNDQ0cPrpp3P66acft2Hv8RjQCyGE+Pj4+Z423ujz8avp+QcE2QAGTeOmwkwqXHa+Wl3P8k07eaCskNM8H95Hu9Ib4LbaZt7q9zPDaePxE4o59SP2EWMvzWLmu1Oy+FpBOv/X1os/rlPhtlPush92yw+b0cDsBAezExzDj8WVYk8wzDbv4AzvJR438xKdY/0yhBBCCCEmjITZ4pD2bH6XkM/LjFOXTHQpk45SOg0ND7Jr9y+xmD3Mmf0XPJ6TJ7qsAyil2LlzJ6tXr8bv93PxxRdTUVEx0WUJIYQQ4iBe6h7gnvp2Ppfl4bNZH75w8bLURJ6dN40vbtvDyi27uKU4m+vz0g6YxdsZiXLX7lYeae0h2Wzkp1NzuTQrBZNBZuhOJKfRyOU5qWM+rlHTKHHYKHHYxnxsIYQQQojJQMJscUjVr67DnpBIQcWciS5lUgmFWqiq+ha9fW+RlnY2M6bfidmcPNFlHaC1tZXnn3+ePXv2kJKSwpVXXklubu5ElyWEEEKIg2gORbihup4ZTht3lo7s7/UUh5XVc0u5saaBH+1qYYs3wD3T83AajYR1nd83DvbFDuk61+alcVNBxnHdE1sIi+k0OQAAIABJREFUIYQQQhz/5GxWHFQ44GfXprepWHo2RpP8M9mrvf0ZanbcilIxZky/m6ysT0+6RR4HBgZYt24d7733Hna7nXPOOYf58+djPEoLHAkhhBDi8ER1xVe21xPWFX+YWXhYizo6TUb+UF7IfQ0d3LW7lZ3+ENfmpvGr+nbqQxHOSkng9pJsimWmrhBCCCGEOA5ISikOqvbtN4hHo5SdesZElzIpxGI+du68g9a2f5GQcALlZb/E4Sic6LL2E4lEeOONN3j99deJx+MsWrSI0047Dbtd+p0LIYQQk9mPd7fwzoCfB8oKjqg9hKZpfK0ggwq3na9sr+emHY1Mc9r4xwnFnC59sYUQQgghxHFEwmxxUNWvrSMpM4vMkqkTXcqEi8W8vPfe5Qx4t1FYeANFhTdgMJgnuqxhuq6zdetWXnzxRbxeLzNmzGDZsmV4PB/ea1MIIYQQo6crxdruAfJsloMu2PhRnu3s57eNnVyZk8qKjNG1LVviSeCFBdN4d8DPealJ0hdbCCGEEEIcdyTMFgfw9nTRsL2SRRevnHQtNI62WMzLe5u/iNdXxayK35KWduZEl7Sfuro6nnvuOVpbW8nOzubTn/40BQUFE12WEEII8bHQHYlxQ3U963q8AMxxO7g028OK9GTcpo9u71UfDHNjTQOz3HbuKMkek5rybBbybJYxGUsIIYQQQojJRsJscYCa19eDUsw4ZclElzKhYjE/m7dcjde7lZkz/2dcg+xwOIzX6z2s7V999VVqampISEjgoosuYubMmRgMI++xKYQQQogjt6HPx5er6umJxvjv0hx0pXi4tYdv7Wji+7UtfCo9kUuzUjgp0XnQyQFhXefa7XUoFH8oL8Qqf8OFEEIIIcQYiUajNDU1EQqFJrqUD2Wz2cjNzcVsHnkHBAmzxQGqX11HVsk0krNyJrqUCROPB9iy9UsMDGymvPxe0tPOHrdjNTY28sgjjxAIBA5rP7PZzNKlS1m4cCEWi8zAEkIIIY4GXSnub+jgrj2t5NksrJpbSoXbAcA1uWm8NxDg4dYenuzo5bG2XortVlZmefhspod06wcn6Xe838IWb5CHZhZSYLdO1MsRQgghhBDHoaamJtxuN4WFhZO264JSiu7ubpqamigqKhrxfhJmi/10NdTRWb+HM6788kSXMmHi8SBbtl5LX99Gyst+QUb6ueN2rMrKSp588kkSEhI466yzRjyzWtM0CgsLcbtlUSchhBDiaOmJxvh6dQNruwf4ZFoiv5yeT8I+7UQ0TWNuopO5iU7uKM3m6Y4+Hmnt4c7drdy9p5UzUxK4NCsFf1znoeYuvpybxrlpSRP4ioQQQgghxPEoFApN6iAbBs+dU1JS6OzsPKz9JMwW+6l+7WU0g4Hpi0+d6FImRDweZuvWr9Db+xZlZT8nM/P8cTmOUor169ezbt068vPz+exnP4vT6RyXYwkhhBBi9Db1+7l2ex2dkRh3luZwVU7qh745cBqNrMxKYWVWCu8HQjzS2sNjbT081zUAwLwEB7cUZx2t8oUQQgghxMfMZA6y9zqSGqU5nximdJ3q116hcNYcHIkfv1lCuh6msvIr9PS+xozpd5OVuWJcjhOLxXjiiSdYt24ds2bN4vLLL5cgWwghhJiklFL8rrGDC96rxahpPDW3lKtz0w7rxLvEYeO24mzeXVTOn2YWcUV2Cn8oL8QifbKFEEIIIcRx7Nlnn2XatGmUlJRw9913j8mYMjNbDGuuqcLb3cmpl14x0aUcdboeobLyBrp71jN92p1kZ396XI4TCAR49NFHaWho4IwzzuC00047Jj4pE0IIIQ5FKUVcQUQporo+dK2IKkVEV8SUIqIUMV3t99zw9dBtq0HjxEQn2bbJsw5EXzTGN2oaeLZrgHNTE7lneh6J5iM/fTYbNJanJbI8LXEMqxRCCCGEEGLyicfjfPWrX+WFF14gNzeXBQsWcP7551NWVjaqcSXMPo69+X+PsPHpJ0a8fTwWxWy1UTJ/4ThWNfnoepRt275OV/dLTJv6Q3JyVo7Lcbq6unj44Yfp7+/n4osvpqKiYlyOI4QQQoy1PYEwN1TX0xGJEdUVEaUPXQ8G1moMj1Vot7A4ycXJSS4WJ7vIsk5MuP3eQIBrt9fRGo7ww5JsrjnM2dhCCCGEEEJ8nG3YsIGSkhKmTJkCwMqVK/n3v/8tYbY4tIwpJcw8Y9lh7ZMzbQZmm22cKpp8dD3G9u3/RWfXC0wt/T65uZeNy3Hq6up49NFHMRgMXHHFFeTn54/LcYQQQoix1heN8YXK3XRHYpyZmoBF0zAbDEPX2vC1WdOwGj54zqRpWIYe3/u8xTD0+NBjpn0e64/FeavPxxt9Pp7p7Ofh1h4AiuwWTk5yszjZxeIkF5lW8xG9DjU0QzwQ1/HH9eFrfzxOYJ/7gbhOSzjCg01dpFtMPDWnlLmJ0g5MCCGEEEIcm+54ejtVLQNjOmZZdgK3f6r8Q7dpbm4mLy9v+H5ubi5vv/32qI8tYfZxbMqcBUyZs2Ciy5i0dD1GVdXNdHSuobTkFvLyxqe9ynvvvcfTTz+Nx+Ph0ksvxePxjMtxhBBCiLEW1RXXbq+jPhjhsdnFLEpyjevxZrkdXJuXTlwpqnxB3hgKt5/q7OVvrd0ATLFbWZzkotRpJbhfKK0T0HX8saGAWtf/I7iOEzuMKeTnpCbyy+l5JI+irYgQQgghhBBibMnZufhYiseD1NTcQnvHKkqKv0N+/lVjfgxd11m3bh2vvvoqRUVFXHLJJdjt9jE/jhBCCDEelFLcWtvE+l4f90zPG/cge19GTaPC7aDC7eDLQ+H2dl+QN3o/CLcHWnUATBo4jUacRgNOowHH0CXdYh6+7zQacBgMg9uZBm879tneaTTud99hNGCVxRmFEEIIIcRx4KNmUI+XnJwcGhsbh+83NTWRk5Mz6nElzBbHvVjMi9dbjde3Ha93G17vdvz+XYBO8ZSbKSi4dsyPGY1GeeKJJ6iqqmLu3Lmcd955GI3GMT+OEEIIMV7+2NzFn1u6uT4vnc9lpUxoLUZNY5bbwSy3g6/kD4bbA7E4TqMBi4TOQgghhBBCTDoLFiygtraWPXv2kJOTw6OPPsrDDz886nElzBbHlUikB6+vCq/3g+A6GKwfft5qycDtLic9bTlJSQvweE4e8xp2797NmjVr6OzsZNmyZSxevFgWjBJCCHFMeal7gO/XNnN2agK3FGdNdDkHMGqatP8QQgghhBBiEjOZTNx3332cffbZxONxrrrqKsrLRz9LXN4FiGOe11dDW9sTdHQ8SyjUNPy4zZaH211OVtbFuN3luF3lWK1p41ZHb28vzz33HDU1NSQlJXHppZcyderUcTueEEIIMR52+EN8eXsdM1w27p9RgFE+kBVCCCGEEEIcgXPPPZdzzz13TMeUMFsck8LhTtrbn6K17Ql8vmo0zUxKymnk5n4et6sct7sMsznpqNQSiUR47bXXeP311zEYDCxdupRFixZhNpuPyvGFEEKIsdIVifGFrbuxGw38pWIKTpO0yBJCCCGEEEJMHhJmi2NGPB6ks/MF2tqeoLvnNUAnIeEEpk79ARnp52GxeI5qPUoptm3bxgsvvMDAwAAVFRWceeaZJCYmHtU6hBBCiLEQ1nWu3raHjkiUf80pIcdmmeiShBBCCCGEEGI/ExJma5q2HPgVYAQeVErd/R/PFwAPAWlAD/B5pVSTpmmzgd8CCUAcuFMp9Y+jWrw4qpTS6et7h9a2J+joWEM87sNmzaaw4CtkZl6I0zllQupqbW1lzZo1NDQ0kJWVxac//Wny8/MnpBYhhBBitJRSfGtHI2/3+3mgrIC5Cc6JLkkIIYQQQgghDnDUw2xN04zAb4BlQBPwjqZpTymlqvbZ7OfAX5RSf9Y0bSlwF/AFIABcrpSq1TQtG9ikadpzSqm+o/wyxDjT9Qh19b+jtfVxQqFmjEYn6ennkJV5IUlJJ6Jphgmpy+/38+KLL/Luu+/icDj41Kc+xZw5czAYJqYeIYQQYq+GYBiDppF7BDOq72vo4LG2Xr5ZmMmKjORxqE4IIYQQQgghRm8iZmafCLyvlNoNoGnao8AFwL5hdhlw09DtdcCTAEqpnXs3UEq1aJrWweDsbQmzjyPRaB9bK6+nr+9tPJ5TKZ7yTdLSlmE02iespng8zjvvvMO6deuIRqMsXLiQ008/Hbt94moSQgghAHqiMX6yu5W/tnSjAzOcNpalJLAsNZG5CY6PXMBxTWcfP97dyor0JG4uzDg6RQshhBBCCCHEEZiIMDsHaNznfhNw0n9sswW4iMFWJBcCbk3TUpRS3Xs30DTtRMAC7BrfcsWhdHW/jNHoJDlpwZiNGQjUsWXrlwgGmykvu4fMzPPHbOwjEYlEePfdd3nzzTfp7++nuLiY5cuXk5aWNqF1CSGEEDFd8dfWbn6yuxVvPM6VOank2yw83z3Abxo7+HVDBx6zkU+kJLAsJZElHjcJ/7GgY6U3wPVVDcxJcHDP9Hy0jwi+hRBCCCGEEGIiTdYFIL8J3Kdp2pXAeqCZwR7ZAGialgX8FbhCKaUfbABN064FrgWkl/EY0/UYu3b9lIbGPwKQm3s5JcXfHvXM6b6+jWyt/AoAc+f8laSk+aOu9Uj5/X42bNjAhg0bCAaD5OXlcd5551FaWipv9IUQ4hgSV4qYUiPe3oCG2TD5f8+/0evj1tomqvwhTk5y8d+lOcxwDf4d/kp+Ov3RGOt6vKztHmBt1wCPt/Vi0mBhootlqYPhtsNo4PLKPXjMRv40swi7UVpmCSGEEEIIIcbOVVddxapVq0hPT2fbtm1jMqamDuMN3pgcUNMWAT9QSp09dP97AEqpuw6xvQuoUUrlDt1PAF4GfqyU+udIjjl//ny1cePGMaheRCLdbNt+I729b5Kb+wU0zURj4//icBRRNuPnJCbOPqJx29qeoqr6O9hs2cw+4Y84HIVjW/gI9fb28uabb/Luu+8Si8WYNm0aJ598snwgIoQQx6DVnX3cWN2AN37Qz70PyW00kGoxkWYxk2YxkWI2kTZ0P3Xf2xYTbqPhqH7I2RyK8MNdLfy7o48cq5kflOTwybTED60hpis2Dfh5oXuAF7oH2OEPAWA3GNA0eHpuKeUuaZslhBBCCCHE8aK6upoZM2ZMdBmsX78el8vF5Zdffsgw+2C1apq2SSl10FmuEzEz+x2gVNO0IgZnXK8ELt13A03TUoGeoVnX3wMeGnrcAjzB4OKQIwqyxdgZ8G6jcut1RKJdlM34KVlZFwOQmrKU6urvsHHTZygsvI6iwhswGEa2+JRSirq637B7zz0kJZ3IrIr7MZuP/sJTbW1tvP7662zbtg1N05g1axaLFy8mPT39qNcihBBidJRS/L6pkx+838Jst4Nz0hJHvG9MKXqiMTojMboiMWr9Yd6M+uiJxg+6vVnTcBkNOIwGXCYjTqNh+OIyGnEM3zfiMhpIsZiY7rRR6rBhO4yZ0KG4zm8bO/h1fQcKxc2FGXw1PwPHCMYwGTROSnJxUpKLW4uzqQ+GWds9wKu9Xi7PTpUgWwghhBBCCDEuTjvtNOrq6sZ0zKMeZiulYpqm3QA8BxiBh5RS2zVN+yGwUSn1FLAEuEvTNMVgm5GvDu1+CXAakDLUggTgSqXU5qP5Gj6OWlv/Rc2OWzGbPcyb+w8SEmYNP+fxLOakk1azc+ePqKv7Dd1dL1NW9nNcrqkfOqauR6ipuYXWtn+RmbGCGTN+jMFgHe+XMmwwSK/jtddeY9euXVgsFhYuXMjChQtJTBx58CGEEGLyiCvFbbXNPNTcxXlpidw3o2BM2mfEdEV3NEZXNEZnJDocdvdEY/jiOv54HH9cxx/T8cd1uiMR/HEdX1wnEI8T1Pf/JpxRgyl2K9Oddma4bMxw2ihz2cmzWTDsM8taKcWzXf3c/n4LDaEI56UlcntxNvn2I/97WWC3cnVuGlfnyvoPQgghhBBCHPfWfBfaKsd2zMwKOOfusR1zhCakZ7ZSajWw+j8e+/4+t/8JHDDzWin1N+Bv416gGKbrUWrf/zFNTX8hKekkKmb+DxZLygHbmUxuysp+SlramVTX3MI7Gy9gypSbyc/7IppmPGD7aLSPrZXX09f3NkVF36Co8Iaj9jXtYDBIdXU1GzdupKWlBYfDwdKlS1mwYAF2u8xOE0KIw6UrRbU/xJt9Pt7o9dEbi5FttZBtNZNlNZNjG7ydbbXgMRvH7fe9Px7nuu31PN89wHV5adxWnL1fMDwaJoNGhtVMhtUMHP7firhSBOI6reEo1f4gNb4Q1f4gW70Bnu7sG97OYTQw3TkYbk932nmxe4CXe71Mddh4/IRiTvW4x+T1CCGEEEIIIcSxaLIuACkmgXCki23bvkZf3wby8q6ipPg7GAwf/k8mLe0sEhPnUlNzK++/fxddnWspK/sZdnve8DaBQD1btn6JYLCJsrJfkJW5YrxfCtFolJ07d1JZWUltbS3xeByPx8N5553H7NmzMZvN416DEEIcL+JKUeULDobXfT7e6vPTFxtsw5Fvs5BpNfN2v4+2cJTYfyzNYTNoZA0F23uD7lOSXJyS7BpVyN0ejvKFyt1s8wa5a2ouX8xJHc1LHHNGTcNtMuI2GZnqtHHBPl2s/LE4O/whqv2DAXe1L8Sarn7+3tpDgsnAf5fmcEV26jGxMKUQQgghhBBikpmgGdTjRcJscVD9A1uorLyeaLSP8rJfkpl5wYj3tVhSqaj4LW1tT7Bj5x28veE8SktvITvrEvr7N7G18jqU0pkz5y8kJy0Yt9cQj8fZs2cPlZWVVFdXE4lEcLlcLFiwgIqKCrKzs4/qol1CCHGsiivFNl+QN3sHw+u3+/30D4XXhXYL56QlsjjJxaIkF7m2D9ZM0JWiMxKjORyhNRylJRTd7/abfT7aIlF+Vd/OHLeD/yrMYFlKwmH/bq7xB7lsy256Y3H+VFHEWanHVqsop8nI3EQncxOdw4+poZ/d3l7cQgghhBBCCCEkzBYH0dLyGDU7bsdqTWP+vMdwu8sPewxN08jKuojk5IVUVX+bmpr/R1vrEwx4t2C1ZjH7hD/icBSNee1KKZqamqisrGTbtm0EAgGsVivl5eVUVFRQWFiIwTD63qlCCHG8iug6tYEw233BwYs3yFZfgIGYDkCR3cIn0xJZNBRe59gOveCvQdu3NcfBhXWdx9p6+J/6Di6v3EOZ08bXCzL4VHoSxhGE2q/2eLlq2x4cRgNPzilhlttx+C96EtI0jfQP+bkJIYQQQgghxGT3uc99jpdffpmuri5yc3O54447uPrqq0c1pqaU+uitjnHz589XGzdunOgyjjpdD6PrsRFvr1ScXbt/RnPzw3iST6a8/F4sFs+o61BKp6npr7y/6ye43RWcMOsBzObkUY+7r2AwyBtvvEFlZSV9fX2YTCamTp1KRUUFpaWlmEzyuY0QQvyn3mjsg9B66LLTHyY6dG5gM2hMc9qY5XYMhddOsqyHDq9HI6Yrnujo5df17dQGwhTbrXytIJ2LMzyHbK/xaGs339zRSInDxt9mTdlvVrgQQgghhBBCfFxVV1czY8aMiS5jRA5Wq6Zpm5RS8w+2vSR8x7E9e+6jrv7+w94vP/8aiqd88yP7Y4+UphnIy7uCzMwVmEyugy4IORo1NTWsWrUKv9/PlClTWLJkCdOnT8dms43pcYQQxy9dKRSMaCbwsSyi6zzV0ce/O/rY7gvSEo4OP5duMVHusnOGJ4Fyl51yl50pdiumo9Sn2WTQ+Eymh4syklnd2c+99W18o6aRn9e1cUN+BiszPdiMg9+sUUrx0z1t3FPfzmnJLh6cWUSCtOIQQgghhBBCiOOehNnHsZSU0zGZEw5rH5drBimeU8alHrN5bHuYBgIB1qxZQ2VlJRkZGVx22WVkZWWN6TGEEMe/mK64onIP73n9XJubxlW5acddMNoZifLn5m7+0tJFRyRGgc3CoiQXZS47M112ylw20iyTo6WFUdP4VHoSn0xLZG33AL+qb+e7O5u4p66Nr+SlszLLw221zfyzvZfPZXn46dQ8WRhRCCGEEEIIIT4mJMw+jiUlzScp6aAz8o95VVVVPPPMMwSDQZYsWcIpp5wirUSEEEfkR7tbeLFngDluB3fvaeP+xg6uzknjS7lppFiO7d8rW7wBHmzq5N/tfUSU4hOeBL6Um8rpHjeGST4LXdM0lqUmcmZKAq/3+bi3rp07drXw37tbiCv4blEmNxZkyEK+QgghhBBCCPExcmy/SxcfOz6fj9WrV1NVVUVWVhZf+MIXyMzMnOiyhBDHqEdbu/ldYydX56Ry59RctnoD/Kq+nXvq2/ldUydXZKdwXV76UVuIT1eKJzv6+H1jJ8lmIxUuO7PcDircdvJtlhEFtzFdsbqrnwebOtnQ78dpNPD57BSuzk2l2HHstV/SNI1Tkt2ckuxmY7+fPzZ1cnZqIisyxnbtBSGEEEIIIYQQk5+E2eKYoJRi+/btrF69mnA4zNKlSzn55JMxGo+vVgBCiKNnY7+fb+9o4pQkFz8oyQFgltvBH2cWUeMP8j/1HfyusZOHmru4NCuFr+anj+sCg6/2ePnRrha2+oJMc9qIRnTub/QSG1qnOclkpMI9FG677JzgdlBgtwzPsO6Jxvh7Szf/29xFSzhKgc3CD0uyWZmVcty0TZmf6GR+onOiyxBCCCGEEEIIMUEkzBaTns/n45lnnqG6upqcnBwuuOAC0tPTJ7osIcQxrCUU4apte8iymvn9zMIDei5Pd9r5TVkB3yzM5L6Gdv7W0s1fW7q4JNPD1/IzKHJYx6yWKl+QH+1qYV2Pl1ybmftm5HNRRjIGTSMU16n2h6j0BtjqDbLVF+APjZ1E1GDCnWAyMNPlIM1i4vmufoK64pQkF3dNzeXMlITjfkFLIYQQQgghhBAfLxJmi0lLKUVlZSVr1qwhEolw5plnsmjRIpmNLYQYlWBc58pte/DHdR6bXYzHfOg/hUUOK7+Yns9/FWZyf0MHf2/t5tHWHlZkJHNFdgpzEhxYDIYjqqMpFOGne1p5vK2XRJOR24uz+WJOKjbjB+PZjAbmJDiYk+AYfiyi6+zwh6j0BtniDVDpC/Jar4+LMzxcnZvKDJf9iOoRQgghhBBCCCHGSmNjI5dffjnt7e1omsa1117LjTfeOOpxJcwWR008HicQCBCJRIhEIoTD4eHbB7vf2dlJXV0dubm5XHDBBaSlpU30SxBCHOOUUty8o5FKb5A/VRQx3Tmy4DfXZuHHU3O5sSCDBxo7+HNLN/9q78Vu0Jif6GRRkotFSS7mJjiwfkS43ReN8T8NHTzY1AnAdXnpfL0gnaQPCdX3ZTEYqHA7qHA7uJSUEe0jhBBCCCGEEEIcTSaTiV/84hfMnTsXr9fLvHnzWLZsGWVlZaMbd4zqE+JDNTc388gjj+Dz+T5yW6PRiMViwWazcdZZZ7Fw4UIMRzjzUQgh9nVfQwf/au/le0VZnJ2aeNj7Z1jN3F6SwzcKMni9z8cbfT7e7PPxsz1tKMBq0JiX4GRR0mDAPS/BiX1opnUorvO/zV38qr6d/licT2cm852irHHtwy2EEEIIIYQQQkyErKwssrKyAHC73cyYMYPm5mYJs8XkV1tby2OPPYbT6eTcc8/FarVisViGr/de9t6XNiJCiH21hCL8u6OPKn+Qy7JSWJjkOqJxnu/q58e7W7kgPYmvF4yu736i2cS5aUmcm5YEDM62frvfPxhu9/q4p66dX9CORdOYm+BgdoKDVZ19NIWinOFxc2txNuXSDkQIIYQQQgghxDj7yYafUNNTM6ZjTvdM5zsnfmfE29fV1fHee+9x0kknjfrYEmaLcbV582aeeuop0tPTueyyy3C73RNdkhBiHOhK0RuNk2w2YhiDRQe7IzFWdfbxRHsvb/f7Ufx/9u48Pq663v/4+5uZJJNM9j1Nmm6ULnSjzW0BURZtAUGhgCCyVJaLetUrVxEU9CKIwFUuWFFR8YdsQpVasSBbKSCLt9RudC/dSJs0+75NZvv+/pihhNIlbSY50/T1fDzmkTNn+c7nhJ4e+s43nyN5XQl6uqZZp2en66bRRZqe4e3zeO91+vQfGys0KS1F948vk4nxgxGzEt06Ky9z72zvtmBI77R06P9aOvV/LR16qLJeE70pum9qmT6Vw9+DAAAAAIBjQ0dHhy666CL9/Oc/V0ZGRr/HI8zGgLDW6q233tLSpUs1atQoXXrppfJ4PE6XBeAIhKxVvT+oPT1+VfcEtMcX2Ltc3RPQnp6AanoCClirNFeCpqWn7n1o4fQMr4qSE/v0OR3BkF5oaNVfa5v1RnO7glYam5qsm0YV6YKCbBUmJ+rRqgY9sKtWn125VWflZejmUcWaeIgZzi2BoOat2yFPQoIemTxKqa6Bb1uU4XZpdl6mZkfDbX84rERjYh6iAwAAAABwMIczgzrWAoGALrroIl1++eW68MILYzImYTZiLhwO68UXX9Ty5cs1efJknX/++XK7+aOGY4+1Vrt9fg33JDkWYvaEw1rT1qV3Wjv1Tkun6v2BPh9rJTUFgqrxBxSyH93mSTAqTk5UcXKSZmV6VZycqLwkt3Z2+7WqrVMP7q5TMHpMcXJipNVGeqqmZ6Rqanqq0tyRdkK+UFivNrVpUW2zXmlsky9sVepJ1FeHF2huYbYmej0f+d59raxAVw7L1e8r6/Xr3XU6819bdH5Blm4cWaSx3o//wCwYtvrKhgpV+gL6y7QxKnGoP3USff8BAAAAAMcQa62uvfZaTZgwQd/+9rdjNi4JI2IqEAjor3/9qzZu3KiTTz5Zs2fP5uGNOGbds7NG8ytqNTY1WZcW5egLRTkq7OMs5SPVHgzpX62d0fC6Q6vbu9QTjqTKY1OTNSIlWYcTq09I82hYclI0uE7UsOREDfMkKdvtOmhA7wuFtb6jW6vburSqrVOnj8WfAAAgAElEQVSr27v09/pWSZKRNM7r0ciUJL3d3KH2UFh5iW59qThXcwuzVZ6RetCx09wu3TCySF8uydNvdtfrd5X1erauRRcXZes7I4s0IiV57753bN+jfzS3677xwzXzCHttAwAAAACAw/P222/r8ccf1+TJkzVt2jRJ0l133aXPfvaz/RrXWGsPvddRrry83K5YscLpMoa87u5uLViwQBUVFZozZ45OOeUUp0sCHPNkdaO+vXm35uRmqCUY0vLWTrmMdEZOhi4rztHs3IyYzNat9we0rKVT77R26J2WTm3o6FZYkstIk9NSNSvLq5MyvZqZmabcJGd/ftkUCGp1W9fegHt7V49OykrT3MIsnZqVLnfCkc1eb/AH9ctdtXqkqkFBa/Wl4lzdMKJQ/2hu139t3q3rSvN059jSGJ8NAAAAAADxadOmTZowYYLTZfTJ/mo1xqy01pbvb3/CbMREW1ubnnjiCTU0NOiCCy7QlClTnC4JcMwbTe360trt+mR2uh6fPFruBKPtXT79qbpJf65pVo0/oJxEly4uzNEXi3MO2fNZivx6Tq0/qHXtXVrX0a317d1a19Gt3T6/JCklwWh6hjcaXqdpRkaqvNFWHseK6h6/5lfU6Y97GpVgpLCVTs7y6skpY444KAcAAAAA4GhDmH2UI8weWPX19Xr88cfl8/l06aWXasyYMU6XBDhmc2e3Prdyq0o9SVo8fazS9wmUg2GrfzS366nqRr3U0KaAtZqSlqIvFudobmG2shPdstaqwufXuvZure/o1tr2Lq3v6Fa9P7h3nNEpyZqUnqKp6ak6KdOryekp9GWO2tXdo/srarWzq0d/mDxK2Yl01AIAAAAAHDuGcpjNv/DRL7t27dKTTz4pl8ulq6++WsXFxU6XBDimriegK9buUKorQU9MGf2xIFuS3AlGn87N0KdzM9QUCGpRbbMWVDfplq1V+tG2PZqUnqJtXT61BcOR/Y10fKpHZ+ZkaHJ6iialpeiEtJT9jo2IspRk3T++zOkyAAAAAABAjBFm44ht2bJFTz/9tDIyMnTllVcqOzvb6ZIAx3SFwrpq3U41+kN6ZvpxKvEkHfKYnES3rivN13Wl+Vrf3qUFNU1a396tuQXZmpyeqklpKRrv9cjjYsY1AAAAAAAAYTaOSH19vZ5++mkVFBTo8ssvl9frdbokwDEha/WNjRV6t71Lj0wepanpqYc9xqT0VN15BMcBAAAAAAAcKwizcdiCwaAWLlyopKQkXXbZZQTZOObdsX2Pnm9o1Z1jS3RWXqbT5QAAAAAAAAxJ/O46Dtsrr7yi2tpanX/++UpPT3e6HMBRf6hq0G931+vakjxdV5rvdDkAAAAAAACO8/l8mjlzpqZOnaoTTjhBt912W0zGZWY2DsvWrVu1bNkyzZw5U+PGjXO6HMBRrzS26db3KjUnN0N3jC1xuhwAAAAAAIC4kJycrFdffVVpaWkKBAI69dRTdc455+ikk07q17jMzEafdXR06JlnnlFBQYFmz57tdDmAo9a3d+krG97XCWkpenDiCLmMcbokAAAAAACAuGCMUVpamiQpEAgoEAjIxCA7YWY2+iQcDuuZZ55RT0+P5s2bp8TERKdLAhyzx+fXlet2KtPt0uNTRsvrdjldEgAAAAAAwMfU3HWXejZtjumYyRPGq+iWWw65XygU0owZM7Rt2zZ9/etf16xZs/r92YTZ6JN33nlH27Zt07nnnquCggKnywFiwhcKa0ljm4LWKjfRrdwkt3IT3cpJdCkpYf+/uNIRDOmqdTvVHgxp8fSxKkrmBzsAAAAAAAD7crlcWrNmjVpaWjR37lytX79ekyZN6teYhNk4pOrqai1ZskTjxo1TeXm50+UA/VbTE9AjVQ16bE+DmgKh/e6T4U6IBNyJbuX0CrpXtXVpU2e3npg8WhPTUga5cgAAAAAAgL7rywzqgZaVlaUzzjhDL774ImE2Bpbf79fChQvl9Xr1+c9/Pia9bQAnWGu1qq1LD1XW67n6FoWsdFZehq4pyVdhcqIa/UE1BYJq/ODl/3C50ufXu+1dagwEZWR0z/GlOiM3w+lTAgAAAAAAiEv19fVKTExUVlaWuru7tWTJEt188839HpcwGwf14osvqrGxUVdddZW8Xq/T5QCHzR8O69m6Fj1U2aA17V3KcCfo2tJ8XVOSpxEpyR/u2Ic/3tZa+a1V8gFakAAAAAAAACDS6WHevHkKhUIKh8O65JJLdN555/V7XMJsHNCGDRu0atUqfeITn9Do0aOdLgc4LPX+gB6ratSjexpU5w/quNRk3X18qS4pzD7iBzYaY5TMbycAAAAAAAAc1JQpU7R69eqYj0uYjf1qbW3Vs88+q2HDhunMM890uhwcozZ3duv2bXu0saNb6W6X0lwupbkSlO52yRv9mu5KUJr7w/WehAS93Niqv9W2yG+tzsxJ17+X5uu0nHQlEEQDAAAAAAActQiz8THhcFiLFi1SOBzWRRddJJfryGaxAkeqNRDUve/X6OGqBqW7XDorL1O+cFjtwZA6QmFVdPeoPRRWRzCk9lBIQfvR472uBF0xLFfXluZpTKrHmZMAAAAAAABATBFm42PefPNNVVRU6IILLlBubq7T5eAYErZWC2qa9JPt1WoKBHXlsFzdPKpYuUkH/qvKWquesFV7KKSOYFgdoZBGpiQr/QhbiQAAAAAAACA+EWbjI3bv3q3XX39dkyZN0tSpU50uB8eQVW2duuW9Kq1p79K/ZXj11NTRmpKeesjjjDHyuIw8rgTlJw1CoQAAAAAAAHAEYTb28vl8+stf/qLMzEydd955MvQXxiCo9wf0k+3VWlDTpIIktx6YUKaLC7P58wcAAAAAAICPIMwewl599VW99dZbfd7f2kjj4WuuuUYeD32GMbACYas/VNXrZztr5Atb/cfwAn17ZKHSaA8CAAAAAACA/SDMHsJGjBixN6Duq7KyMg0fPnyAKgIi3mpu161bq7Sl06czctL147ElOo4HNQIAAAAAAAwpoVBI5eXlKikp0XPPPdfv8Qizh7AxY8ZozJgxTpcByFqrjZ0+LWlo1ZLGNq1s61KZJ0mPTBqls/IyaCkCAAAAAAAwBM2fP18TJkxQW1tbTMYjzAYwILpCYb3V3K5XGtv0SmOb9vQEJElT01P0wzHDdE1JnlJcCQ5XCQAAAAAAgIFQWVmpv//977r11lt13333xWRMwmwAMbPb59crjW1a0tCqf7Z0yBe28roSdHpOum7MzdBncjJUkJzodJkAAAAAAADHhDf//J4adnfEdMy84Wn65CXHH3K/G264QT/96U/V3t4es88mzAZwRKy1qu4JaH1Ht5a3duqVxjZt7vRJkkamJOnKYbmanZupWVleJScwAxsAAAAAAOBY8dxzz6mgoEAzZszQ66+/HrNxCbMBHFIwbLW9u0cbOrq1rr1LGzq6tb6jW02BkCTJbaRZmWn60Zhh+kxehsakJNMHGwAAAAAAwGF9mUE9EN5++20tXrxYzz//vHw+n9ra2nTFFVfoiSee6Ne4hNkAPsJaqzXt3Vrb3qX1Hd1a396tzZ3d6g5bSVKSMRqf5tHZeZmalJaiSWkpOiEtRV63y+HKAQAAAAAAEA/uvvtu3X333ZKk119/Xffee2+/g2yJMBtAlD8c1qLaZj24u15bou1CMt0uTUpL0VXD8jQpPRJcH5fqUWICs64BAAAAAAAwuAizgWNcWzCkx6oa9PvKBtX4A5rg9ejn44frE9npKk1OpF0IAAAAAAAAjtjpp5+u008/PSZjEWYDx6g9Pr8eqqzX43sa1REK65PZabp//HCdnpNOgA0AAAAAAIC4Q5gNHGM2dXTr17vr9NfaZllJn8vP0n+UFWhKeqrTpQEAAAAAAAAHRJgNHAOstXq7pUO/2lWn15ralZKQoC+X5On60nyVpSQ7XR4AAAAAAABwSITZwBDUEw7rvU6f1nV0a317t5a1dGhjp095iW59b1SR5pXkKTuRyx8AAAAAAABHD9Is4CjXHgxpQ0e31nd0a117t9Z3dOm9zh4FrJUkeV0JmpSWop+NK9UXCnPkcSU4XDEAAAAAAABw+AizAYdZa/W3uhZt6fT1+ZiwpO1dPq3v6Nb73f696/MS3ZqcnqIzczJ0QlqKJqenaFRKshJ4oCMAAAAAAACOcoTZgIPe7+7Rdzbv1tstHZKkw4mcyzxJmpSeokuLcjQpLUWT01NVmOSWIbgGAAAAAACAw0aOHKn09HS5XC653W6tWLGi32MSZgMOCFmr31fW654d1XIbo3vHDdflxTkE0QAAAAAAABgyXnvtNeXl5cVsPMJsYJBt6fTp25t3aWVbl2bnZuh/ji/VME+S02UBAAAAAAAAcY0wGxgk/nBYv9xVp5+/X6s0d4J+PXGE5hZkMRsbAAAAAAAAA+K1R36nuoodMR2zYMRonfHl6w+5nzFGc+bMkTFGX/nKV3T99Yc+5lAIs4FBsKatS9/evEsbO326oCBLd44tVV4Slx8AAAAAAACGprfeekslJSWqq6vT7NmzNX78eH3qU5/q15ikacAA6g6Fde/7NXpwV50KkhL16ORROisv0+myAAAAAAAAcAzoywzqgVJSUiJJKigo0Ny5c7V8+fJ+h9kJsSgMwMcta+nQp/+1Rb/aVafLinP0j5njCLIBAAAAAAAw5HV2dqq9vX3v8ssvv6xJkyb1e1xHwmxjzNnGmC3GmG3GmO/tZ/sIY8xSY8xaY8zrxpjSXtvmGWO2Rl/zBrdy4NB6wmH9cGulLli9TUFr9fTUMfrf8WXKTOQXIQAAAAAAADD01dbW6tRTT9XUqVM1c+ZMnXvuuTr77LP7Pe6gp2vGGJekX0maLalS0r+MMYuttRt77XavpMestY8aY86UdLekK40xOZJuk1QuyUpaGT22eXDPAti/Xd09un5Dhda0d+makjzdOqZYXpfL6bIAAAAAAACAQTN69Gi9++67MR/XiZnZMyVts9busNb6JS2QdP4++0yU9Gp0+bVe28+StMRa2xQNsJdI6n+kD8TASw2tmr3iPe3o9unhSSN11/GlBNkAAAAAAABAjDgRZpdI2t3rfWV0XW/vSrowujxXUroxJrePxwKDKhC2un1bleat26kRniQtKR+nz+ZnOV0WAAAAAAAAMKTE6wMgb5R0mjFmtaTTJFVJCh3OAMaY640xK4wxK+rr6weiRkB7fH5duHqbHtxdry+X5Gnx9LEakZLsdFkAAAAAAADAkOPEE+mqJA3v9b40um4va+0eRWdmG2PSJF1krW0xxlRJOn2fY1/f34dYa38n6XeSVF5ebmNUO7DXq41t+samCvWErX4zcYQuKMx2uiQAAAAAAABgyHJiZva/JI01xowyxiRJ+qKkxb13MMbkGWM+qO37kh6OLr8kaY4xJtsYky1pTnQdMGiCYat7dlTrS2t3qDApUS+VH0+QDQAAAAAAAAywQZ+Zba0NGmO+oUgI7ZL0sLV2gzHmDkkrrLWLFZl9fbcxxkp6Q9LXo8c2GWN+rEggLkl3WGubBvsccOyq7Qnoqxvf1/+1dOpLxTm6c2ypUl3x2q0HAAAAAAAAGDqcaDMia+3zkp7fZ91/91peKGnhAY59WB/O1AYGzVvN7frqhgp1hsL6xYQyXVKU43RJAAAAAAAAQFxqaWnRddddp/Xr18sYo4cfflgnn3xyv8Z0JMwGjiZ7fH49sKtOj1Q16LjUZC08cYzGe1OcLgsAAAAAAACIW9/61rd09tlna+HChfL7/erq6ur3mITZwAHs9vn1QEWtFlQ3KSyrK4fl6rYxw+R1u5wuDQAAAAAAAIhbra2teuONN/TII49IkpKSkpSUlNTvcQmzgX1UdPfoFxW1+lNNk4yMLivO0TfKClSWkux0aQAAAAAAAECftTy7Xf49nTEdM2mYV1mfG3PQfXbu3Kn8/HxdffXVevfddzVjxgzNnz9fXq+3X5/Nk+uAqO1dPv3npgqd8s4mLaxt1lXD8rTspAn66bjhBNkAAAAAAABAHwWDQa1atUpf+9rXtHr1anm9Xt1zzz39HpeZ2Tjmben0aX5FrZ6pbVZygtG1Jfn6j7ICFSUnOl0aAAAAAAAAcMQONYN6oJSWlqq0tFSzZs2SJF188cWE2UB/bOro1v0VtXq2rkWehAR9dXiBvlaWr/wkQmwAAAAAAADgSBUVFWn48OHasmWLxo0bp6VLl2rixIn9HpcwG8ecSp9fd++o1l9qm5XmStA3ywp0/fAC5SVxOQAAAAAAAACx8MADD+jyyy+X3+/X6NGj9Yc//KHfY5Le4ZjREQzpl7vq9JvddZKk/ywr0NfKCpSdyGUAAAAAAAAAxNK0adO0YsWKmI5JiochL2St/lTdpHt2VqvOH9SFhdm6ZXSxSj1JTpcGAAAAAAAAoI8IszGkvdnUrtu2VWljp0//luHVI5NGaXqm1+myAAAAAAAAABwmwmwMSVs7fbpj+x4taWzTcE+SfnfCSH0uP1PGGKdLAwAAAAAAAHAECLMRt3rCYSXIKDGh7wF0UyCo/91Zo0f3NCglIUE/GF2s60rz5XElDGClAAAAAAAAAAYaYTbiTlcorAcqavXr3XXqCVulJCQo0+1Shtv14dfEfd67XWr0B/Xr3XVqD4Z05bBc3TiqSPlJiU6fDgAAAAAAAIAYIMxG3LDW6oWGVv33tipV+gK6oCBL47wetQZDaguG9n6tDwS0vdu3d13IfjjGmTnp+u/jhmm8N8W5EwEAAAAAAAAQc4TZiAvbu3z6wdYqvdbUrglej/564gidnJV2yOOsteoKhdUWCikQtipLSR6EagEAAAAAAAAcyJYtW3TppZfufb9jxw7dcccduuGGG/o1LmE2HNUZCmn++7V6cHe9PAlGPz6uRFeX5Mndxz7Zxhh53S553a4BrhQAAAAAAABAX4wbN05r1qyRJIVCIZWUlGju3Ln9HpcwG46w1uq5+lb9aFuVqnoC+kJRtn44epgKkulxDQAAAAAAAAwVS5cu1ZgxYzRixIh+j0WYjUG3tdOnW7dW6o3mDk30evTriSM0qw8tRQAAAAAAAAD03QsvvKCampqYjllUVKRzzjmnz/svWLBAl112WUw+mzAbg6YzGNJ9FbX63e56pbiM7hxboi8P63tLEQAAAAAAAABHD7/fr8WLF+vuu++OyXiE2RgwbcGQVrV1akVrl1a2dWplW6fagmFdWpSjH4wpVn4SLUUAAAAAAACAgXI4M6gHwgsvvKDp06ersLAwJuMRZiMmwtZqe1ePVrR1amVrl/7V1qn3On2ykoyk470efS4/S5cV56o80+t0uQAAAAAAAAAG2FNPPRWzFiMSYTb6YXuXT3+ra9GK1k6tautSSzAkScp0uzQ9I1Wfy89SeWaqpmd4leF2OVwtAAAAAAAAgMHS2dmpJUuW6Le//W3MxiTMxhFpD4b0+VXb1BQI6nivR+fmZ2pGplflGV4dl5qsBEMfbAAAAAAAAOBY5fV61djYGNMxCbNxRH69q06NgaCenz5W02kbAgAAAAAAAGCAJThdAI4+dT0B/WZ3vc4vyCLIBgAAAAAAADAoCLNx2O59v0YBG9b3RhU7XQoAAAAAAACAYwRhNg7L9i6f/ljdqCuH5WlUarLT5QAAAAAAAAA4RhBm47DcvaNanoQEfXtkodOlAAAAAAAAADiGEGajz1a1duq5+lZ9bXiB8pMSnS4HAAAAAAAAwDGEMBt9Yq3VHdv3KC/Rra8Oz3e6HAAAAAAAAABx7P7779cJJ5ygSZMm6bLLLpPP5+v3mITZ6JOlTe1a1tqp74wqUprb5XQ5AAAAAAAAAOJUVVWVfvGLX2jFihVav369QqGQFixY0O9xCbNxSCFrdef2PRqVkqQrinOdLgcAAAAAAABAnAsGg+ru7lYwGFRXV5eGDRvW7zHdMagLQ9zCmmZt7vTptyeMUGKCcbocAAAAAAAAAH3w3ns/VnvHppiOmZ42Qccf/8OD7lNSUqIbb7xRZWVlSklJ0Zw5czRnzpx+fzYzs3FQvlBYP91ZrWnpqfp8fpbT5QAAAAAAAACIc83Nzfrb3/6mnTt3as+ePers7NQTTzzR73GZmY2DeriqQVU9Ac2fUCZjmJUNAAAAAAAAHC0ONYN6oLzyyisaNWqU8vPzJUkXXnih/vnPf+qKK67o17jMzMYBtQSC+kVFrc7ISdep2elOlwMAAAAAAADgKFBWVqZly5apq6tL1lotXbpUEyZM6Pe4hNk4oF/uqlNrMKQfjOl/c3YAAAAAAAAAx4ZZs2bp4osv1vTp0zV58mSFw2Fdf/31/R6XNiPYryqfX7+vrNdFhdk6IS3F6XIAAAAAAAAAHEVuv/123X777TEdk5nZ2K97369R2Eo3jSpyuhQAAAAAAAAAIMzGx23u7Nafqpt0dWmeylKSnS4HAAAAAAAAAAiz8XF3ba+W15Wgb40odLoUAAAAAAAAAJBEmI19LGvp0MuNbfrmiELlJNJSHQAAAAAAAEB8IMzGXtZa3bl9j4qSEnVdab7T5QAAAAAAAADAXky9HcJWtXbq3Y7uPu9f6fNrRVuX/nfccKW6+DkHAAAAAAAAgPhBmD2EvdzYpp9X1B7WMSemp+rSopwBqggAAAAAAADAsWD+/Pl66KGHZK3Vv//7v+uGG27o95iE2UPYN8sKdG1p3mEdk+12y51gBqgiAAAAAAAAAEPd+vXr9dBDD2n58uVKSkrS2WefrfPOO0/HHXdcv8YlzB7CvG6XvHI5XQYAAAAAAACAY8imTZs0a9YspaamSpJOO+00LVq0SDfddFO/xiXMBgAAAAAAAIAh6IdbK7X+MJ6p1xeT0lL047GlB99n0iTdeuutamxsVEpKip5//nmVl5f3+7MJswEAAAAAAAAAMTNhwgTdfPPNmjNnjrxer6ZNmyaXq/8dJAizAQAAAAAAAGAIOtQM6oF07bXX6tprr5Uk3XLLLSot7X8thNkAAAAAAAAAgJiqq6tTQUGBdu3apUWLFmnZsmX9HpMwGwAAAAAAAAAQUxdddJEaGxuVmJioX/3qV8rKyur3mITZAAAAAAAAAICYevPNN2M+ZkLMRwQAAAAAAAAAIMYIswEAAAAAAAAAcY8wGwAAAAAAAAAQ9wizAQAAAAAAAGAIsdY6XcIhHUmNhNkAAAAAAAAAMER4PB41NjbGdaBtrVVjY6M8Hs9hHeceoHoAAAAAAAAAAIOstLRUlZWVqq+vd7qUg/J4PCotLT2sYwizAQAAAAAAAGCISExM1KhRo5wuY0DQZgQAAAAAAAAAEPcIswEAAAAAAAAAcY8wGwAAAAAAAAAQ90w8P9UyVowx9ZIqnK7DIXmSGpwuAkCfcc0CRxeuWeDowjULHF24ZoGjC9csYmWEtTZ/fxuOiTD7WGaMWWGtLXe6DgB9wzULHF24ZoGjC9cscHThmgWOLlyzGAy0GQEAAAAAAAAAxD3CbAAAAAAAAABA3CPMHvp+53QBAA4L1yxwdOGaBY4uXLPA0YVrFji6cM1iwNEzGwAAAAAAAAAQ95iZDQAAAAAAAACIe4TZQ5gx5mxjzBZjzDZjzPecrgfARxljhhtjXjPGbDTGbDDGfCu6PscYs8QYszX6NdvpWgF8yBjjMsasNsY8F30/yhjzTvR++ydjTJLTNQKIMMZkGWMWGmM2G2M2GWNO5j4LxC9jzH9F/794vTHmKWOMh/ssED+MMQ8bY+qMMet7rdvvfdVE/CJ67a41xkx3rnIMJYTZQ5QxxiXpV5LOkTRR0mXGmInOVgVgH0FJ37HWTpR0kqSvR6/T70laaq0dK2lp9D2A+PEtSZt6vf8fSfdba4+T1CzpWkeqArA/8yW9aK0dL2mqItcu91kgDhljSiT9p6Rya+0kSS5JXxT3WSCePCLp7H3WHei+eo6ksdHX9ZIeHKQaMcQRZg9dMyVts9busNb6JS2QdL7DNQHoxVpbba1dFV1uV+Qf2CWKXKuPRnd7VNIFzlQIYF/GmFJJ50r6ffS9kXSmpIXRXbhmgThhjMmU9ClJ/0+SrLV+a22LuM8C8cwtKcUY45aUKqla3GeBuGGtfUNS0z6rD3RfPV/SYzZimaQsY0zx4FSKoYwwe+gqkbS71/vK6DoAccgYM1LSiZLekVRora2ObqqRVOhQWQA+7ueSbpIUjr7PldRirQ1G33O/BeLHKEn1kv4QbQ30e2OMV9xngbhkra2SdK+kXYqE2K2SVor7LBDvDnRfJZfCgCDMBgCHGWPSJP1F0g3W2rbe26y1VpJ1pDAAH2GMOU9SnbV2pdO1AOgTt6Tpkh601p4oqVP7tBThPgvEj2if3fMV+UHUMElefbydAYA4xn0Vg4Ewe+iqkjS81/vS6DoAccQYk6hIkP1Ha+2i6OraD379Kvq1zqn6AHzEJyR93hjzviLtu85UpB9vVvTXoSXut0A8qZRUaa19J/p+oSLhNvdZID59RtJOa229tTYgaZEi917us0B8O9B9lVwKA4Iwe+j6l6Sx0Sc/Jyny4IzFDtcEoJdor93/J2mTtfa+XpsWS5oXXZ4n6W+DXRuAj7PWft9aW2qtHanIffVVa+3lkl6TdHF0N65ZIE5Ya2sk7TbGjIuu+rSkjeI+C8SrXZJOMsakRv8/+YNrlvssEN8OdF9dLOkqE3GSpNZe7UiAI2YivwGAocgY81lFenu6JD1srf2JwyUB6MUYc6qkNyWt04f9d29RpG/2nyWVSaqQdIm1dt+HbABwkDHmdEk3WmvPM8aMVmSmdo6k1ZKusNb2OFkfgAhjzDRFHtiaJGmHpKsVmdDDfRaIQ8aY2yVdKimoyD31OkV67HKfBeKAMeYpSadLypNUK+k2Sc9oP/fV6A+lfqlIu6AuSVdba1c4UTeGFsJsAAAAAAAAAEDco80IAAAAAAAAACDuEWYDAAAAAAAAAOIeYTYAAAAAAAAAIO4RZnmyJOwAACAASURBVAMAAAAAAAAA4h5hNgAAAAAAAAAg7hFmAwAAADFkjLnbGHOGMeYCY8z3D7DPj4wxN0aXv2yMGRbDzz/dGHNKr/dfNcZcFavxAQAAAKcQZgMAAACxNUvSMkmnSXqjD/t/WdJhhdnGGPdBNp8uaW+Yba39jbX2scMZHwAAAIhHxlrrdA0AAADAUc8Y8zNJZ0kaJWm7pDGSdkpaaK29Y599fySpQ9L7kh6RVCWpW9LJkiZKuk9SmqQGSV+21lYbY16XtEbSqZKekvSepB9ISpLUKOlySSmKBOkhSfWSvinp05I6rLX3GmOmSfqNpNRojddYa5ujY78j6QxJWZKutda+aYw5QdIfop+RIOkia+3WGH3LAAAAgMPCzGwAAAAgBqy135V0rSLh9L9JWmutnbJvkL3PMQslrZB0ubV2mqSgpAckXWytnSHpYUk/6XVIkrW23Fr7v5LeknSStfZESQsk3WStfV+RsPp+a+00a+2b+3zkY5JuttZOkbRO0m29trmttTMl3dBr/VclzY/WVi6p8rC+KQAAAEAMHezXEwEAAAAcnumS3pU0XtKmIzh+nKRJkpYYYyTJJam61/Y/9VoulfQnY0yxIjOndx5sYGNMpqQsa+0/oqselfR0r10WRb+ulDQyuvx/km41xpRKWsSsbAAAADiJMBsAAADop2j7jkcUCZgbFGnjYYwxaySdbK3t7utQkjZYa08+wPbOXssPSLrPWrvYGHO6pB8dQem99US/hhT9d4K19kljzDuSzpX0vDHmK9baV/v5OQAAAMARoc0IAAAA0E/W2jXRVhzvKdLz+lVJZ0VbfRwqyG6XlB5d3iIp3xhzsiQZYxKjfav3J1ORXtuSNO8A4/WusVVSszHmk9FVV0r6x7779WaMGS1ph7X2F5L+JmnKIc4FAAAAGDCE2QAAAEAMGGPyJTVba8OSxltrN/bx0Eck/SY6i9sl6WJJ/2OMeVeRBz6ecoDjfiTpaWPMSkVmg3/gWUlzjTFregXXH5gn6WfGmLWSpkk6YD/vqEskrY/WNkmRntsAAACAI4y11ukaAAAAAAAAAAA4KGZmAwAAAAAAAADiHmE2AAAAAAAAACDuEWYDAAAAAAAAAOIeYTYAAAAAAAAAIO4RZgMAAAAAAAAA4h5hNgAAAAAAAAAg7hFmAwAAAAAAAADiHmE2AAAAAAAAACDuEWYDAAAAAAAAAOIeYTYAAAAAAAAAIO4RZgMAAAAAAAAA4h5hNgAAAAAAAAAg7hFmAwAAAAAAAADiHmE2AAAAAAAAACDuEWYDAAAAAAAAAOIeYTYAAAAAAAAAIO4RZgMAAAAAAAAA4h5hNgAAAAAAAAAg7hFmAwAAAAAAAADiHmE2AAAAAAAAACDuEWYDAAAAAAAAAOIeYTYAAAAAAAAAIO4RZgMAAAAAAAAA4h5hNgAAAAAAAAAg7hFmAwAAAAAAAADiHmE2AAAAAAAAACDuEWYDAAAAAAAAAOIeYTYAAAAAAAAAIO4RZgMAAAAAAAAA4h5hNgAAAAAAAAAg7hFmAwAAAAAAAADiHmE2AAAAAAAAACDuEWYDAAAAAAAAAOIeYTYAAAAAAAAAIO4RZgMAAAAAAAAA4h5hNgAAAAAAAAAg7hFmAwAAAAAAAADiHmE2AAAAAAAAACDuEWYDAAAAAAAAAOIeYTYAAAAAAAAAIO4RZgMAAAAAAAAA4h5hNgAAAAAAAAAg7hFmAwAAAAAAAADiHmE2AAAAAAAAACDuEWYDAAAAAAAAAOIeYTYAAAAAAAAAIO4RZgMAAAAAAAAA4h5hNgAAAAAAAAAg7hFmAwAAAAAAAADintvpAgZDXl6eHTlypNNlAAAAAAAAAAAOYuXKlQ3W2vz9bTsmwuyRI0dqxYoVTpcBAAAAAAAAADgIY0zFgbbRZgQAAAAAAAAAEPcIswEAAAAAAAAAcY8wGwAAAAAAAAAQ9wizAQAAAAAAAABxjzAbAAAAAAAAABD3BjTMNsacbYzZYozZZoz53n62jzDGLDXGrDXGvG6MKe21rcwY87IxZpMxZqMxZmR0/SPGmJ3GmDXR17SBPAcAAAAAAAAAgPMGLMw2xrgk/UrSOZImSrrMGDNxn93ulfSYtXaKpDsk3d1r22OSfmatnSBppqS6Xtu+a62dFn2tGahzAAAAAAAAAADEh4GcmT1T0jZr7Q5rrV/SAknn77PPREmvRpdf+2B7NPR2W2uXSJK1tsNa2zWAtQIAAAAAAAAA4thAhtklknb3el8ZXdfbu5IujC7PlZRujMmVdLykFmPMImPMamPMz6IzvT/wk2hrkvuNMckDdQIAAAAAAAAAgPjg9AMgb5R0mjFmtaTTJFVJCklyS/pkdPu/SRot6cvRY74vaXx0fY6km/c3sDHmemPMCmPMivr6+oE8BwAAAAAAAADAABvIMLtK0vBe70uj6/ay1u6x1l5orT1R0q3RdS2KzOJeE21REpT0jKTp0e3VNqJH0h8UaWfyMdba31lry6215fn5+bE+NwAAAAAAAADAIBrIMPtfksYaY0YZY5IkfVHS4t47GGPyjDEf1PB9SQ/3OjbLGPNBCn2mpI3RY4qjX42kCyStH8BzAAAAAAAAAADEgQELs6Mzqr8h6SVJmyT92Vq7wRhzhzHm89HdTpe0xRjznqRCST+JHhtSpMXIUmPMOklG0kPRY/4YXbdOUp6kOwfqHAAAAAAAAAAA8cFYa52uYcCVl5fbFStWOF0GAAAAAAAAAOAgjDErrbXl+9vm9AMgAQAAAAAAAAA4JLfTBQAAAAAAAACAU9p8AbV0Bpwu4yOKMj1KcjMPeV+E2QAAAAAAAACOOesqW/XIP9/Xs2v3yB8MO13ORyz5r09pbGG602XEHcJsAAAAAAAAAMcEfzCsF9ZX69F/vq9Vu1qUmuTSpeXDNXV4lozTxfVSkOFxuoS4RJgNAAAAAAAAYEira/Ppj+/s0pPLd6m+vUcjc1P13+dN1MXlpcrwJDpdHvqIMBsAAAAAAADAkGOt1apdLXr0n+/rhfXVCoSszhiXr3mnjNSnxuYrISGe5mKjLwizAQAAAAAAAAyqpk6/guGB6VNtrfTm1gY9+s/3ta6qVenJbl150khddfIIjczzDshnYnAQZgMAAAAAAAAYNPe+tEW/fG3bgH/O2II0/fiCSbrwxBJ5k4lBhwL+KwIAAAAAAAAYFM++u0e/fG2bzp1SrJNH5w7Y54zJT9NJo3NkDK1EhhLCbAAAAAAAAAADblN1m25auFblI7J1/yXTlOROcLokHGX4EwMAAAAAAABgQLV0+XX94yuUkeLWr6+YTpCNI8LMbAAAAAAAAAADJhS2+uZTq1Xb2qMFXzlJBekep0vCUYowGwAAAAAAAMCA+dlLW/Tm1gbdc+FkTS/LdrocHMWYzw8AAAAAAABgQDy3do9+84/tunxWmb44s8zpcnCUI8wGAAAAAAAAEHObqtv03acjD3y87XMnOF0OhgDCbAAAAAAAAAAx1dLl11ceX8kDHxFT9MwGAAAAAAAAEDMfPPCxptXHAx8RU4TZAAAAAAAAAGKGBz5ioDC/HwAAAAAAAEBM8MBHDCRmZgMAAAAAAABDQChs1dTpV0NHz95XfXuPGjr8aur0qyjDo8mlmZpckqniTI+MMTH9/M01kQc+zuCBjxgghNkAAAAAAABAjFlrJSnmgbEkhcNWf1y+S6sqmqNhdeTV1OlX2H58/yR3gnJSk1Tf0aNQdIdcb9LeYHtySaYml2aqKOPIA+6WLr+ufyzywMcHL+eBjxgYhNkAAAAAAABAPwRDYe1o6NTGPW3aWN2292uyO0H3XDRFpx2fH7PPau7067/+vEavb6nXsEyPCjI8Ks1O1YllWcpLS1ZeWrLy05Ojy0nKS09WerJbxhj5AiFtrG7T+qpWra1s1fqqVr25tWFvwJ2XlrQ33J44LFPeZFef6/rdGzs+fOBjBg98xMAgzAYAAAAAAAD6qKMnqM3VHw2tN9e0yx8MS5KSXAkaV5Su2RMKtXp3s+Y9vFzXfGKUbjp7nDyJfQ+H92dlRbO++eQqNXT49eMLJumKWWWHNZPak+jS9LLsjzyUsdv/YcC9rqpV6ypb9Y/36vc7w/tQeOAjBhphNgAAAAAAAKDIDOv6jh7VtvWots2391XT2qO6dp92N3Xp/cauvftnpyZq4rAMzTt5hCYOy9DE4kyNzvcq0RVpseELhHTPC5v18Ns79c/tDZr/xRM1rij9sOuy1ur/vbVT97ywWcVZHv3la6docmlmTM45JcmlGSOyNWPERwPurXUfBvR9kZWaqOMKDv/cgMNhPujfM5SVl5fbFStWOF0GAAAAAABAv9S392jB8l3qCoT6fIw7wSg/PVmFGR4VZXhUlOlRXlqyXAl9n9EbCIVV3eJTRVOndjV1RV6Nka9tvoASXQlKciUo0ZWgRJeJvHfv8z66PSs1UcWZHg3LStGwrBQVZ3qU400akN7S+2Ot1Y6GTq2saNa6ylZVt3artq1HNW0+NXT0aN+ozJ1gVJCerIIMj0qyUjS+KD0SXA/L6HOP6dc21+m7C99Vmy+oW84Zr3mnjOzz+bZ2B/Tdp9/VyxtrNWdioX72hanKTEk8klMHjgrGmJXW2vL9biPMBgAAAAAAiA1/MKyGjh7lpyfvnZ0bC+Gw1Z9X7NZdz29Smy+opMMYOxgOf6xlhCvBKD8tWYWZHhVlJKsowxNd9ijZ7dLu5o8G1lUt3Xv7KkuRBwoOz05RWU6qslKTFAiFoy+rQCgsf3Cf99Ht/mBYzV2Bj834TXYn7A24izNTNCzLo+LMFBVnRQLk4kyP0j1HFuB2+0NaW9milbuataqiWSsrmtXcFZAkpSe7VZKdsjfoL8xI3vt9KIy+cr1JSjiM4P9AGjp6dNPCtXp1c51OOz5f935hqvLTkw96zNrKFn39yVWqbvHp+5+doGs+0fcQHDhaEWYTZgMAAAAAgH7yBUKqafWputWnmrbuyNcP3rf6PjKztzQ7Rd/69FjNPbFE7n6G2tvqOnTLX9dp+c4mzRyVo7vmTtZxBWl9Pj4Utmrs7FFta2T2cU2bT7XReiMtNCLL7b7gR47L8SapLCdVZTmpGpGbquG9lgvTPUcc8Fpr1djp156Wbu1p8am6tTuy3OpTdUvk+1rb5vtYAJ+e7I6E3VnRWd2ZnmjwHQm/izIjQXxNq08ro6H1yl3N2lDVqmB0sNH5Xs0oy1b5yEhbjdF5aTEJqg/n3J9YVqE7/75Jaclu/ewLU3Tm+ML97vf4sgrd+dwm5aUl6ZeXT6cXNY4ZhNmE2QAAAAAA4DDtburSyxtrtWRjjTbXtKslOpu3twyPW8WZKSrK9Kg4MxKoZqUk6i+rqrSuqlWj87y6YfbxOm9y8WGHpj3BkB58fbt+/dp2eRITdOu5E/SFGcMHLHzt8gdV0+pTTzCs0uyUI54JHQvBUFi17T2qjobce1q6Vd3Srapo+F3d6lNTp/9jx6V73HtD+WR3gqYOz4r0gy7L1vQR2crxJg32qezX1tp2/eeCNdpU3aarTh6hWz47Ye/DIdt9AX1v0Tr9fW21zhiXr/sumabsOKkbGAyE2YTZAAAAAADgEKy12lLbrpfW1+qlDTXaWN0mSRpflK4ZI7I1LCtFRRkfhtZFmR6lJrkPONbLG2t138vvaUttu8YVpuvbc47XnImFfWoTsXxnk76/aK2213fq81OH6YfnTTxkS4pjTbc/tDfYrmrpVnWLT/UdPo3KS9OMEdmaWJyhJHfsWr3EWk8wpHtf2qKH3typ4wrSNP+L02Rk9PUnV6misVM3njVOX/3UmEGdOQ7EA8JswmwAAAAAABxlrY3LXr/hsNWqXc16aUONXt5Yq4rGLhkjTS/L1lknFGrOxCKNzPP2a/zn1lXr50ve046GTk0uydR35hyv047P3+/3o7UroHte3KSnlu9WSVaK7pw7SWeMK+jPKSLOvbm1Xt/587tq6QrIGCkzJVG/uOxEnTQ61+nSAEcQZhNmAwAAAAAw6EJhqze21uuPy3bptS11+sRxebr21FH61Ni8mAbb4bBVdZtPfc04rJW21Xfo5Q21WrKxVg0dPUp0GZ0yJk9nnVCkz0wsUEG6J2b1SZG2GX9dXaX5S7eqsrlb5SOy9Z0543TymNxoTVbPra3W7c9uVFNnj6775Gjd8JmxB5z5jaGlqdOv2xZvULc/pLsvnMwsfBzTCLMJswEAAAAAGDT17T3684rdemr5LlU2dysvLUmfHl+oV7fUqb69R2ML0nTNqaM098SSvX2Cj8SWmnYtWl2pxWv2qLrVd9jHe5NcOn18gc46oUhnjMsflB7R/mBYf16xW798dZtq2nz6xHG5uvqUUfrjOxV6bUu9Jpdk6u4LJ2tSSeaA1wIA8YgwmzAbAAAAAIABZa3Vsh1N+uM7FXppQ40CIauTR+fqipNGaPb/Z+++w7Mszz6Of+/sHUgYYYW9l2gEFRX3qKPuOmpr7bK7b6d2+Ha5Wu3eb6vVWrc42ipusW6mbBCQFRIIgeyd53r/IFpUDAESEuD7OY7neMZ9P9d93vyByY/T8xrTm6SEOOqbmvnXG0X89cW3WFJUQU56EpdNyefyIwbSK6ttndCbKup4dP5Gps8rZGlRBQlxEdNG9OS4Ub1I3o35yD0zkzlySO5ehel7o66xmbteW8fvn1/JlqoG0pLi+fopI/n4kQNJiO+6c54lqaMZZhtmS5IkSZLUIcprGnlg7gb+8dpaVpdUk52ayAWH9eeSyfkM65Wx0++8HXz/9cW3eGbZJhLiIs6a0Jcrjx68047k6vomZiwq5uH5hby0cguxAIcM6Ma5k/px5oQ+5GbsvyMZahqaeGbpZibld6N/97TOLkeSOp1htmG2JEmSJEnt6o31Zfz91bX8842N1DfFmJTfjcumDOTMCX12q9t5zZZq/vbyGu6bvZ6ahmamDM7hk0cP5riRvXhp1RYenlfIk4s3UdvYzICcVM49pB/nTOrHkJ47D8olSfs3w2zDbEmSJEmS2sXqkipumrGMJxZvIi0pnnMm9ePSyfl7PeO5vLaRe2et4/aX11JYVktSfBwNzTGyUxM5c0Ifzp3Uj8MGdm/XjSMlSV2PYbZhtiRJkiRJe6W0qp5fPfMmd722juSEOK6aNpQrpg5q900Tm5pjzFhczCurSjl2RE+OG9mT5ITOmWstSdr3WguzE/Z1MZIkSZIkaf9R19jMX198iz88v4raxmYuPnwAXz1pBD0zO2ZOdUJ8HGdO6MuZE/p2yPqSpP2XYbYkSZIkSXqfWCwwfV4htzy5nKLyOk4a3ZurTx/1gZs6SpLU0QyzJUmSJEnSu7z45hauf2wpS4oqmNA/m1985BCOGJLb2WVJkg5yhtmSJEmSJAmA5cWVXP/YUmauKKFft1R+dfEhnDWhL3FxbrooSep8htmSJEmSJB1EmppjbK6sp6i8juLyOorKaykur2NNaQ3PLttERnIC3/nQKD525CBSEt14UZLUdRhmS5IkSZJ0gKlrbOb1t7ayrLhih9B6+/Pmyjpi4d3npyTG0Sc7lSunDuYLxw+je3pS5xQuSVIrDLMlSZIkSQeNxuYYCXERUXTgjc0oKq/luWUlPLtsMy+t3EJtYzMA6Unx9OmWSp/sFIb36kGf7BTyslNbnlPok51CdmriAflnIkk6sBhmS5IkSZIOeAs3lHP7K2t49I2N9MxI5pSxvTl1bB4FA7uTEB/X2eXtkeZYYP76bTy7bDPPLithaVEFAP27p3JhQX+OH9WLQ/O7k52a2MmVSpLUPgyzJUmSJEkHpIamGI8vKuL2l9cwd10ZaUnxnDepH1uq6vnHa+u47aU1dE9L5KTRvTllbB7HDO/R4TOiQwiUVNXz5qYqlhdXsqmijrSkBNKT48lMSSAjOZGMlAQyklseO7yOj4soq2lg5ooSnlu2mZkrSthW00h8XMRhA7tz9emjOHFUL4b1yrDLWpJ0QDLMliRJkiQdUDZV1PGP19Zx12vr2FJVz+Ae6Vx75hguKOhPVsr2LuXq+iZeWFHCE4uLmbG4mPvnbCA1MZ5pI3py6rjenDCyN9lpe9fRXFbTwPLiSlZsrmJFcSUrNm1/bKtpfOecpPg4GppjbVovLSmeusZmYgFy0pM4fmQvjh/Vi2OH99zrWiVJ2h9EIYRdn7WfKygoCLNnz+7sMiRJkiRJHSSEwOy127j95TXMWFRMcwgcP7IXHztyIMcO70lc3Ad3Kjc2x3h1dSlPLt7Ek0uK2VRRT0JcxBFDcjlhVC+yUxNpjgWaYoHmWKzlOfz3ufm/n9c0NLNycxUrNlWyubL+nWtkJicwIi+TEb0zGNE7851Hj4wkmmOB6vpmqhqaqKproqq+kcq6Jqrq337/39dpyQkcN7InE/t3I76Ve5IkaX8VRdGcEELBTo8ZZkuSJEmSOlsIgbKaRgrLaqmubyIhPiIhLo74uKjldUR8XFzLc/TOM8DTSzdx+8trWVJUQWZKAhcVDODyIwYyqEf6btcRiwUWFJbzxOJinlhczOqS6jZ/NzE+IjkhniE901vC6v8G132yUxz9IUlSGxhmG2ZLkiRJ0k6FECivbSQ7NbFDw9a6xmaKy+vYWFZLYVktRTu83lhWy8ayOmobm/d4/ZG9M/nYUQM5d1I/0pLab6JmUXktjU2B+PjofUH6O2F7XNRq57ckSWq71sJsZ2ZLkiRJUhe2cnMVd7++jnH9sjjnkH7tGjiXVtXzvYcX8fiiYib2z+YTUwfzofF9SEqI2+u13x77ceera3lpZSlbqurfd07PzGT6dktlZF4mx4/sRZ9uqfTrlkJmSuJ/R3o0v2ekRyzQ1PzuUR9j+2YxZXBOh4TxfbJT231NSZK0Z+zMliRJkqQu6M1Nlfz62ZX8a8FGAEKAo4f14LpzxzEwd/fHZ7zXjEVFfPehRVTWNfGRwwfw0qotrC6ppldmMh87ciCXThlITnrSbq9bWdfIw/MKufPVdSzfVElmSgInj+nNoNx0+nZLpW+3FPp1SyUvO4XkhPi9vg9JknRgccyIYbYkSZKk/cTy4kp+/eybPLawiLTEeD521CA+efRgHl9YxE0zltMUi/HVk0bwyaMHkxi/+x3UZTUN/ODRxTw8fyNj+2bx84sOYWReJrFYYOabJdz20hpeWFFCckIc507qxyemDmZkXuYu111aVMGdr67l4XmFVDc0M65fFpcfMZCzJvZt17EfkiTpwNZpYXYURacBvwLigb+EEG58z/GBwK1AT2Ar8NEQwoaWY/nAX4ABQAA+FEJYE0XRYOAeIBeYA1weQmhorQ7DbEmSJEkdJYRARW0TURxkpSTu8TpLiyr49TNv8viiYjKSE/j4UQP51NFD6L5Dd3RReS3XPrKYp5ZsYnSfLG46fzwT+ndr8zWeXbaJqx9cyNbqBr54wjC+cPywnQbib26q5LaX1zB97gbqGmNMHZbLlVMHc/zIXu+aDV3X2Mzji4q489V1zFm7jeSEOM6a2JePHjGQif2z3fBQkiTttk4Js6MoigdWACcDG4BZwCUhhCU7nHM/8K8Qwu1RFJ0AfCKEcHnLseeB60IIT0VRlAHEQgg1URTdB0wPIdwTRdEfgTdCCH9orRbDbEmSJOnAEULg76+u5dfPrOSM8Xl87rhh5GWndNj1mppjFFfUsbHsvxsWvr1pYeG27c/VDds3LszPSWNcvyzG9s1mXL9sxvbNokdGcqvrL95Yzq+feZMnFm8iMzmBK6Zu78TulvbBIz5mLCri2kcWs6Wqnk9MHczXTh5BevIHdz9X1DXy438u4f45GxjZO5NbLprIuH7Zu7z3bdUN3D1rHXe8vJbiijoG5aZxxVGDOHJoD6bP28D9szewtbqBwT3SuWxKPhcc1r/VuiVJknals8LsI4EfhBBObXl/DUAI4YYdzlkMnBZCWB9t/yf78hBCVhRFY4A/hxCOfs+aEVAC5IUQmt57jQ9imC1JkiQdGMprG/n2AwuYsbiYUXmZrNxcRVxcxKWT87lq2tB2CbULy2q5b9Z6Xlq5hY1ltRRX1BF7z69NOelJ78x+7tstlX7dUqlvirFkYwWLNpaztrTmnXPzslLeFXCP65dFXlYKiwor+NUzb/L00k1kpiRw5dTBXDl1MNlpbevurqhr5KbHl/GP19bRr1sqPzlnHMeP6vW+8/7zZgnffmABxRV1XDVtKF85afhuz6pubI7x+KJi/vriW7yxvgyA+LiIk0f35qNHDOSoobnv6tiWJEnaU50VZl/A9qD6Uy3vLwemhBC+uMM5dwGvhRB+FUXRecCDQA/gGOBTQAMwGHgauBroDrwaQhjW8v0BwOMhhHGt1WKYLUmSJO3/5q3bxpfunkdxeR3fOm0knzp6CIVltfzuuZU8MGfDO6H2544bSu+s3Qu1G5tjPLN0M/fMWsfMFSUAHJrfnUG56fTrltKycWEq/bqn0jc7ldSk1sPg8tpGlmysYPHGchYVlrNoYwWrSqp4+9evbmmJlNU0kpWSwCePHsIVUweRnbpnI0pmrdnKNdMXsnJzFWdN7Mu1Z46hZ2Yy1fVNXP/YUv7x2jqG9EznlgsnMim/+x5dY0dz121j4YZyTh2b16Ed8ZIk6eDUlcPsvsBv2R5YvwCcD4wDTgL+CkwC1gH3Ao8Bj9DGMDuKos8AnwHIz88/bO3atR1yn5IkSdLBorq+iQBktDLOoiPEYoG/vvgWN81YRu+sFH5z6SQOfU8ou35rzR6F2mtLq7ln1noemLOBksp68rJSuKigPxcWDGBATlq73kd1fRPLiitYVFjBko0V5OemcfmRA/dqzvbb6pua+ePzq/ndcytJTYrn08cM5t7Z69mwrZZPHT2Yr58ykpTE3evGliRJ6gxddszIe87PAJaFEPpHUXQEcFMIYVrLscuBI4Av4pgRSZIkaZ8KIXDPrPVc/9hSGptjuXE28AAAIABJREFUnDupH5cfMYgxfbM6/Npbqxv4xv1v8OyyzZw6tjc/PX9iq2M42hJq1zc188TiTdzz+jpeXlVKfFzE8SN7ccnkAUwb0ZOEnWyIuL9YubmSa6YvZNaabQzMTePmCydy+KCczi5LkiSpzTorzE5g+waQJwKFbN8A8tIQwuIdzukBbA0hxKIoug5oDiFc27J55FzgpBBCSRRFtwGzQwi/a9k08sEdNoBcEEL4fWu1GGZLkiRJe2bNlmqunr6AV1dv5YghOeTnpPHI/I3UN8WYPCiHjx01kFPH5pHYAQHw629t5ct3z2NrdQPfO3M0lx8xkO3b6OzautKWUHvuBhLiIi6dks+ZE/rw+MJiHpy7gW01jfTvnspHCgZwYcGAA2pcRiwWePWtUg4Z0I20pH3bRS9JkrS3OiXMbrnwh4BfAvHArSGE66Io+hHbg+lHW0aR3AAEto8Z+UIIob7luycDtwARMAf4TAihIYqiIcA9QA4wD/jo29/5IIbZkiRJ0u5pao7x1xff4udPrSApPo7vnDGajxQMIC4uoqymgftnb+COV9ewfmstvTKTuWzKQC6ZMoBemXsfCjfHAr9/biW/eHoF+Tlp/PbSQxnXL3uP1tox1G6OBRLjI04e05uLD8/n6GE93LRQkiSpi+m0MLurMMyWJEmS2m7xxnKufnAhCwvLOXlMb3784XE77VxujgVmrtjM7S+vZeaKEhLjI04f14ePHzWQQ/O7t7mLekebK+v4n3vn89LKUs6e2JfrzxvfLjO615XWMGvNVqaN7EmPjOS9Xk+SJEkdwzDbMFuSJEnapbrGZn7z7Jv8ceZquqcl8sOzx/Gh8XltCqVXl1Rx56vruH/2eirrmxjbN4uPHzmIsf3aPld7/dYavvfwIqrqm/jh2WO5qGDAHgXikiRJ2n8ZZhtmS5IkSa16/a2tXD19AatLqrngsP5874zRdEtL2u11quubeHh+IXe8vJblmyp3+/vDe2Xwu8sOZUTvzN3+riRJkvZ/rYXZ7gYiSZIkHcQq6xq5acYy7nx1Hf27p3LHlZM5dkTPPV4vPTmBy6YM5NLJ+cxbX0ZJZavb27xLQlzEUUN7kJoUv8fXlyRJ0oHLMFuSJEk6SM1cUcLVDy6guKKOK6cO5uunjCC9HeZTA0RRxKH53dtlLUmSJAkMsyVJkqSDTmNzjJufWM6fXljN8F4ZPPi5owyeJUmS1OUZZkuSJEldWH1TM8kJ7Td2Y/3WGr58zzzmrSvjsin5fP/MMaQkOtZDkiRJXZ9htiRJktRFPTBnA99+cAEXHNqfr548nD7ZqXu13oxFRXzrgQWEAL+79FDOmNCnnSqVJEmSOp5htiRJktQFlVTW86N/LiYvK4WH5hXy0PxCrjhqEJ8/bijd0pJ2a626xmauf2wpd7yylon9s/nNJYeSn5vWQZVLkiRJHcMwW5IkSeqCrvv3Emobm5n++akkJ8Txi6dX8H//Wc3dr6/jqmlD+cTUQaQl7frH+dUlVXzxrnksKarg08cM5punjiIpIW4f3IEkSZLUvvwpVpIkSepiXnxzCw/P38jnpg1lWK8MBuSk8fOLDmHGV45lyuAcfvbEcqb97Hn+/upaGptjH7jO9LkbOPM3L1JUXsutVxTw3TPGGGRLkiRpvxWFEDq7hg5XUFAQZs+e3dllSJIkSbtU19jMab98AYAZXz12p5szzl6zlZtmLGPWmm0MzE3j66eM5MzxfYiLiwCoaWji2kcW88CcDUwelMOvLjlkr+dtS5IkSftCFEVzQggFOzvmmBFJkiSpC/ndcytZU1rDnZ+cstMgG6BgUA73ffZInl22mZ/OWM6X757Hn2au4lunjaJXZjJfvGsuq7dU8+UThvHlE4eTEG83tiRJkvZ/htmSJElSF7FycyV/nLmKcyf14+jhPVo9N4oiThzdm+NG9uKR+YX8/KkVfPzW14mLIDcjmX98cgpHDWt9DUmSJGl/YpgtSZIkdQEhBL7z0CLSkhL47hmj2/y9+LiI8w7tzxkT+nD3a+tYUlTBt04bRY+M5A6sVpIkSdr3DLMlSZKkLuD+ORt4/a2t3Hje+D0KopMT4rli6uAOqEySJEnqGhyeJ0mSJHWy0qp6rn9sKQUDu3NRwYDOLkeSJEnqkgyzJUmSpE523WNLqapr4vrzxhMXF3V2OZIkSVKXZJgtSZIkdaKXV21h+txCPjttCCN6Z3Z2OZIkSVKXZZgtSZIk7aGFG8r5wl1z+b8XVlPf1Lzb369rbOZ7Dy0iPyeNL50wvAMqlCRJkg4cbgApSZIk7aaq+iZueXI5t7+8hpTEeP69oIg7X1vLNaeP4tSxeURR20aF/OH5VazeUs3tV04mJTG+g6uWJEmS9m92ZkuSJEm74YnFxZz885n87eU1XDZlIK9ccyJ3XDmZ5IQ4rrpzLhf/+VUWFZbvcp1VJVX84flVnDWxL9NG9NwHlUuSJEn7NzuzJUmS1Ca1Dc1sqapna3UDpdX1bKlq2P66qp7SqgZKWz4vrWqgqq6J7LREcjOS6ZGeRG5GErkZyeSmJ9EjI3n7+/RkemQmkZOWREJ81++x2FhWy/8+upinlmxiVF4mv7vsUA7N7w7AsSN68tjQY7hn1np+8dQKzvrti5x/aH++eepIemelvG+tEALffWghyYlxfP/M0fv6ViRJkqT9kmG2JEmSWrWqpIrL//IaG8vrdno8JTFuezCdkUTPjGRG5WWRkZxARW0jW6obKK6oY9HGckqrGmiKhZ2uMaRHOjeeP4HJg3M68lb2SFNzjNtfWcstTy4nFgLXnD6KK48eTOJ7AviE+Dg+esRAzj6kL797diW3vbSGfy8o4qppQ/nMsUNITfrvGJHpcwt5dfVWrjt3HL0y3x92S5IkSXq/KISd/0JxICkoKAizZ8/u7DIkSZL2O7FY4CN/foUVm6r4zLFD6JmRTE5Lp/XbHdZpSW3rjwghUFHbxJaW7u3Sqnq2tHR2PzyvkHVba/jqSSP4wvHDiI9r28zpjrZwQznXPLSARYUVHDeyJz/+8DgG5KS16bvrSmu44fGlPL6omD7ZKXzrtJF8eGI/ymobOfGW5xncI50HrjqKuC5yr5IkSVJXEEXRnBBCwU6PGWZLkiTpg/z91bV8/+FF/OyCCVxYMKDDrlNV38T3HlrIw/M3cuSQXH558SE7Hc+xr+y4wWNuRjI/OGssHxrf9o0dd/Ta6lJ+8u+lLCwsZ2L/bHIzknlhRQn/+vLRjMrL6oDqJUmSpP2XYbZhtiRJ0m4rKq/l5J+/wCEDuvH3T07eoyB3d4QQeGDOBq59ZDFpSfHcfNFEjh/Zq0Ov+V7V9U08tWQTNz6+jE2VdXx0ykC+edpIslIS92rdWCwwfV4hP3tiGZsq6rlq2lCuPn1UO1UtSZIkHTgMsw2zJUmSdksIgU/dPpuXV5XyxFePJT+3baM12sPKzZV88a55LCuu5DPHDuEbp4wkKaHjNojcUlXPM0s38eTiTfxn5RYammKMysvk+vPGv7PBY3upaWhi5vISThjdi+SE+F1/QZIkSTrItBZmuwGkJEmS3uefC4p4ZtlmvnfG6H0aZAMM65XJw1+Yyk/+vYQ/v7Ca197aym8untSudazZUs1TSzbx5JJiZq/dRgjQr1sql03J55QxeUwenNMhc7vTkhI4fXyfdl9XkiRJOhjYmS1JkqR32VbdwEk/n0n/7qlM//zUTt2M8fGFRXzrwQUQ4MbzJ3DGhD0LgkMILCws58nF2wPsFZuqABjTJ4tTxvbmlDF5jO6T2eGjVCRJkiS1zs5sSZIktdmP/72E8tpG7vzUlE4NsgFOH9+Hcf2y+fI98/jCXXN5cWU+1545htSknY/oaGiKUVRey/qttWzYVsOGbbWs31bD629tpai8jrgIJg/O4dozx3DymN4MyNm3XeeSJEmS9pxhtiRJkt4xc0UJ0+cW8sXjhzG6T1ZnlwPAgJw07vvskdzy5Ar+OHMVc9Zu5eunjKSspoEN22pbHtuD6+KKOnb8Hw/j4yL6ZKcwvl82Xz9lJCeM6kVOelLn3YwkSZKkPeaYEUmSpANACGGvR2RU1zdxyi9eIDkxjse+fAwpiV1vg8KZK0r42r3zKa1uACAugj7ZqfTvnsqAnDT6d0+lf/e3n1PJy0ohIb7jNo+UJEmS1L4cMyJJknQAm7N2G/9z73wG5KRy84UT6ZOdukfr3PzkcgrLarn/qiO7ZJANMG1ET57+2jRWbKqkb7dU8rJTSDSsliRJkg4K/uQvSZK0n4rFAr9/fiUX/ekVmppjzFtXxmm//A+PLyza7bXmrtvG315ew+VHDOTwQTkdUG376Z6exJQhuQzISTPIliRJkg4idmZLkiS1o1gssKW6nqKyOjaW1bKxfPtzUXktaUkJfP64oQzpmbHX19lcWcfX7n2DF1du4Yzxfbj+vPFsrW7gq/fM43P/mMvFhw/g2rPGkJa06x/3GppiXP3gAvKyUvjWaSP3ujZJkiRJ6giG2ZIkSXtgW3UDMxYXU7ittiW0rmVjWR3F5XU0NMfedW5qYjx9u6VQVF7HQ/MKufjwAXzlxOH0ykrZo2vPXFHC1++bT2VdEzecN56LDx9AFEVkpybywOeO4hdPreAPM1fx+ltb+dXFkxjfP7vV9f7w/CpWbKrirx8vIDMlcY9qkiRJkqSO5gaQkiRJu+nJxcV856FFbKmqJz4uIi8rhT7ZKfTtltrySKFvdip9uqXQr1sq2amJRFFESWU9v3n2Te56bR2J8XF8+pjBfPrYIW0OkBubY9z85HL+NHM1I3pn8NtLD2VE78ydnvvKqlL+5975lFbX8/VTRvKZY4YQF/f+DSLf3FTJh379H04b14ffXDJpr/5cJEmSJGlvtbYBpGG2JElSG5XVNPDDfy7hoXmFjOmTxQ3njWds3ywSdnNu85ot1fzsyeX8e0EROelJfOmEYVw2ZSBJCR+8zvqtNXzp7nnMX1/GpVPy+f4ZY0hNan2TxrKaBq6ZvpDHFxUzdVgut1x4CHnZ/+0Gb44FLvzjy6zeUs3TX5tGj4zk3boPSZIkSWpvhtmG2ZIkaS89s3QT10xfyNbqBr5w/DC+cPywVsPntnhjfRk3Pr6MV1aXkp+TxtdPGcFZE/q+r4P6Xws2cs2DCyGCG8+bwBkT+rT5GiEE7pu9nh88uoTkxDhuOn8Cp47NA+BvL73FD/65hJ9fNJHzDu2/V/ciSZIkSe3BMNswW5Ik7aHy2kZ+9M8lPDh3A6PyMrn5womM69f6DOrdEUJg5ooSbnx8GcuKKxnXL4urTxvN0cN7UNvQzI/+tZi7X1/PpPxu/PriSQzISduj66wqqeIr98xjUWEFl07J58qpgzn7ty9y2MDu3HHlZKLo/SNIJEmSJGlfM8w2zJYkSXvgueWbuebBhZRU1fP544bypROG73U39geJxQIPzy/klidXUFhWyzHDe1BcXsfKkiqumjaUr508gsTdHGfyXg1NMW55avvM7YS4iKSEOJ746rF7HJBLkiRJUnszzDbMliRJu6GirpHr/rWUe2evZ0TvDG6+cCIT+nfbJ9eua2zmzlfX8tvnVpIQF8cvPjKRY4b3bNdrvLRyC//76GI+fcxgPnJ4fruuLUmSJEl7wzDbMFuSJLXRCytK+PaDC9hUUcdV04bylZOGk5zQ+kaLHaGmoYlYgIzkhH1+bUmSJEnqLK2F2f52JEmSDjgVdY0sL67kzU1VNDbH2vy9RYXl3D9nA8N6ZTD981M5ZMC+6cbembQkf0yTJEmSpB35W5IkSdpvNTXHWFNaw7LiCpYVVbKsuIKlRZUUltXu0XpxEXx22hD+56QRpCTu+25sSZIkSdIHM8yWJEn7jQUbypi1ZhvLiipYVlzJik2V1Ddt77yOj4sY2jOdwwZ257Ij8hmdl8Xw3hm71eGcnBBHumM9JEmSJKlL8rc1SZLU5W2pqucn/1rCw/M3AtAzM5lReZl8/KhBjOydyag+mQzrldEps60lSZIkSfuGYbYkSeqyYrHAfbPXc8Pjy6htaObLJw7nY0cOpEdGcmeXJkmSJEnaxwyzJUlSl7RiUyXfmb6Q2Wu3MWVwDtedO55hvTI6uyxJkiRJUicxzJYkSV1KXWMzv3n2Tf40czWZKQn87IIJXHBYf6Io6uzSJEmSJEmdyDBbkiS1m1gs0BwCifFxe/T9F1aU8L2HF7Fuaw0XHNaf73xoNDnpSe1cpSRJkiRpf2SYLUmS9tqGbTXcO2s9981eT2lVA0N7ZjC6Tyaj+2Qxpm8Wo/tktTrnuqSynp/8ewmPzN/IkB7p3PXpKRw1tMc+vANJkiRJUldnmC1JkvZIU3OMZ5Zt5u7X1zFzRQkAx43oyag+WSwvruS1t7by8PyN75zfMzOZ0X2yGN0nkzF9tgfcg3LTeWDOBm58fCl1jTG+etJwPnfcUJIT4jvrtiRJkiRJXVSHhtlRFJ0G/AqIB/4SQrjxPccHArcCPYGtwEdDCBtajjUDC1tOXRdCOLvl878B04DylmNXhBDmd+R9SJKk/3q7C/veWevZXFlP76xkvnT8MC46fAD9u6e969xt1Q0sLa5gycYKlhZVsrSogttWldLQHAMgLoJYgCOGbN/gcWhPN3iUJEmSJO1ch4XZURTFA78DTgY2ALOiKHo0hLBkh9NuBu4IIdweRdEJwA3A5S3HakMIh3zA8t8MITzQUbVLkqR3+6Au7J9MzueEUb1I+IAZ2d3TkzhqaI93jQxpbI6xqqSKpUUVLCuuZEyfLM6e2NcNHiVJkiRJrerIzuzJwMoQwmqAKIruAT4M7BhmjwG+1vL6OeDhDqxHkiTtppLKeu54ZU2burDbKjE+jlF5WYzKy2rfYiVJkiRJB7SODLP7Aet3eL8BmPKec94AzmP7KJJzgcwoinJDCKVAShRFs4Em4MYQwo5B93VRFF0LPANcHUKo76ibkCTpYBRC4KF5hfzwn0uoqGtsUxe2JEmSJEkdqbM3gPwG8Nsoiq4AXgAKgeaWYwNDCIVRFA0Bno2iaGEIYRVwDVAMJAF/Br4N/Oi9C0dR9BngMwD5+fkdfR+SJB0wisvr+O5DC3lm2WYm5XfjZxdMYFivzM4uS5IkSZJ0kOvIMLsQGLDD+/4tn70jhLCR7Z3ZRFGUAZwfQihrOVbY8rw6iqLngUnAqhBCUcvX66Mouo3tgfj7hBD+zPawm4KCgtBO9yRJUoepa2xmS1U9lXVNDO+Vsc87oEMI3D9nAz/+1xIam2N874zRfGLqYOLjnGUtSZIkSep8HRlmzwKGR1E0mO0h9sXApTueEEVRD2BrCCHG9o7rW1s+7w7UhBDqW86ZCvy05VifEEJRtH2XqHOARR14D5Kkg8Arq0p5fFERqYnxpCUlkJYUT1py/Pbnt9+/87z9dXxcRHMsEAuBplggFgs0xwLNoeV5x0cIlNc2srWqga3VDWyprmdrVQOl1dsfW6vrKa1qoKah+Z2ahvRM51unjuTUsXn7ZGPEjWW1XD19IS+sKGHyoBxuumACg3ukd/h1JUmSJElqqw4Ls0MITVEUfRF4AogHbg0hLI6i6EfA7BDCo8BxwA1RFAW2jxn5QsvXRwN/iqIoBsSxfWb22xtH/iOKop5ABMwHruqoe5AkHfiWF1dy5d9mEQiEAPVNsQ6/ZlJ8HDnpSeSkJ5GbkcTg3DRy0pPJzUgiNz2JKIL/+89bXHXnXA4Z0I1vnzaKI4fmdkgtIQTufn091z+2lFgI/PDssVx+xEDi7MaWJEmSJHUxUQgH/gSOgoKCMHv27M4uQ5LUxVTUNfLh375EVX0T//7S0fTKSqE5FqhpaKK2oZnqhmZqGpqoaWje/qh/+3UTzbFAfFxEfFwc8XEQF0Ut71seUURcXERC3PbnrJQEctOTyclIIjM5YZfd1k3NMabPLeTnT62guKKOaSN68q3TRjK2b3a73f/6rTVcPX0BL60s5cghufz0ggkMyElrt/UlSZIkSdpdURTNCSEU7PSYYbYk6WAUQuCqO+fw9NLN3P3pI5g8OKezS9qpusZmbn95Db9/fhXltY18+JC+fP3kkeTn7nnoHIsF7nxtLTc+vowIuOZDo7l0cr7d2JIkSZKkTtdamN2RM7MlSeqy/vTCap5YvInvnTG6ywbZACmJ8Xx22lAunpzPH2eu4raX3uKxhUVcOjmfL504nB4ZybtcozkWKCqvZV1pDWtKa3hkfiGvvbWVY4b34MbzJ9CvW+o+uBNJkiRJkvaOndmSpIPOK6tKuewvr3LauDx+d+mh+2SDxfayqaKOXz79JvfNXk9KQhyfOmYInz52CEnxcWzYVsPa0hrWllazprSGdVtrWFNazYattTQ0/3cWeHZqIt/90GguLOi/X927JEmSJOnA55gRw2xJUovi8jrO/M1/yE5N5JEvHk1G8v75PymtKqnilieX89jCYlIT46lvaia2w3/S05Piyc9NZ1BuGvm5aQzKTWdgbhoDc9PJy0oh3pEikiRJkqQuyDEjkiQBDU0xvnDXXGoamrnnM0fst0E2wNCeGfz+ssN4Y30Z989ZT05aEgN3CKx7ZCTZdS1JkiRJOqDsv7/FS5K0m65/bClz1m7jt5dOYlivzM4up11MHNCNiQO6dXYZkiRJkiR1uLjOLkCSpH3hkfmF/O3lNVw5dTBnTujb2eVIkiRJkqTdZJgtSTrgrdhUydUPLqRgYHeu+dCozi5HkiRJkiTtAcNsSdIBrbKukav+Pof05AR+d9mhJMb7nz5JkiRJkvZHzsyWJB2wQgh88/4FrN1awz8+NYXeWSmdXZIkSZIkSdpDtqdJkg5Y//ef1cxYXMy3TxvJEUNyO7scSZIkSZK0F+zMliR1ea+uLuXBORvonp5EXlYKfbulkJedSt/sFHpkJBMXF+30OzfNWM5pY/P49DFDOqFqSZIkSZLUngyzJUldVllNAzc8tox7Z68nMyWBhqYY9U2xd52TEBfROyuFPtkp9OmWSp/sFHpnpfCH51cxMCeNn104gSh6f9gtSZIkSZL2L4bZkqS9VtfYzBvryxjRO5Pu6Ul7vV4IgX8uKOJH/1zMtppGPnvsEL5y0nBSE+PZVtPIxrJaisvrKCqvpai8ruVRy4INZTyxuI6GphiZyQn88dNTyExJbIc7lCRJkiRJnc0wW5K0R6rqm3h++WZmLCrmuWWbqW5oJiUxjnMn9ecTUwcxonfmHq27fmsN339kEc8vL2F8v2z+9onJjOuX/c7xnPQkctKT3vXZjkIIbK1uICkhziBbkiRJkqQDiGG2JKnNymoaeHrp9gD7hTdLaGiKkZuexNmH9OWY4T15YUUJ0+du4O7X13HM8B58YuogjhvRa6czrd+rqTnG315ewy1PriCK4Nozx/DxowYR34bv7iiKInIzkvf0FiVJkiRJUhcVhRA6u4YOV1BQEGbPnt3ZZUjSfmlzRR1PLNnEE4uKeWV1Kc2xQN/sFE4dl8dpY/MoGJTzrsB5a3UDd7++jjteWcOminoG90jniqMGcf5h/clI3vm/oS4qLOea6QtZWFjOCaN68eNzxtGvW+o+ukNJkiRJktRVRFE0J4RQsNNjhtmSdHCYvWYrM1eUtPn8plhg1ltbmbNuGyHA4B7pnDYuj9PH5TG+X/YuN1VsbI7x2MIibntpDfPXl5GZnMBFhw/giqMGMSAnDYCahiZ++fSb/PXFt+ielsQPzh7DGeP7uGGjJEmSJEkHKcNsw2xJB7nCslpO/vlMahqa2Z2pHSPzsjh9XB6njctjeK+MPQ6Z567bxm0vreHxhUXEQuCk0b05bmQvfv/8SjZsq+WSyflcfdoostOccS1JkiRJ0sGstTC7TTOzoyg6GhgeQrgtiqKeQEYI4a32LFKS1HF+8OhiYiHwn28d/05X9L50aH53Ds3vTvGHRvP3V9dw12vreHLJJob2TOe+zx7J5ME5+7wmSZIkSZK0f9llmB1F0f8CBcBI4DYgEbgTmNqxpUmS2sOTi4t5askmrj59VKcE2TvKy07hm6eO4ksnDOeN9WUckt+N5IT4Tq1JkiRJkiTtH9rSmX0uMAmYCxBC2BhFUWaHViVJahfV9U384NHFjMrL5JNHD+7sct6RkhjPlCG5nV2GJEmSJEnaj8S14ZyGsH2wdgCIoii9Y0uSJLWXXz69go3ldVx37jgS49vyV74kSZIkSVLX1JZk474oiv4EdIui6NPA08D/dWxZkqS9tWRjBbe+tIZLJudz2EBnUkuSJEmSpP1bq2NGoiiKgHuBUUAF2+dmXxtCeGof1CZJ2kPNscB3HlpIt9REvn3ayM4uR5IkSZIkaa+1GmaHEEIURY+FEMYDBtiStJ+46/V1zF9fxi8+MpFuaUmdXY4kSZIkSdJea8uYkblRFB3e4ZVIktrF5so6fjpjGVOH5XLOIf06uxxJkiRJkqR20WpndospwGVRFK0FqoGI7U3bEzq0MknSHvnJv5ZS3xjjxx8ex/ZpUZIkSZIkSfu/toTZp3Z4FZKkdvHCihIefWMjXz1pOEN6ZnR2OZIkSZIkSe1ml2NGQghrgW7AWS2Pbi2fSZK6kLrGZr7/yCIG90jnqmlDO7scSZIkSZKkdrXLMDuKoq8A/wB6tTzujKLoSx1dmCRp9/zuuZWsLa3hunPGkZIY39nlSJIkSZIktau2jBn5JDAlhFANEEXRTcArwG86sjBJUtut3FzJH2eu4txJ/ThqWI/OLkeSJEmSJKnd7bIzm+0bPjbv8L655TNJUhcQQuC7Dy0iNTGe754xurPLkSRJkiRJ6hBt6cy+DXgtiqKHWt6fA/y140qSJO2OB+cW8tpbW7n+3PH0yEju7HIkSZIkSZI6xC7D7BDCz6Moeh44uuWjT4QQ5nVoVZKkNtlW3cD1jy3lsIHdufjwAZ1djiRJkiRJUofZZZgdRdERwOIQwtyW91lRFE0JIbzW4dWXN0apAAAgAElEQVRJklp1w+NLqaht5LpzxxEX5wQoSZIkSZJ04GrLzOw/AFU7vK9q+UyS1IleXrWF+2Zv4JPHDGZUXlZnlyNJkiRJktSh2jIzOwohhLffhBBiURS15XuSpA7QHAv89cXV3PzkCvJz0vjKicM7uyRJkiRJkqQO15ZQenUURV/mv93YnwdWd1xJkqQPsra0mm/c/waz1mzj1LG9ue7c8aQl+e+LkiRJkiTpwNeWBOQq4NfA91rePw18psMqkiS9TwiBO19bx/X/XkpCfMTPL5rIuZP6EUXOyZYkSZIkSQeHXYbZIYTNwMX7oBZJ0k4UldfyrQcW8J83t3DM8B789IIJ9MlO7eyyJEmSJEmS9qkPDLOjKPo08HwI4c1oe+vfX4HzgbXAFSGEufuoRkk6KIUQeHh+Idc+spim5sCPzxnHR6fk240tSZIkSZIOSq11Zn8F+FvL60uAicAQYBLwK+CYDq1Mkg5ipVX1fPehRcxYXEzBwO7cctFEBuamd3ZZkiRJkiRJnaa1MLsphNDY8vpM4I4QQinwdBRFP+340iTp4PTE4mK+M30hlXVNXHP6KD51zBDi4+zGliRJkiRJB7fWwuxYFEV9gG3AicB1OxxzWKsktbPSqnque2wp0+cWMq5fFndfdAgjemd2dlmSJEmSJEldQmth9rXAbCAeeDSEsBggiqJpwOp9UJskHRQWbyzntpfW8OgbG2mOBb584nC+dMIwEuPjOrs0SZIkSZKkLuMDw+wQwr+iKBoIZIYQtu1waDbwkQ6vTJIOYE3NMZ5asonbXlrD62u2kpoYz0UF/bniqMEM65XR2eVJkiRJkiR1Oa11ZhNCaGL7mJEdP6vu0Iok6QBWVtPAPbPW8/dX1lJYVkv/7ql890OjuejwAWSnJnZ2eZIkSZIkSV1Wq2G2JKl9rNhUyW0vreGheRuoa4xxxJAcrj1rDCeN7u3mjpIkSZIkSW1gmC1JHSQWCzy7bDO3vfwWL60sJTkhjnMO6ccVUwcxuk9WZ5cnSZIkSZK0X9mjMDuKolEhhGXtXYwkHShmrdnKT/61hDc2lJOXlcI3Tx3JJZPzyUlP6uzSJEmSJEmS9kt72pn9JJDfnoVI0oFgbWk1N81YxmMLi+mdlczPLpjAOZP6kRgf19mlSZIkSZIk7dc+MMyOoujXH3QI6NYx5UjS/qm8tpHfPvsmf3t5DQlxcfzPSSP49LGDSUtympMkSZIkSVJ7aC1l+QTwdaB+J8cuacviURSdBvwKiAf+EkK48T3HBwK3Aj2BrcBHQwgbWo41AwtbTl0XQji75fPBwD1ALjAHuDyE0NCWeiSpvTU2x7jrtXX88ukVlNU2cuFh/fn6KSPpnZXS2aVJkiRJkiQdUFoLs2cBi0IIL7/3QBRFP9jVwlEUxQO/A04GNgCzoih6NISwZIfTbgbuCCHcHkXRCcANwOUtx2pDCIfsZOmbgF+EEO6JouiPwCeBP+yqHklqTyFs39zxuseWsrqkmqOG5vLdM0Yztm92Z5cmSZIkSZJ0QGotzL4AqNvZgRDC4DasPRlYGUJYDRBF0T3Ah4Edw+wxwNdaXj8HPNzaglEURcAJwKUtH90O/ADDbEn70OKN5Vz376W8vKqUIT3T+cvHCjhxdC+2/xUlSZIkSZKkjtDajmT3hxBqoii6aQ/X7ges3+H9hpbPdvQGcF7L63OBzCiKclvep0RRNDuKolejKDqn5bNcoCyE0NTKmpLUIbZWN/CtB97gzN+8yNKiCn549lie+OqxnDSmt0G2JEmSJElSB2utM7tPFEVHAWe3dFW/K6kJIcxth+t/A/htFEVXAC8AhUBzy7GBIYTCKIqGAM9GUbQQKG/rwlEUfQb4DEB+fn47lCrpYBVC4LGFxVz7yCIq6hr51NGD+eLxw8lOS+zs0iRJkiRJkg4arYXZ1wLfB/oDt/DuMDuwfdxHawqBATu879/y2X8XCWEjLZ3ZURRlAOeHEMpajhW2PK+Oouh5YBLwINAtiqKElu7s9625w9p/Bv4MUFBQEHZRqyTt1ObKOq59eDEzFhczoX82/7hgCqPysjq7LEmSJEmSpIPOB4bZIYQHgAeiKPp+COHHe7D2LGB4FEWD2R44X8x/Z10DEEVRD2BrCCEGXAPc2vJ5d6AmhFDfcs5U4KchhBBF0XNsn+d9D/Bx4JE9qE2SWhVC4KF5hfzwn0uobWzm6tNH8amjB5MQ39p0JkmSJEmSJHWU1jqzAdjDIJsQQlMURV8EngDigVtDCIujKPoRMDuE8ChwHHBDFEWB7WNGvtDy9dHAn6IoirF9rveNIYS3N478NnBPFEU/AeYBf92T+iTpgxSV1/Kd6Qt5bnkJhw3szk8vmMDQnhmdXZYkSZIkSdJBLQrhwJ/AUVBQEGbPnt3ZZUjaDSEE3thQztNLNtE9PYnLjxhIUkLHdkWHELhn1nqu//dSmmKBb502ko8dOYj4ODd3lCRJkiRJ2heiKJoTQijY2bFddmZL0r7S1Bzj9be28sTiYp5csomi8jriIogFuOf1dVx/3ngOH5TTIddev7WGq6cv4KWVpRw5JJebzp9Afm5ah1xLkiRJkiRJu69NYXYURUcDw0MIt0VR1BPICCG81bGlSToY1DU28583tzBjUTHPLNtEWU0jyQlxHDuiJ984ZSQnju7F3HXb+P7Di7nwj69wyeR8rj5tFNlpie1y/VgscMcra7hpxnLi4yKuO3cclxyeT5zd2JIkSZIkSV3KLseMRFH0v0ABMDKEMCKKor7A/SGEqfuiwPbgmBGpaymvbeS5ZZt5YnExM1eUUNPQTFZKAieO7s2pY3tz7IiepCW9+9/aahqa+MVTK7j1pTV0T0vi2rPGcNaEPkTRnoXOdY3NPLG4mNteWsP89WVMG9GT688bT79uqe1xi5IkSZIkSdoDrY0ZaUuYPR+YBMwNIUxq+WxBCGFCu1faQQyzpa7jTzNXcfOTy2lsDvTKTOaUsb05dWweRwzJJTF+1zOxFxWW852HFrJgQznTRvTkJ+eMY0BO28aBhBBYVFjBfbPX88j8QirqmujfPZWvnjSC8w/tt8fBuCRJkiRJktrH3s7MbgghhCiKQsti6e1anaSDxsurtnDjjGWcMLIXnz9+GJMGdNvtcR7j+mXz0Oencscra7j5ieWc/IuZfPWkEXzy6MEfGIZvq27g4fmF3DtrPcuKK0lOiOP0cXlcVDCAI4bkOlJEkiRJkiRpP9CWzuxvAMOBk4EbgCuBu0IIv+n48tqHndlS5yutquf0X/2HjJQE/vnFo0lP3vv9Z4vKa/nfRxbz5JJNjMrL5IbzxjMpvzsAzbHAf94s4f7ZG3hqySYammNM6J/NhQUDOHtiX7JT22fmtiRJkiRJktrPXo0ZaVngZOAUIAKeCCE81b4ldizDbKlzxWKBK2+fxcurSnno80cxtm92u67/xOJi/veRxWyqrOOjUwbSLS2RB+ZsoKi8ju5piZwzqR8XFQxgdJ+sdr2uJEmSJEmS2tfejhmhJbzerwJsSV3HrS+9xfPLS/jRh8e2e5ANcOrYPKYO68HNTyzn9lfWEAHHjujJ988cw4mje5GcEN/u15QkSZIkSdK+tcswO4qiSuC97dvlwGzg6yGE1R1RmKQDwxvry7hpxjJOGdOby48Y2GHXyUhO4Adnj31ndnZedkqHXUuSJEmSJEn7Xls6s38JbADuYvuYkYuBocBc4FbguI4qTtL+raKukS/dPY9emSn89IIJRFHHb7Q4ICetw68hSZIkSZKkfS+uDeecHUL4UwihMoRQEUL4M3BqCOFeoHsH1ydpPxVC4DvTF1JYVsuvLj6EbmlJnV2SJEmSJEmS9mNtCbNroii6KIqiuJbHRUBdy7Fd7x4p6aB03+z1/GtBEV87eQQFg3I6uxxJkiRJkiTt59oSZl8GXA5sBja1vP5oFEWpwBc7sDZJ+6n/Z+/Ow+ys67vxvz8kYd/DIhAwARFERJbIolhRu7hVxBWKigqidWlttS12VVsf7e/Rqqg/fKiooAIiWsUNlcWtfZKayL7HAJKwJCQCYQlbvs8fc7BjzDIJM3PumXm9rmuuOec+97nnPcPcc8h7vvO5b7hjWf7pvKvyrCdNzVufs0e/4wAAAAAwDqx1ZnbvAo9/vJqHfza8cYCxbvnDj+YdZ16SzTacnI+9ev9M2mDk52QDAAAAMP6ttcyuqo2THJ/kqUk2fmx7a+1NI5gLGKM+8O2rc90dy/KFNz4jO2y58dqfAAAAAABDMJQxI19M8oQkf5Tkx0mmJVk2kqGAsek7l9+WM2f/Km/5vd1zxF479DsOAAAAAOPIUMrsJ7XW/iHJfa2105O8OMkhIxsLGGtuWXp/Tvr65dl/163znj/aq99xAAAAABhnhlJmP9x7f1dV7ZtkqySWXAK/8fCjK/LOsy5JWvLJYw7IlElD+dECAAAAAEO31pnZSU6tqm2S/H2S85JsnuQfRjQVMKZ89AfX59Jb7sqn/+TA7Lrtpv2OAwAAAMA4tMYyu6o2SHJPa+3XSX6SZPdRSQWMCdfdvixf+8WCnPqT+Tnm4N3y4v126nckAAAAAMapNZbZrbUVVfXXSc4ZpTxAx9129wP55qW35huXLMy1ty/LpA0qL9z3CfnHl+zT72gAAAAAjGNDGTNyQVW9J8lXktz32MbW2tIRSwV0yt0PPJzvXXFbvnHpwsy+cWlaSw7Ybeu8/6VPzYv32ynbbb5RvyMCAAAAMM4Npcx+Te/92wdtazFyBMa1Bx95NBdfuzjfuGRhLrp2UR56dEV2326zvOv5T86R+++c6dtt1u+IAAAAAEwgay2zW2szRiMI0A0L73ogn7rohnzn8ttyz/JHst3mG+XYQ3fLy/bfJftN2ypV1e+IAAAAAExAay2zq2rTJH+ZZLfW2olVtWeSvVpr3x7xdMCoWbGi5Yuzbs6/nn9tVrSWF+27U448YJc8a4+pmTxpg37HAwAAAGCCG8qYkc8nmZvkmb37C5N8NYkyG8aJeYuW5W++dkXm3vzrPHvP7fK/jnpadt12037HAgAAAIDfGEqZvUdr7TVVdUyStNbuL3MGYFx4+NEV+cyPfplPXjQvm2w4KR991dPz8gN3MUoEAAAAgM4ZSpn9UFVtkoGLPqaq9kjy4IimAkbc5Qvuyl+fe3muvX1ZXrzfTnnfHz8122+xUb9jAQAAAMAqDaXMfl+S85PsWlVfTvKsJG8YwUzACHrgoUfzsQuuz2d/Oj/bb7FRTn3dQfnDpz6h37EAAAAAYI3WWma31n5QVXOTHJqkkvx5a+3OEU8GDLv/+uWdee/Xr8jNS+7PMQfvmpNe+JRstcmUfscCAAAAgLVaa5ldVd9KcmaS81pr9418JGC43f3Aw/nQd6/J2T+/JU+cumnOfPMheeYe2/U7FgAAAAAM2VDGjHwkyWuSfLiqfp7k7CTfbq0tH9FkwOPWWsv5V96efzrvqtx574N5y+/tnnf9/pOzyYaT+h0NAAAAANbJUMaM/DjJj6tqUpLnJXlzks8l2XKEswGPw613PZB//OaVueCaRXnKTlvms8fNzH7Ttu53LAAAAABYL0NZmZ2q2iTJH2dghfaBSU4fyVDA+nt0RcsX/uumfPQH16W15G9ftHfe9KwZmTxpg35HAwAAAID1NpSZ2eckOTjJ+Uk+leTHrbUVIx0MWHdXLrw77/36Fbli4d05Yq/t889H7ptdt92037EAAAAA4HEbysrs05Ic01p7NEmq6vCqOqa19vaRjQYM1X0PPpKP/fD6fO4/b8y2m22UTx5zQF6y306pqn5HAwAAAIBhMZSZ2d+vqgOq6pgkr05yY5Kvj3gyYEguvnZR/v4bV2bhXQ/kmIN3y0kv2DtbbTql37EAAAAAYFittsyuqicnOab3dmeSrySp1tpzRykbsAaLli3P+791db5z+W150g6b56tvPSzPmL5tv2MBAAAAwIhY08rsa5P8NMlLWmvzkqSq/mJUUsEEM/fmpbly4T1D3v+u+x/OZ382Pw8+siJ/+QdPzlues3s2mjxpBBMCAAAAQH+tqcx+eZKjk1xcVecnOTuJAbwwzM6/8va8/cxf5NEVbZ2ed9juU/PBo/bN7ttvPkLJAAAAAKA7Vltmt9a+keQbVbVZkiOTvCvJDlV1SpL/aK39YJQywrj1o+sW5Z1n/SL7Tdsqpxx7UDacvMGQnrdBJVttMsUFHgEAAACYMIZyAcj7kpyZ5Myq2ibJq5L8TRJlNjwOs+cvyVu+ODd77rBFvvCGg120EQAAAADWYGjLQHtaa79urZ3aWnv+SAWCieDSW+7K8afPybRtNskZxyuyAQAAAGBt1qnMBh6/a267J8d97r+zzWZT8uUTDs12m2/U70gAAAAA0HnKbBhF8xffm9edNjubTJmUM084NE/YauN+RwIAAACAMUGZDaPklqX359jPzk5ryZdOOCS7brtpvyMBAAAAwJihzIZRsOie5XntabNz34OP5IzjD86Tdti835EAAAAAYEyZ3O8AMN4tve+hHPvZ2Vm87MF86YRD8tSdt+p3JAAAAAAYc6zMhhF0z/KH8/rPzc6vlt6f0457Rg7cbZt+RwIAAACAMUmZDSPk/oceyRs///Ncd/uyfOa1B+WwPab2OxIAAAAAjFnKbBgByx9+NG8+Y04u+dWv84mjD8hz996h35EAAAAAYEwzMxtGwD9+88r857wl+cirnp4XPW2nfscBAAAAgDHPymwYZvMW3Zuvzl2QNz97Rl550LR+xwEAAACAcWFEy+yqekFVXVdV86rqpFU8/sSqurCqLq+qH1XVtJUe37KqFlTVpwZt+1HvmJf23sxvoFNOvvCGbDJlUv70iCf1OwoAAAAAjBsjVmZX1aQkn07ywiT7JDmmqvZZabePJDmjtbZfkg8k+dBKj/9zkp+s4vDHttb2770tGubosN5uuGNZvnX5rTnumdOz7WYb9jsOAAAAAIwbI7ky++Ak81pr81trDyU5O8mRK+2zT5KLercvHvx4VR2UZMckPxjBjDCsTr5oXjadMilvfvbu/Y4CAAAAAOPKSJbZuyS5ZdD9Bb1tg12W5OW920cl2aKqplbVBkk+muQ9qzn253sjRv6hqmo4Q8P6uv6OZfm2VdkAAAAAMCL6fQHI9yR5TlVdkuQ5SRYmeTTJ25J8t7W2YBXPOba19rQkz+69vW5VB66qE6tqTlXNWbx48cikh0FOvvAGq7IBAAAAYIRMHsFjL0yy66D703rbfqO1dmt6K7OravMkr2it3VVVhyV5dlW9LcnmSTasqntbaye11hb2nrusqs7MwDiTM1b+4K21U5OcmiQzZ85sw/7ZwSDX37Es37nitrztiD2yjVXZAAAAADDsRrLM/nmSPatqRgZK7KOT/MngHapquyRLW2srkrw3yeeSpLV27KB93pBkZmvtpKqanGTr1tqdVTUlyUuSXDCCnwMMyScuuCGbbTg5JxxuVTYAAAAAjIQRGzPSWnskyTuSfD/JNUnOaa1dVVUfqKqX9nY7Isl1VXV9Bi72+MG1HHajJN+vqsuTXJqBkvzfRyI/DNV1tw+syn7DM6dblQ0AAAAAI6RaG/8TOGbOnNnmzJnT7xiMU2/78tz85Po787O/eW623lSZDQAAAADrq6rmttZmruqxfl8AEsa0a2+/J9+94va88VnTFdkAAAAAMIKU2fA4fOKCG7LFRmZlAwAAAMBIU2bDerr61nvyvStvzxsPn5GtNp3S7zgAAAAAMK4ps2E9nXzhDdli48k5/lkz+h0FAAAAAMY9ZTash6tuvTvnX3V73vQsq7IBAAAAYDQos2E9PLYq+02HW5UNAAAAAKNBmQ3r6Kpb7873r7ojxx8+I1ttYlU2AAAAAIwGZTaso49fMLAq+41mZQMAAADAqFFmwzq4cuHd+eHVd+SEw3e3KhsAAAAARpEyG9bBxy+4IVtuPDlvPHx6v6MAAAAAwISizIYhunLh3bngmjtywrN3z5YbW5UNAAAAAKNJmQ1D9PELrs9Wm0zJG541vd9RAAAAAGDCUWbDEFx6y1254JpFOeHwGVZlAwAAAEAfTO53AOiyFStazvr5r/Kh716bqZttaFU2AAAAAPSJMhtW4+Yl9+VvvnZ5Zs1fmmc9aWo+/PL9soVV2QAAAADQF8psWMmjK1o+/5835iM/uC5TNtggH3750/KaZ+yaqup3NAAAAACYsJTZMMi8RcvyV+denkt+dVeev/cO+Zej9s1OW23S71gAAAAAMOEpsyHJw4+uyKk/mZ9PXHBDNt1oUj7+mv1z5P47W40NAAAAAB2hzGbCu+rWu/PX516eq269Jy962hPy/pfum+232KjfsQAAAACAQZTZTFgPPvJoPnXRvJzyo19m6003zCnHHpgXPm2nfscCAAAAAFZBmc2ENH/xvXnLF+fmhkX35uUH7pJ/fMk+2XrTDfsdCwAAAABYDWU2E86y5Q/nhDPm5K77H87n3/CMPHfvHfodCQAAAABYC2U2E8qKFS3vPuey3Lzk/nz5hENy6O5T+x0JAAAAABiCDfodAEbT//+jefnB1Xfkb1/0FEU2AAAAAIwhymwmjIuvW5SP/vD6HLn/znnTs6b3Ow4AAAAAsA6U2UwINy+5L39+1iXZ+wlb5sMv3y9V1e9IAAAAAMA6UGYz7t3/0CN5yxfnpqryf157UDbZcFK/IwEAAAAA68gFIBnXWmv5m69dkevuWJbPv+EZ2W3qpv2OBAAAAACsByuzGddO+9mN+dZlt+Y9f7hXjthrh37HAQAAAADWkzKbceu/fnlnPvS9a/NHT90xbztij37HAQAAAAAeB2U249Ktdz2Qd555SaZP3TQfedXTXfARAAAAAMY4ZTbjzvKHH81bvzQ3Dz6yIqe+fma22HhKvyMBAAAAAI+TC0AyrrTW8o/fvDKXL7g7p77uoOyx/eb9jgQAAAAADAMrsxlXvjz7VzlnzoK883lPyh8+9Qn9jgMAAAAADBNlNuPG3Jt/nfd/66ocsdf2edfvP7nfcQAAAACAYaTMZly4ecl9+dMvzc3OW2+ST7zmgEzawAUfAQAAAGA8MTObMe+nNyzOO868JEly+psOzlabuuAjAAAAAIw3ymzGrNZaPvvTG/Oh712TPXfYIv/++pnZbeqm/Y4FAAAAAIwAZTZj0vKHH817v35F/uOShXnhvk/IR1719Gy2kW9nAAAAABivtH+MObfe9UDe8sW5uWLh3Xn3Hzw573jek1JlRjYAAAAAjGfKbMaUn9+0NH/6pblZ/vCKfPb1M/P7++zY70gAAAAAwChQZjNmfHn2zXnfeVdl2jab5uwTD8qTdtii35EAAAAAgFGizKbzHnpkRd73raty5uxf5Yi9ts8njj4gW20ypd+xAAAAAIBRpMym0xYvezBv+/Lc/PymX+dPj9gj7/nDvTJpA/OxAQAAAGCiUWbTWZcvuCtv+eLc/Pr+h/LJYw7IHz99535HAgAAAAD6RJlNJ5132a35q69elu023yhf+9Nn5qk7b9XvSAAAAABAHymz6ZQVK1o+fsH1OfmieTl4+rY55bUHZurmG/U7FgAAAADQZ8psOuP+hx7Ju8+5LN+78va8eua0/MvLnpYNJ2/Q71gAAAAAQAcos+mE2+5+IG8+Y06uuvWe/P2Ln5LjD5+RKhd6BAAAAAAGKLPpu0tvuSsnnjEn9z/0aE47bmaet/eO/Y4EAAAAAHSMMpu+euxCjztsuVG+dMIhefKOW/Q7EgAAAADQQcps+sKFHgEAAACAdaHMZtQNvtDjqw6alg8e5UKPAAAAAMCajWiDWFUvqKrrqmpeVZ20isefWFUXVtXlVfWjqpq20uNbVtWCqvrUoG0HVdUVvWOeXK4SOKbcdvcDefX/+b85/6rb83cvekr+v1fup8gGAAAAANZqxFrEqpqU5NNJXphknyTHVNU+K+32kSRntNb2S/KBJB9a6fF/TvKTlbadkuTNSfbsvb1gmKMzQi675a4c+an/zE133p/TjpuZN//e7vG7CAAAAABgKEZySezBSea11ua31h5KcnaSI1faZ58kF/VuXzz48ao6KMmOSX4waNtOSbZsrc1qrbUkZyR52ch9CgyX6+9Ylj/591nZaMoG+frbnpnn7b1jvyMBAAAAAGPISJbZuyS5ZdD9Bb1tg12W5OW920cl2aKqplbVBkk+muQ9qzjmgrUck465+4GHc+IZc7LpRpPz1bc8M0/ecYt+RwIAAAAAxph+Dyt+T5LnVNUlSZ6TZGGSR5O8Lcl3W2sL1vTkNamqE6tqTlXNWbx48fCkZZ2tWNHyrrMvycK7Hsgpxx6YJ2y1cb8jAQAAAABj0OQRPPbCJLsOuj+tt+03Wmu3prcyu6o2T/KK1tpdVXVYkmdX1duSbJ5kw6q6N8knesdZ7TEHHfvUJKcmycyZM9uwfEass49fcH0uvm5x/uVl+2bm9G37HQcAAAAAGKNGssz+eZI9q2pGBgrno5P8yeAdqmq7JEtbayuSvDfJ55KktXbsoH3ekGRma+2k3v17qurQJLOTvD7JJ0fwc+BxOP/K23PyRfPympm75thDdut3HAAAAABgDBuxMSOttUeSvCPJ95Nck+Sc1tpVVfWBqnppb7cjklxXVddn4GKPHxzCod+W5LNJ5iX5ZZLvDXd2Hr95i5bl3edcmqfvunXef+RTU1X9jgQAAAAAjGHV2vifwDFz5sw2Z86cfseYMO5Z/nBe9qn/zD3LH8633nl4dtpqk35HAgAAAADGgKqa21qbuarHRnLMCBPQihUtf/mVS/OrpffnyyccosgGAAAAAIbFiI0ZYWI6+aIbcsE1i/IPL9knh+w+td9xAAAAAIBxQpnNsPnh1Xfk4xfckFceNC2vP+yJ/Y4DAAAAAIwjymyGxbxF9+YvvnJp9pu2Vf7lZfu64CMAAAAAMKyU2Txuy5Y/nLd8cUSHiEYAACAASURBVE42mrxBPvPag7LxlEn9jgQAAAAAjDMuAMnjsmJFy7vPuSw3Lbk/Xzr+kOy8tQs+AgAAAADDz8psHpdPXzwvP7j6jvzdi56Sw/ZwwUcAAAAAYGQos1lvF117R/7tgutz1AG75I3Pmt7vOAAAAADAOKbMZr39y7evyV47bpH/ddTTXPARAAAAABhRymzWy+13L8/8O+/LKw+alk02dMFHAAAAAGBkKbNZL7NvXJIkOXR3c7IBAAAAgJGnzGa9zJq/JFtuPDlP2WnLfkcBAAAAACYAZTbrZdb8pTl4xraZtIFZ2QAAAADAyFNms85uv3t5brzzPiNGAAAAAIBRo8xmnZmXDQAAAACMNmU262zW/KXZwrxsAAAAAGAUKbNZZ7PnL8kh5mUDAAAAAKNImc06ueOe5Zl/5305ZIYRIwAAAADA6FFms05mzTcvGwAAAAAYfcps1sms+UuzxUaTs8/O5mUDAAAAAKNHmc06mX3jkhxsXjYAAAAAMMqU2QzZonuWZ/7i+4wYAQAAAABGnTKbIZt149IkySG7b9vnJAAAAADARKPMZshmzV8yMC97J/OyAQAAAIDRpcxmyGbNX5JnzNg2kyf5tgEAAAAARpdWkiFZtOyxedlGjAAAAAAAo0+ZzZDMnj8wL9vFHwEAAACAflBmMySz5i/J5uZlAwAAAAB9osxmSGbNX5JnTN/GvGwAAAAAoC80k6zVomXL88vF9xkxAgAAAAD0jTKbtfrvG83LBgAAAAD6S5nNWj02L/upO5uXDQAAAAD0hzKbtZo1f6l52QAAAABAX2knWaPFyx7MvEX35hAjRgAAAACAPlJms0azb1ySxLxsAAAAAKC/lNms0ez5S7PZhpOyr3nZAAAAAEAfKbNZo1nzl+QZM7Y1LxsAAAAA6CsNJat1570P5oZF9xoxAgAAAAD0nTKb1Zo9f2mS5JAZ2/Y5CQAAAAAw0SmzWa1Z85cMzMveZat+RwEAAAAAJjhlNqs1+8YlmTl920wxLxsAAAAA6DMtJat0570P5vo7zMsGAAAAALpBmc0q/feNA/OyD93dvGwAAAAAoP+U2azSrPlLsql52QAAAABARyizWaVZ883LBgAAAAC6Q1PJ71jym3nZRowAAAAAAN2gzOZ3/M+8bBd/BAAAAAC6QZnN73hsXvbTzMsGAAAAADpCmc3vmDV/aQ564jbmZQMAAAAAnaGt5LcsuffBXHfHMiNGAAAAAIBOUWbzW8zLBgAAAAC6aHK/A9Ats29cmk2mTMp+08zLBgAAAICx5uGHH86CBQuyfPnyfkdZo4033jjTpk3LlClThvwcZTa/Zdb8JZk53bxsAAAAABiLFixYkC222CLTp09PVfU7ziq11rJkyZIsWLAgM2bMGPLzRrSxrKoXVNV1VTWvqk5axeNPrKoLq+ryqvpRVU0btP0XVXVpVV1VVW8d9Jwf9Y55ae9th5H8HCaSpfc9lGtvNy8bAAAAAMaq5cuXZ+rUqZ0tspOkqjJ16tR1Xj0+Yiuzq2pSkk8n+YMkC5L8vKrOa61dPWi3jyQ5o7V2elU9L8mHkrwuyW1JDmutPVhVmye5svfcW3vPO7a1Nmeksk9U/33jkiTJobtv2+ckAAAAAMD66nKR/Zj1yTiSY0YOTjKvtTY/Sarq7CRHJhlcZu+T5C97ty9O8o0kaa09NGifjeJClevlzNm/ytd/sWDI+9929/JsMmVSnrbL1iOYCgAAAABg3Y1kSbxLklsG3V/Q2zbYZUle3rt9VJItqmpqklTVrlV1ee8Y/zpoVXaSfL43YuQfaiz8mqFPJk+qbDRlgyG/Td9u07zz+U/KhpP97gAAAAAAWH/f+MY3UlW59tprh+2Y/b4A5HuSfKqq3pDkJ0kWJnk0SVprtyTZr6p2TvKNqjq3tXZHBkaMLKyqLZJ8LQNjSc5Y+cBVdWKSE5Nkt912G43PpXNePXPXvHrmrv2OAQAAAABMMGeddVYOP/zwnHXWWXn/+98/LMccySW4C5MMblKn9bb9Rmvt1tbay1trByT5u962u1beJ8mVSZ7du7+w935ZkjMzMM7kd7TWTm2tzWytzdx+++2H5zMCAAAAAGCN7r333vzsZz/LaaedlrPPPnvYjjuSK7N/nmTPqpqRgRL76CR/MniHqtouydLW2ook703yud72aUmWtNYeqKptkhye5GNVNTnJ1q21O6tqSpKXJLlgBD8HAAAAAIAx6f3fuipX33rPsB5zn523zD/98VPXuM83v/nNvOAFL8iTn/zkTJ06NXPnzs1BBx30uD/2iK3Mbq09kuQdSb6f5Jok57TWrqqqD1TVS3u7HZHkuqq6PsmOST7Y2/6UJLOr6rIkP07ykdbaFRm4GOT3e7O0L81ASf7vI/U5AAAAAACwbs4666wcffTRSZKjjz46Z5111rAct1prw3KgLps5c2abM2dOv2MAAAAAAIyoa665Jk95ylP69vGXLl2aadOmZfvtt09V5dFHH01V5eabb05V/da+q8paVXNbazNXdeyRnJkNAAAAAMAEcu655+Z1r3tdbr755tx000255ZZbMmPGjPz0pz993MdWZgMAAAAAMCzOOuusHHXUUb+17RWveMWwjBoZyQtAAgAAAAAwgVx88cW/s+3P/uzPhuXYVmYDAAAAANB5ymwAAAAAADpPmQ0AAAAAMI601vodYa3WJ6MyGwAAAABgnNh4442zZMmSThfarbUsWbIkG2+88To9zwUgAQAAAADGiWnTpmXBggVZvHhxv6Os0cYbb5xp06at03OU2QAAAAAA48SUKVMyY8aMfscYEcaMAAAAAADQecpsAAAAAAA6T5kNAAAAAEDnVZevajlcqmpxkpv7naNPtktyZ79DAEPmnIWxxTkLY4tzFsYW5yyMLc5ZhssTW2vbr+qBCVFmT2RVNae1NrPfOYChcc7C2OKchbHFOQtji3MWxhbnLKPBmBEAAAAAADpPmQ0AAAAAQOcps8e/U/sdAFgnzlkYW5yzMLY4Z2Fscc7C2OKcZcSZmQ0AAAAAQOdZmQ0AAAAAQOcpswEAAAAA6Dxl9jhWVS+oquuqal5VndTvPMBvq6pdq+riqrq6qq6qqj/vbd+2qn5YVTf03m/T76zA/6iqSVV1SVV9u3d/RlXN7r3efqWqNux3RmBAVW1dVedW1bVVdU1VHeZ1Frqrqv6i9//FV1bVWVW1sddZ6I6q+lxVLaqqKwdtW+Xrag04uXfuXl5VB/YvOeOJMnucqqpJST6d5IVJ9klyTFXt099UwEoeSfLu1to+SQ5N8vbeeXpSkgtba3smubB3H+iOP09yzaD7/5rkY621JyX5dZLj+5IKWJVPJDm/tbZ3kqdn4Nz1OgsdVFW7JPmzJDNba/smmZTk6HidhS75QpIXrLRtda+rL0yyZ+/txCSnjFJGxjll9vh1cJJ5rbX5rbWHkpyd5Mg+ZwIGaa3d1lr7Re/2sgz8A3uXDJyrp/d2Oz3Jy/qTEFhZVU1L8uIkn+3dryTPS3JubxfnLHREVW2V5PeSnJYkrbWHWmt3xessdNnkJJtU1eQkmya5LV5noTNaaz9JsnSlzat7XT0yyRltwKwkW1fVTqOTlPFMmT1+7ZLklkH3F/S2AR1UVdOTHJBkdpIdW2u39R66PcmOfYoF/K6PJ/nrJCt696cmuau19kjvvtdb6I4ZSRYn+XxvNNBnq2qzeJ2FTmqtLUzykSS/ykCJfXeSufE6C123utdVvRQjQpkN0GdVtXmSryV5V2vtnsGPtdZaktaXYMBvqaqXJFnUWpvb7yzAkExOcmCSU1prByS5LyuNFPE6C93Rm7N7ZAZ+EbVzks3yu+MMgA7zuspoUGaPXwuT7Dro/rTeNqBDqmpKBorsL7fWvt7bfMdjf37Ve7+oX/mA3/KsJC+tqpsyML7reRmYx7t178+hE6+30CULkixorc3u3T83A+W211nopt9PcmNrbXFr7eEkX8/Aa6/XWei21b2u6qUYEcrs8evnSfbsXfl5wwxcOOO8PmcCBunN2j0tyTWttX8b9NB5SY7r3T4uyTdHOxvwu1pr722tTWutTc/A6+pFrbVjk1yc5JW93Zyz0BGttduT3FJVe/U2PT/J1fE6C131qySHVtWmvf9Pfuyc9ToL3ba619Xzkry+Bhya5O5B40hgvdXAXwAwHlXVizIw23NSks+11j7Y50jAIFV1eJKfJrki/zN/928zMDf7nCS7Jbk5yatbaytfZAPoo6o6Isl7WmsvqardM7BSe9sklyR5bWvtwX7mAwZU1f4ZuGDrhknmJ3ljBhb0eJ2FDqqq9yd5TZJHMvCaekIGZux6nYUOqKqzkhyRZLskdyT5pyTfyCpeV3u/lPpUBsYF3Z/kja21Of3IzfiizAYAAAAAoPOMGQEAAAAAoPOU2QAAAAAAdJ4yGwAAAACAzlNmAwAAAADQecpsAAAAAAA6T5kNAADDqKo+VFXPraqXVdV7V7PP+6rqPb3bb6iqnYfx4x9RVc8cdP+tVfX64To+AAD0izIbAACG1yFJZiV5TpKfDGH/NyRZpzK7qiav4eEjkvymzG6tfaa1dsa6HB8AALqoWmv9zgAAAGNeVf3vJH+UZEaSXybZI8mNSc5trX1gpX3fl+TeJDcl+UKShUkeSHJYkn2S/FuSzZPcmeQNrbXbqupHSS5NcniSs5Jcn+Tvk2yYZEmSY5NskoEi/dEki5O8M8nzk9zbWvtIVe2f5DNJNu1lfFNr7de9Y89O8twkWyc5vrX206p6apLP9z7GBkle0Vq7YZi+ZAAAsE6szAYAgGHQWvurJMdnoJx+RpLLW2v7rVxkr/Scc5PMSXJsa23/JI8k+WSSV7bWDkryuSQfHPSUDVtrM1trH03ysySHttYOSHJ2kr9urd2UgbL6Y621/VtrP13pQ56R5G9aa/sluSLJPw16bHJr7eAk7xq0/a1JPtHLNjPJgnX6ogAAwDBa058nAgAA6+bAJJcl2TvJNevx/L2S7Jvkh1WVJJOS3Dbo8a8Muj0tyVeqaqcMrJy+cU0HrqqtkmzdWvtxb9PpSb46aJev997PTTK9d/v/Jvm7qpqW5OtWZQMA0E/KbAAAeJx64zu+kIGC+c4MjPGoqro0yWGttQeGeqgkV7XWDlvN4/cNuv3JJP/WWjuvqo5I8r71iD7Yg733j6b374TW2plVNTvJi5N8t6re0lq76HF+HAAAWC/GjAAAwOPUWru0N4rj+gzMvL4oyR/1Rn2srchelmSL3u3rkmxfVYclSVVN6c2tXpWtMjBrO0mOW83xBme8O8mvq+rZvU2vS/LjlfcbrKp2TzK/tXZykm8m2W8tnwsAAIwYZTYAAAyDqto+ya9bayuS7N1au3qIT/1Cks/0VnFPSvLKJP9aVZdl4IKPz1zN896X5KtVNTcDq8Ef860kR1XVpYOK68ccl+R/V9XlSfZPstp53j2vTnJlL9u+GZi5DQAAfVGttX5nAAAAAACANbIyGwAAAACAzlNmAwAAAADQecpsAAAAAAA6T5kNAAAAAEDnKbMBAAAAAOg8ZTYAAAAAAJ2nzAYAAAAAoPOU2QAAAAAAdJ4yGwAAAACAzlNmAwAAAADQecpsAAAAAAA6T5kNAAAAAEDnKbMBAAAAAOg8ZTYAAAAAAJ2nzAYAAAAAoPOU2QAAAAAAdJ4yGwAAAACAzlNmAwAAAADQecpsAAAAAAA6T5kNAAAAAEDnKbMBAAAAAOg8ZTYAAAAAAJ2nzAYAAAAAoPOU2QAAAAAAdJ4yGwAAAACAzlNmAwAAAADQecpsAAAAAAA6T5kNAAAAAEDnKbMBAAAAAOg8ZTYAAAAAAJ2nzAYAAAAAoPOU2QAAAAAAdJ4yGwAAAACAzlNmAwAAAADQecpsAAAAAAA6T5kNAAAAAEDnKbMBAAAAAOg8ZTYAAAAAAJ2nzAYAAAAAoPOU2QAAAAAAdJ4yGwAAAACAzlNmAwAAAADQecpsAAAAAAA6T5kNAAAAAEDnKbMBAAAAAOg8ZTYAAAAAAJ2nzAYAAAAAoPOU2QAAAAAAdJ4yGwAAAACAzpvc7wCjYbvttmvTp0/vdwwAAAAAANZg7ty5d7bWtl/VYxOizJ4+fXrmzJnT7xgAAAAAAKxBVd28useMGQEAAAAAoPOU2QAAAAAAdJ4yGwAAAACAzlNmAwAAAADQecpsAAAAAAA6T5kNAAAAAEDnKbMBAAAAAOi8TpTZVbV1VZ1bVddW1TVVdVhVbVtVP6yqG3rvt+ntW1V1clXNq6rLq+rAfucHAAAAAGBkdaLMTvKJJOe31vZO8vQk1yQ5KcmFrbU9k1zYu58kL0yyZ+/txCSnjH5cAAAAAABGU9/L7KraKsnvJTktSVprD7XW7kpyZJLTe7udnuRlvdtHJjmjDZiVZOuq2mmUYwMAAAAAMIr6XmYnmZFkcZLPV9UlVfXZqtosyY6ttdt6+9yeZMfe7V2S3DLo+Qt62wAAAAAAGKe6UGZPTnJgklNaawckuS//M1IkSdJaa0nauhy0qk6sqjlVNWfx4sXDFhYAAAAAgNHXhTJ7QZIFrbXZvfvnZqDcvuOx8SG994t6jy9Msuug50/rbfstrbVTW2szW2szt99++xELDwAAAADAyOt7md1auz3JLVW1V2/T85NcneS8JMf1th2X5Ju92+cleX0NODTJ3YPGkQAAAAAAMA5N7neAnncm+XJVbZhkfpI3ZqBoP6eqjk9yc5JX9/b9bpIXJZmX5P7evgAAAAAAjGOdKLNba5cmmbmKh56/in1bkrePeCgAAAAAADqj72NGAAAAAABgbTqxMhsAAAAAxrvpJ31nrfvc9OEXj0ISGJuU2QAAAADQMUMpvhPlNxOLMSMAAAAAAHSeldkAAAAMC6sIYWzo2rlq9AYwVMpsAAAAxp2ulXUTiWISgJGizAYAABjD1rU4VDQCY926/Bzziy0YX5TZAEDnKV4AgK5RkgKMPmU2AMAIUsTD+OTcZiLx/d4fXfqri4lU3Hfp6w78LmU2AABMEBOpjAAAYPxRZgMAj5sVKdA/zj9Gkl+ArN5YPvfGcnYAJjZlNgAAsEr+1Jqu8T3GuvI9AzC+KLMBYIRYzQYAPEapCgCPnzIbADpiIv0j1wWKxoZ1+e/k6z58JtLPgi7p0s+liXQ+den7fSx/3cdy9q7p0vfkWObrCIwUZTYAQEeMdBkxlv9hOZaz0x++ZxjrfA+PP37pAPD4KbMBYIj8AwTGji6VQF3KMpb5GQwkfhYATHTKbACAMco/6AEAgIlEmQ1ApynrVs9qTxgefs70j59jgJ/BAKwLZTYATAAuPkbX+B4DAADWlTIbYAzqWglkZR1jme9fAACAsUGZDTBCFGQAAAAAw0eZDXSaQhgAAACAJNmg3wEAAAAAAGBtrMwGfkvXZjGvi7GcHQAAAIA1U2YDo6pLY0OU3wAAAABjhzIbAADWgV+GAgBAfyizAQDWQZf+wgQAAGAiUWYzqhQAsHrOj+Hh6wgAAADjkzIbgFHlz/MBAACA9aHMprMmUuE1kT5X6BoruQEAAGBsUGYzYSmwYPWcHwAAAEDXKLMZN7pUvllpTdd06fwAAAAAWB/KbBiDFJMAAAAATDTKbB6XiVSqTqTPlVXzPQAAAADQPxv0OwAAAAAAAKyNMhsAAAAAgM4zZgR4XFzsEgAAAIDRoMyGCcCsZwAAAADGOmNGAAAAAADoPGU2AAAAAACdp8wGAAAAAKDzlNkAAAAAAHSeMhsAAAAAgM5TZgMAAAAA0HnKbAAAAAAAOm9yvwMwsqaf9J0h7XfTh1885P0f2xcAAAAAYLRYmQ0AAAAAQOcpswEAAAAA6DxlNgAAAAAAnafMBgAAAACg85TZAAAAAAB0njIbAAAAAIDOU2YDAAAAANB5ymwAAAAAADpPmQ0AAAAAQOcpswEAAAAA6LxOlNlVdVNVXVFVl1bVnN62bavqh1V1Q+/9Nr3tVVUnV9W8qrq8qg7sb3oAAAAAAEZaJ8rsnue21vZvrc3s3T8pyYWttT2TXNi7nyQvTLJn7+3EJKeMelIAAAAAAEZVl8rslR2Z5PTe7dOTvGzQ9jPagFlJtq6qnfoREAAAAACA0dGVMrsl+UFVza2qE3vbdmyt3da7fXuSHXu3d0lyy6DnLuht+y1VdWJVzamqOYsXLx6p3AAAAAAAjILJ/Q7Qc3hrbWFV7ZDkh1V17eAHW2utqtq6HLC1dmqSU5Nk5syZ6/RcAAAAAAC6pRMrs1trC3vvFyX5jyQHJ7njsfEhvfeLersvTLLroKdP620DAAAAAGCc6nuZXVWbVdUWj91O8odJrkxyXpLjersdl+SbvdvnJXl9DTg0yd2DxpEAAAAAADAOdWHMyI5J/qOqkoE8Z7bWzq+qnyc5p6qOT3Jzklf39v9ukhclmZfk/iRvHP3IAAAAAACMpr6X2a21+UmevortS5I8fxXbW5K3j0I0AAAAAAA6ou9jRgAAAAAAYG2U2QAAAAAAdJ4yGwAAAACAzlNmAwAAAADQecpsAAAAAAA6T5kNAAAAAEDnKbMBAAAAAOg8ZTYAAAAAAJ2nzAYAAAAAoPOU2QAAAAAAdJ4yGwAAAACAzlNmAwAAAADQecpsAAAAAAA6T5kNAAAAAEDnKbMBAAAAAOg8ZTYAAAAAAJ2nzAYAAAAAoPOU2QAAAAAAdJ4yGwAAAACAzlNmAwAAAADQecpsAAAAAAA6T5kNAAAAAEDnKbMBAAAAAOg8ZTYAAAAAAJ2nzAYAgP/X3t1H7VbWdQL//jgHAl9GfEGW8eLBZHSho0gnA7VCGVcSKjSZ6ZCiQ1GTGUw1CeaMWraC8S1tTCNRocw30kRBJxJEaxIDQRAZE5EEQkF5DQqEfvPHvQ8+nThw4NnPc+9z7s9nrWfd+7r2df/u6z5r7bXP+Z7ruTYAADB5wmwAAAAAACZPmA0AAAAAwOQJswEAAAAAmDxhNgAAAAAAk7d23hMAAAAAAJZn3dGnbta4y449aIVnAivHymwAAAAAACZPmA0AAAAAwOQJswEAAAAAmDxhNgAAAAAAkyfMBgAAAABg8oTZAAAAAABMnjAbAAAAAIDJE2YDAAAAADB5wmwAAAAAACZPmA0AAAAAwOQJswEAAAAAmDxhNgAAAAAAkyfMBgAAAABg8oTZAAAAAABMnjAbAAAAAIDJE2YDAAAAADB5wmwAAAAAACZPmA0AAAAAwOQJswEAAAAAmDxhNgAAAAAAkyfMBgAAAABg8oTZAAAAAABMnjAbAAAAAIDJE2YDAAAAADB5wmwAAAAAACZvMmF2Va2pqvOq6uNDe4+qOruqLqmqD1TVdkP/9w3tS4bz6+Y5bwAAAAAAVt5kwuwkRya5eEn7uCRv7u5HJ7kuyeFD/+FJrhv63zyMAwAAAABgKzaJMLuqdk1yUJJ3Du1K8owkJw9DTkxyyHB88NDOcP6AYTwAAAAAAFupSYTZSX4vyW8k+Zeh/dAk13f37UP7iiS7DMe7JLk8SYbzNwzjAQAAAADYSs09zK6qZye5urvPHbnuEVV1TlWdc80114xZGgAAAACAVTb3MDvJU5M8t6ouS/L+zLYXeUuSHatq7TBm1yRXDsdXJtktSYbzD0rynY2Ldvfx3b2+u9fvtNNOK/sNAAAAAABYUXMPs7v7mO7etbvXJXlBkjO6+9AkZyZ53jDssCQfHY5PGdoZzp/R3b2KUwYAAAAAYJWtvechd6+qfvXuznf3m+5j6VckeX9VvS7JeUlOGPpPSPLHVXVJkmszC8ABAAAAANiKLTvMTvLA4fUxSX4os5XTSfKcJJ+/N4W6+9NJPj0cX5rkyXcx5p+T/PR9myoAAAAAAFuiZYfZ3f3aJKmqzyTZp7tvGtqvSXLqcusDAAAAAMCYe2bvnOS2Je3bhj4AAAAAAFiWMbYZ2eCkJJ+vqo8M7UOSnDhifQAAAAAAFtRoYXZ3/05VfSLJjwxdL+3u88aqDwAAAACMY93R97w78GXHHrQKM4HNN+Y2I0lyvyQ3dvdbklxRVXuMXB8AAAAAgAU0WphdVa9O8ookxwxd2yb5k7HqAwAAAACwuMZcmf2TSZ6b5OYk6e5/SPLAEesDAAAAALCgxgyzb+vuTtJJUlX3H7E2AAAAAAALbMww+4NV9YdJdqyqn0/yl0neOWJ9AAAAAAAW1NqxCnX3G6rqmUluTPKYJP+zu08fqz4AAAAAAItrtDC7qo7r7lckOf0u+gAAAAAA4D4bc5uRZ95F34Ej1gcAAAAAYEEte2V2Vf3XJL+U5FFVdcGSUw9M8tfLrQ8AAAAAAGNsM/KnST6R5HeTHL2k/6buvnaE+gAAAAAALLhlh9ndfUOSG5K8MEmq6uFJtk/ygKp6QHd/Y7mfAQAAAADAYhttz+yqek5VfTXJ15OcleSyzFZsAwAAAADAsoz5AMjXJdk3yd919x5JDkjyuRHrAwAAAACwoMYMs7/b3d9Jsk1VbdPdZyZZP2J9AAAAAAAW1BgPgNzg+qp6QJLPJnlvVV2d5OYR6wMAAAAAsKDGXJl9cJJbkhyV5JNJvpbkOSPWBwAAAABgQY22Mru7b66qRybZs7tPrKr7JVkzVn0AAAAAABbXaCuzq+rnk5yc5A+Hrl2S/PlY9QEAAAAAWFxjbjPysiRPTXJjknT3V5M8fMT6AAAAAAAsqDHD7Fu7+7YNjapam6RHrA8AAAAAwIIaM8w+q6pemWSHqnpmkg8l+diI9QEAAAAAWFBjhtmvSHJNkguT/EKS05K8asT6AAAAAAAsqLVjFKmqNUku6u7HJvmjMWoCAAAAAMAGo6zM7u47knylqnYfox4AAAAAACw1ysrswYOTXFRVn09y84bO7n7uiJ8BAAAAAMACGjPM/h8j1gIAAAAAgDstO8yuqkcn2bm7z9qo/2lJrlpufQAAAAAAGGNl9u8lOeYu+m8Yzj1nhM8AAAAAAOZkireSHwAAGKVJREFU3dGn3uOYy449aBVmwiIb4wGQO3f3hRt3Dn3rRqgPAAAAAMCCGyPM3vFuzu0wQn0AAAAAABbcGGH2OVX18xt3VtXPJTl3hPoAAAAAACy4MfbMPirJR6rq0HwvvF6fZLskPzlCfQAAAAAAFtyyw+zu/laSp1TV05M8fug+tbvPWG5tAAAAAABIxlmZnSTp7jOTnDlWPQAAAAAA2GCMPbMBAAAAAGBFCbMBAAAAAJi80cLsqrp/VW0zHP/7qnpuVW07Vn0AAAAAABbXmCuzP5Nk+6raJclfJHlRkveMWB8AAAAAgAU1Zphd3X1Lkv+U5A+6+6eTPG7E+gAAAAAALKhRw+yq2i/JoUlOHfrWjFgfAAAAAIAFNWaYfVSSY5J8pLsvqqpHJTlzxPoAAAAAACyotWMV6u6zkpy1pH1pkl8Zqz4AAAAAAItr2WF2VX0sSW/qfHc/d7mfAQAAAADAYhtjZfYbRqgBAAAAAACbtOwwe9heJElSVTsk2b27v7LcugAAAAAAsMFoD4CsquckOT/JJ4f23lV1ylj1AQAAAABYXKOF2Ulek+TJSa5Pku4+P8keI9YHAAAAAGBBjRlmf7e7b9iob5MPhgQAAAAAgM01xgMgN7ioqv5zkjVVtWeSX0nyf0esDwAAAADAghpzZfbLkzwuya1J3pfkxiRHjVgfAAAAAIAFNdrK7O6+JclvVtVxs2bfNFZtAAAAAAAW22grs6vqh6rqwiQXJLmwqr5YVT84Vn0AAAAAABbXmNuMnJDkl7p7XXevS/KyJO++pzdV1fZV9fkh/L6oql479O9RVWdX1SVV9YGq2m7o/76hfclwft2I3wEAAAAAgAkaM8y+o7s/u6HR3X+V5PbNeN+tSZ7R3U9MsneSZ1XVvkmOS/Lm7n50kuuSHD6MPzzJdUP/m4dxAAAAAABsxZYdZlfVPlW1T5KzquoPq2r/qvqxqvqDJJ++p/f3zD8OzW2Hn07yjCQnD/0nJjlkOD54aGc4f0BV1XK/BwAAAAAA0zXGAyDfuFH71UuOe3MKVNWaJOcmeXSStyX5WpLru3vDyu4rkuwyHO+S5PIk6e7bq+qGJA9N8u2Nah6R5Igk2X333Tf3uwAAAAAAMEHLDrO7++kj1Lgjyd5VtWOSjyR57Ag1j09yfJKsX79+s0J1AAAAAACmaYyV2XeqqoOSPC7J9hv6uvu3Nvf93X19VZ2ZZL8kO1bV2mF19q5JrhyGXZlktyRXVNXaJA9K8p2RvgIAAAAAABM02gMgq+odSX4mycuTVJKfTvLIzXjfTsOK7FTVDkmemeTiJGcmed4w7LAkHx2OTxnaGc6f0d1WXgMAAAAAbMXGXJn9lO5+QlVd0N2vrao3JvnEZrzvEUlOHPbN3ibJB7v741X15STvr6rXJTkvyQnD+BOS/HFVXZLk2iQvGPE7AAAAAAAwQWOG2f80vN5SVd+f2dYfj7inN3X3BUmedBf9lyZ58l30/3Nmq74BAAAAAFgQY4bZHx+2C3l9ki8k6SR/NGJ9AAAAAAAW1Ghhdnf/9nD4Z1X18cweAvnYseoDAAAAALC4RnsA5FLdfWt335DkQytRHwAAAACAxbIiYfYStcL1AQAAAABYACsdZvcK1wcAAAAAYAEse8/sqvpY7jq0riQPXW59AAAAAAAY4wGQb7iP5wAAAAAAYLMsO8zu7rM27quqfbr7C8utDQAAAAAAycrtmf3OFaoLAAAAAMACWqkwu1aoLgAAAAAAC2ilwuzXrlBdAAAAAAAW0BgPgLxTVT0xyY9sOO7uL45ZHwAAAACAxTTayuyqOjLJe5M8fPj5k6p6+Vj1AQAAAABYXGOuzD48yQ93981JUlXHJfmbJL8/4mcAAAAAALCAxtwzu5LcsaR9RzwIEgAAAACAEYy5MvvdSc6uqo8M7UOSnDBifQAAAAAAFtRoYXZ3v6mqPp3kaUPXS7v7vLHqAwAAAACwuJYdZlfVQ5Y0Lxt+7jzX3dcu9zMAAAAAAFhsY6zMPjdJZ7Y/9u5JrhuOd0zyjSR7jPAZAAAAAAAssGU/ALK79+juRyX5yyTP6e6HdfdDkzw7yV8stz4AAAAAACw7zF5i3+4+bUOjuz+R5Ckj1gcAAAAAYEGN9gDIJP9QVa9K8idD+9Ak/zBifQAAAAAAFtSYK7NfmGSnJB8Zfh4+9AEAAAAAwLKMtjK7u69NcuRY9QAAAAAAYIPRwuyqOjNJb9zf3c8Y6zMAAAAAAFhMY+6Z/etLjrdP8lNJbh+xPgAAAAAAC2rMbUbO3ajrr6vq82PVBwAAAABgcY25zchDljS3SfKDSR40Vn0AAAAAABbXmNuMnJvZntmV2fYiX09y+Ij1AQAAAABYUGNuM7LHWLUAAAAAAGCpbcYqVFX3q6pXVdXxQ3vPqnr2WPUBAAAAAFhco4XZSd6d5LYkTxnaVyZ53Yj1AQAAAABYUGOG2T/Q3f8ryXeTpLtvyWz/bAAAAAAAWJYxw+zbqmqHzB4Cmar6gSS3jlgfAAAAAIAFNdoDIJO8Osknk+xWVe9N8tQkLxmxPgAAAAAAC2q0MLu7T6+qLyTZN7PtRY7s7m+PVR8AAAAAgMU12jYjVfXUJP/c3acm2THJK6vqkWPVBwAAAABgcY25Z/bbk9xSVU9M8qtJvpbkpBHrAwAAAACwoMYMs2/v7k5ycJK3dffbkjxwxPoAAAAAACyoMR8AeVNVHZPkZ5P8aFVtk2TbEesDAAAAALCgxlyZ/TNJbk1yeHd/M8muSV4/Yn0AAAAAABbUsldmV9X2SX4xyaOTXJjkb5Kku78Re2YDAAAAwEJZd/SpmzXusmMPWuGZsLUZY2X2iUnWZxZkH5jkjSPUBAAAAACAO42xZ/Ze3f0fkqSqTkjy+RFqAgAAAADAncZYmf3dDQfdffsI9QAAAAAA4F8ZY2X2E6vqxuG4kuwwtCtJd/e/G+EzAAAAAABYYMsOs7t7zRgTAQAAAACATRljmxEAAAAAAFhRwmwAAAAAACZPmA0AAAAAwOQJswEAAAAAmDxhNgAAAAAAkyfMBgAAAABg8oTZAAAAAABMnjAbAAAAAIDJm3uYXVW7VdWZVfXlqrqoqo4c+h9SVadX1VeH1wcP/VVVb62qS6rqgqraZ77fAAAAAACAlTb3MDvJ7Ul+rbv3SrJvkpdV1V5Jjk7yqe7eM8mnhnaSHJhkz+HniCRvX/0pAwAAAACwmuYeZnf3Vd39heH4piQXJ9klycFJThyGnZjkkOH44CQn9cznkuxYVY9Y5WkDAAAAALCK5h5mL1VV65I8KcnZSXbu7quGU99MsvNwvEuSy5e87YqhDwAAAACArdRkwuyqekCSP0tyVHffuPRcd3eSvpf1jqiqc6rqnGuuuWbEmQIAAAAAsNomEWZX1baZBdnv7e4PD93f2rB9yPB69dB/ZZLdlrx916HvX+nu47t7fXev32mnnVZu8gAAAAAArLi5h9lVVUlOSHJxd79pyalTkhw2HB+W5KNL+l9cM/smuWHJdiQAAAAAAGyF1s57AkmemuRFSS6sqvOHvlcmOTbJB6vq8CR/n+T5w7nTkvxEkkuS3JLkpas7XQAAAAAAVtvcw+zu/qsktYnTB9zF+E7yshWdFAAAAAAAkzL3bUYAAAAAAOCeCLMBAAAAAJg8YTYAAAAAAJMnzAYAAAAAYPKE2QAAAAAATJ4wGwAAAACAyRNmAwAAAAAwecJsAAAAAAAmT5gNAAAAAMDkCbMBAAAAAJg8YTYAAAAAAJMnzAYAAAAAYPKE2QAAAAAATJ4wGwAAAACAyRNmAwAAAAAwecJsAAAAAAAmT5gNAAAAAMDkCbMBAAAAAJg8YTYAAAAAAJMnzAYAAAAAYPKE2QAAAAAATJ4wGwAAAACAyRNmAwAAAAAwecJsAAAAAAAmT5gNAAAAAMDkCbMBAAAAAJg8YTYAAAAAAJMnzAYAAAAAYPKE2QAAAAAATJ4wGwAAAACAyRNmAwAAAAAwecJsAAAAAAAmb+28JwAAAAAALK51R5+6WeMuO/agFZ4JU2dlNgAAAAAAkyfMBgAAAABg8oTZAAAAAABMnjAbAAAAAIDJE2YDAAAAADB5wmwAAAAAACZPmA0AAAAAwOQJswEAAAAAmDxhNgAAAAAAkyfMBgAAAABg8oTZAAAAAABMnjAbAAAAAIDJE2YDAAAAADB5wmwAAAAAACZPmA0AAAAAwOQJswEAAAAAmDxhNgAAAAAAkyfMBgAAAABg8oTZAAAAAABMnjAbAAAAAIDJE2YDAAAAADB5wmwAAAAAACZPmA0AAAAAwOTNPcyuqndV1dVV9aUlfQ+pqtOr6qvD64OH/qqqt1bVJVV1QVXtM7+ZAwAAAACwWuYeZid5T5JnbdR3dJJPdfeeST41tJPkwCR7Dj9HJHn7Ks0RAAAAAIA5mnuY3d2fSXLtRt0HJzlxOD4xySFL+k/qmc8l2bGqHrE6MwUAAAAAYF7mHmZvws7dfdVw/M0kOw/HuyS5fMm4K4a+f6Oqjqiqc6rqnGuuuWblZgoAAAAAwIqbaph9p+7uJH0f3nd8d6/v7vU77bTTCswMAAAAAIDVMtUw+1sbtg8ZXq8e+q9MstuScbsOfQAAAAAAbMWmGmafkuSw4fiwJB9d0v/imtk3yQ1LtiMBAAAAAGArtXbeE6iq9yXZP8nDquqKJK9OcmySD1bV4Un+Psnzh+GnJfmJJJckuSXJS1d9wgAAAAAArLq5h9nd/cJNnDrgLsZ2kpet7IwAAAAAAJiaqW4zAgAAAAAAdxJmAwAAAAAwecJsAAAAAAAmT5gNAAAAAMDkCbMBAAAAAJg8YTYAAAAAAJMnzAYAAAAAYPKE2QAAAAAATJ4wGwAAAACAyRNmAwAAAAAwecJsAAAAAAAmT5gNAAAAAMDkCbMBAAAAAJg8YTYAAAAAAJMnzAYAAAAAYPKE2QAAAAAATJ4wGwAAAACAyRNmAwAAAAAwecJsAAAAAAAmT5gNAAAAAMDkCbMBAAAAAJg8YTYAAAAAAJMnzAYAAAAAYPKE2QAAAAAATJ4wGwAAAACAyRNmAwAAAAAwecJsAAAAAAAmT5gNAAAAAMDkCbMBAAAAAJg8YTYAAAAAAJMnzAYAAAAAYPKE2QAAAAAATN7aeU8AAAAAAGBzrTv61Hscc9mxB63CTFhtVmYDAAAAADB5wmwAAAAAACZPmA0AAAAAwOTZMxsAAAAA2GrZY3vrYWU2AAAAAACTZ2U2AAAAAEA2bxV3YiX3vFiZDQAAAADA5AmzAQAAAACYPGE2AAAAAACTJ8wGAAAAAGDyhNkAAAAAAEze2nlPAAAAAABgS7Tu6FM3a9xlxx60wjNZDFZmAwAAAAAwecJsAAAAAAAmT5gNAAAAAMDkCbMBAAAAAJg8YTYAAAAAAJMnzAYAAAAAYPKE2QAAAAAATJ4wGwAAAACAyRNmAwAAAAAwecJsAAAAAAAmb4sMs6vqWVX1laq6pKqOnvd8AAAAAABYWVtcmF1Va5K8LcmBSfZK8sKq2mu+swIAAAAAYCVtcWF2kicnuaS7L+3u25K8P8nBc54TAAAAAAAraEsMs3dJcvmS9hVDHwAAAAAAW6nq7nnP4V6pqucleVZ3/9zQflGSH+7uX95o3BFJjhiaj0nylVWd6LQ9LMm35z0J4B65VmHL4XqFLYNrFbYMrlXYMrhWWSmP7O6d7urE2tWeyQiuTLLbkvauQ9+/0t3HJzl+tSa1Jamqc7p7/bznAdw91ypsOVyvsGVwrcKWwbUKWwbXKvOwJW4z8rdJ9qyqPapquyQvSHLKnOcEAAAAAMAK2uJWZnf37VX1y0n+T5I1Sd7V3RfNeVoAAAAAAKygLS7MTpLuPi3JafOexxbM9iuwZXCtwpbD9QpbBtcqbBlcq7BlcK2y6ra4B0ACAAAAALB4tsQ9swEAAAAAWDDC7AVSVc+qqq9U1SVVdfS85wN8T1XtVlVnVtWXq+qiqjpy6H9IVZ1eVV8dXh8877kCSVWtqarzqurjQ3uPqjp7uMd+YHhINTBHVbVjVZ1cVf+vqi6uqv3cV2F6quq/DX///VJVva+qtndfhWmoqndV1dVV9aUlfXd5L62Ztw7X7QVVtc/8Zs7WTJi9IKpqTZK3JTkwyV5JXlhVe813VsAStyf5te7eK8m+SV42XKNHJ/lUd++Z5FNDG5i/I5NcvKR9XJI3d/ejk1yX5PC5zApY6i1JPtndj03yxMyuWfdVmJCq2iXJryRZ392PT7ImyQvivgpT8Z4kz9qob1P30gOT7Dn8HJHk7as0RxaMMHtxPDnJJd19aXffluT9SQ6e85yAQXdf1d1fGI5vyuwf3Ltkdp2eOAw7Mckh85khsEFV7ZrkoCTvHNqV5BlJTh6GuFZhzqrqQUl+NMkJSdLdt3X39XFfhSlam2SHqlqb5H5Jror7KkxCd38mybUbdW/qXnpwkpN65nNJdqyqR6zOTFkkwuzFsUuSy5e0rxj6gImpqnVJnpTk7CQ7d/dVw6lvJtl5TtMCvuf3kvxGkn8Z2g9Ncn133z603WNh/vZIck2Sdw9bAr2zqu4f91WYlO6+MskbknwjsxD7hiTnxn0VpmxT91K5E6tCmA0wIVX1gCR/luSo7r5x6bnu7iQ9l4kBSZKqenaSq7v73HnPBbhba5Psk+Tt3f2kJDdnoy1F3Fdh/oa9dg/O7D+gvj/J/fNvtzQAJsq9lHkQZi+OK5PstqS969AHTERVbZtZkP3e7v7w0P2tDb+aNbxePa/5AUmSpyZ5blVdltmWXc/IbF/eHYdfj07cY2EKrkhyRXefPbRPzizcdl+FafmPSb7e3dd093eTfDize637KkzXpu6lcidWhTB7cfxtkj2Hp0Jvl9lDNU6Z85yAwbDn7glJLu7uNy05dUqSw4bjw5J8dLXnBnxPdx/T3bt297rM7qVndPehSc5M8rxhmGsV5qy7v5nk8qp6zNB1QJIvx30VpuYbSfatqvsNfx/ecK26r8J0bepeekqSF9fMvkluWLIdCYymZr8RwCKoqp/IbJ/PNUne1d2/M+cpAYOqelqSzya5MN/bh/eVme2b/cEkuyf5+yTP7+6NH8ABzEFV7Z/k17v72VX1qMxWaj8kyXlJfra7b53n/GDRVdXemT2odbsklyZ5aWaLedxXYUKq6rVJfibJ7ZndQ38us3123VdhzqrqfUn2T/KwJN9K8uokf567uJcO/yH1vzPbKuiWJC/t7nPmMW+2bsJsAAAAAAAmzzYjAAAAAABMnjAbAAAAAIDJE2YDAAAAADB5wmwAAAAAACZPmA0AAAAAwOQJswEAYERV9btV9fSqOqSqjtnEmNdU1a8Pxy+pqu8f8fP3r6qnLGn/YlW9eKz6AAAwL8JsAAAY1w8n+VySH0vymc0Y/5Ik9yrMrqq1d3N6/yR3htnd/Y7uPune1AcAgCmq7p73HAAAYItXVa9P8uNJ9kjytSQ/kOTrSU7u7t/aaOxrkvxjksuSvCfJlUn+Kcl+SfZK8qYkD0jy7SQv6e6rqurTSc5P8rQk70vyd0lelWS7JN9JcmiSHTIL0u9Ick2Slyc5IMk/dvcbqmrvJO9Icr9hjv+lu68bap+d5OlJdkxyeHd/tqoel+Tdw2dsk+SnuvurI/2RAQDAvWJlNgAAjKC7/3uSwzMLp38oyQXd/YSNg+yN3nNyknOSHNrdeye5PcnvJ3led/9gkncl+Z0lb9muu9d39xuT/FWSfbv7SUnen+Q3uvuyzMLqN3f33t392Y0+8qQkr+juJyS5MMmrl5xb291PTnLUkv5fTPKWYW7rk1xxr/5QAABgRHf364kAAMC9s0+SLyZ5bJKL78P7H5Pk8UlOr6okWZPkqiXnP7DkeNckH6iqR2S2cvrrd1e4qh6UZMfuPmvoOjHJh5YM+fDwem6SdcPx3yT5zaraNcmHrcoGAGCehNkAALBMw/Yd78ksYP52Ztt4VFWdn2S/7v6nzS2V5KLu3m8T529ecvz7Sd7U3adU1f5JXnMfpr7UrcPrHRn+ndDdf1pVZyc5KMlpVfUL3X3GMj8HAADuE9uMAADAMnX3+cNWHH+X2Z7XZyT58WGrj3sKsm9K8sDh+CtJdqqq/ZKkqrYd9q2+Kw/KbK/tJDlsE/WWzvGGJNdV1Y8MXS9KctbG45aqqkclubS735rko0mecA/fBQAAVowwGwAARlBVOyW5rrv/Jclju/vLm/nW9yR5x7CKe02S5yU5rqq+mNkDH5+yife9JsmHqurczFaDb/CxJD9ZVecvCa43OCzJ66vqgiR7J9nkft6D5yf50jC3x2e25zYAAMxFdfe85wAAAAAAAHfLymwAAAAAACZPmA0AAAAAwOQJswEAAAAAmDxhNgAAAAAAkyfMBgAAAABg8oTZAAAAAABMnjAbAAAAAIDJE2YDAAAAADB5/x+xHvenqptZewAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1800x1800 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJ1qlQBTM3_N"
      },
      "source": [
        "result_dict_1 = {'batch_size': batch_size,\n",
        "                 'epochs': epochs,\n",
        "                 'num_pseudo': num_pseudo,\n",
        "                 'confidence': confidence,\n",
        "                 'y_test': y_test,\n",
        "                 'y_test_pred': y_test_pred,\n",
        "                 'test_f1s': test_f1s,\n",
        "                 'test_f1s_avg': test_f1s_avg,\n",
        "                 'pseudo_labels': pseudo_labels,\n",
        "                 'num_iterations': num_iterations}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9w5glWPvhIku",
        "outputId": "0d9bca11-681e-4484-880b-ce8909b179f7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URa2k2W7hQjE",
        "outputId": "b7fd1cc4-71d6-4508-c450-762746a3eece"
      },
      "source": [
        "%cd drive/MyDrive/Projects/ssl-mnist/src/Results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Projects/ssl-mnist/src/Results\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WJ-TG71Ls1p"
      },
      "source": [
        "import json\n",
        "\n",
        "data = {}\n",
        "data['results'] = []\n",
        "with open('cnn_results.txt', 'w') as outfile:\n",
        "    json.dump(data, outfile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuX3-wLxgMKp"
      },
      "source": [
        "result_dict_1 = {'batch_size': batch_size,\n",
        "                 'epochs': epochs,\n",
        "                 'num_pseudo': num_pseudo,\n",
        "                 'confidence': confidence,\n",
        "                 'y_test': y_test,\n",
        "                 'y_test_pred': y_test_pred,\n",
        "                 'test_f1s': test_f1s,\n",
        "                 'test_f1s_avg': test_f1s_avg,\n",
        "                 'pseudo_labels': pseudo_labels,\n",
        "                 'num_iterations': num_iterations}\n",
        "with open('data.txt') as json_file:\n",
        "    data = json.load(json_file)\n",
        "    data['results'].append(results_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfwDWxbKmVtR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "629a49dd-4895-4eda-d850-82b3625b8dfd"
      },
      "source": [
        "#HyperParams\n",
        "batch_size = 64\n",
        "epochs = 100 \n",
        "num_pseudo = 100\n",
        "confidence = 0.95\n",
        "y_test_2, y_test_pred_2, test_f1s_2, test_f1s_avg_2, pseudo_labels_2, num_iterations_2 = self_train_with_pretrain('CNN', num_pseudo, batch_size, epochs, confidence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "441/441 [==============================] - 2s 5ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 9/100\n",
            "441/441 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 10/100\n",
            "441/441 [==============================] - 3s 6ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 11/100\n",
            "441/441 [==============================] - 2s 5ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 12/100\n",
            "441/441 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 13/100\n",
            "441/441 [==============================] - 2s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 14/100\n",
            "441/441 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 15/100\n",
            "441/441 [==============================] - 2s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 16/100\n",
            "441/441 [==============================] - 2s 5ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 17/100\n",
            "441/441 [==============================] - 2s 6ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 18/100\n",
            "441/441 [==============================] - 2s 5ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 19/100\n",
            "441/441 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 20/100\n",
            "441/441 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 21/100\n",
            "441/441 [==============================] - 2s 6ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 22/100\n",
            "441/441 [==============================] - 2s 5ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 23/100\n",
            "441/441 [==============================] - 2s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 24/100\n",
            "441/441 [==============================] - 2s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 25/100\n",
            "441/441 [==============================] - 3s 6ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 26/100\n",
            "441/441 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 27/100\n",
            "441/441 [==============================] - 2s 5ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 28/100\n",
            "441/441 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 29/100\n",
            "441/441 [==============================] - 3s 6ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 30/100\n",
            "441/441 [==============================] - 2s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 31/100\n",
            "441/441 [==============================] - 2s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 32/100\n",
            "441/441 [==============================] - 3s 6ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 33/100\n",
            "441/441 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 34/100\n",
            "441/441 [==============================] - 2s 5ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 00034: early stopping\n",
            "Elapsed time: 77.436 sec\n",
            "Train f1 Score: [0.95669587 0.93955341 0.82866569 0.71793198 0.85787558 0.68117593\n",
            " 0.89277431 0.88034615 0.78972907 0.76973401]\n",
            "Test f1 Score: [0.95508982 0.95741056 0.83012259 0.73584158 0.8840219  0.70255349\n",
            " 0.88568257 0.87321063 0.79490291 0.79493671]\n",
            "Train f1 Score: 0.8314482004902365\n",
            "Test f1 Score: 0.8413772775593629\n",
            "Now predicting labels for unlabeled data...\n",
            "95 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3455 unlabelled instances remained to be predict in next iteration\n",
            "145 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 319\n",
            "28300 new labelled data is training...\n",
            "Epoch 1/100\n",
            "443/443 [==============================] - 2s 5ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 2/100\n",
            "443/443 [==============================] - 3s 6ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 3/100\n",
            "443/443 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 4/100\n",
            "443/443 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 5/100\n",
            "443/443 [==============================] - 2s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 6/100\n",
            "443/443 [==============================] - 3s 6ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 7/100\n",
            "443/443 [==============================] - 2s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 8/100\n",
            "443/443 [==============================] - 2s 5ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 9/100\n",
            "443/443 [==============================] - 2s 5ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 10/100\n",
            "443/443 [==============================] - 2s 6ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 11/100\n",
            "443/443 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 12/100\n",
            "443/443 [==============================] - 2s 5ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 13/100\n",
            "443/443 [==============================] - 2s 6ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 14/100\n",
            "443/443 [==============================] - 2s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 00014: early stopping\n",
            "Elapsed time: 32.200 sec\n",
            "Train f1 Score: [0.95628233 0.94040584 0.82883021 0.71885005 0.85768689 0.68301544\n",
            " 0.89277431 0.87920361 0.78944708 0.76924393]\n",
            "Test f1 Score: [0.95461347 0.95822677 0.83085013 0.73555028 0.88467299 0.7047488\n",
            " 0.8860478  0.87211094 0.79490291 0.79156203]\n",
            "Train f1 Score: 0.8315739697509519\n",
            "Test f1 Score: 0.8413286115989514\n",
            "Now predicting labels for unlabeled data...\n",
            "94 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3461 unlabelled instances remained to be predict in next iteration\n",
            "139 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 320\n",
            "28400 new labelled data is training...\n",
            "Epoch 1/100\n",
            "444/444 [==============================] - 2s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 2/100\n",
            "444/444 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 3/100\n",
            "444/444 [==============================] - 3s 6ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 4/100\n",
            "444/444 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 5/100\n",
            "444/444 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 6/100\n",
            "444/444 [==============================] - 2s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 7/100\n",
            "444/444 [==============================] - 3s 6ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 8/100\n",
            "444/444 [==============================] - 2s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 9/100\n",
            "444/444 [==============================] - 2s 5ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 10/100\n",
            "444/444 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 11/100\n",
            "444/444 [==============================] - 3s 6ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 12/100\n",
            "444/444 [==============================] - 2s 5ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 13/100\n",
            "444/444 [==============================] - 2s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 14/100\n",
            "444/444 [==============================] - 2s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 15/100\n",
            "444/444 [==============================] - 3s 6ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 16/100\n",
            "444/444 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 17/100\n",
            "444/444 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 18/100\n",
            "444/444 [==============================] - 2s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 19/100\n",
            "444/444 [==============================] - 2s 5ms/step - loss: 0.0090 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 20/100\n",
            "444/444 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 21/100\n",
            "444/444 [==============================] - 2s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 22/100\n",
            "444/444 [==============================] - 3s 6ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 23/100\n",
            "444/444 [==============================] - 2s 5ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 24/100\n",
            "444/444 [==============================] - 2s 5ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 25/100\n",
            "444/444 [==============================] - 2s 5ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 26/100\n",
            "444/444 [==============================] - 3s 6ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 27/100\n",
            "444/444 [==============================] - 2s 5ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 28/100\n",
            "444/444 [==============================] - 2s 5ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 29/100\n",
            "444/444 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 30/100\n",
            "444/444 [==============================] - 3s 6ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 31/100\n",
            "444/444 [==============================] - 2s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 32/100\n",
            "444/444 [==============================] - 2s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 33/100\n",
            "444/444 [==============================] - 2s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 34/100\n",
            "444/444 [==============================] - 3s 6ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 35/100\n",
            "444/444 [==============================] - 2s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 36/100\n",
            "444/444 [==============================] - 2s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 00036: early stopping\n",
            "Elapsed time: 82.820 sec\n",
            "Train f1 Score: [0.95656524 0.94012232 0.82687457 0.71837802 0.85806505 0.68121377\n",
            " 0.89168901 0.87992667 0.78923948 0.76974761]\n",
            "Test f1 Score: [0.95508982 0.95781849 0.82830931 0.7350495  0.88279302 0.70296347\n",
            " 0.88703395 0.87147977 0.79636364 0.79231935]\n",
            "Train f1 Score: 0.8311821742877411\n",
            "Test f1 Score: 0.840922032304033\n",
            "Now predicting labels for unlabeled data...\n",
            "91 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3470 unlabelled instances remained to be predict in next iteration\n",
            "130 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 321\n",
            "28500 new labelled data is training...\n",
            "Epoch 1/100\n",
            "446/446 [==============================] - 2s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 2/100\n",
            "446/446 [==============================] - 3s 6ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 3/100\n",
            "446/446 [==============================] - 2s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 4/100\n",
            "446/446 [==============================] - 2s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 5/100\n",
            "446/446 [==============================] - 3s 6ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 6/100\n",
            "446/446 [==============================] - 2s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 7/100\n",
            "446/446 [==============================] - 2s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 8/100\n",
            "446/446 [==============================] - 2s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 9/100\n",
            "446/446 [==============================] - 3s 6ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 10/100\n",
            "446/446 [==============================] - 2s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 11/100\n",
            "446/446 [==============================] - 2s 5ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 12/100\n",
            "446/446 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 13/100\n",
            "446/446 [==============================] - 2s 5ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 14/100\n",
            "446/446 [==============================] - 2s 5ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 15/100\n",
            "446/446 [==============================] - 2s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 16/100\n",
            "446/446 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 17/100\n",
            "446/446 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 18/100\n",
            "446/446 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 19/100\n",
            "446/446 [==============================] - 2s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 20/100\n",
            "446/446 [==============================] - 3s 6ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 21/100\n",
            "446/446 [==============================] - 2s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 22/100\n",
            "446/446 [==============================] - 2s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 23/100\n",
            "446/446 [==============================] - 2s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 00023: early stopping\n",
            "Elapsed time: 53.182 sec\n",
            "Train f1 Score: [0.95686994 0.94034738 0.82779781 0.7203928  0.8577822  0.68327078\n",
            " 0.89230494 0.88064543 0.79368273 0.77020874]\n",
            "Test f1 Score: [0.95461347 0.95822677 0.83121438 0.73680032 0.88355822 0.70434183\n",
            " 0.88555556 0.87263427 0.80072464 0.79355488]\n",
            "Train f1 Score: 0.832330275426776\n",
            "Test f1 Score: 0.842122433518082\n",
            "Now predicting labels for unlabeled data...\n",
            "93 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3477 unlabelled instances remained to be predict in next iteration\n",
            "123 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 322\n",
            "28600 new labelled data is training...\n",
            "Epoch 1/100\n",
            "447/447 [==============================] - 2s 6ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 2/100\n",
            "447/447 [==============================] - 2s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 3/100\n",
            "447/447 [==============================] - 2s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 4/100\n",
            "447/447 [==============================] - 2s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 5/100\n",
            "447/447 [==============================] - 3s 6ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 6/100\n",
            "447/447 [==============================] - 2s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 7/100\n",
            "447/447 [==============================] - 2s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 8/100\n",
            "447/447 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 9/100\n",
            "447/447 [==============================] - 3s 6ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 10/100\n",
            "447/447 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 11/100\n",
            "447/447 [==============================] - 2s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 12/100\n",
            "447/447 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 13/100\n",
            "447/447 [==============================] - 3s 6ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 14/100\n",
            "447/447 [==============================] - 2s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 15/100\n",
            "447/447 [==============================] - 2s 5ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 16/100\n",
            "447/447 [==============================] - 2s 5ms/step - loss: 0.0088 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 17/100\n",
            "447/447 [==============================] - 2s 6ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 18/100\n",
            "447/447 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 19/100\n",
            "447/447 [==============================] - 2s 5ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 20/100\n",
            "447/447 [==============================] - 3s 6ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 21/100\n",
            "447/447 [==============================] - 2s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 22/100\n",
            "447/447 [==============================] - 2s 5ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 23/100\n",
            "447/447 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 24/100\n",
            "447/447 [==============================] - 3s 6ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 25/100\n",
            "447/447 [==============================] - 2s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 26/100\n",
            "447/447 [==============================] - 2s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 27/100\n",
            "447/447 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 28/100\n",
            "447/447 [==============================] - 3s 6ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 29/100\n",
            "447/447 [==============================] - 2s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 30/100\n",
            "447/447 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 31/100\n",
            "447/447 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 32/100\n",
            "447/447 [==============================] - 3s 6ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 00032: early stopping\n",
            "Elapsed time: 74.526 sec\n",
            "Train f1 Score: [0.95679064 0.9416126  0.82671149 0.71661238 0.8582312  0.67927969\n",
            " 0.89263722 0.8802535  0.78952159 0.76933654]\n",
            "Test f1 Score: [0.95604396 0.95863539 0.83085013 0.73343849 0.88411588 0.69986169\n",
            " 0.88777778 0.87352791 0.79709267 0.79475542]\n",
            "Train f1 Score: 0.8310986858941725\n",
            "Test f1 Score: 0.8416099315049068\n",
            "Now predicting labels for unlabeled data...\n",
            "96 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3481 unlabelled instances remained to be predict in next iteration\n",
            "119 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 323\n",
            "28700 new labelled data is training...\n",
            "Epoch 1/100\n",
            "449/449 [==============================] - 2s 5ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 2/100\n",
            "449/449 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 3/100\n",
            "449/449 [==============================] - 2s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 4/100\n",
            "449/449 [==============================] - 3s 6ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 5/100\n",
            "449/449 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 6/100\n",
            "449/449 [==============================] - 2s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 7/100\n",
            "449/449 [==============================] - 2s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 8/100\n",
            "449/449 [==============================] - 3s 6ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 9/100\n",
            "449/449 [==============================] - 2s 4ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 10/100\n",
            "449/449 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 11/100\n",
            "449/449 [==============================] - 2s 5ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 12/100\n",
            "449/449 [==============================] - 3s 6ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 13/100\n",
            "449/449 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 14/100\n",
            "449/449 [==============================] - 2s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 15/100\n",
            "449/449 [==============================] - 2s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 16/100\n",
            "449/449 [==============================] - 3s 6ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 17/100\n",
            "449/449 [==============================] - 2s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 18/100\n",
            "449/449 [==============================] - 2s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 19/100\n",
            "449/449 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 20/100\n",
            "449/449 [==============================] - 3s 6ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 21/100\n",
            "449/449 [==============================] - 2s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 22/100\n",
            "449/449 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 23/100\n",
            "449/449 [==============================] - 2s 5ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 00023: early stopping\n",
            "Elapsed time: 51.957 sec\n",
            "Train f1 Score: [0.9565435  0.939254   0.82720588 0.718519   0.85830026 0.68183887\n",
            " 0.8926312  0.88048008 0.78997372 0.771261  ]\n",
            "Test f1 Score: [0.95413759 0.95741056 0.83012259 0.73780246 0.88557214 0.70255349\n",
            " 0.88482835 0.8741044  0.79854809 0.79837481]\n",
            "Train f1 Score: 0.8316007518126071\n",
            "Test f1 Score: 0.8423454480264756\n",
            "Now predicting labels for unlabeled data...\n",
            "88 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3493 unlabelled instances remained to be predict in next iteration\n",
            "107 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 324\n",
            "28800 new labelled data is training...\n",
            "Epoch 1/100\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 2/100\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 3/100\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 4/100\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 5/100\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 6/100\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 7/100\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 8/100\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 9/100\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 10/100\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 11/100\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 12/100\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 13/100\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 14/100\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 15/100\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 16/100\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 17/100\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 18/100\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 19/100\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 20/100\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 21/100\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 22/100\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 23/100\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 00023: early stopping\n",
            "Elapsed time: 52.080 sec\n",
            "Train f1 Score: [0.95704496 0.93995447 0.8265564  0.71888075 0.85861097 0.68416866\n",
            " 0.89172315 0.87950704 0.78874949 0.76993049]\n",
            "Test f1 Score: [0.95508982 0.95863539 0.83172656 0.73830293 0.88365095 0.70344828\n",
            " 0.88470067 0.87321063 0.79782082 0.79457559]\n",
            "Train f1 Score: 0.8315126382388224\n",
            "Test f1 Score: 0.842116164590393\n",
            "Now predicting labels for unlabeled data...\n",
            "94 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3499 unlabelled instances remained to be predict in next iteration\n",
            "101 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 325\n",
            "28900 new labelled data is training...\n",
            "Epoch 1/100\n",
            "452/452 [==============================] - 3s 6ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 2/100\n",
            "452/452 [==============================] - 2s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 3/100\n",
            "452/452 [==============================] - 2s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 4/100\n",
            "452/452 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 5/100\n",
            "452/452 [==============================] - 2s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 6/100\n",
            "452/452 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 7/100\n",
            "452/452 [==============================] - 2s 5ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 8/100\n",
            "452/452 [==============================] - 2s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 9/100\n",
            "452/452 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 10/100\n",
            "452/452 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 11/100\n",
            "452/452 [==============================] - 2s 5ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 12/100\n",
            "452/452 [==============================] - 2s 5ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 13/100\n",
            "452/452 [==============================] - 2s 5ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 14/100\n",
            "452/452 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 15/100\n",
            "452/452 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 16/100\n",
            "452/452 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 17/100\n",
            "452/452 [==============================] - 3s 6ms/step - loss: 0.0092 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 18/100\n",
            "452/452 [==============================] - 2s 5ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 19/100\n",
            "452/452 [==============================] - 2s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 20/100\n",
            "452/452 [==============================] - 2s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 21/100\n",
            "452/452 [==============================] - 3s 6ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 22/100\n",
            "452/452 [==============================] - 2s 5ms/step - loss: 0.0089 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 23/100\n",
            "452/452 [==============================] - 2s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 24/100\n",
            "452/452 [==============================] - 2s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 25/100\n",
            "452/452 [==============================] - 2s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 00025: early stopping\n",
            "Elapsed time: 57.642 sec\n",
            "Train f1 Score: [0.95771352 0.94105068 0.82718595 0.71845168 0.85837336 0.68530677\n",
            " 0.89186535 0.88003999 0.78668561 0.76868938]\n",
            "Test f1 Score: [0.95504496 0.95863539 0.83099825 0.73534073 0.88355822 0.70604396\n",
            " 0.88555556 0.87423313 0.79343864 0.79355488]\n",
            "Train f1 Score: 0.8315362289746007\n",
            "Test f1 Score: 0.8416403711827245\n",
            "Now predicting labels for unlabeled data...\n",
            "91 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3508 unlabelled instances remained to be predict in next iteration\n",
            "92 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 326\n",
            "Train f1 Score: [0.95771352 0.94105068 0.82718595 0.71845168 0.85837336 0.68530677\n",
            " 0.89186535 0.88003999 0.78668561 0.76868938]\n",
            "Test f1 Score: [0.95504496 0.95863539 0.83099825 0.73534073 0.88355822 0.70604396\n",
            " 0.88555556 0.87423313 0.79343864 0.79355488]\n",
            "Train f1 Score: 0.8315362289746007\n",
            "Test f1 Score: 0.8416403711827245\n",
            "Now predicting labels for unlabeled data...\n",
            "95 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3513 unlabelled instances remained to be predict in next iteration\n",
            "187 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 327\n",
            "29000 new labelled data is training...\n",
            "Epoch 1/100\n",
            "454/454 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 2/100\n",
            "454/454 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 3/100\n",
            "454/454 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 4/100\n",
            "454/454 [==============================] - 3s 6ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 5/100\n",
            "454/454 [==============================] - 2s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 6/100\n",
            "454/454 [==============================] - 2s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 7/100\n",
            "454/454 [==============================] - 2s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 8/100\n",
            "454/454 [==============================] - 2s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 9/100\n",
            "454/454 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 10/100\n",
            "454/454 [==============================] - 2s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 11/100\n",
            "454/454 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 12/100\n",
            "454/454 [==============================] - 2s 5ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 13/100\n",
            "454/454 [==============================] - 2s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 14/100\n",
            "454/454 [==============================] - 2s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 15/100\n",
            "454/454 [==============================] - 2s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 16/100\n",
            "454/454 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 17/100\n",
            "454/454 [==============================] - 2s 5ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 18/100\n",
            "454/454 [==============================] - 2s 5ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 19/100\n",
            "454/454 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 20/100\n",
            "454/454 [==============================] - 3s 6ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 21/100\n",
            "454/454 [==============================] - 2s 5ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 22/100\n",
            "454/454 [==============================] - 2s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 23/100\n",
            "454/454 [==============================] - 2s 5ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 24/100\n",
            "454/454 [==============================] - 3s 6ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 00024: early stopping\n",
            "Elapsed time: 55.295 sec\n",
            "Train f1 Score: [0.95720495 0.93970421 0.82751745 0.71788183 0.85820587 0.6811958\n",
            " 0.89164142 0.87944565 0.79026558 0.77064536]\n",
            "Test f1 Score: [0.95652174 0.95822677 0.83230904 0.7364678  0.88568588 0.69896194\n",
            " 0.88531856 0.87397541 0.8        0.79797468]\n",
            "Train f1 Score: 0.831370810800794\n",
            "Test f1 Score: 0.8425441825753172\n",
            "Now predicting labels for unlabeled data...\n",
            "90 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3523 unlabelled instances remained to be predict in next iteration\n",
            "177 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 328\n",
            "29100 new labelled data is training...\n",
            "Epoch 1/100\n",
            "455/455 [==============================] - 2s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 2/100\n",
            "455/455 [==============================] - 2s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 3/100\n",
            "455/455 [==============================] - 2s 5ms/step - loss: 0.0094 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 4/100\n",
            "455/455 [==============================] - 3s 6ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 5/100\n",
            "455/455 [==============================] - 2s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 6/100\n",
            "455/455 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 7/100\n",
            "455/455 [==============================] - 2s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 8/100\n",
            "455/455 [==============================] - 3s 6ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 9/100\n",
            "455/455 [==============================] - 2s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 10/100\n",
            "455/455 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 11/100\n",
            "455/455 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 12/100\n",
            "455/455 [==============================] - 3s 6ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 13/100\n",
            "455/455 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 14/100\n",
            "455/455 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 15/100\n",
            "455/455 [==============================] - 2s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 16/100\n",
            "455/455 [==============================] - 3s 6ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 17/100\n",
            "455/455 [==============================] - 2s 5ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 18/100\n",
            "455/455 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 19/100\n",
            "455/455 [==============================] - 2s 5ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 20/100\n",
            "455/455 [==============================] - 2s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 21/100\n",
            "455/455 [==============================] - 3s 6ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 22/100\n",
            "455/455 [==============================] - 2s 5ms/step - loss: 0.0091 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 23/100\n",
            "455/455 [==============================] - 2s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 24/100\n",
            "455/455 [==============================] - 3s 6ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 25/100\n",
            "455/455 [==============================] - 2s 5ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 26/100\n",
            "455/455 [==============================] - 2s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 27/100\n",
            "455/455 [==============================] - 2s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 28/100\n",
            "455/455 [==============================] - 3s 6ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 29/100\n",
            "455/455 [==============================] - 2s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 30/100\n",
            "455/455 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 31/100\n",
            "455/455 [==============================] - 2s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 00031: early stopping\n",
            "Elapsed time: 72.331 sec\n",
            "Train f1 Score: [0.95735073 0.93916998 0.82657899 0.71843393 0.85873266 0.68125356\n",
            " 0.89209916 0.87908606 0.78887203 0.77066895]\n",
            "Test f1 Score: [0.95652174 0.95781849 0.83027122 0.73634204 0.88309082 0.70255349\n",
            " 0.88531856 0.8741044  0.79782082 0.79617514]\n",
            "Train f1 Score: 0.8312246055389398\n",
            "Test f1 Score: 0.8420016715129174\n",
            "Now predicting labels for unlabeled data...\n",
            "97 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3526 unlabelled instances remained to be predict in next iteration\n",
            "174 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 329\n",
            "29200 new labelled data is training...\n",
            "Epoch 1/100\n",
            "457/457 [==============================] - 3s 6ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 2/100\n",
            "457/457 [==============================] - 2s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 3/100\n",
            "457/457 [==============================] - 2s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 4/100\n",
            "457/457 [==============================] - 2s 5ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 5/100\n",
            "457/457 [==============================] - 2s 5ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 6/100\n",
            "457/457 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 7/100\n",
            "457/457 [==============================] - 2s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 8/100\n",
            "457/457 [==============================] - 2s 5ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 9/100\n",
            "457/457 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 10/100\n",
            "457/457 [==============================] - 3s 6ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 11/100\n",
            "457/457 [==============================] - 2s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 12/100\n",
            "457/457 [==============================] - 2s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 13/100\n",
            "457/457 [==============================] - 2s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 14/100\n",
            "457/457 [==============================] - 2s 5ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 15/100\n",
            "457/457 [==============================] - 2s 5ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 16/100\n",
            "457/457 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 17/100\n",
            "457/457 [==============================] - 2s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 00017: early stopping\n",
            "Elapsed time: 39.969 sec\n",
            "Train f1 Score: [0.95686994 0.93996301 0.82844867 0.71832734 0.85782774 0.68138873\n",
            " 0.89156842 0.8804592  0.78911702 0.76928369]\n",
            "Test f1 Score: [0.95508982 0.95822677 0.83157895 0.7352592  0.88214818 0.70523416\n",
            " 0.8865406  0.87455197 0.79636364 0.79535119]\n",
            "Train f1 Score: 0.8313253763828186\n",
            "Test f1 Score: 0.8420344477917159\n",
            "Now predicting labels for unlabeled data...\n",
            "94 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3532 unlabelled instances remained to be predict in next iteration\n",
            "168 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 330\n",
            "29300 new labelled data is training...\n",
            "Epoch 1/100\n",
            "458/458 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 2/100\n",
            "458/458 [==============================] - 2s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 3/100\n",
            "458/458 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 4/100\n",
            "458/458 [==============================] - 2s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 5/100\n",
            "458/458 [==============================] - 3s 6ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 6/100\n",
            "458/458 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 7/100\n",
            "458/458 [==============================] - 2s 5ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 8/100\n",
            "458/458 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 9/100\n",
            "458/458 [==============================] - 3s 6ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 10/100\n",
            "458/458 [==============================] - 2s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 11/100\n",
            "458/458 [==============================] - 2s 5ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 12/100\n",
            "458/458 [==============================] - 2s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 13/100\n",
            "458/458 [==============================] - 3s 6ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 14/100\n",
            "458/458 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 15/100\n",
            "458/458 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 16/100\n",
            "458/458 [==============================] - 2s 5ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 17/100\n",
            "458/458 [==============================] - 3s 6ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 18/100\n",
            "458/458 [==============================] - 2s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 19/100\n",
            "458/458 [==============================] - 2s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 00019: early stopping\n",
            "Elapsed time: 43.616 sec\n",
            "Train f1 Score: [0.958452   0.94002134 0.82695838 0.71865423 0.85867769 0.68221641\n",
            " 0.89131017 0.87989339 0.78787879 0.76999742]\n",
            "Test f1 Score: [0.95743615 0.95781849 0.83260298 0.7355959  0.88545817 0.70199587\n",
            " 0.8865406  0.87468031 0.79417122 0.79737241]\n",
            "Train f1 Score: 0.8314059828085391\n",
            "Test f1 Score: 0.8423672097806948\n",
            "Now predicting labels for unlabeled data...\n",
            "97 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3535 unlabelled instances remained to be predict in next iteration\n",
            "165 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 331\n",
            "29400 new labelled data is training...\n",
            "Epoch 1/100\n",
            "460/460 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 2/100\n",
            "460/460 [==============================] - 3s 6ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 3/100\n",
            "460/460 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 4/100\n",
            "460/460 [==============================] - 2s 5ms/step - loss: 0.0094 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 5/100\n",
            "460/460 [==============================] - 2s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 6/100\n",
            "460/460 [==============================] - 3s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 7/100\n",
            "460/460 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 8/100\n",
            "460/460 [==============================] - 2s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 9/100\n",
            "460/460 [==============================] - 2s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 10/100\n",
            "460/460 [==============================] - 2s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 11/100\n",
            "460/460 [==============================] - 2s 5ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 12/100\n",
            "460/460 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 13/100\n",
            "460/460 [==============================] - 2s 5ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 14/100\n",
            "460/460 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 15/100\n",
            "460/460 [==============================] - 2s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 16/100\n",
            "460/460 [==============================] - 2s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 17/100\n",
            "460/460 [==============================] - 2s 5ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 18/100\n",
            "460/460 [==============================] - 2s 5ms/step - loss: 0.0089 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 19/100\n",
            "460/460 [==============================] - 3s 6ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 20/100\n",
            "460/460 [==============================] - 2s 5ms/step - loss: 0.0089 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 21/100\n",
            "460/460 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 22/100\n",
            "460/460 [==============================] - 2s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 23/100\n",
            "460/460 [==============================] - 3s 6ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 00023: early stopping\n",
            "Elapsed time: 53.695 sec\n",
            "Train f1 Score: [0.95799866 0.93989615 0.82691572 0.71832365 0.85851557 0.68318745\n",
            " 0.89203887 0.88023952 0.78784195 0.77010407]\n",
            "Test f1 Score: [0.95656515 0.95781849 0.83063457 0.73496835 0.88423154 0.70385675\n",
            " 0.88555556 0.87525562 0.79490291 0.79615579]\n",
            "Train f1 Score: 0.831506160718828\n",
            "Test f1 Score: 0.8419944741437331\n",
            "Now predicting labels for unlabeled data...\n",
            "97 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3538 unlabelled instances remained to be predict in next iteration\n",
            "162 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 332\n",
            "29500 new labelled data is training...\n",
            "Epoch 1/100\n",
            "461/461 [==============================] - 2s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 2/100\n",
            "461/461 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 3/100\n",
            "461/461 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 4/100\n",
            "461/461 [==============================] - 3s 6ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 5/100\n",
            "461/461 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 6/100\n",
            "461/461 [==============================] - 2s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 7/100\n",
            "461/461 [==============================] - 2s 5ms/step - loss: 0.0088 - sparse_categorical_accuracy: 0.9965\n",
            "Epoch 8/100\n",
            "461/461 [==============================] - 3s 6ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 9/100\n",
            "461/461 [==============================] - 2s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 10/100\n",
            "461/461 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 11/100\n",
            "461/461 [==============================] - 2s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 12/100\n",
            "461/461 [==============================] - 3s 6ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 13/100\n",
            "461/461 [==============================] - 2s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 14/100\n",
            "461/461 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 15/100\n",
            "461/461 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 16/100\n",
            "461/461 [==============================] - 3s 6ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 17/100\n",
            "461/461 [==============================] - 2s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 18/100\n",
            "461/461 [==============================] - 2s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 19/100\n",
            "461/461 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 20/100\n",
            "461/461 [==============================] - 3s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 21/100\n",
            "461/461 [==============================] - 2s 5ms/step - loss: 0.0056 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 22/100\n",
            "461/461 [==============================] - 2s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 23/100\n",
            "461/461 [==============================] - 2s 5ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 24/100\n",
            "461/461 [==============================] - 2s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 25/100\n",
            "461/461 [==============================] - 3s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 26/100\n",
            "461/461 [==============================] - 2s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 27/100\n",
            "461/461 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 28/100\n",
            "461/461 [==============================] - 2s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 29/100\n",
            "461/461 [==============================] - 3s 6ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 30/100\n",
            "461/461 [==============================] - 2s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 31/100\n",
            "461/461 [==============================] - 2s 5ms/step - loss: 0.0093 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 32/100\n",
            "461/461 [==============================] - 2s 5ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 33/100\n",
            "461/461 [==============================] - 3s 6ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 00033: early stopping\n",
            "Elapsed time: 76.838 sec\n",
            "Train f1 Score: [0.95687714 0.93985497 0.82755978 0.71847067 0.85839828 0.68127354\n",
            " 0.8914245  0.88011988 0.78830196 0.77005072]\n",
            "Test f1 Score: [0.9551346  0.95741056 0.83063457 0.73388691 0.88288288 0.69896194\n",
            " 0.88372093 0.87468031 0.79490291 0.7959596 ]\n",
            "Train f1 Score: 0.8312331428203729\n",
            "Test f1 Score: 0.8408175209836987\n",
            "Now predicting labels for unlabeled data...\n",
            "95 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3543 unlabelled instances remained to be predict in next iteration\n",
            "157 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 333\n",
            "29600 new labelled data is training...\n",
            "Epoch 1/100\n",
            "463/463 [==============================] - 2s 5ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 2/100\n",
            "463/463 [==============================] - 2s 5ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 3/100\n",
            "463/463 [==============================] - 2s 5ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 4/100\n",
            "463/463 [==============================] - 3s 6ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 5/100\n",
            "463/463 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 6/100\n",
            "463/463 [==============================] - 2s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 7/100\n",
            "463/463 [==============================] - 2s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 8/100\n",
            "463/463 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 9/100\n",
            "463/463 [==============================] - 2s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 10/100\n",
            "463/463 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 11/100\n",
            "463/463 [==============================] - 2s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 12/100\n",
            "463/463 [==============================] - 3s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 13/100\n",
            "463/463 [==============================] - 2s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 00013: early stopping\n",
            "Elapsed time: 30.449 sec\n",
            "Train f1 Score: [0.95779356 0.94102564 0.82853855 0.71856835 0.85877578 0.68148148\n",
            " 0.89243099 0.87975368 0.79086684 0.7700755 ]\n",
            "Test f1 Score: [0.95652174 0.95904437 0.83245614 0.73330699 0.88522954 0.70255349\n",
            " 0.88691796 0.87352791 0.79782082 0.79616549]\n",
            "Train f1 Score: 0.8319310377439504\n",
            "Test f1 Score: 0.8423544445969483\n",
            "Now predicting labels for unlabeled data...\n",
            "92 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3551 unlabelled instances remained to be predict in next iteration\n",
            "149 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 334\n",
            "29700 new labelled data is training...\n",
            "Epoch 1/100\n",
            "465/465 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 2/100\n",
            "465/465 [==============================] - 2s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 3/100\n",
            "465/465 [==============================] - 2s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 4/100\n",
            "465/465 [==============================] - 3s 6ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 5/100\n",
            "465/465 [==============================] - 2s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 6/100\n",
            "465/465 [==============================] - 2s 5ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 7/100\n",
            "465/465 [==============================] - 2s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 8/100\n",
            "465/465 [==============================] - 3s 6ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 9/100\n",
            "465/465 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 10/100\n",
            "465/465 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 11/100\n",
            "465/465 [==============================] - 2s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 12/100\n",
            "465/465 [==============================] - 3s 6ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 13/100\n",
            "465/465 [==============================] - 2s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 14/100\n",
            "465/465 [==============================] - 2s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 15/100\n",
            "465/465 [==============================] - 2s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 16/100\n",
            "465/465 [==============================] - 3s 6ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 17/100\n",
            "465/465 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 18/100\n",
            "465/465 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 00018: early stopping\n",
            "Elapsed time: 42.251 sec\n",
            "Train f1 Score: [0.95742194 0.939521   0.82877764 0.71780142 0.85865607 0.68209278\n",
            " 0.89255167 0.87857024 0.78915967 0.77057613]\n",
            "Test f1 Score: [0.95508982 0.95741056 0.83172656 0.73388691 0.88578554 0.70034602\n",
            " 0.88617435 0.87224218 0.79782082 0.79596977]\n",
            "Train f1 Score: 0.831512857858122\n",
            "Test f1 Score: 0.8416452526540077\n",
            "Now predicting labels for unlabeled data...\n",
            "91 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3560 unlabelled instances remained to be predict in next iteration\n",
            "140 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 335\n",
            "29800 new labelled data is training...\n",
            "Epoch 1/100\n",
            "466/466 [==============================] - 2s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 2/100\n",
            "466/466 [==============================] - 3s 6ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 3/100\n",
            "466/466 [==============================] - 2s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 4/100\n",
            "466/466 [==============================] - 2s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 5/100\n",
            "466/466 [==============================] - 2s 5ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 6/100\n",
            "466/466 [==============================] - 3s 6ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 7/100\n",
            "466/466 [==============================] - 2s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 8/100\n",
            "466/466 [==============================] - 2s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9966\n",
            "Epoch 9/100\n",
            "466/466 [==============================] - 2s 5ms/step - loss: 0.0089 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 10/100\n",
            "466/466 [==============================] - 3s 6ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 11/100\n",
            "466/466 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 12/100\n",
            "466/466 [==============================] - 2s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 13/100\n",
            "466/466 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 14/100\n",
            "466/466 [==============================] - 3s 6ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 15/100\n",
            "466/466 [==============================] - 2s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 16/100\n",
            "466/466 [==============================] - 2s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 17/100\n",
            "466/466 [==============================] - 2s 5ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 00017: early stopping\n",
            "Elapsed time: 40.745 sec\n",
            "Train f1 Score: [0.95812395 0.94120162 0.82648541 0.71867643 0.85903704 0.68502777\n",
            " 0.89093181 0.87919967 0.78944175 0.77027259]\n",
            "Test f1 Score: [0.95647824 0.95904437 0.83099825 0.73475851 0.88555722 0.7032967\n",
            " 0.8865406  0.87179487 0.79854809 0.79436903]\n",
            "Train f1 Score: 0.8318398046041517\n",
            "Test f1 Score: 0.842138588907266\n",
            "Now predicting labels for unlabeled data...\n",
            "94 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3566 unlabelled instances remained to be predict in next iteration\n",
            "134 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 336\n",
            "29900 new labelled data is training...\n",
            "Epoch 1/100\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 2/100\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 3/100\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 4/100\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 5/100\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 6/100\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 7/100\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 8/100\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 9/100\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0097 - sparse_categorical_accuracy: 0.9966\n",
            "Epoch 10/100\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 11/100\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 12/100\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 13/100\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 14/100\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 15/100\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 16/100\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 17/100\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 18/100\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 19/100\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 20/100\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.0095 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 21/100\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.0092 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 22/100\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 23/100\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 24/100\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 25/100\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 26/100\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 27/100\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 28/100\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 29/100\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 30/100\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 31/100\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 32/100\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 33/100\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 34/100\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.0088 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 35/100\n",
            "468/468 [==============================] - 3s 5ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 36/100\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 37/100\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 38/100\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 39/100\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 40/100\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 41/100\n",
            "468/468 [==============================] - 2s 5ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 00041: early stopping\n",
            "Elapsed time: 97.191 sec\n",
            "Train f1 Score: [0.95713928 0.94056516 0.82712176 0.71956422 0.85799503 0.68482579\n",
            " 0.89094962 0.88061191 0.7893139  0.76953393]\n",
            "Test f1 Score: [0.95508982 0.95700298 0.83136224 0.73797217 0.88455772 0.70661157\n",
            " 0.88470067 0.87321063 0.79538555 0.7933635 ]\n",
            "Train f1 Score: 0.8317620589980212\n",
            "Test f1 Score: 0.8419256849264368\n",
            "Now predicting labels for unlabeled data...\n",
            "97 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3569 unlabelled instances remained to be predict in next iteration\n",
            "131 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 337\n",
            "30000 new labelled data is training...\n",
            "Epoch 1/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 2/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 3/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 4/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 5/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0091 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 6/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 7/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0090 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 8/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 9/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 10/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 11/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 12/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 13/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 00013: early stopping\n",
            "Elapsed time: 30.864 sec\n",
            "Train f1 Score: [0.95726924 0.93996301 0.82745457 0.71873772 0.8588245  0.68397677\n",
            " 0.89128498 0.87838289 0.7877129  0.7689543 ]\n",
            "Test f1 Score: [0.95561097 0.95659574 0.83041958 0.73579658 0.88411588 0.70214236\n",
            " 0.88372093 0.87224218 0.79465371 0.79396985]\n",
            "Train f1 Score: 0.8312560886765784\n",
            "Test f1 Score: 0.8409267789436834\n",
            "Now predicting labels for unlabeled data...\n",
            "99 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3570 unlabelled instances remained to be predict in next iteration\n",
            "130 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 338\n",
            "30100 new labelled data is training...\n",
            "Epoch 1/100\n",
            "471/471 [==============================] - 3s 6ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 2/100\n",
            "471/471 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 3/100\n",
            "471/471 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 4/100\n",
            "471/471 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 5/100\n",
            "471/471 [==============================] - 2s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 6/100\n",
            "471/471 [==============================] - 3s 6ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 7/100\n",
            "471/471 [==============================] - 2s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 8/100\n",
            "471/471 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 9/100\n",
            "471/471 [==============================] - 2s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 10/100\n",
            "471/471 [==============================] - 3s 6ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 11/100\n",
            "471/471 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 12/100\n",
            "471/471 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 13/100\n",
            "471/471 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 14/100\n",
            "471/471 [==============================] - 3s 6ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 15/100\n",
            "471/471 [==============================] - 2s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 16/100\n",
            "471/471 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 17/100\n",
            "471/471 [==============================] - 2s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 18/100\n",
            "471/471 [==============================] - 3s 6ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 19/100\n",
            "471/471 [==============================] - 2s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 00019: early stopping\n",
            "Elapsed time: 45.089 sec\n",
            "Train f1 Score: [0.95814886 0.94018067 0.82832618 0.71871322 0.85976366 0.68191647\n",
            " 0.89200536 0.87995999 0.79026066 0.77006266]\n",
            "Test f1 Score: [0.95504496 0.95741056 0.83282141 0.7352592  0.88723299 0.70076019\n",
            " 0.88617435 0.87352791 0.79733817 0.79615579]\n",
            "Train f1 Score: 0.8319337711948835\n",
            "Test f1 Score: 0.8421725527849373\n",
            "Now predicting labels for unlabeled data...\n",
            "94 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3576 unlabelled instances remained to be predict in next iteration\n",
            "124 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 339\n",
            "30200 new labelled data is training...\n",
            "Epoch 1/100\n",
            "472/472 [==============================] - 2s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 2/100\n",
            "472/472 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 3/100\n",
            "472/472 [==============================] - 2s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 4/100\n",
            "472/472 [==============================] - 3s 6ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 5/100\n",
            "472/472 [==============================] - 2s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 6/100\n",
            "472/472 [==============================] - 2s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 7/100\n",
            "472/472 [==============================] - 2s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 8/100\n",
            "472/472 [==============================] - 3s 6ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 9/100\n",
            "472/472 [==============================] - 2s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 10/100\n",
            "472/472 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 11/100\n",
            "472/472 [==============================] - 2s 5ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 12/100\n",
            "472/472 [==============================] - 3s 6ms/step - loss: 0.0090 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 13/100\n",
            "472/472 [==============================] - 2s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 14/100\n",
            "472/472 [==============================] - 2s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 15/100\n",
            "472/472 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 16/100\n",
            "472/472 [==============================] - 3s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 00016: early stopping\n",
            "Elapsed time: 38.407 sec\n",
            "Train f1 Score: [0.95780062 0.93932073 0.82856924 0.71901422 0.85844145 0.68546834\n",
            " 0.891151   0.87995999 0.78730094 0.76973177]\n",
            "Test f1 Score: [0.95504496 0.95659574 0.83136224 0.73600635 0.88513178 0.70378007\n",
            " 0.88555556 0.87237314 0.79392097 0.79435484]\n",
            "Train f1 Score: 0.8316758301235891\n",
            "Test f1 Score: 0.841412564696865\n",
            "Now predicting labels for unlabeled data...\n",
            "96 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3580 unlabelled instances remained to be predict in next iteration\n",
            "120 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 340\n",
            "30300 new labelled data is training...\n",
            "Epoch 1/100\n",
            "474/474 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 2/100\n",
            "474/474 [==============================] - 2s 5ms/step - loss: 0.0094 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 3/100\n",
            "474/474 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 4/100\n",
            "474/474 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 5/100\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 6/100\n",
            "474/474 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 7/100\n",
            "474/474 [==============================] - 2s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 8/100\n",
            "474/474 [==============================] - 2s 5ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 9/100\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 10/100\n",
            "474/474 [==============================] - 2s 5ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 11/100\n",
            "474/474 [==============================] - 2s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 12/100\n",
            "474/474 [==============================] - 2s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 13/100\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 14/100\n",
            "474/474 [==============================] - 2s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 15/100\n",
            "474/474 [==============================] - 2s 5ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 16/100\n",
            "474/474 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 17/100\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 18/100\n",
            "474/474 [==============================] - 2s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 19/100\n",
            "474/474 [==============================] - 2s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 20/100\n",
            "474/474 [==============================] - 2s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 21/100\n",
            "474/474 [==============================] - 2s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 22/100\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 23/100\n",
            "474/474 [==============================] - 2s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 24/100\n",
            "474/474 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 25/100\n",
            "474/474 [==============================] - 2s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 26/100\n",
            "474/474 [==============================] - 3s 6ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 27/100\n",
            "474/474 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 00027: early stopping\n",
            "Elapsed time: 64.631 sec\n",
            "Train f1 Score: [0.95758183 0.9399047  0.82936173 0.71921569 0.85851398 0.6834925\n",
            " 0.89208505 0.88045288 0.7857433  0.76909901]\n",
            "Test f1 Score: [0.95652174 0.95700298 0.83245614 0.7348874  0.88334995 0.70434183\n",
            " 0.88913649 0.87308086 0.79123554 0.7919598 ]\n",
            "Train f1 Score: 0.8315450662644688\n",
            "Test f1 Score: 0.8413972732882605\n",
            "Now predicting labels for unlabeled data...\n",
            "96 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3584 unlabelled instances remained to be predict in next iteration\n",
            "116 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 341\n",
            "30400 new labelled data is training...\n",
            "Epoch 1/100\n",
            "475/475 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 2/100\n",
            "475/475 [==============================] - 2s 5ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 3/100\n",
            "475/475 [==============================] - 3s 6ms/step - loss: 0.0100 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 4/100\n",
            "475/475 [==============================] - 2s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 5/100\n",
            "475/475 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 6/100\n",
            "475/475 [==============================] - 2s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 7/100\n",
            "475/475 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 8/100\n",
            "475/475 [==============================] - 3s 6ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 9/100\n",
            "475/475 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 10/100\n",
            "475/475 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 11/100\n",
            "475/475 [==============================] - 3s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 12/100\n",
            "475/475 [==============================] - 3s 6ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 13/100\n",
            "475/475 [==============================] - 2s 5ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 14/100\n",
            "475/475 [==============================] - 2s 5ms/step - loss: 0.0088 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 15/100\n",
            "475/475 [==============================] - 2s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 16/100\n",
            "475/475 [==============================] - 3s 6ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 17/100\n",
            "475/475 [==============================] - 2s 5ms/step - loss: 0.0089 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 18/100\n",
            "475/475 [==============================] - 2s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 19/100\n",
            "475/475 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 20/100\n",
            "475/475 [==============================] - 3s 6ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 21/100\n",
            "475/475 [==============================] - 2s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 22/100\n",
            "475/475 [==============================] - 2s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 23/100\n",
            "475/475 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 24/100\n",
            "475/475 [==============================] - 3s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 25/100\n",
            "475/475 [==============================] - 2s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 00025: early stopping\n",
            "Elapsed time: 60.532 sec\n",
            "Train f1 Score: [0.95752508 0.93924536 0.82796604 0.71871728 0.85917826 0.68343195\n",
            " 0.89118801 0.88107119 0.78767609 0.769891  ]\n",
            "Test f1 Score: [0.95652174 0.95659574 0.83136224 0.7350495  0.88323353 0.70255349\n",
            " 0.88531856 0.87583035 0.79343864 0.7969697 ]\n",
            "Train f1 Score: 0.8315890270144054\n",
            "Test f1 Score: 0.8416873497753372\n",
            "Now predicting labels for unlabeled data...\n",
            "96 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3588 unlabelled instances remained to be predict in next iteration\n",
            "112 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 342\n",
            "30500 new labelled data is training...\n",
            "Epoch 1/100\n",
            "477/477 [==============================] - 2s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 2/100\n",
            "477/477 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 3/100\n",
            "477/477 [==============================] - 2s 5ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 4/100\n",
            "477/477 [==============================] - 3s 6ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 5/100\n",
            "477/477 [==============================] - 2s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 6/100\n",
            "477/477 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 7/100\n",
            "477/477 [==============================] - 2s 5ms/step - loss: 0.0094 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 8/100\n",
            "477/477 [==============================] - 3s 6ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 9/100\n",
            "477/477 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 10/100\n",
            "477/477 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 11/100\n",
            "477/477 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 12/100\n",
            "477/477 [==============================] - 2s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 13/100\n",
            "477/477 [==============================] - 3s 6ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 14/100\n",
            "477/477 [==============================] - 2s 5ms/step - loss: 0.0092 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 15/100\n",
            "477/477 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 16/100\n",
            "477/477 [==============================] - 2s 5ms/step - loss: 0.0090 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 00016: early stopping\n",
            "Elapsed time: 38.093 sec\n",
            "Train f1 Score: [0.95767107 0.93977103 0.82891603 0.71779821 0.85773469 0.68096759\n",
            " 0.89153839 0.88020008 0.78907436 0.76825614]\n",
            "Test f1 Score: [0.95647824 0.95700298 0.83282141 0.73351757 0.88244122 0.69944598\n",
            " 0.88482835 0.87339826 0.79636364 0.79296482]\n",
            "Train f1 Score: 0.8311927609585211\n",
            "Test f1 Score: 0.8409262471835127\n",
            "Now predicting labels for unlabeled data...\n",
            "96 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3592 unlabelled instances remained to be predict in next iteration\n",
            "108 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 343\n",
            "30600 new labelled data is training...\n",
            "Epoch 1/100\n",
            "479/479 [==============================] - 3s 6ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 2/100\n",
            "479/479 [==============================] - 2s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 3/100\n",
            "479/479 [==============================] - 2s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 4/100\n",
            "479/479 [==============================] - 2s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 5/100\n",
            "479/479 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 6/100\n",
            "479/479 [==============================] - 3s 6ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 7/100\n",
            "479/479 [==============================] - 2s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 8/100\n",
            "479/479 [==============================] - 2s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 9/100\n",
            "479/479 [==============================] - 2s 5ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 10/100\n",
            "479/479 [==============================] - 3s 6ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 11/100\n",
            "479/479 [==============================] - 2s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 12/100\n",
            "479/479 [==============================] - 2s 5ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 13/100\n",
            "479/479 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 14/100\n",
            "479/479 [==============================] - 2s 5ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 15/100\n",
            "479/479 [==============================] - 3s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 16/100\n",
            "479/479 [==============================] - 2s 5ms/step - loss: 0.0090 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 17/100\n",
            "479/479 [==============================] - 2s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 18/100\n",
            "479/479 [==============================] - 2s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 19/100\n",
            "479/479 [==============================] - 3s 6ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 20/100\n",
            "479/479 [==============================] - 2s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 21/100\n",
            "479/479 [==============================] - 2s 5ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 22/100\n",
            "479/479 [==============================] - 2s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 23/100\n",
            "479/479 [==============================] - 3s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 24/100\n",
            "479/479 [==============================] - 3s 5ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 25/100\n",
            "479/479 [==============================] - 2s 5ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 26/100\n",
            "479/479 [==============================] - 2s 5ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 27/100\n",
            "479/479 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 28/100\n",
            "479/479 [==============================] - 3s 6ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 29/100\n",
            "479/479 [==============================] - 2s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 30/100\n",
            "479/479 [==============================] - 2s 5ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 31/100\n",
            "479/479 [==============================] - 2s 5ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 32/100\n",
            "479/479 [==============================] - 3s 6ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 33/100\n",
            "479/479 [==============================] - 3s 5ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 34/100\n",
            "479/479 [==============================] - 2s 5ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 35/100\n",
            "479/479 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 36/100\n",
            "479/479 [==============================] - 2s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 37/100\n",
            "479/479 [==============================] - 3s 6ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 38/100\n",
            "479/479 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 00038: early stopping\n",
            "Elapsed time: 91.557 sec\n",
            "Train f1 Score: [0.95732777 0.94010528 0.82949662 0.71987971 0.85825275 0.68678389\n",
            " 0.89160061 0.88044749 0.78766984 0.76915158]\n",
            "Test f1 Score: [0.95652174 0.95741056 0.83245614 0.73555028 0.88369781 0.70206897\n",
            " 0.88384956 0.87384615 0.79392097 0.7959596 ]\n",
            "Train f1 Score: 0.8320715541568413\n",
            "Test f1 Score: 0.8415281777390626\n",
            "Now predicting labels for unlabeled data...\n",
            "94 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3598 unlabelled instances remained to be predict in next iteration\n",
            "102 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 344\n",
            "30700 new labelled data is training...\n",
            "Epoch 1/100\n",
            "480/480 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 2/100\n",
            "480/480 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 3/100\n",
            "480/480 [==============================] - 3s 6ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 4/100\n",
            "480/480 [==============================] - 2s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 5/100\n",
            "480/480 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 6/100\n",
            "480/480 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 7/100\n",
            "480/480 [==============================] - 2s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 8/100\n",
            "480/480 [==============================] - 3s 6ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 9/100\n",
            "480/480 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 10/100\n",
            "480/480 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 11/100\n",
            "480/480 [==============================] - 2s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 12/100\n",
            "480/480 [==============================] - 3s 6ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 13/100\n",
            "480/480 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 14/100\n",
            "480/480 [==============================] - 2s 5ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 15/100\n",
            "480/480 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 16/100\n",
            "480/480 [==============================] - 3s 5ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 17/100\n",
            "480/480 [==============================] - 3s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 18/100\n",
            "480/480 [==============================] - 2s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 19/100\n",
            "480/480 [==============================] - 2s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 20/100\n",
            "480/480 [==============================] - 2s 5ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 21/100\n",
            "480/480 [==============================] - 3s 6ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 22/100\n",
            "480/480 [==============================] - 2s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 23/100\n",
            "480/480 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 24/100\n",
            "480/480 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 25/100\n",
            "480/480 [==============================] - 3s 6ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 26/100\n",
            "480/480 [==============================] - 3s 5ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 27/100\n",
            "480/480 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 28/100\n",
            "480/480 [==============================] - 2s 5ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 00028: early stopping\n",
            "Elapsed time: 68.584 sec\n",
            "Train f1 Score: [0.95808584 0.94028895 0.8272755  0.71906879 0.85939314 0.68653672\n",
            " 0.89192081 0.8798133  0.78779895 0.769799  ]\n",
            "Test f1 Score: [0.95695696 0.95741056 0.8325317  0.73496835 0.88544272 0.70385675\n",
            " 0.88531856 0.87352791 0.79684657 0.79757698]\n",
            "Train f1 Score: 0.8319981000399652\n",
            "Test f1 Score: 0.8424437065504465\n",
            "Now predicting labels for unlabeled data...\n",
            "96 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3602 unlabelled instances remained to be predict in next iteration\n",
            "98 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 345\n",
            "Train f1 Score: [0.95808584 0.94028895 0.8272755  0.71906879 0.85939314 0.68653672\n",
            " 0.89192081 0.8798133  0.78779895 0.769799  ]\n",
            "Test f1 Score: [0.95695696 0.95741056 0.8325317  0.73496835 0.88544272 0.70385675\n",
            " 0.88531856 0.87352791 0.79684657 0.79757698]\n",
            "Train f1 Score: 0.8319981000399652\n",
            "Test f1 Score: 0.8424437065504465\n",
            "Now predicting labels for unlabeled data...\n",
            "96 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3606 unlabelled instances remained to be predict in next iteration\n",
            "194 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 346\n",
            "30800 new labelled data is training...\n",
            "Epoch 1/100\n",
            "482/482 [==============================] - 3s 6ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 2/100\n",
            "482/482 [==============================] - 3s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 3/100\n",
            "482/482 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 4/100\n",
            "482/482 [==============================] - 2s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 5/100\n",
            "482/482 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 6/100\n",
            "482/482 [==============================] - 3s 6ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 7/100\n",
            "482/482 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 8/100\n",
            "482/482 [==============================] - 2s 5ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 9/100\n",
            "482/482 [==============================] - 2s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 10/100\n",
            "482/482 [==============================] - 3s 6ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 11/100\n",
            "482/482 [==============================] - 2s 5ms/step - loss: 0.0089 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 12/100\n",
            "482/482 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 13/100\n",
            "482/482 [==============================] - 2s 5ms/step - loss: 0.0090 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 14/100\n",
            "482/482 [==============================] - 3s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 00014: early stopping\n",
            "Elapsed time: 35.299 sec\n",
            "Train f1 Score: [0.95729775 0.93865379 0.82780242 0.71842501 0.85882256 0.68134124\n",
            " 0.89146733 0.87991321 0.78849271 0.76911197]\n",
            "Test f1 Score: [0.95465869 0.95659574 0.83114611 0.73496835 0.88511489 0.69896194\n",
            " 0.88408209 0.87339826 0.79392097 0.79677257]\n",
            "Train f1 Score: 0.8311327982757655\n",
            "Test f1 Score: 0.8409619605427521\n",
            "Now predicting labels for unlabeled data...\n",
            "93 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3613 unlabelled instances remained to be predict in next iteration\n",
            "187 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 347\n",
            "30900 new labelled data is training...\n",
            "Epoch 1/100\n",
            "483/483 [==============================] - 2s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 2/100\n",
            "483/483 [==============================] - 2s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 3/100\n",
            "483/483 [==============================] - 2s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 4/100\n",
            "483/483 [==============================] - 2s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 5/100\n",
            "483/483 [==============================] - 3s 6ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 6/100\n",
            "483/483 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 7/100\n",
            "483/483 [==============================] - 2s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 8/100\n",
            "483/483 [==============================] - 2s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 9/100\n",
            "483/483 [==============================] - 3s 6ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 10/100\n",
            "483/483 [==============================] - 2s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 11/100\n",
            "483/483 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 12/100\n",
            "483/483 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 13/100\n",
            "483/483 [==============================] - 3s 5ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 00013: early stopping\n",
            "Elapsed time: 32.432 sec\n",
            "Train f1 Score: [0.95795369 0.93998009 0.82813932 0.72034121 0.85825597 0.68501251\n",
            " 0.89173789 0.87942552 0.79057539 0.76865161]\n",
            "Test f1 Score: [0.95604396 0.95781849 0.83078268 0.73650794 0.883      0.70214236\n",
            " 0.88336097 0.87179487 0.79782082 0.79556898]\n",
            "Train f1 Score: 0.8320073189218045\n",
            "Test f1 Score: 0.8414841083326756\n",
            "Now predicting labels for unlabeled data...\n",
            "93 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3620 unlabelled instances remained to be predict in next iteration\n",
            "180 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 348\n",
            "31000 new labelled data is training...\n",
            "Epoch 1/100\n",
            "485/485 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 2/100\n",
            "485/485 [==============================] - 2s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 3/100\n",
            "485/485 [==============================] - 2s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 4/100\n",
            "485/485 [==============================] - 2s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 5/100\n",
            "485/485 [==============================] - 3s 6ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 6/100\n",
            "485/485 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 7/100\n",
            "485/485 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 8/100\n",
            "485/485 [==============================] - 2s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 9/100\n",
            "485/485 [==============================] - 3s 6ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 10/100\n",
            "485/485 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 11/100\n",
            "485/485 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 12/100\n",
            "485/485 [==============================] - 2s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 13/100\n",
            "485/485 [==============================] - 3s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 14/100\n",
            "485/485 [==============================] - 3s 6ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 00014: early stopping\n",
            "Elapsed time: 35.153 sec\n",
            "Train f1 Score: [0.95734914 0.94035587 0.8305801  0.72077965 0.85787558 0.68481961\n",
            " 0.89279657 0.87978005 0.78955888 0.76826865]\n",
            "Test f1 Score: [0.95508982 0.95822677 0.83245614 0.73575949 0.88179551 0.70337233\n",
            " 0.88703395 0.87295082 0.79588128 0.79435484]\n",
            "Train f1 Score: 0.8322164102195545\n",
            "Test f1 Score: 0.8416920955592102\n",
            "Now predicting labels for unlabeled data...\n",
            "96 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3624 unlabelled instances remained to be predict in next iteration\n",
            "176 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 349\n",
            "31100 new labelled data is training...\n",
            "Epoch 1/100\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 2/100\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 3/100\n",
            "486/486 [==============================] - 3s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 4/100\n",
            "486/486 [==============================] - 3s 5ms/step - loss: 0.0088 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 5/100\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 6/100\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 7/100\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 8/100\n",
            "486/486 [==============================] - 3s 6ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 9/100\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 10/100\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0090 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 11/100\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 12/100\n",
            "486/486 [==============================] - 3s 6ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 13/100\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 14/100\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 15/100\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 16/100\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 17/100\n",
            "486/486 [==============================] - 3s 6ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 18/100\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 19/100\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 20/100\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0098 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 21/100\n",
            "486/486 [==============================] - 3s 6ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 22/100\n",
            "486/486 [==============================] - 3s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 23/100\n",
            "486/486 [==============================] - 3s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 24/100\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 25/100\n",
            "486/486 [==============================] - 3s 6ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 26/100\n",
            "486/486 [==============================] - 3s 6ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 27/100\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 28/100\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 29/100\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 30/100\n",
            "486/486 [==============================] - 3s 6ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 31/100\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 32/100\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 33/100\n",
            "486/486 [==============================] - 2s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 00033: early stopping\n",
            "Elapsed time: 82.871 sec\n",
            "Train f1 Score: [0.95829503 0.94029745 0.83003528 0.72075966 0.85811484 0.68555241\n",
            " 0.89187985 0.87961959 0.79013344 0.76946748]\n",
            "Test f1 Score: [0.95552224 0.95781849 0.83282141 0.73671689 0.88232349 0.70434183\n",
            " 0.88580931 0.87192623 0.79758308 0.79618474]\n",
            "Train f1 Score: 0.8324155008732446\n",
            "Test f1 Score: 0.8421047715948452\n",
            "Now predicting labels for unlabeled data...\n",
            "92 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3632 unlabelled instances remained to be predict in next iteration\n",
            "168 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 350\n",
            "31200 new labelled data is training...\n",
            "Epoch 1/100\n",
            "488/488 [==============================] - 3s 6ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 2/100\n",
            "488/488 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 3/100\n",
            "488/488 [==============================] - 2s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 4/100\n",
            "488/488 [==============================] - 2s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 5/100\n",
            "488/488 [==============================] - 3s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 6/100\n",
            "488/488 [==============================] - 3s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 7/100\n",
            "488/488 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 8/100\n",
            "488/488 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 9/100\n",
            "488/488 [==============================] - 2s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 10/100\n",
            "488/488 [==============================] - 3s 6ms/step - loss: 0.0091 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 11/100\n",
            "488/488 [==============================] - 2s 5ms/step - loss: 0.0092 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 12/100\n",
            "488/488 [==============================] - 2s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 13/100\n",
            "488/488 [==============================] - 2s 5ms/step - loss: 0.0094 - sparse_categorical_accuracy: 0.9966\n",
            "Epoch 14/100\n",
            "488/488 [==============================] - 3s 6ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 15/100\n",
            "488/488 [==============================] - 3s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 16/100\n",
            "488/488 [==============================] - 2s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 17/100\n",
            "488/488 [==============================] - 2s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 00017: early stopping\n",
            "Elapsed time: 42.069 sec\n",
            "Train f1 Score: [0.95791147 0.94143631 0.83042012 0.71898833 0.85825211 0.68332576\n",
            " 0.89187745 0.88047278 0.78762677 0.76807851]\n",
            "Test f1 Score: [0.95647824 0.95904437 0.83369899 0.73286052 0.88282026 0.70247934\n",
            " 0.88728484 0.87583035 0.79465371 0.79695431]\n",
            "Train f1 Score: 0.8318389612577581\n",
            "Test f1 Score: 0.8422104930645565\n",
            "Now predicting labels for unlabeled data...\n",
            "97 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3635 unlabelled instances remained to be predict in next iteration\n",
            "165 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 351\n",
            "31300 new labelled data is training...\n",
            "Epoch 1/100\n",
            "490/490 [==============================] - 3s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 2/100\n",
            "490/490 [==============================] - 3s 6ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 3/100\n",
            "490/490 [==============================] - 2s 5ms/step - loss: 0.0089 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 4/100\n",
            "490/490 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 5/100\n",
            "490/490 [==============================] - 2s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 6/100\n",
            "490/490 [==============================] - 3s 6ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 7/100\n",
            "490/490 [==============================] - 2s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 8/100\n",
            "490/490 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 9/100\n",
            "490/490 [==============================] - 2s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 10/100\n",
            "490/490 [==============================] - 2s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 11/100\n",
            "490/490 [==============================] - 3s 6ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 12/100\n",
            "490/490 [==============================] - 2s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 13/100\n",
            "490/490 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 14/100\n",
            "490/490 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 00014: early stopping\n",
            "Elapsed time: 34.789 sec\n",
            "Train f1 Score: [0.95797477 0.94143631 0.82828129 0.72134374 0.85837265 0.68570129\n",
            " 0.89154264 0.87994657 0.79367637 0.76911197]\n",
            "Test f1 Score: [0.95604396 0.95822677 0.82984293 0.73579658 0.88267599 0.70401107\n",
            " 0.88531856 0.87224218 0.80048222 0.79656739]\n",
            "Train f1 Score: 0.8327387589117988\n",
            "Test f1 Score: 0.8421207634653571\n",
            "Now predicting labels for unlabeled data...\n",
            "92 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3643 unlabelled instances remained to be predict in next iteration\n",
            "157 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 352\n",
            "31400 new labelled data is training...\n",
            "Epoch 1/100\n",
            "491/491 [==============================] - 3s 6ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 2/100\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 3/100\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 4/100\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 5/100\n",
            "491/491 [==============================] - 3s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 6/100\n",
            "491/491 [==============================] - 3s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 7/100\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 8/100\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 9/100\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 10/100\n",
            "491/491 [==============================] - 3s 6ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 11/100\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 12/100\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 13/100\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 14/100\n",
            "491/491 [==============================] - 3s 6ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 15/100\n",
            "491/491 [==============================] - 3s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 16/100\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 17/100\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 18/100\n",
            "491/491 [==============================] - 3s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 19/100\n",
            "491/491 [==============================] - 3s 6ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 20/100\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 21/100\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 22/100\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 23/100\n",
            "491/491 [==============================] - 3s 6ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 24/100\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 25/100\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 26/100\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 27/100\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.0094 - sparse_categorical_accuracy: 0.9966\n",
            "Epoch 28/100\n",
            "491/491 [==============================] - 3s 6ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 29/100\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 30/100\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 31/100\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 32/100\n",
            "491/491 [==============================] - 3s 6ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 33/100\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 34/100\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 35/100\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 36/100\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 37/100\n",
            "491/491 [==============================] - 3s 6ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 38/100\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 39/100\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 40/100\n",
            "491/491 [==============================] - 2s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 00040: early stopping\n",
            "Elapsed time: 99.677 sec\n",
            "Train f1 Score: [0.95793259 0.9401138  0.82671343 0.71995807 0.85925311 0.68440805\n",
            " 0.89110675 0.87983299 0.79033562 0.77004798]\n",
            "Test f1 Score: [0.95604396 0.95741056 0.82933217 0.73462912 0.88344172 0.7017301\n",
            " 0.88433868 0.87224218 0.7980653  0.7953629 ]\n",
            "Train f1 Score: 0.8319702387588475\n",
            "Test f1 Score: 0.841259668553169\n",
            "Now predicting labels for unlabeled data...\n",
            "96 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3647 unlabelled instances remained to be predict in next iteration\n",
            "153 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 353\n",
            "31500 new labelled data is training...\n",
            "Epoch 1/100\n",
            "493/493 [==============================] - 3s 6ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 2/100\n",
            "493/493 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 3/100\n",
            "493/493 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 4/100\n",
            "493/493 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 5/100\n",
            "493/493 [==============================] - 3s 6ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 6/100\n",
            "493/493 [==============================] - 2s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 7/100\n",
            "493/493 [==============================] - 2s 5ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 8/100\n",
            "493/493 [==============================] - 2s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 9/100\n",
            "493/493 [==============================] - 3s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 10/100\n",
            "493/493 [==============================] - 3s 6ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 11/100\n",
            "493/493 [==============================] - 2s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 12/100\n",
            "493/493 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 13/100\n",
            "493/493 [==============================] - 2s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 14/100\n",
            "493/493 [==============================] - 3s 6ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 15/100\n",
            "493/493 [==============================] - 2s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 16/100\n",
            "493/493 [==============================] - 2s 5ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 17/100\n",
            "493/493 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 18/100\n",
            "493/493 [==============================] - 3s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 19/100\n",
            "493/493 [==============================] - 3s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 20/100\n",
            "493/493 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 21/100\n",
            "493/493 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 22/100\n",
            "493/493 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 00022: early stopping\n",
            "Elapsed time: 55.936 sec\n",
            "Train f1 Score: [0.95807181 0.94114294 0.824736   0.72018349 0.85816191 0.68900713\n",
            " 0.89121115 0.87874226 0.7910689  0.76907234]\n",
            "Test f1 Score: [0.95843766 0.95904437 0.83137255 0.73275178 0.88288288 0.70741758\n",
            " 0.88630061 0.87268994 0.7980653  0.79576399]\n",
            "Train f1 Score: 0.8321397931971302\n",
            "Test f1 Score: 0.8424726662396378\n",
            "Now predicting labels for unlabeled data...\n",
            "92 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3655 unlabelled instances remained to be predict in next iteration\n",
            "145 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 354\n",
            "31600 new labelled data is training...\n",
            "Epoch 1/100\n",
            "494/494 [==============================] - 3s 6ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 2/100\n",
            "494/494 [==============================] - 2s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 3/100\n",
            "494/494 [==============================] - 2s 5ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 4/100\n",
            "494/494 [==============================] - 2s 5ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 5/100\n",
            "494/494 [==============================] - 3s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 6/100\n",
            "494/494 [==============================] - 3s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 7/100\n",
            "494/494 [==============================] - 2s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 8/100\n",
            "494/494 [==============================] - 2s 5ms/step - loss: 0.0088 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 9/100\n",
            "494/494 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 10/100\n",
            "494/494 [==============================] - 3s 6ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 11/100\n",
            "494/494 [==============================] - 2s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 12/100\n",
            "494/494 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 13/100\n",
            "494/494 [==============================] - 2s 5ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 14/100\n",
            "494/494 [==============================] - 3s 6ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 15/100\n",
            "494/494 [==============================] - 3s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 16/100\n",
            "494/494 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 00016: early stopping\n",
            "Elapsed time: 40.185 sec\n",
            "Train f1 Score: [0.95782177 0.94081618 0.82771793 0.72070773 0.85742607 0.68685494\n",
            " 0.89213764 0.88070029 0.78975605 0.76819824]\n",
            "Test f1 Score: [0.95656515 0.95863539 0.83005679 0.73462912 0.88282026 0.70523416\n",
            " 0.88630061 0.87512794 0.79417122 0.79411765]\n",
            "Train f1 Score: 0.8322136840205608\n",
            "Test f1 Score: 0.8417658293725596\n",
            "Now predicting labels for unlabeled data...\n",
            "91 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3664 unlabelled instances remained to be predict in next iteration\n",
            "136 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 355\n",
            "31700 new labelled data is training...\n",
            "Epoch 1/100\n",
            "496/496 [==============================] - 2s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 2/100\n",
            "496/496 [==============================] - 3s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 3/100\n",
            "496/496 [==============================] - 3s 6ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 4/100\n",
            "496/496 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 5/100\n",
            "496/496 [==============================] - 2s 5ms/step - loss: 0.0091 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 6/100\n",
            "496/496 [==============================] - 2s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 7/100\n",
            "496/496 [==============================] - 3s 6ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 8/100\n",
            "496/496 [==============================] - 2s 5ms/step - loss: 0.0090 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 9/100\n",
            "496/496 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 10/100\n",
            "496/496 [==============================] - 2s 5ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 11/100\n",
            "496/496 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 12/100\n",
            "496/496 [==============================] - 3s 6ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 13/100\n",
            "496/496 [==============================] - 2s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 14/100\n",
            "496/496 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 15/100\n",
            "496/496 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 16/100\n",
            "496/496 [==============================] - 3s 6ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 17/100\n",
            "496/496 [==============================] - 3s 5ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 18/100\n",
            "496/496 [==============================] - 2s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 19/100\n",
            "496/496 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 00019: early stopping\n",
            "Elapsed time: 47.817 sec\n",
            "Train f1 Score: [0.95780062 0.94070752 0.82841413 0.7208601  0.85733223 0.68584423\n",
            " 0.89219265 0.88124584 0.79147733 0.76870222]\n",
            "Test f1 Score: [0.95556665 0.95863539 0.83093054 0.73542245 0.881      0.70303867\n",
            " 0.88482835 0.87512794 0.79515152 0.79435484]\n",
            "Train f1 Score: 0.832457687063558\n",
            "Test f1 Score: 0.8414056353762629\n",
            "Now predicting labels for unlabeled data...\n",
            "95 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3669 unlabelled instances remained to be predict in next iteration\n",
            "131 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 356\n",
            "31800 new labelled data is training...\n",
            "Epoch 1/100\n",
            "497/497 [==============================] - 2s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 2/100\n",
            "497/497 [==============================] - 3s 6ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 3/100\n",
            "497/497 [==============================] - 2s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 4/100\n",
            "497/497 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 5/100\n",
            "497/497 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 6/100\n",
            "497/497 [==============================] - 3s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 7/100\n",
            "497/497 [==============================] - 3s 6ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 8/100\n",
            "497/497 [==============================] - 2s 5ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 9/100\n",
            "497/497 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 10/100\n",
            "497/497 [==============================] - 2s 5ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 11/100\n",
            "497/497 [==============================] - 3s 6ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 12/100\n",
            "497/497 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 13/100\n",
            "497/497 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 14/100\n",
            "497/497 [==============================] - 2s 5ms/step - loss: 0.0092 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 15/100\n",
            "497/497 [==============================] - 3s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 16/100\n",
            "497/497 [==============================] - 3s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 17/100\n",
            "497/497 [==============================] - 2s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 18/100\n",
            "497/497 [==============================] - 2s 5ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 19/100\n",
            "497/497 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 20/100\n",
            "497/497 [==============================] - 3s 6ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 21/100\n",
            "497/497 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 22/100\n",
            "497/497 [==============================] - 2s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 23/100\n",
            "497/497 [==============================] - 2s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 24/100\n",
            "497/497 [==============================] - 3s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 25/100\n",
            "497/497 [==============================] - 3s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 26/100\n",
            "497/497 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 27/100\n",
            "497/497 [==============================] - 2s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 28/100\n",
            "497/497 [==============================] - 2s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 29/100\n",
            "497/497 [==============================] - 3s 6ms/step - loss: 0.0090 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 30/100\n",
            "497/497 [==============================] - 2s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 00030: early stopping\n",
            "Elapsed time: 75.802 sec\n",
            "Train f1 Score: [0.95800284 0.93978816 0.82864803 0.72095761 0.85875332 0.68657733\n",
            " 0.89067381 0.88212801 0.78951099 0.77087095]\n",
            "Test f1 Score: [0.95656515 0.95781849 0.83223828 0.73546856 0.88622754 0.70214236\n",
            " 0.88421053 0.87570332 0.79709267 0.79959514]\n",
            "Train f1 Score: 0.8325911039210714\n",
            "Test f1 Score: 0.8427062063927877\n",
            "Now predicting labels for unlabeled data...\n",
            "97 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3672 unlabelled instances remained to be predict in next iteration\n",
            "128 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 357\n",
            "31900 new labelled data is training...\n",
            "Epoch 1/100\n",
            "499/499 [==============================] - 2s 5ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 2/100\n",
            "499/499 [==============================] - 3s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 3/100\n",
            "499/499 [==============================] - 3s 6ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 4/100\n",
            "499/499 [==============================] - 3s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 5/100\n",
            "499/499 [==============================] - 2s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 6/100\n",
            "499/499 [==============================] - 2s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 7/100\n",
            "499/499 [==============================] - 2s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 8/100\n",
            "499/499 [==============================] - 3s 6ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 9/100\n",
            "499/499 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 10/100\n",
            "499/499 [==============================] - 2s 5ms/step - loss: 0.0092 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 11/100\n",
            "499/499 [==============================] - 2s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 12/100\n",
            "499/499 [==============================] - 3s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 13/100\n",
            "499/499 [==============================] - 3s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 00013: early stopping\n",
            "Elapsed time: 33.438 sec\n",
            "Train f1 Score: [0.95770645 0.94038981 0.82997162 0.71999477 0.85796958 0.68488783\n",
            " 0.89196873 0.88094047 0.79028832 0.76903248]\n",
            "Test f1 Score: [0.95704296 0.95863539 0.83238512 0.73417722 0.88302638 0.70311419\n",
            " 0.8839779  0.87570332 0.79563372 0.79614604]\n",
            "Train f1 Score: 0.8323150053560827\n",
            "Test f1 Score: 0.8419842242564567\n",
            "Now predicting labels for unlabeled data...\n",
            "91 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3681 unlabelled instances remained to be predict in next iteration\n",
            "119 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 358\n",
            "32000 new labelled data is training...\n",
            "Epoch 1/100\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 2/100\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 3/100\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 4/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 5/100\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 6/100\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 7/100\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 8/100\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 9/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 10/100\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 11/100\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 12/100\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 13/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.0094 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 14/100\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 15/100\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 16/100\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 17/100\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 18/100\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 19/100\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 20/100\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 21/100\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 22/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 23/100\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 24/100\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 00024: early stopping\n",
            "Elapsed time: 60.987 sec\n",
            "Train f1 Score: [0.95858087 0.94028895 0.82859327 0.72020929 0.85832574 0.68363058\n",
            " 0.89156197 0.88074773 0.7891377  0.76912533]\n",
            "Test f1 Score: [0.957      0.95863539 0.8325317  0.7352592  0.88367449 0.70344828\n",
            " 0.88433868 0.87442337 0.79417122 0.79576399]\n",
            "Train f1 Score: 0.8320201435000134\n",
            "Test f1 Score: 0.8419246330015898\n",
            "Now predicting labels for unlabeled data...\n",
            "91 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3690 unlabelled instances remained to be predict in next iteration\n",
            "110 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 359\n",
            "32100 new labelled data is training...\n",
            "Epoch 1/100\n",
            "502/502 [==============================] - 3s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 2/100\n",
            "502/502 [==============================] - 3s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 3/100\n",
            "502/502 [==============================] - 3s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 4/100\n",
            "502/502 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 5/100\n",
            "502/502 [==============================] - 2s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 6/100\n",
            "502/502 [==============================] - 2s 5ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 7/100\n",
            "502/502 [==============================] - 3s 6ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 8/100\n",
            "502/502 [==============================] - 2s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 9/100\n",
            "502/502 [==============================] - 2s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 10/100\n",
            "502/502 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 11/100\n",
            "502/502 [==============================] - 3s 6ms/step - loss: 0.0098 - sparse_categorical_accuracy: 0.9964\n",
            "Epoch 12/100\n",
            "502/502 [==============================] - 3s 6ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 13/100\n",
            "502/502 [==============================] - 2s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 14/100\n",
            "502/502 [==============================] - 2s 5ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 15/100\n",
            "502/502 [==============================] - 2s 5ms/step - loss: 0.0090 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 16/100\n",
            "502/502 [==============================] - 3s 6ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 17/100\n",
            "502/502 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 18/100\n",
            "502/502 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 19/100\n",
            "502/502 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 20/100\n",
            "502/502 [==============================] - 3s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 21/100\n",
            "502/502 [==============================] - 3s 6ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 22/100\n",
            "502/502 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 23/100\n",
            "502/502 [==============================] - 2s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 24/100\n",
            "502/502 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 25/100\n",
            "502/502 [==============================] - 3s 6ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 26/100\n",
            "502/502 [==============================] - 2s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 27/100\n",
            "502/502 [==============================] - 2s 5ms/step - loss: 0.0061 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 28/100\n",
            "502/502 [==============================] - 2s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 29/100\n",
            "502/502 [==============================] - 3s 6ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 30/100\n",
            "502/502 [==============================] - 3s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 31/100\n",
            "502/502 [==============================] - 2s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 32/100\n",
            "502/502 [==============================] - 2s 5ms/step - loss: 0.0092 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 33/100\n",
            "502/502 [==============================] - 3s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 34/100\n",
            "502/502 [==============================] - 3s 6ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 35/100\n",
            "502/502 [==============================] - 2s 5ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 36/100\n",
            "502/502 [==============================] - 2s 5ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 37/100\n",
            "502/502 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 38/100\n",
            "502/502 [==============================] - 3s 5ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 39/100\n",
            "502/502 [==============================] - 3s 6ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 00039: early stopping\n",
            "Elapsed time: 101.434 sec\n",
            "Train f1 Score: [0.95848678 0.94121838 0.82740227 0.72031956 0.85974952 0.68607163\n",
            " 0.89169932 0.88057961 0.78954831 0.76991682]\n",
            "Test f1 Score: [0.957      0.95945369 0.83158813 0.7336763  0.88411588 0.70255349\n",
            " 0.88433868 0.87442337 0.79490291 0.79656739]\n",
            "Train f1 Score: 0.8324992206265044\n",
            "Test f1 Score: 0.8418619848122122\n",
            "Now predicting labels for unlabeled data...\n",
            "93 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3697 unlabelled instances remained to be predict in next iteration\n",
            "103 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 360\n",
            "32200 new labelled data is training...\n",
            "Epoch 1/100\n",
            "504/504 [==============================] - 2s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 2/100\n",
            "504/504 [==============================] - 2s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 3/100\n",
            "504/504 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 4/100\n",
            "504/504 [==============================] - 3s 6ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 5/100\n",
            "504/504 [==============================] - 3s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 6/100\n",
            "504/504 [==============================] - 2s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 7/100\n",
            "504/504 [==============================] - 2s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 8/100\n",
            "504/504 [==============================] - 2s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 9/100\n",
            "504/504 [==============================] - 3s 6ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 10/100\n",
            "504/504 [==============================] - 2s 5ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 11/100\n",
            "504/504 [==============================] - 2s 5ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 12/100\n",
            "504/504 [==============================] - 2s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 13/100\n",
            "504/504 [==============================] - 3s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 14/100\n",
            "504/504 [==============================] - 3s 5ms/step - loss: 0.0091 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 15/100\n",
            "504/504 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 16/100\n",
            "504/504 [==============================] - 2s 5ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 17/100\n",
            "504/504 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 18/100\n",
            "504/504 [==============================] - 3s 6ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 19/100\n",
            "504/504 [==============================] - 3s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 20/100\n",
            "504/504 [==============================] - 2s 5ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 21/100\n",
            "504/504 [==============================] - 2s 5ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 22/100\n",
            "504/504 [==============================] - 3s 6ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 23/100\n",
            "504/504 [==============================] - 3s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 00023: early stopping\n",
            "Elapsed time: 59.603 sec\n",
            "Train f1 Score: [0.95767593 0.94016364 0.82811306 0.72115006 0.85804103 0.68710263\n",
            " 0.89136639 0.88044749 0.79081994 0.76948135]\n",
            "Test f1 Score: [0.95608782 0.95904437 0.83093054 0.73542245 0.88423154 0.70612526\n",
            " 0.88372093 0.87487179 0.79563372 0.7959596 ]\n",
            "Train f1 Score: 0.832436153660358\n",
            "Test f1 Score: 0.8422028015194009\n",
            "Now predicting labels for unlabeled data...\n",
            "92 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3705 unlabelled instances remained to be predict in next iteration\n",
            "95 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 361\n",
            "Train f1 Score: [0.95767593 0.94016364 0.82811306 0.72115006 0.85804103 0.68710263\n",
            " 0.89136639 0.88044749 0.79081994 0.76948135]\n",
            "Test f1 Score: [0.95608782 0.95904437 0.83093054 0.73542245 0.88423154 0.70612526\n",
            " 0.88372093 0.87487179 0.79563372 0.7959596 ]\n",
            "Train f1 Score: 0.832436153660358\n",
            "Test f1 Score: 0.8422028015194009\n",
            "Now predicting labels for unlabeled data...\n",
            "94 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3711 unlabelled instances remained to be predict in next iteration\n",
            "189 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 362\n",
            "32300 new labelled data is training...\n",
            "Epoch 1/100\n",
            "505/505 [==============================] - 3s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 2/100\n",
            "505/505 [==============================] - 3s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 3/100\n",
            "505/505 [==============================] - 3s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 4/100\n",
            "505/505 [==============================] - 3s 6ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 5/100\n",
            "505/505 [==============================] - 2s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 6/100\n",
            "505/505 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 7/100\n",
            "505/505 [==============================] - 2s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 8/100\n",
            "505/505 [==============================] - 3s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 9/100\n",
            "505/505 [==============================] - 3s 6ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 10/100\n",
            "505/505 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 11/100\n",
            "505/505 [==============================] - 2s 5ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 12/100\n",
            "505/505 [==============================] - 2s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 13/100\n",
            "505/505 [==============================] - 3s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 14/100\n",
            "505/505 [==============================] - 3s 6ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 15/100\n",
            "505/505 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 16/100\n",
            "505/505 [==============================] - 2s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 17/100\n",
            "505/505 [==============================] - 2s 5ms/step - loss: 0.0089 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 18/100\n",
            "505/505 [==============================] - 3s 6ms/step - loss: 0.0095 - sparse_categorical_accuracy: 0.9964\n",
            "Epoch 19/100\n",
            "505/505 [==============================] - 2s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 20/100\n",
            "505/505 [==============================] - 2s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 21/100\n",
            "505/505 [==============================] - 2s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 22/100\n",
            "505/505 [==============================] - 3s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 23/100\n",
            "505/505 [==============================] - 3s 6ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 24/100\n",
            "505/505 [==============================] - 2s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 00024: early stopping\n",
            "Elapsed time: 62.117 sec\n",
            "Train f1 Score: [0.9583403  0.94042281 0.82816083 0.72010478 0.85853739 0.68713881\n",
            " 0.89188225 0.88243109 0.78835818 0.76904536]\n",
            "Test f1 Score: [0.95704296 0.95781849 0.83267803 0.73417722 0.88302638 0.7047488\n",
            " 0.88519135 0.87570332 0.79318735 0.79593909]\n",
            "Train f1 Score: 0.8324421802587022\n",
            "Test f1 Score: 0.8419512972930686\n",
            "Now predicting labels for unlabeled data...\n",
            "96 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3715 unlabelled instances remained to be predict in next iteration\n",
            "185 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 363\n",
            "32400 new labelled data is training...\n",
            "Epoch 1/100\n",
            "507/507 [==============================] - 3s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 2/100\n",
            "507/507 [==============================] - 2s 5ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 3/100\n",
            "507/507 [==============================] - 3s 6ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 4/100\n",
            "507/507 [==============================] - 3s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 5/100\n",
            "507/507 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 6/100\n",
            "507/507 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 7/100\n",
            "507/507 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 8/100\n",
            "507/507 [==============================] - 3s 6ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 9/100\n",
            "507/507 [==============================] - 2s 5ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 10/100\n",
            "507/507 [==============================] - 2s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 11/100\n",
            "507/507 [==============================] - 2s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 12/100\n",
            "507/507 [==============================] - 3s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 13/100\n",
            "507/507 [==============================] - 3s 6ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 14/100\n",
            "507/507 [==============================] - 2s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 15/100\n",
            "507/507 [==============================] - 2s 5ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 16/100\n",
            "507/507 [==============================] - 3s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 17/100\n",
            "507/507 [==============================] - 3s 6ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 18/100\n",
            "507/507 [==============================] - 2s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 19/100\n",
            "507/507 [==============================] - 2s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 20/100\n",
            "507/507 [==============================] - 2s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 21/100\n",
            "507/507 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 22/100\n",
            "507/507 [==============================] - 3s 6ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 23/100\n",
            "507/507 [==============================] - 2s 5ms/step - loss: 0.0091 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 24/100\n",
            "507/507 [==============================] - 2s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 25/100\n",
            "507/507 [==============================] - 2s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 26/100\n",
            "507/507 [==============================] - 3s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 27/100\n",
            "507/507 [==============================] - 3s 6ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9966\n",
            "Epoch 00027: early stopping\n",
            "Elapsed time: 70.378 sec\n",
            "Train f1 Score: [0.95681894 0.93959636 0.83063464 0.72126418 0.85766182 0.68786193\n",
            " 0.89150397 0.88109908 0.7899585  0.76937634]\n",
            "Test f1 Score: [0.95561097 0.95741056 0.83150985 0.73475851 0.88226528 0.70352453\n",
            " 0.88408209 0.87455197 0.79563372 0.79452055]\n",
            "Train f1 Score: 0.8325775765282619\n",
            "Test f1 Score: 0.8413868024371473\n",
            "Now predicting labels for unlabeled data...\n",
            "92 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3723 unlabelled instances remained to be predict in next iteration\n",
            "177 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 364\n",
            "32500 new labelled data is training...\n",
            "Epoch 1/100\n",
            "508/508 [==============================] - 3s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 2/100\n",
            "508/508 [==============================] - 2s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 3/100\n",
            "508/508 [==============================] - 2s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 4/100\n",
            "508/508 [==============================] - 3s 6ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 5/100\n",
            "508/508 [==============================] - 3s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 6/100\n",
            "508/508 [==============================] - 3s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 7/100\n",
            "508/508 [==============================] - 3s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 8/100\n",
            "508/508 [==============================] - 3s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 9/100\n",
            "508/508 [==============================] - 3s 6ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 10/100\n",
            "508/508 [==============================] - 3s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 11/100\n",
            "508/508 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 12/100\n",
            "508/508 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 13/100\n",
            "508/508 [==============================] - 3s 6ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 14/100\n",
            "508/508 [==============================] - 3s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 15/100\n",
            "508/508 [==============================] - 2s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 16/100\n",
            "508/508 [==============================] - 2s 5ms/step - loss: 0.0088 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 17/100\n",
            "508/508 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 18/100\n",
            "508/508 [==============================] - 3s 6ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 19/100\n",
            "508/508 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 20/100\n",
            "508/508 [==============================] - 2s 5ms/step - loss: 0.0092 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 00020: early stopping\n",
            "Elapsed time: 52.295 sec\n",
            "Train f1 Score: [0.95832636 0.93983786 0.82905917 0.72075966 0.85771045 0.68723766\n",
            " 0.89160061 0.88115846 0.78824126 0.76868938]\n",
            "Test f1 Score: [0.95847924 0.95781849 0.83340621 0.73380727 0.88279302 0.70165746\n",
            " 0.88482835 0.87512794 0.79245283 0.79434058]\n",
            "Train f1 Score: 0.8322620873402883\n",
            "Test f1 Score: 0.8414711382184779\n",
            "Now predicting labels for unlabeled data...\n",
            "94 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3729 unlabelled instances remained to be predict in next iteration\n",
            "171 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 365\n",
            "32600 new labelled data is training...\n",
            "Epoch 1/100\n",
            "510/510 [==============================] - 3s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 2/100\n",
            "510/510 [==============================] - 3s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 3/100\n",
            "510/510 [==============================] - 3s 6ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 4/100\n",
            "510/510 [==============================] - 2s 5ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 5/100\n",
            "510/510 [==============================] - 2s 5ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 6/100\n",
            "510/510 [==============================] - 2s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 7/100\n",
            "510/510 [==============================] - 3s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 8/100\n",
            "510/510 [==============================] - 3s 6ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 9/100\n",
            "510/510 [==============================] - 2s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9966\n",
            "Epoch 10/100\n",
            "510/510 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 11/100\n",
            "510/510 [==============================] - 2s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 12/100\n",
            "510/510 [==============================] - 3s 6ms/step - loss: 0.0088 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 13/100\n",
            "510/510 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 14/100\n",
            "510/510 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 15/100\n",
            "510/510 [==============================] - 2s 5ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 16/100\n",
            "510/510 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 17/100\n",
            "510/510 [==============================] - 3s 6ms/step - loss: 0.0093 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 18/100\n",
            "510/510 [==============================] - 2s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 19/100\n",
            "510/510 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 20/100\n",
            "510/510 [==============================] - 2s 5ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 21/100\n",
            "510/510 [==============================] - 2s 5ms/step - loss: 0.0090 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 22/100\n",
            "510/510 [==============================] - 3s 6ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 23/100\n",
            "510/510 [==============================] - 2s 5ms/step - loss: 0.0088 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 24/100\n",
            "510/510 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 25/100\n",
            "510/510 [==============================] - 2s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 26/100\n",
            "510/510 [==============================] - 3s 5ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 27/100\n",
            "510/510 [==============================] - 3s 6ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 28/100\n",
            "510/510 [==============================] - 2s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 29/100\n",
            "510/510 [==============================] - 2s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 30/100\n",
            "510/510 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 31/100\n",
            "510/510 [==============================] - 3s 6ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 32/100\n",
            "510/510 [==============================] - 2s 5ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 33/100\n",
            "510/510 [==============================] - 2s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 34/100\n",
            "510/510 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 00034: early stopping\n",
            "Elapsed time: 88.186 sec\n",
            "Train f1 Score: [0.95820097 0.94024755 0.82936538 0.720466   0.85674204 0.68561037\n",
            " 0.89227208 0.88165237 0.79102214 0.76759834]\n",
            "Test f1 Score: [0.95747874 0.95822677 0.83223828 0.73409719 0.88039702 0.70311419\n",
            " 0.88531856 0.87570332 0.7980653  0.79410269]\n",
            "Train f1 Score: 0.8323177234726916\n",
            "Test f1 Score: 0.8418742070342594\n",
            "Now predicting labels for unlabeled data...\n",
            "95 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3734 unlabelled instances remained to be predict in next iteration\n",
            "166 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 366\n",
            "32700 new labelled data is training...\n",
            "Epoch 1/100\n",
            "511/511 [==============================] - 3s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 2/100\n",
            "511/511 [==============================] - 3s 6ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 3/100\n",
            "511/511 [==============================] - 2s 5ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 4/100\n",
            "511/511 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 5/100\n",
            "511/511 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 6/100\n",
            "511/511 [==============================] - 3s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 7/100\n",
            "511/511 [==============================] - 3s 6ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 8/100\n",
            "511/511 [==============================] - 2s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 9/100\n",
            "511/511 [==============================] - 2s 5ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 10/100\n",
            "511/511 [==============================] - 2s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 11/100\n",
            "511/511 [==============================] - 3s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 12/100\n",
            "511/511 [==============================] - 3s 6ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 13/100\n",
            "511/511 [==============================] - 2s 5ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 14/100\n",
            "511/511 [==============================] - 2s 5ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 15/100\n",
            "511/511 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 00015: early stopping\n",
            "Elapsed time: 38.333 sec\n",
            "Train f1 Score: [0.958173   0.94015513 0.82921606 0.72078689 0.85872439 0.68691218\n",
            " 0.89076978 0.88148025 0.788561   0.76921757]\n",
            "Test f1 Score: [0.95695696 0.95700298 0.83150985 0.73454834 0.88413725 0.70523416\n",
            " 0.88384956 0.875      0.78976234 0.79494949]\n",
            "Train f1 Score: 0.8323996233845138\n",
            "Test f1 Score: 0.8412950917189681\n",
            "Now predicting labels for unlabeled data...\n",
            "93 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3741 unlabelled instances remained to be predict in next iteration\n",
            "159 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 367\n",
            "32800 new labelled data is training...\n",
            "Epoch 1/100\n",
            "513/513 [==============================] - 3s 6ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 2/100\n",
            "513/513 [==============================] - 3s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 3/100\n",
            "513/513 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 4/100\n",
            "513/513 [==============================] - 3s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 5/100\n",
            "513/513 [==============================] - 3s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 6/100\n",
            "513/513 [==============================] - 3s 6ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 7/100\n",
            "513/513 [==============================] - 2s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 8/100\n",
            "513/513 [==============================] - 2s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 9/100\n",
            "513/513 [==============================] - 2s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 10/100\n",
            "513/513 [==============================] - 2s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 11/100\n",
            "513/513 [==============================] - 3s 6ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 12/100\n",
            "513/513 [==============================] - 2s 5ms/step - loss: 0.0093 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 13/100\n",
            "513/513 [==============================] - 2s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 14/100\n",
            "513/513 [==============================] - 3s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 15/100\n",
            "513/513 [==============================] - 3s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 16/100\n",
            "513/513 [==============================] - 3s 6ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 17/100\n",
            "513/513 [==============================] - 2s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 18/100\n",
            "513/513 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 19/100\n",
            "513/513 [==============================] - 2s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 20/100\n",
            "513/513 [==============================] - 3s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 21/100\n",
            "513/513 [==============================] - 3s 6ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 22/100\n",
            "513/513 [==============================] - 2s 5ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 23/100\n",
            "513/513 [==============================] - 2s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 24/100\n",
            "513/513 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 25/100\n",
            "513/513 [==============================] - 3s 6ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 26/100\n",
            "513/513 [==============================] - 3s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 27/100\n",
            "513/513 [==============================] - 2s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 28/100\n",
            "513/513 [==============================] - 2s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 29/100\n",
            "513/513 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 30/100\n",
            "513/513 [==============================] - 3s 6ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 31/100\n",
            "513/513 [==============================] - 3s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 32/100\n",
            "513/513 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 33/100\n",
            "513/513 [==============================] - 2s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 34/100\n",
            "513/513 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 00034: early stopping\n",
            "Elapsed time: 87.647 sec\n",
            "Train f1 Score: [0.95767593 0.94038981 0.82869804 0.72069237 0.85934139 0.68661453\n",
            " 0.8907548  0.88063439 0.79135091 0.77065796]\n",
            "Test f1 Score: [0.95660848 0.95781849 0.83165719 0.73425743 0.88446215 0.70441989\n",
            " 0.88568257 0.875      0.79661017 0.79736575]\n",
            "Train f1 Score: 0.8326810144538715\n",
            "Test f1 Score: 0.8423882129184154\n",
            "Now predicting labels for unlabeled data...\n",
            "90 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3751 unlabelled instances remained to be predict in next iteration\n",
            "149 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 368\n",
            "32900 new labelled data is training...\n",
            "Epoch 1/100\n",
            "515/515 [==============================] - 3s 6ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 2/100\n",
            "515/515 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 3/100\n",
            "515/515 [==============================] - 2s 5ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 4/100\n",
            "515/515 [==============================] - 2s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 5/100\n",
            "515/515 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 6/100\n",
            "515/515 [==============================] - 3s 6ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 7/100\n",
            "515/515 [==============================] - 2s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 8/100\n",
            "515/515 [==============================] - 2s 4ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 9/100\n",
            "515/515 [==============================] - 2s 4ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 10/100\n",
            "515/515 [==============================] - 2s 4ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 11/100\n",
            "515/515 [==============================] - 3s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 12/100\n",
            "515/515 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 13/100\n",
            "515/515 [==============================] - 2s 4ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 14/100\n",
            "515/515 [==============================] - 2s 4ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 15/100\n",
            "515/515 [==============================] - 2s 4ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 16/100\n",
            "515/515 [==============================] - 3s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 17/100\n",
            "515/515 [==============================] - 3s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 18/100\n",
            "515/515 [==============================] - 2s 4ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 19/100\n",
            "515/515 [==============================] - 2s 4ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 20/100\n",
            "515/515 [==============================] - 2s 4ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 21/100\n",
            "515/515 [==============================] - 2s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 22/100\n",
            "515/515 [==============================] - 3s 6ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 23/100\n",
            "515/515 [==============================] - 2s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 24/100\n",
            "515/515 [==============================] - 2s 4ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 25/100\n",
            "515/515 [==============================] - 2s 4ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 26/100\n",
            "515/515 [==============================] - 2s 4ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 00026: early stopping\n",
            "Elapsed time: 63.507 sec\n",
            "Train f1 Score: [0.95836817 0.94175519 0.82675188 0.72009428 0.85877483 0.6832878\n",
            " 0.89045873 0.88108153 0.79147302 0.7690066 ]\n",
            "Test f1 Score: [0.95752124 0.95904437 0.83195111 0.73301738 0.88115365 0.69902913\n",
            " 0.88555556 0.875      0.79612825 0.79432624]\n",
            "Train f1 Score: 0.8321052038716326\n",
            "Test f1 Score: 0.8412726928064804\n",
            "Now predicting labels for unlabeled data...\n",
            "95 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3756 unlabelled instances remained to be predict in next iteration\n",
            "144 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 369\n",
            "33000 new labelled data is training...\n",
            "Epoch 1/100\n",
            "516/516 [==============================] - 3s 6ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 2/100\n",
            "516/516 [==============================] - 2s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 3/100\n",
            "516/516 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 4/100\n",
            "516/516 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 5/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 6/100\n",
            "516/516 [==============================] - 3s 6ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 7/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 8/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 9/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 10/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 11/100\n",
            "516/516 [==============================] - 3s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 12/100\n",
            "516/516 [==============================] - 3s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 13/100\n",
            "516/516 [==============================] - 2s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 14/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 15/100\n",
            "516/516 [==============================] - 2s 5ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 16/100\n",
            "516/516 [==============================] - 3s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 17/100\n",
            "516/516 [==============================] - 3s 6ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 18/100\n",
            "516/516 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 19/100\n",
            "516/516 [==============================] - 2s 5ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 20/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 21/100\n",
            "516/516 [==============================] - 3s 5ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 22/100\n",
            "516/516 [==============================] - 3s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 23/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 24/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 25/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 26/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 27/100\n",
            "516/516 [==============================] - 3s 6ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 28/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 29/100\n",
            "516/516 [==============================] - 2s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 30/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.0091 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 31/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 32/100\n",
            "516/516 [==============================] - 3s 6ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 33/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 34/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 35/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 36/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 37/100\n",
            "516/516 [==============================] - 3s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 38/100\n",
            "516/516 [==============================] - 3s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 39/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 40/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 41/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 42/100\n",
            "516/516 [==============================] - 3s 5ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 43/100\n",
            "516/516 [==============================] - 3s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 44/100\n",
            "516/516 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 45/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 46/100\n",
            "516/516 [==============================] - 2s 4ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 47/100\n",
            "516/516 [==============================] - 3s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 48/100\n",
            "516/516 [==============================] - 3s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 00048: early stopping\n",
            "Elapsed time: 117.891 sec\n",
            "Train f1 Score: [0.95780767 0.94196492 0.83166948 0.71928567 0.85888559 0.68210334\n",
            " 0.89260313 0.88153397 0.78902056 0.76903226]\n",
            "Test f1 Score: [0.95795796 0.95986336 0.83406497 0.73314939 0.88185863 0.70124481\n",
            " 0.88495575 0.8766001  0.79490291 0.79410269]\n",
            "Train f1 Score: 0.8323906597272572\n",
            "Test f1 Score: 0.8418700581697166\n",
            "Now predicting labels for unlabeled data...\n",
            "96 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3760 unlabelled instances remained to be predict in next iteration\n",
            "140 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 370\n",
            "33100 new labelled data is training...\n",
            "Epoch 1/100\n",
            "518/518 [==============================] - 2s 4ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 2/100\n",
            "518/518 [==============================] - 2s 4ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 3/100\n",
            "518/518 [==============================] - 2s 4ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 4/100\n",
            "518/518 [==============================] - 3s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 5/100\n",
            "518/518 [==============================] - 3s 5ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 6/100\n",
            "518/518 [==============================] - 2s 4ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 7/100\n",
            "518/518 [==============================] - 2s 4ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 8/100\n",
            "518/518 [==============================] - 2s 4ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 9/100\n",
            "518/518 [==============================] - 2s 4ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 10/100\n",
            "518/518 [==============================] - 3s 6ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 11/100\n",
            "518/518 [==============================] - 2s 4ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 12/100\n",
            "518/518 [==============================] - 2s 4ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 13/100\n",
            "518/518 [==============================] - 2s 4ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 14/100\n",
            "518/518 [==============================] - 2s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 15/100\n",
            "518/518 [==============================] - 3s 6ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 16/100\n",
            "518/518 [==============================] - 2s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 17/100\n",
            "518/518 [==============================] - 2s 4ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 18/100\n",
            "518/518 [==============================] - 2s 4ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 19/100\n",
            "518/518 [==============================] - 2s 4ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 20/100\n",
            "518/518 [==============================] - 3s 5ms/step - loss: 0.0092 - sparse_categorical_accuracy: 0.9964\n",
            "Epoch 21/100\n",
            "518/518 [==============================] - 3s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 22/100\n",
            "518/518 [==============================] - 2s 4ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 23/100\n",
            "518/518 [==============================] - 2s 4ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 24/100\n",
            "518/518 [==============================] - 2s 4ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 25/100\n",
            "518/518 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 26/100\n",
            "518/518 [==============================] - 3s 6ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 27/100\n",
            "518/518 [==============================] - 2s 4ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 28/100\n",
            "518/518 [==============================] - 2s 4ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 29/100\n",
            "518/518 [==============================] - 2s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 30/100\n",
            "518/518 [==============================] - 2s 4ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 31/100\n",
            "518/518 [==============================] - 3s 6ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 00031: early stopping\n",
            "Elapsed time: 75.769 sec\n",
            "Train f1 Score: [0.95920248 0.94128545 0.82932417 0.72083279 0.85882061 0.68770501\n",
            " 0.89150817 0.88101392 0.79020342 0.76911197]\n",
            "Test f1 Score: [0.95891784 0.95986336 0.83391608 0.73251679 0.88258706 0.70701513\n",
            " 0.88630061 0.87544849 0.79417122 0.79474216]\n",
            "Train f1 Score: 0.8329007992678525\n",
            "Test f1 Score: 0.8425478753617283\n",
            "Now predicting labels for unlabeled data...\n",
            "92 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3768 unlabelled instances remained to be predict in next iteration\n",
            "132 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 371\n",
            "33200 new labelled data is training...\n",
            "Epoch 1/100\n",
            "519/519 [==============================] - 2s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 2/100\n",
            "519/519 [==============================] - 2s 4ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 3/100\n",
            "519/519 [==============================] - 2s 4ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 4/100\n",
            "519/519 [==============================] - 2s 4ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 5/100\n",
            "519/519 [==============================] - 3s 5ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 6/100\n",
            "519/519 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 7/100\n",
            "519/519 [==============================] - 2s 4ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 8/100\n",
            "519/519 [==============================] - 2s 4ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 9/100\n",
            "519/519 [==============================] - 2s 4ms/step - loss: 0.0089 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 10/100\n",
            "519/519 [==============================] - 3s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 11/100\n",
            "519/519 [==============================] - 3s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 12/100\n",
            "519/519 [==============================] - 2s 4ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 13/100\n",
            "519/519 [==============================] - 2s 4ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 14/100\n",
            "519/519 [==============================] - 2s 4ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 15/100\n",
            "519/519 [==============================] - 2s 4ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 16/100\n",
            "519/519 [==============================] - 3s 6ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 17/100\n",
            "519/519 [==============================] - 2s 4ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 00017: early stopping\n",
            "Elapsed time: 41.147 sec\n",
            "Train f1 Score: [0.95864032 0.93985497 0.82805464 0.72110536 0.85874866 0.68708872\n",
            " 0.89031568 0.88198551 0.78934036 0.76999914]\n",
            "Test f1 Score: [0.95891784 0.95822677 0.83267803 0.73359684 0.88369781 0.70255349\n",
            " 0.88482835 0.87672634 0.79490291 0.79735907]\n",
            "Train f1 Score: 0.8325133360293069\n",
            "Test f1 Score: 0.8423487436998969\n",
            "Now predicting labels for unlabeled data...\n",
            "94 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3774 unlabelled instances remained to be predict in next iteration\n",
            "126 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 372\n",
            "33300 new labelled data is training...\n",
            "Epoch 1/100\n",
            "521/521 [==============================] - 2s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 2/100\n",
            "521/521 [==============================] - 2s 4ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 3/100\n",
            "521/521 [==============================] - 2s 4ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 4/100\n",
            "521/521 [==============================] - 3s 6ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 5/100\n",
            "521/521 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 6/100\n",
            "521/521 [==============================] - 2s 4ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 7/100\n",
            "521/521 [==============================] - 2s 4ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 8/100\n",
            "521/521 [==============================] - 2s 4ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 9/100\n",
            "521/521 [==============================] - 3s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 10/100\n",
            "521/521 [==============================] - 3s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 11/100\n",
            "521/521 [==============================] - 2s 4ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 12/100\n",
            "521/521 [==============================] - 2s 4ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 13/100\n",
            "521/521 [==============================] - 2s 4ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 14/100\n",
            "521/521 [==============================] - 2s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 15/100\n",
            "521/521 [==============================] - 3s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 16/100\n",
            "521/521 [==============================] - 2s 4ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 17/100\n",
            "521/521 [==============================] - 2s 4ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 18/100\n",
            "521/521 [==============================] - 2s 4ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 19/100\n",
            "521/521 [==============================] - 2s 4ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 00019: early stopping\n",
            "Elapsed time: 45.840 sec\n",
            "Train f1 Score: [0.95813487 0.93978816 0.82908924 0.71981687 0.85924944 0.68494709\n",
            " 0.89049274 0.88180986 0.78892944 0.77014361]\n",
            "Test f1 Score: [0.95752124 0.95741056 0.83165719 0.73301738 0.88567149 0.70124481\n",
            " 0.88531856 0.87627812 0.79343864 0.798583  ]\n",
            "Train f1 Score: 0.832240132520846\n",
            "Test f1 Score: 0.8420140991238693\n",
            "Now predicting labels for unlabeled data...\n",
            "97 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3777 unlabelled instances remained to be predict in next iteration\n",
            "123 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 373\n",
            "33400 new labelled data is training...\n",
            "Epoch 1/100\n",
            "522/522 [==============================] - 2s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 2/100\n",
            "522/522 [==============================] - 2s 4ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 3/100\n",
            "522/522 [==============================] - 2s 4ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 4/100\n",
            "522/522 [==============================] - 2s 4ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 5/100\n",
            "522/522 [==============================] - 2s 4ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 6/100\n",
            "522/522 [==============================] - 3s 6ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 7/100\n",
            "522/522 [==============================] - 2s 4ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 8/100\n",
            "522/522 [==============================] - 2s 4ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 9/100\n",
            "522/522 [==============================] - 2s 4ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 10/100\n",
            "522/522 [==============================] - 2s 4ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 11/100\n",
            "522/522 [==============================] - 3s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 12/100\n",
            "522/522 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 13/100\n",
            "522/522 [==============================] - 2s 4ms/step - loss: 0.0059 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 14/100\n",
            "522/522 [==============================] - 2s 4ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 15/100\n",
            "522/522 [==============================] - 2s 4ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 16/100\n",
            "522/522 [==============================] - 3s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 17/100\n",
            "522/522 [==============================] - 3s 6ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 18/100\n",
            "522/522 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 19/100\n",
            "522/522 [==============================] - 2s 4ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 20/100\n",
            "522/522 [==============================] - 2s 4ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 21/100\n",
            "522/522 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 22/100\n",
            "522/522 [==============================] - 3s 6ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 23/100\n",
            "522/522 [==============================] - 2s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 24/100\n",
            "522/522 [==============================] - 2s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 25/100\n",
            "522/522 [==============================] - 2s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 00025: early stopping\n",
            "Elapsed time: 60.857 sec\n",
            "Train f1 Score: [0.95784289 0.94057362 0.82891013 0.72065574 0.85785124 0.68643876\n",
            " 0.8911121  0.88170071 0.79044824 0.77006358]\n",
            "Test f1 Score: [0.95656515 0.95781849 0.83093054 0.73267327 0.8840219  0.70523416\n",
            " 0.88679245 0.87557604 0.79343864 0.79736575]\n",
            "Train f1 Score: 0.8325597028451561\n",
            "Test f1 Score: 0.8420416393499783\n",
            "Now predicting labels for unlabeled data...\n",
            "89 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3788 unlabelled instances remained to be predict in next iteration\n",
            "112 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 374\n",
            "33500 new labelled data is training...\n",
            "Epoch 1/100\n",
            "524/524 [==============================] - 3s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 2/100\n",
            "524/524 [==============================] - 3s 6ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 3/100\n",
            "524/524 [==============================] - 3s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 4/100\n",
            "524/524 [==============================] - 3s 5ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 5/100\n",
            "524/524 [==============================] - 2s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 6/100\n",
            "524/524 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 7/100\n",
            "524/524 [==============================] - 3s 6ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 8/100\n",
            "524/524 [==============================] - 3s 5ms/step - loss: 0.0088 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 9/100\n",
            "524/524 [==============================] - 3s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 10/100\n",
            "524/524 [==============================] - 2s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 11/100\n",
            "524/524 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 12/100\n",
            "524/524 [==============================] - 3s 6ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 13/100\n",
            "524/524 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 14/100\n",
            "524/524 [==============================] - 2s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 15/100\n",
            "524/524 [==============================] - 3s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 16/100\n",
            "524/524 [==============================] - 3s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 00016: early stopping\n",
            "Elapsed time: 42.502 sec\n",
            "Train f1 Score: [0.957683   0.94089161 0.83019157 0.72096531 0.85803999 0.68665837\n",
            " 0.89105197 0.88222555 0.79175508 0.77006358]\n",
            "Test f1 Score: [0.95704296 0.95945369 0.83289589 0.73396675 0.88457711 0.70612526\n",
            " 0.88519135 0.87512794 0.79709267 0.79716024]\n",
            "Train f1 Score: 0.8329526040218764\n",
            "Test f1 Score: 0.8428633860214371\n",
            "Now predicting labels for unlabeled data...\n",
            "96 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3792 unlabelled instances remained to be predict in next iteration\n",
            "108 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 375\n",
            "33600 new labelled data is training...\n",
            "Epoch 1/100\n",
            "525/525 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 2/100\n",
            "525/525 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 3/100\n",
            "525/525 [==============================] - 3s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 4/100\n",
            "525/525 [==============================] - 3s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 5/100\n",
            "525/525 [==============================] - 3s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 6/100\n",
            "525/525 [==============================] - 3s 6ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 7/100\n",
            "525/525 [==============================] - 2s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 8/100\n",
            "525/525 [==============================] - 2s 5ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 9/100\n",
            "525/525 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 10/100\n",
            "525/525 [==============================] - 3s 5ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 11/100\n",
            "525/525 [==============================] - 3s 6ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 12/100\n",
            "525/525 [==============================] - 3s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 13/100\n",
            "525/525 [==============================] - 2s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 14/100\n",
            "525/525 [==============================] - 3s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 15/100\n",
            "525/525 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 16/100\n",
            "525/525 [==============================] - 3s 6ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 17/100\n",
            "525/525 [==============================] - 3s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 18/100\n",
            "525/525 [==============================] - 2s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 19/100\n",
            "525/525 [==============================] - 2s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 20/100\n",
            "525/525 [==============================] - 3s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 00020: early stopping\n",
            "Elapsed time: 52.429 sec\n",
            "Train f1 Score: [0.95884911 0.94081618 0.82945499 0.71996339 0.85780347 0.68444344\n",
            " 0.89128498 0.88128806 0.78946302 0.7684509 ]\n",
            "Test f1 Score: [0.957      0.95863539 0.83311432 0.73264984 0.88226528 0.70393375\n",
            " 0.88531856 0.87589744 0.79343864 0.79574252]\n",
            "Train f1 Score: 0.8321817538464276\n",
            "Test f1 Score: 0.8417995741760749\n",
            "Now predicting labels for unlabeled data...\n",
            "90 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3802 unlabelled instances remained to be predict in next iteration\n",
            "98 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 376\n",
            "Train f1 Score: [0.95884911 0.94081618 0.82945499 0.71996339 0.85780347 0.68444344\n",
            " 0.89128498 0.88128806 0.78946302 0.7684509 ]\n",
            "Test f1 Score: [0.957      0.95863539 0.83311432 0.73264984 0.88226528 0.70393375\n",
            " 0.88531856 0.87589744 0.79343864 0.79574252]\n",
            "Train f1 Score: 0.8321817538464276\n",
            "Test f1 Score: 0.8417995741760749\n",
            "Now predicting labels for unlabeled data...\n",
            "95 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3807 unlabelled instances remained to be predict in next iteration\n",
            "193 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 377\n",
            "33700 new labelled data is training...\n",
            "Epoch 1/100\n",
            "527/527 [==============================] - 3s 6ms/step - loss: 0.0089 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 2/100\n",
            "527/527 [==============================] - 3s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 3/100\n",
            "527/527 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 4/100\n",
            "527/527 [==============================] - 3s 5ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 5/100\n",
            "527/527 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 6/100\n",
            "527/527 [==============================] - 3s 6ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 7/100\n",
            "527/527 [==============================] - 3s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 8/100\n",
            "527/527 [==============================] - 3s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 9/100\n",
            "527/527 [==============================] - 2s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 10/100\n",
            "527/527 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 11/100\n",
            "527/527 [==============================] - 3s 6ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 12/100\n",
            "527/527 [==============================] - 3s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 13/100\n",
            "527/527 [==============================] - 3s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 14/100\n",
            "527/527 [==============================] - 2s 5ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 15/100\n",
            "527/527 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 16/100\n",
            "527/527 [==============================] - 3s 6ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 00016: early stopping\n",
            "Elapsed time: 42.713 sec\n",
            "Train f1 Score: [0.95890182 0.94217469 0.82957067 0.72070658 0.85752044 0.68596073\n",
            " 0.89118801 0.88128806 0.79281461 0.76927039]\n",
            "Test f1 Score: [0.95795796 0.95945369 0.83362522 0.73351757 0.88127173 0.70303867\n",
            " 0.88580931 0.8764736  0.79951691 0.79593909]\n",
            "Train f1 Score: 0.8329396001482164\n",
            "Test f1 Score: 0.8426603755011092\n",
            "Now predicting labels for unlabeled data...\n",
            "89 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3818 unlabelled instances remained to be predict in next iteration\n",
            "182 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 378\n",
            "33800 new labelled data is training...\n",
            "Epoch 1/100\n",
            "529/529 [==============================] - 3s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 2/100\n",
            "529/529 [==============================] - 3s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 3/100\n",
            "529/529 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 4/100\n",
            "529/529 [==============================] - 3s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 5/100\n",
            "529/529 [==============================] - 3s 6ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 6/100\n",
            "529/529 [==============================] - 3s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 7/100\n",
            "529/529 [==============================] - 2s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 8/100\n",
            "529/529 [==============================] - 2s 5ms/step - loss: 0.0088 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 9/100\n",
            "529/529 [==============================] - 2s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 10/100\n",
            "529/529 [==============================] - 3s 6ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 11/100\n",
            "529/529 [==============================] - 3s 5ms/step - loss: 0.0088 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 12/100\n",
            "529/529 [==============================] - 3s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 13/100\n",
            "529/529 [==============================] - 2s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 14/100\n",
            "529/529 [==============================] - 2s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 15/100\n",
            "529/529 [==============================] - 3s 6ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 16/100\n",
            "529/529 [==============================] - 3s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 17/100\n",
            "529/529 [==============================] - 3s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 18/100\n",
            "529/529 [==============================] - 2s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 00018: early stopping\n",
            "Elapsed time: 47.823 sec\n",
            "Train f1 Score: [0.95789474 0.94027304 0.82827049 0.72075026 0.85744891 0.68786915\n",
            " 0.8901765  0.88211281 0.78876382 0.76815594]\n",
            "Test f1 Score: [0.95752124 0.95781849 0.83144105 0.73404677 0.8807521  0.70393375\n",
            " 0.88336097 0.8766001  0.7919708  0.79368314]\n",
            "Train f1 Score: 0.8321715659450316\n",
            "Test f1 Score: 0.8411128415450182\n",
            "Now predicting labels for unlabeled data...\n",
            "94 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3824 unlabelled instances remained to be predict in next iteration\n",
            "176 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 379\n",
            "33900 new labelled data is training...\n",
            "Epoch 1/100\n",
            "530/530 [==============================] - 3s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 2/100\n",
            "530/530 [==============================] - 3s 6ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 3/100\n",
            "530/530 [==============================] - 3s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 4/100\n",
            "530/530 [==============================] - 3s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 5/100\n",
            "530/530 [==============================] - 3s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 6/100\n",
            "530/530 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 7/100\n",
            "530/530 [==============================] - 3s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 8/100\n",
            "530/530 [==============================] - 3s 5ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 9/100\n",
            "530/530 [==============================] - 3s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 10/100\n",
            "530/530 [==============================] - 2s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 11/100\n",
            "530/530 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 12/100\n",
            "530/530 [==============================] - 3s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 13/100\n",
            "530/530 [==============================] - 3s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 14/100\n",
            "530/530 [==============================] - 2s 5ms/step - loss: 0.0089 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 15/100\n",
            "530/530 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 00015: early stopping\n",
            "Elapsed time: 40.091 sec\n",
            "Train f1 Score: [0.95756766 0.94086672 0.82892928 0.72097599 0.85785083 0.68647541\n",
            " 0.89124432 0.88212738 0.79065061 0.76971988]\n",
            "Test f1 Score: [0.95608782 0.95822677 0.83180428 0.73441842 0.88413725 0.70352453\n",
            " 0.88433868 0.87615148 0.79490291 0.79696203]\n",
            "Train f1 Score: 0.8326408083762656\n",
            "Test f1 Score: 0.8420554178315305\n",
            "Now predicting labels for unlabeled data...\n",
            "92 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3832 unlabelled instances remained to be predict in next iteration\n",
            "168 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 380\n",
            "34000 new labelled data is training...\n",
            "Epoch 1/100\n",
            "532/532 [==============================] - 3s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 2/100\n",
            "532/532 [==============================] - 3s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 3/100\n",
            "532/532 [==============================] - 3s 6ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 4/100\n",
            "532/532 [==============================] - 3s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 5/100\n",
            "532/532 [==============================] - 2s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 6/100\n",
            "532/532 [==============================] - 3s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 7/100\n",
            "532/532 [==============================] - 3s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 8/100\n",
            "532/532 [==============================] - 3s 6ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 9/100\n",
            "532/532 [==============================] - 3s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 10/100\n",
            "532/532 [==============================] - 3s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 11/100\n",
            "532/532 [==============================] - 3s 5ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 12/100\n",
            "532/532 [==============================] - 2s 5ms/step - loss: 0.0088 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 13/100\n",
            "532/532 [==============================] - 3s 6ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 14/100\n",
            "532/532 [==============================] - 3s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 15/100\n",
            "532/532 [==============================] - 3s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 16/100\n",
            "532/532 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 17/100\n",
            "532/532 [==============================] - 3s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 18/100\n",
            "532/532 [==============================] - 3s 6ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 19/100\n",
            "532/532 [==============================] - 3s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 20/100\n",
            "532/532 [==============================] - 2s 5ms/step - loss: 0.0095 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 00020: early stopping\n",
            "Elapsed time: 53.961 sec\n",
            "Train f1 Score: [0.95759599 0.94190605 0.83005586 0.72021472 0.85884791 0.68529245\n",
            " 0.89122494 0.88166667 0.78990575 0.76908593]\n",
            "Test f1 Score: [0.95704296 0.95945369 0.83216783 0.73396675 0.885      0.70303867\n",
            " 0.88482835 0.875      0.79490291 0.79617514]\n",
            "Train f1 Score: 0.8325796259872369\n",
            "Test f1 Score: 0.8421576301900812\n",
            "Now predicting labels for unlabeled data...\n",
            "92 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3840 unlabelled instances remained to be predict in next iteration\n",
            "160 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 381\n",
            "34100 new labelled data is training...\n",
            "Epoch 1/100\n",
            "533/533 [==============================] - 3s 5ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 2/100\n",
            "533/533 [==============================] - 3s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 3/100\n",
            "533/533 [==============================] - 3s 6ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 4/100\n",
            "533/533 [==============================] - 3s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 5/100\n",
            "533/533 [==============================] - 3s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 6/100\n",
            "533/533 [==============================] - 3s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 7/100\n",
            "533/533 [==============================] - 3s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 8/100\n",
            "533/533 [==============================] - 3s 6ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 9/100\n",
            "533/533 [==============================] - 3s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 10/100\n",
            "533/533 [==============================] - 3s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 11/100\n",
            "533/533 [==============================] - 3s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 12/100\n",
            "533/533 [==============================] - 2s 5ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 13/100\n",
            "533/533 [==============================] - 3s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 14/100\n",
            "533/533 [==============================] - 3s 6ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 15/100\n",
            "533/533 [==============================] - 3s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 16/100\n",
            "533/533 [==============================] - 2s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 17/100\n",
            "533/533 [==============================] - 2s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 18/100\n",
            "533/533 [==============================] - 3s 5ms/step - loss: 0.0088 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 19/100\n",
            "533/533 [==============================] - 3s 6ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 20/100\n",
            "533/533 [==============================] - 3s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 21/100\n",
            "533/533 [==============================] - 3s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 22/100\n",
            "533/533 [==============================] - 3s 5ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 23/100\n",
            "533/533 [==============================] - 2s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 24/100\n",
            "533/533 [==============================] - 3s 6ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 00024: early stopping\n",
            "Elapsed time: 65.287 sec\n",
            "Train f1 Score: [0.95735625 0.94188948 0.82905199 0.71990043 0.85924092 0.6869053\n",
            " 0.89067237 0.88283787 0.79061299 0.77021313]\n",
            "Test f1 Score: [0.95660848 0.95986336 0.83093054 0.73288484 0.88415842 0.70385675\n",
            " 0.88519135 0.87512794 0.79490291 0.79693878]\n",
            "Train f1 Score: 0.8328680749889559\n",
            "Test f1 Score: 0.8420463368209182\n",
            "Now predicting labels for unlabeled data...\n",
            "98 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3842 unlabelled instances remained to be predict in next iteration\n",
            "158 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 382\n",
            "34200 new labelled data is training...\n",
            "Epoch 1/100\n",
            "535/535 [==============================] - 3s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 2/100\n",
            "535/535 [==============================] - 3s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 3/100\n",
            "535/535 [==============================] - 3s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 4/100\n",
            "535/535 [==============================] - 3s 5ms/step - loss: 0.0095 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 5/100\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 6/100\n",
            "535/535 [==============================] - 3s 5ms/step - loss: 0.0090 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 7/100\n",
            "535/535 [==============================] - 3s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 8/100\n",
            "535/535 [==============================] - 3s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 9/100\n",
            "535/535 [==============================] - 3s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 10/100\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 11/100\n",
            "535/535 [==============================] - 3s 5ms/step - loss: 0.0089 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 12/100\n",
            "535/535 [==============================] - 3s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 13/100\n",
            "535/535 [==============================] - 2s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 14/100\n",
            "535/535 [==============================] - 3s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 15/100\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 16/100\n",
            "535/535 [==============================] - 3s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 17/100\n",
            "535/535 [==============================] - 2s 4ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 18/100\n",
            "535/535 [==============================] - 2s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 19/100\n",
            "535/535 [==============================] - 2s 5ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 20/100\n",
            "535/535 [==============================] - 3s 5ms/step - loss: 0.0095 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 21/100\n",
            "535/535 [==============================] - 3s 6ms/step - loss: 0.0090 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 22/100\n",
            "535/535 [==============================] - 2s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 00022: early stopping\n",
            "Elapsed time: 58.967 sec\n",
            "Train f1 Score: [0.95812787 0.94263699 0.83136594 0.72024082 0.85877295 0.68789665\n",
            " 0.89270157 0.88343864 0.7908953  0.7712711 ]\n",
            "Test f1 Score: [0.95704296 0.95945369 0.83326039 0.73259494 0.88568588 0.70385675\n",
            " 0.88544549 0.8778743  0.79417122 0.80020336]\n",
            "Train f1 Score: 0.8337347819298596\n",
            "Test f1 Score: 0.8429588976396337\n",
            "Now predicting labels for unlabeled data...\n",
            "95 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3847 unlabelled instances remained to be predict in next iteration\n",
            "153 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 383\n",
            "34300 new labelled data is training...\n",
            "Epoch 1/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 2/100\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 3/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 4/100\n",
            "536/536 [==============================] - 3s 6ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 5/100\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 6/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 7/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 8/100\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 9/100\n",
            "536/536 [==============================] - 3s 6ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 10/100\n",
            "536/536 [==============================] - 2s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 11/100\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 12/100\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.0092 - sparse_categorical_accuracy: 0.9963\n",
            "Epoch 13/100\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.0088 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 14/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 15/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 16/100\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9966\n",
            "Epoch 17/100\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 18/100\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.0088 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 19/100\n",
            "536/536 [==============================] - 2s 4ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 20/100\n",
            "536/536 [==============================] - 3s 5ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 00020: early stopping\n",
            "Elapsed time: 51.357 sec\n",
            "Train f1 Score: [0.9582741  0.94105083 0.83061115 0.72124271 0.85931308 0.6866045\n",
            " 0.89212724 0.8817545  0.79191511 0.7711588 ]\n",
            "Test f1 Score: [0.95652174 0.95863539 0.832021   0.73521239 0.88392857 0.7049067\n",
            " 0.8839779  0.87589744 0.79709267 0.79898734]\n",
            "Train f1 Score: 0.8334052028462237\n",
            "Test f1 Score: 0.8427181141113058\n",
            "Now predicting labels for unlabeled data...\n",
            "96 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3851 unlabelled instances remained to be predict in next iteration\n",
            "149 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 384\n",
            "34400 new labelled data is training...\n",
            "Epoch 1/100\n",
            "538/538 [==============================] - 2s 4ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 2/100\n",
            "538/538 [==============================] - 2s 4ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 3/100\n",
            "538/538 [==============================] - 2s 4ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 4/100\n",
            "538/538 [==============================] - 2s 4ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 5/100\n",
            "538/538 [==============================] - 2s 4ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 6/100\n",
            "538/538 [==============================] - 3s 6ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 7/100\n",
            "538/538 [==============================] - 2s 4ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 8/100\n",
            "538/538 [==============================] - 2s 4ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 9/100\n",
            "538/538 [==============================] - 2s 4ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 10/100\n",
            "538/538 [==============================] - 2s 4ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 11/100\n",
            "538/538 [==============================] - 3s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 12/100\n",
            "538/538 [==============================] - 3s 6ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 13/100\n",
            "538/538 [==============================] - 3s 5ms/step - loss: 0.0090 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 14/100\n",
            "538/538 [==============================] - 3s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 15/100\n",
            "538/538 [==============================] - 3s 5ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 16/100\n",
            "538/538 [==============================] - 3s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 17/100\n",
            "538/538 [==============================] - 3s 6ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 18/100\n",
            "538/538 [==============================] - 3s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 19/100\n",
            "538/538 [==============================] - 3s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 20/100\n",
            "538/538 [==============================] - 3s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 21/100\n",
            "538/538 [==============================] - 3s 6ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 22/100\n",
            "538/538 [==============================] - 3s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 23/100\n",
            "538/538 [==============================] - 3s 5ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 24/100\n",
            "538/538 [==============================] - 3s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 25/100\n",
            "538/538 [==============================] - 3s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 26/100\n",
            "538/538 [==============================] - 3s 6ms/step - loss: 0.0096 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 27/100\n",
            "538/538 [==============================] - 3s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 00027: early stopping\n",
            "Elapsed time: 73.105 sec\n",
            "Train f1 Score: [0.95849372 0.94034838 0.83009337 0.71923177 0.85940987 0.68508413\n",
            " 0.89161991 0.88285145 0.79039611 0.77115717]\n",
            "Test f1 Score: [0.95891784 0.95700298 0.83187391 0.7318612  0.88150719 0.70393375\n",
            " 0.88482835 0.87627812 0.79343864 0.79755227]\n",
            "Train f1 Score: 0.8328685886175305\n",
            "Test f1 Score: 0.8417194233066047\n",
            "Now predicting labels for unlabeled data...\n",
            "94 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3857 unlabelled instances remained to be predict in next iteration\n",
            "143 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 385\n",
            "34500 new labelled data is training...\n",
            "Epoch 1/100\n",
            "540/540 [==============================] - 3s 5ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 2/100\n",
            "540/540 [==============================] - 3s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 3/100\n",
            "540/540 [==============================] - 3s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 4/100\n",
            "540/540 [==============================] - 3s 6ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 5/100\n",
            "540/540 [==============================] - 3s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 6/100\n",
            "540/540 [==============================] - 3s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 7/100\n",
            "540/540 [==============================] - 3s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 8/100\n",
            "540/540 [==============================] - 3s 5ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 9/100\n",
            "540/540 [==============================] - 3s 6ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 10/100\n",
            "540/540 [==============================] - 3s 6ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 11/100\n",
            "540/540 [==============================] - 3s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 12/100\n",
            "540/540 [==============================] - 3s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 13/100\n",
            "540/540 [==============================] - 3s 5ms/step - loss: 0.0090 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 14/100\n",
            "540/540 [==============================] - 3s 6ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 15/100\n",
            "540/540 [==============================] - 3s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 16/100\n",
            "540/540 [==============================] - 3s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 17/100\n",
            "540/540 [==============================] - 3s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 18/100\n",
            "540/540 [==============================] - 3s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 19/100\n",
            "540/540 [==============================] - 4s 7ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 20/100\n",
            "540/540 [==============================] - 3s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 21/100\n",
            "540/540 [==============================] - 3s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 00021: early stopping\n",
            "Elapsed time: 59.856 sec\n",
            "Train f1 Score: [0.95853536 0.94119322 0.82932049 0.7192627  0.85934011 0.68235294\n",
            " 0.89124244 0.8811749  0.79032584 0.76946827]\n",
            "Test f1 Score: [0.957      0.95863539 0.83056769 0.73259494 0.88337469 0.7013167\n",
            " 0.88372093 0.87429451 0.79709267 0.79675621]\n",
            "Train f1 Score: 0.8322216276140374\n",
            "Test f1 Score: 0.841535372806284\n",
            "Now predicting labels for unlabeled data...\n",
            "97 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3860 unlabelled instances remained to be predict in next iteration\n",
            "140 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 386\n",
            "34600 new labelled data is training...\n",
            "Epoch 1/100\n",
            "541/541 [==============================] - 3s 5ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 2/100\n",
            "541/541 [==============================] - 3s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 3/100\n",
            "541/541 [==============================] - 3s 6ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 4/100\n",
            "541/541 [==============================] - 3s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 5/100\n",
            "541/541 [==============================] - 3s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 6/100\n",
            "541/541 [==============================] - 3s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 7/100\n",
            "541/541 [==============================] - 3s 5ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 8/100\n",
            "541/541 [==============================] - 4s 7ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 9/100\n",
            "541/541 [==============================] - 3s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 10/100\n",
            "541/541 [==============================] - 3s 5ms/step - loss: 0.0091 - sparse_categorical_accuracy: 0.9966\n",
            "Epoch 11/100\n",
            "541/541 [==============================] - 3s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 12/100\n",
            "541/541 [==============================] - 3s 5ms/step - loss: 0.0089 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 13/100\n",
            "541/541 [==============================] - 3s 6ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 14/100\n",
            "541/541 [==============================] - 3s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 15/100\n",
            "541/541 [==============================] - 3s 5ms/step - loss: 0.0090 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 16/100\n",
            "541/541 [==============================] - 3s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 17/100\n",
            "541/541 [==============================] - 3s 6ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 18/100\n",
            "541/541 [==============================] - 3s 6ms/step - loss: 0.0092 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 19/100\n",
            "541/541 [==============================] - 3s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 00019: early stopping\n",
            "Elapsed time: 55.288 sec\n",
            "Train f1 Score: [0.9582568  0.94079977 0.83014537 0.72083879 0.85914679 0.68589598\n",
            " 0.89156197 0.88130787 0.79191102 0.76927052]\n",
            "Test f1 Score: [0.95561097 0.95863539 0.832021   0.73475851 0.88241107 0.7017301\n",
            " 0.88470067 0.87442337 0.79782082 0.79510703]\n",
            "Train f1 Score: 0.8329134893128028\n",
            "Test f1 Score: 0.841721894158229\n",
            "Now predicting labels for unlabeled data...\n",
            "98 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3862 unlabelled instances remained to be predict in next iteration\n",
            "138 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 387\n",
            "34700 new labelled data is training...\n",
            "Epoch 1/100\n",
            "543/543 [==============================] - 3s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 2/100\n",
            "543/543 [==============================] - 3s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 3/100\n",
            "543/543 [==============================] - 3s 6ms/step - loss: 0.0088 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 4/100\n",
            "543/543 [==============================] - 3s 6ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 5/100\n",
            "543/543 [==============================] - 3s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 6/100\n",
            "543/543 [==============================] - 3s 5ms/step - loss: 0.0088 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 7/100\n",
            "543/543 [==============================] - 3s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 8/100\n",
            "543/543 [==============================] - 3s 6ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 9/100\n",
            "543/543 [==============================] - 3s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 10/100\n",
            "543/543 [==============================] - 3s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 11/100\n",
            "543/543 [==============================] - 3s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 12/100\n",
            "543/543 [==============================] - 3s 5ms/step - loss: 0.0091 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 13/100\n",
            "543/543 [==============================] - 3s 6ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 14/100\n",
            "543/543 [==============================] - 3s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 15/100\n",
            "543/543 [==============================] - 3s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 16/100\n",
            "543/543 [==============================] - 3s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 00016: early stopping\n",
            "Elapsed time: 46.413 sec\n",
            "Train f1 Score: [0.95860166 0.94076605 0.82922724 0.71973856 0.85810978 0.6852988\n",
            " 0.8915212  0.88172043 0.78790339 0.76897945]\n",
            "Test f1 Score: [0.95891784 0.95822677 0.83180428 0.73193841 0.88162457 0.70165746\n",
            " 0.88372093 0.87429451 0.79270517 0.79634332]\n",
            "Train f1 Score: 0.8321866555426041\n",
            "Test f1 Score: 0.8411233253009037\n",
            "Now predicting labels for unlabeled data...\n",
            "91 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3871 unlabelled instances remained to be predict in next iteration\n",
            "129 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 388\n",
            "34800 new labelled data is training...\n",
            "Epoch 1/100\n",
            "544/544 [==============================] - 3s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 2/100\n",
            "544/544 [==============================] - 4s 6ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 3/100\n",
            "544/544 [==============================] - 3s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 4/100\n",
            "544/544 [==============================] - 3s 5ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 5/100\n",
            "544/544 [==============================] - 3s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 6/100\n",
            "544/544 [==============================] - 3s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 7/100\n",
            "544/544 [==============================] - 4s 7ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 8/100\n",
            "544/544 [==============================] - 3s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 9/100\n",
            "544/544 [==============================] - 2s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 10/100\n",
            "544/544 [==============================] - 3s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 11/100\n",
            "544/544 [==============================] - 3s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 12/100\n",
            "544/544 [==============================] - 3s 6ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 13/100\n",
            "544/544 [==============================] - 3s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 14/100\n",
            "544/544 [==============================] - 3s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 15/100\n",
            "544/544 [==============================] - 3s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 16/100\n",
            "544/544 [==============================] - 3s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 00016: early stopping\n",
            "Elapsed time: 45.421 sec\n",
            "Train f1 Score: [0.9582568  0.94156214 0.83146585 0.72044488 0.85834711 0.68535119\n",
            " 0.8922145  0.88177422 0.79171299 0.76929681]\n",
            "Test f1 Score: [0.95804196 0.95863539 0.83311432 0.73388691 0.88083416 0.70482759\n",
            " 0.88531856 0.87487179 0.79709267 0.79553526]\n",
            "Train f1 Score: 0.8330426493123244\n",
            "Test f1 Score: 0.8422158621486439\n",
            "Now predicting labels for unlabeled data...\n",
            "95 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3876 unlabelled instances remained to be predict in next iteration\n",
            "124 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 389\n",
            "34900 new labelled data is training...\n",
            "Epoch 1/100\n",
            "546/546 [==============================] - 3s 6ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 2/100\n",
            "546/546 [==============================] - 3s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 3/100\n",
            "546/546 [==============================] - 3s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 4/100\n",
            "546/546 [==============================] - 3s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 5/100\n",
            "546/546 [==============================] - 3s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 6/100\n",
            "546/546 [==============================] - 3s 6ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 7/100\n",
            "546/546 [==============================] - 3s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 8/100\n",
            "546/546 [==============================] - 3s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 9/100\n",
            "546/546 [==============================] - 3s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 10/100\n",
            "546/546 [==============================] - 3s 5ms/step - loss: 0.0093 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 11/100\n",
            "546/546 [==============================] - 3s 6ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 12/100\n",
            "546/546 [==============================] - 3s 5ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 13/100\n",
            "546/546 [==============================] - 3s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 14/100\n",
            "546/546 [==============================] - 3s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 15/100\n",
            "546/546 [==============================] - 3s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 16/100\n",
            "546/546 [==============================] - 4s 6ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 17/100\n",
            "546/546 [==============================] - 3s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 18/100\n",
            "546/546 [==============================] - 3s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 19/100\n",
            "546/546 [==============================] - 3s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 20/100\n",
            "546/546 [==============================] - 3s 5ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 21/100\n",
            "546/546 [==============================] - 3s 6ms/step - loss: 0.0088 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 22/100\n",
            "546/546 [==============================] - 3s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 23/100\n",
            "546/546 [==============================] - 3s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 24/100\n",
            "546/546 [==============================] - 3s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 00024: early stopping\n",
            "Elapsed time: 69.308 sec\n",
            "Train f1 Score: [0.95865007 0.94013083 0.82925711 0.72124271 0.85957377 0.68694665\n",
            " 0.89057344 0.881602   0.79056585 0.77035509]\n",
            "Test f1 Score: [0.958      0.95822677 0.83071553 0.73383578 0.88415842 0.70441989\n",
            " 0.88372093 0.87532068 0.79490291 0.79796954]\n",
            "Train f1 Score: 0.8328897510621831\n",
            "Test f1 Score: 0.8421270449323135\n",
            "Now predicting labels for unlabeled data...\n",
            "96 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3880 unlabelled instances remained to be predict in next iteration\n",
            "120 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 390\n",
            "35000 new labelled data is training...\n",
            "Epoch 1/100\n",
            "547/547 [==============================] - 3s 6ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 2/100\n",
            "547/547 [==============================] - 3s 6ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 3/100\n",
            "547/547 [==============================] - 3s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 4/100\n",
            "547/547 [==============================] - 3s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 5/100\n",
            "547/547 [==============================] - 3s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 6/100\n",
            "547/547 [==============================] - 3s 6ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 7/100\n",
            "547/547 [==============================] - 3s 6ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 8/100\n",
            "547/547 [==============================] - 3s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 9/100\n",
            "547/547 [==============================] - 3s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 10/100\n",
            "547/547 [==============================] - 3s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 11/100\n",
            "547/547 [==============================] - 3s 6ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 12/100\n",
            "547/547 [==============================] - 3s 6ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 13/100\n",
            "547/547 [==============================] - 3s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 14/100\n",
            "547/547 [==============================] - 3s 5ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 15/100\n",
            "547/547 [==============================] - 3s 5ms/step - loss: 0.0094 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 16/100\n",
            "547/547 [==============================] - 3s 6ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 17/100\n",
            "547/547 [==============================] - 3s 6ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 18/100\n",
            "547/547 [==============================] - 3s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 19/100\n",
            "547/547 [==============================] - 3s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 20/100\n",
            "547/547 [==============================] - 3s 5ms/step - loss: 0.0093 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 21/100\n",
            "547/547 [==============================] - 3s 6ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 22/100\n",
            "547/547 [==============================] - 3s 6ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 23/100\n",
            "547/547 [==============================] - 3s 5ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 24/100\n",
            "547/547 [==============================] - 3s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 25/100\n",
            "547/547 [==============================] - 3s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 26/100\n",
            "547/547 [==============================] - 3s 6ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 27/100\n",
            "547/547 [==============================] - 3s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 28/100\n",
            "547/547 [==============================] - 3s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 29/100\n",
            "547/547 [==============================] - 3s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 30/100\n",
            "547/547 [==============================] - 3s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 31/100\n",
            "547/547 [==============================] - 3s 6ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 32/100\n",
            "547/547 [==============================] - 3s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 33/100\n",
            "547/547 [==============================] - 3s 5ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 34/100\n",
            "547/547 [==============================] - 3s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 35/100\n",
            "547/547 [==============================] - 3s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 36/100\n",
            "547/547 [==============================] - 3s 6ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 37/100\n",
            "547/547 [==============================] - 3s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 38/100\n",
            "547/547 [==============================] - 3s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 39/100\n",
            "547/547 [==============================] - 3s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 40/100\n",
            "547/547 [==============================] - 3s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 41/100\n",
            "547/547 [==============================] - 3s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 42/100\n",
            "547/547 [==============================] - 3s 6ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 43/100\n",
            "547/547 [==============================] - 3s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 44/100\n",
            "547/547 [==============================] - 3s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 45/100\n",
            "547/547 [==============================] - 3s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 00045: early stopping\n",
            "Elapsed time: 128.485 sec\n",
            "Train f1 Score: [0.95865007 0.94129382 0.82938751 0.72111789 0.85870104 0.6874504\n",
            " 0.89186057 0.88371319 0.79011345 0.77026329]\n",
            "Test f1 Score: [0.959      0.95904437 0.83158813 0.73441842 0.88305253 0.70434183\n",
            " 0.88421053 0.87672634 0.79490291 0.79674797]\n",
            "Train f1 Score: 0.833255123361395\n",
            "Test f1 Score: 0.8424033030844875\n",
            "Now predicting labels for unlabeled data...\n",
            "93 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3887 unlabelled instances remained to be predict in next iteration\n",
            "113 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 391\n",
            "35100 new labelled data is training...\n",
            "Epoch 1/100\n",
            "549/549 [==============================] - 3s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 2/100\n",
            "549/549 [==============================] - 3s 6ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 3/100\n",
            "549/549 [==============================] - 3s 5ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 4/100\n",
            "549/549 [==============================] - 3s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 5/100\n",
            "549/549 [==============================] - 3s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 6/100\n",
            "549/549 [==============================] - 3s 5ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 7/100\n",
            "549/549 [==============================] - 4s 6ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 8/100\n",
            "549/549 [==============================] - 3s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 9/100\n",
            "549/549 [==============================] - 3s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 10/100\n",
            "549/549 [==============================] - 3s 5ms/step - loss: 0.0090 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 11/100\n",
            "549/549 [==============================] - 3s 5ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 12/100\n",
            "549/549 [==============================] - 3s 6ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 13/100\n",
            "549/549 [==============================] - 3s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 14/100\n",
            "549/549 [==============================] - 3s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 15/100\n",
            "549/549 [==============================] - 3s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 16/100\n",
            "549/549 [==============================] - 3s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 17/100\n",
            "549/549 [==============================] - 3s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 18/100\n",
            "549/549 [==============================] - 3s 6ms/step - loss: 0.0093 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 19/100\n",
            "549/549 [==============================] - 3s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 20/100\n",
            "549/549 [==============================] - 3s 5ms/step - loss: 0.0088 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 21/100\n",
            "549/549 [==============================] - 3s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 22/100\n",
            "549/549 [==============================] - 3s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 23/100\n",
            "549/549 [==============================] - 3s 6ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 00023: early stopping\n",
            "Elapsed time: 64.387 sec\n",
            "Train f1 Score: [0.95881714 0.94209926 0.83046307 0.72007318 0.85827421 0.68521463\n",
            " 0.89202213 0.88218127 0.79179715 0.76950904]\n",
            "Test f1 Score: [0.95704296 0.95986336 0.83144105 0.73251679 0.88162457 0.70344828\n",
            " 0.8860478  0.87602459 0.79709267 0.79633401]\n",
            "Train f1 Score: 0.8330451089722246\n",
            "Test f1 Score: 0.842143608181266\n",
            "Now predicting labels for unlabeled data...\n",
            "97 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3890 unlabelled instances remained to be predict in next iteration\n",
            "110 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 392\n",
            "35200 new labelled data is training...\n",
            "Epoch 1/100\n",
            "550/550 [==============================] - 3s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 2/100\n",
            "550/550 [==============================] - 3s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 3/100\n",
            "550/550 [==============================] - 3s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 4/100\n",
            "550/550 [==============================] - 3s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 5/100\n",
            "550/550 [==============================] - 3s 5ms/step - loss: 0.0092 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 6/100\n",
            "550/550 [==============================] - 3s 5ms/step - loss: 0.0089 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 7/100\n",
            "550/550 [==============================] - 3s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 8/100\n",
            "550/550 [==============================] - 3s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 9/100\n",
            "550/550 [==============================] - 3s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 10/100\n",
            "550/550 [==============================] - 3s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 11/100\n",
            "550/550 [==============================] - 3s 6ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 12/100\n",
            "550/550 [==============================] - 3s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 13/100\n",
            "550/550 [==============================] - 3s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 14/100\n",
            "550/550 [==============================] - 3s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 15/100\n",
            "550/550 [==============================] - 3s 5ms/step - loss: 0.0092 - sparse_categorical_accuracy: 0.9965\n",
            "Epoch 16/100\n",
            "550/550 [==============================] - 3s 6ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 17/100\n",
            "550/550 [==============================] - 3s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 18/100\n",
            "550/550 [==============================] - 3s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 19/100\n",
            "550/550 [==============================] - 3s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 00019: early stopping\n",
            "Elapsed time: 52.040 sec\n",
            "Train f1 Score: [0.9585038  0.94096703 0.8304864  0.72032956 0.85860673 0.68746455\n",
            " 0.89192081 0.88162721 0.79076362 0.7687414 ]\n",
            "Test f1 Score: [0.95756365 0.95904437 0.83078268 0.73230526 0.88150719 0.70709855\n",
            " 0.88630061 0.87487179 0.79417122 0.79431183]\n",
            "Train f1 Score: 0.8329411117785039\n",
            "Test f1 Score: 0.8417957167255837\n",
            "Now predicting labels for unlabeled data...\n",
            "97 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3893 unlabelled instances remained to be predict in next iteration\n",
            "107 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 393\n",
            "35300 new labelled data is training...\n",
            "Epoch 1/100\n",
            "552/552 [==============================] - 3s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 2/100\n",
            "552/552 [==============================] - 3s 6ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 3/100\n",
            "552/552 [==============================] - 3s 6ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 4/100\n",
            "552/552 [==============================] - 3s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 5/100\n",
            "552/552 [==============================] - 3s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 6/100\n",
            "552/552 [==============================] - 3s 5ms/step - loss: 0.0093 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 7/100\n",
            "552/552 [==============================] - 3s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 8/100\n",
            "552/552 [==============================] - 3s 6ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 9/100\n",
            "552/552 [==============================] - 3s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 10/100\n",
            "552/552 [==============================] - 3s 5ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 11/100\n",
            "552/552 [==============================] - 3s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 12/100\n",
            "552/552 [==============================] - 3s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 13/100\n",
            "552/552 [==============================] - 3s 6ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 14/100\n",
            "552/552 [==============================] - 3s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 15/100\n",
            "552/552 [==============================] - 3s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 16/100\n",
            "552/552 [==============================] - 3s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 17/100\n",
            "552/552 [==============================] - 3s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 18/100\n",
            "552/552 [==============================] - 3s 5ms/step - loss: 0.0091 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 19/100\n",
            "552/552 [==============================] - 3s 6ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 20/100\n",
            "552/552 [==============================] - 3s 5ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 21/100\n",
            "552/552 [==============================] - 3s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 22/100\n",
            "552/552 [==============================] - 3s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 23/100\n",
            "552/552 [==============================] - 3s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 24/100\n",
            "552/552 [==============================] - 3s 6ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 25/100\n",
            "552/552 [==============================] - 3s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 26/100\n",
            "552/552 [==============================] - 3s 5ms/step - loss: 0.0064 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 27/100\n",
            "552/552 [==============================] - 3s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 28/100\n",
            "552/552 [==============================] - 3s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 29/100\n",
            "552/552 [==============================] - 3s 6ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 30/100\n",
            "552/552 [==============================] - 3s 6ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 31/100\n",
            "552/552 [==============================] - 3s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 32/100\n",
            "552/552 [==============================] - 3s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 00032: early stopping\n",
            "Elapsed time: 88.771 sec\n",
            "Train f1 Score: [0.95831593 0.94131054 0.83192503 0.72068537 0.85858419 0.68662132\n",
            " 0.89309517 0.88230878 0.79109762 0.77038055]\n",
            "Test f1 Score: [0.95752124 0.95904437 0.83187391 0.73280632 0.88314272 0.70661157\n",
            " 0.88446656 0.87532068 0.79490291 0.79716024]\n",
            "Train f1 Score: 0.8334324503756729\n",
            "Test f1 Score: 0.8422850512243609\n",
            "Now predicting labels for unlabeled data...\n",
            "93 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3900 unlabelled instances remained to be predict in next iteration\n",
            "100 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 394\n",
            "Train f1 Score: [0.95831593 0.94131054 0.83192503 0.72068537 0.85858419 0.68662132\n",
            " 0.89309517 0.88230878 0.79109762 0.77038055]\n",
            "Test f1 Score: [0.95752124 0.95904437 0.83187391 0.73280632 0.88314272 0.70661157\n",
            " 0.88446656 0.87532068 0.79490291 0.79716024]\n",
            "Train f1 Score: 0.8334324503756729\n",
            "Test f1 Score: 0.8422850512243609\n",
            "Now predicting labels for unlabeled data...\n",
            "90 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3910 unlabelled instances remained to be predict in next iteration\n",
            "190 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 395\n",
            "35400 new labelled data is training...\n",
            "Epoch 1/100\n",
            "554/554 [==============================] - 3s 5ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 2/100\n",
            "554/554 [==============================] - 3s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 3/100\n",
            "554/554 [==============================] - 3s 6ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 4/100\n",
            "554/554 [==============================] - 3s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 5/100\n",
            "554/554 [==============================] - 3s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 6/100\n",
            "554/554 [==============================] - 3s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 7/100\n",
            "554/554 [==============================] - 3s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 8/100\n",
            "554/554 [==============================] - 3s 6ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 9/100\n",
            "554/554 [==============================] - 3s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 10/100\n",
            "554/554 [==============================] - 3s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 11/100\n",
            "554/554 [==============================] - 3s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 12/100\n",
            "554/554 [==============================] - 3s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 13/100\n",
            "554/554 [==============================] - 3s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 14/100\n",
            "554/554 [==============================] - 4s 6ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 15/100\n",
            "554/554 [==============================] - 3s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 16/100\n",
            "554/554 [==============================] - 3s 5ms/step - loss: 0.0091 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 17/100\n",
            "554/554 [==============================] - 3s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 18/100\n",
            "554/554 [==============================] - 3s 5ms/step - loss: 0.0090 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 19/100\n",
            "554/554 [==============================] - 3s 6ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 20/100\n",
            "554/554 [==============================] - 3s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 21/100\n",
            "554/554 [==============================] - 3s 5ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 22/100\n",
            "554/554 [==============================] - 3s 5ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 00022: early stopping\n",
            "Elapsed time: 61.234 sec\n",
            "Train f1 Score: [0.95939724 0.94214994 0.82938751 0.719838   0.85874495 0.68624561\n",
            " 0.89215424 0.88306922 0.79023105 0.77086207]\n",
            "Test f1 Score: [0.9593985  0.95986336 0.83173496 0.73259494 0.8807521  0.70523416\n",
            " 0.88421053 0.87487179 0.79490291 0.79592875]\n",
            "Train f1 Score: 0.833207982824072\n",
            "Test f1 Score: 0.8419492008050848\n",
            "Now predicting labels for unlabeled data...\n",
            "93 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3917 unlabelled instances remained to be predict in next iteration\n",
            "183 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 396\n",
            "35500 new labelled data is training...\n",
            "Epoch 1/100\n",
            "555/555 [==============================] - 3s 5ms/step - loss: 0.0094 - sparse_categorical_accuracy: 0.9966\n",
            "Epoch 2/100\n",
            "555/555 [==============================] - 3s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 3/100\n",
            "555/555 [==============================] - 3s 6ms/step - loss: 0.0094 - sparse_categorical_accuracy: 0.9966\n",
            "Epoch 4/100\n",
            "555/555 [==============================] - 3s 5ms/step - loss: 0.0090 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 5/100\n",
            "555/555 [==============================] - 3s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 6/100\n",
            "555/555 [==============================] - 3s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 7/100\n",
            "555/555 [==============================] - 3s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 8/100\n",
            "555/555 [==============================] - 3s 6ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 9/100\n",
            "555/555 [==============================] - 3s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 10/100\n",
            "555/555 [==============================] - 3s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 11/100\n",
            "555/555 [==============================] - 3s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 12/100\n",
            "555/555 [==============================] - 3s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 13/100\n",
            "555/555 [==============================] - 3s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 14/100\n",
            "555/555 [==============================] - 4s 6ms/step - loss: 0.0088 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 15/100\n",
            "555/555 [==============================] - 3s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 16/100\n",
            "555/555 [==============================] - 3s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 17/100\n",
            "555/555 [==============================] - 3s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 18/100\n",
            "555/555 [==============================] - 3s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 19/100\n",
            "555/555 [==============================] - 4s 6ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 20/100\n",
            "555/555 [==============================] - 3s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 21/100\n",
            "555/555 [==============================] - 3s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 22/100\n",
            "555/555 [==============================] - 3s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 23/100\n",
            "555/555 [==============================] - 3s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 00023: early stopping\n",
            "Elapsed time: 64.842 sec\n",
            "Train f1 Score: [0.9589087  0.94158712 0.82790698 0.71981657 0.85877106 0.6879529\n",
            " 0.8922337  0.88195545 0.79059872 0.76970793]\n",
            "Test f1 Score: [0.95795796 0.95904437 0.83086312 0.73375594 0.88118812 0.70839065\n",
            " 0.88470067 0.87416538 0.79563372 0.79450661]\n",
            "Train f1 Score: 0.8329439137173844\n",
            "Test f1 Score: 0.8420206533640263\n",
            "Now predicting labels for unlabeled data...\n",
            "92 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3925 unlabelled instances remained to be predict in next iteration\n",
            "175 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 397\n",
            "35600 new labelled data is training...\n",
            "Epoch 1/100\n",
            "557/557 [==============================] - 3s 6ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 2/100\n",
            "557/557 [==============================] - 3s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 3/100\n",
            "557/557 [==============================] - 3s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 4/100\n",
            "557/557 [==============================] - 3s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 5/100\n",
            "557/557 [==============================] - 3s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 6/100\n",
            "557/557 [==============================] - 3s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 7/100\n",
            "557/557 [==============================] - 4s 6ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 8/100\n",
            "557/557 [==============================] - 3s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 9/100\n",
            "557/557 [==============================] - 3s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 10/100\n",
            "557/557 [==============================] - 3s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 11/100\n",
            "557/557 [==============================] - 3s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 12/100\n",
            "557/557 [==============================] - 3s 6ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 13/100\n",
            "557/557 [==============================] - 3s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 14/100\n",
            "557/557 [==============================] - 3s 5ms/step - loss: 0.0091 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 15/100\n",
            "557/557 [==============================] - 3s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 00015: early stopping\n",
            "Elapsed time: 42.916 sec\n",
            "Train f1 Score: [0.95908977 0.94138594 0.8297465  0.72060269 0.85924457 0.68654348\n",
            " 0.89209145 0.88228915 0.79109312 0.77059025]\n",
            "Test f1 Score: [0.95991984 0.95863539 0.83093054 0.73346535 0.88238213 0.70758621\n",
            " 0.88384956 0.87358684 0.79636364 0.79554656]\n",
            "Train f1 Score: 0.8332676901778713\n",
            "Test f1 Score: 0.8422266056314527\n",
            "Now predicting labels for unlabeled data...\n",
            "95 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3930 unlabelled instances remained to be predict in next iteration\n",
            "170 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 398\n",
            "35700 new labelled data is training...\n",
            "Epoch 1/100\n",
            "558/558 [==============================] - 3s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 2/100\n",
            "558/558 [==============================] - 3s 6ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 3/100\n",
            "558/558 [==============================] - 3s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 4/100\n",
            "558/558 [==============================] - 3s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 5/100\n",
            "558/558 [==============================] - 3s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 6/100\n",
            "558/558 [==============================] - 3s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 7/100\n",
            "558/558 [==============================] - 3s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 8/100\n",
            "558/558 [==============================] - 3s 6ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 9/100\n",
            "558/558 [==============================] - 3s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 10/100\n",
            "558/558 [==============================] - 3s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 11/100\n",
            "558/558 [==============================] - 3s 5ms/step - loss: 0.0094 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 12/100\n",
            "558/558 [==============================] - 3s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 13/100\n",
            "558/558 [==============================] - 3s 6ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 14/100\n",
            "558/558 [==============================] - 3s 6ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 15/100\n",
            "558/558 [==============================] - 3s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 16/100\n",
            "558/558 [==============================] - 3s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 00016: early stopping\n",
            "Elapsed time: 45.554 sec\n",
            "Train f1 Score: [0.95925709 0.9419732  0.82873941 0.72093631 0.85962445 0.68758496\n",
            " 0.89257082 0.88151738 0.79183508 0.77101798]\n",
            "Test f1 Score: [0.95847924 0.95904437 0.83129371 0.73280632 0.88282026 0.70798898\n",
            " 0.88482835 0.87461459 0.79636364 0.79654997]\n",
            "Train f1 Score: 0.8335056683525632\n",
            "Test f1 Score: 0.8424789432513261\n",
            "Now predicting labels for unlabeled data...\n",
            "91 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3939 unlabelled instances remained to be predict in next iteration\n",
            "161 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 399\n",
            "35800 new labelled data is training...\n",
            "Epoch 1/100\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 2/100\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 3/100\n",
            "560/560 [==============================] - 3s 6ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 4/100\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 5/100\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.0094 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 6/100\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.0095 - sparse_categorical_accuracy: 0.9966\n",
            "Epoch 7/100\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 8/100\n",
            "560/560 [==============================] - 3s 6ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 9/100\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.0089 - sparse_categorical_accuracy: 0.9966\n",
            "Epoch 10/100\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 11/100\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 12/100\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 13/100\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 14/100\n",
            "560/560 [==============================] - 3s 6ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 15/100\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 16/100\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 17/100\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 18/100\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 19/100\n",
            "560/560 [==============================] - 3s 6ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 20/100\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 21/100\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 22/100\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 23/100\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 24/100\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.0067 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 25/100\n",
            "560/560 [==============================] - 3s 6ms/step - loss: 0.0097 - sparse_categorical_accuracy: 0.9966\n",
            "Epoch 26/100\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 27/100\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 28/100\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 29/100\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 30/100\n",
            "560/560 [==============================] - 3s 6ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 31/100\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 32/100\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 33/100\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 34/100\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 35/100\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 36/100\n",
            "560/560 [==============================] - 4s 6ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 00036: early stopping\n",
            "Elapsed time: 103.482 sec\n",
            "Train f1 Score: [0.95941083 0.9422089  0.8296036  0.72011491 0.85789691 0.68737248\n",
            " 0.89197613 0.88207784 0.78958038 0.76923077]\n",
            "Test f1 Score: [0.95843766 0.95945369 0.83195111 0.73288484 0.8807521  0.70976616\n",
            " 0.88580931 0.87403599 0.79490291 0.79390863]\n",
            "Train f1 Score: 0.8329472743387205\n",
            "Test f1 Score: 0.8421902414721025\n",
            "Now predicting labels for unlabeled data...\n",
            "91 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3948 unlabelled instances remained to be predict in next iteration\n",
            "152 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 400\n",
            "35900 new labelled data is training...\n",
            "Epoch 1/100\n",
            "561/561 [==============================] - 3s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 2/100\n",
            "561/561 [==============================] - 3s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 3/100\n",
            "561/561 [==============================] - 3s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 4/100\n",
            "561/561 [==============================] - 3s 5ms/step - loss: 0.0089 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 5/100\n",
            "561/561 [==============================] - 3s 6ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 6/100\n",
            "561/561 [==============================] - 3s 5ms/step - loss: 0.0088 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 7/100\n",
            "561/561 [==============================] - 3s 5ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 8/100\n",
            "561/561 [==============================] - 3s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 9/100\n",
            "561/561 [==============================] - 3s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 10/100\n",
            "561/561 [==============================] - 3s 6ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 11/100\n",
            "561/561 [==============================] - 4s 7ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 12/100\n",
            "561/561 [==============================] - 3s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 13/100\n",
            "561/561 [==============================] - 3s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 14/100\n",
            "561/561 [==============================] - 3s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 15/100\n",
            "561/561 [==============================] - 3s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 16/100\n",
            "561/561 [==============================] - 4s 7ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 17/100\n",
            "561/561 [==============================] - 3s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 18/100\n",
            "561/561 [==============================] - 3s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 19/100\n",
            "561/561 [==============================] - 3s 5ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 20/100\n",
            "561/561 [==============================] - 3s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 00020: early stopping\n",
            "Elapsed time: 58.298 sec\n",
            "Train f1 Score: [0.95876202 0.94228437 0.82917144 0.7204709  0.85881964 0.68656378\n",
            " 0.89258403 0.88195545 0.78953771 0.76916466]\n",
            "Test f1 Score: [0.95895896 0.95904437 0.83231441 0.73338608 0.88138958 0.70847691\n",
            " 0.88544549 0.8751926  0.79343864 0.79432624]\n",
            "Train f1 Score: 0.8329314000915092\n",
            "Test f1 Score: 0.842197327865539\n",
            "Now predicting labels for unlabeled data...\n",
            "93 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3955 unlabelled instances remained to be predict in next iteration\n",
            "145 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 401\n",
            "36000 new labelled data is training...\n",
            "Epoch 1/100\n",
            "563/563 [==============================] - 3s 6ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 2/100\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 3/100\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.0088 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 4/100\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.0091 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 5/100\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.0088 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 6/100\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 7/100\n",
            "563/563 [==============================] - 3s 6ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 8/100\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 9/100\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 10/100\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 11/100\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 12/100\n",
            "563/563 [==============================] - 3s 6ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 13/100\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 14/100\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 15/100\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 16/100\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 17/100\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 18/100\n",
            "563/563 [==============================] - 3s 6ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 19/100\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 20/100\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.0092 - sparse_categorical_accuracy: 0.9969\n",
            "Epoch 21/100\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 22/100\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 23/100\n",
            "563/563 [==============================] - 3s 6ms/step - loss: 0.0072 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 24/100\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 00024: early stopping\n",
            "Elapsed time: 70.629 sec\n",
            "Train f1 Score: [0.95887663 0.94119322 0.82998928 0.72128146 0.85938662 0.68573382\n",
            " 0.89233235 0.88222056 0.79186893 0.7704721 ]\n",
            "Test f1 Score: [0.959      0.95863539 0.83078268 0.73338608 0.88194444 0.70498615\n",
            " 0.88580931 0.87429451 0.79709267 0.7965587 ]\n",
            "Train f1 Score: 0.8333354983493022\n",
            "Test f1 Score: 0.8422489947379994\n",
            "Now predicting labels for unlabeled data...\n",
            "92 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3963 unlabelled instances remained to be predict in next iteration\n",
            "137 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 402\n",
            "36100 new labelled data is training...\n",
            "Epoch 1/100\n",
            "565/565 [==============================] - 3s 5ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 2/100\n",
            "565/565 [==============================] - 3s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 3/100\n",
            "565/565 [==============================] - 3s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 4/100\n",
            "565/565 [==============================] - 3s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 5/100\n",
            "565/565 [==============================] - 4s 6ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 6/100\n",
            "565/565 [==============================] - 3s 5ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 7/100\n",
            "565/565 [==============================] - 3s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 8/100\n",
            "565/565 [==============================] - 3s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 9/100\n",
            "565/565 [==============================] - 3s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 10/100\n",
            "565/565 [==============================] - 3s 6ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 11/100\n",
            "565/565 [==============================] - 3s 6ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 12/100\n",
            "565/565 [==============================] - 3s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 13/100\n",
            "565/565 [==============================] - 3s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 14/100\n",
            "565/565 [==============================] - 3s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 15/100\n",
            "565/565 [==============================] - 3s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 00015: early stopping\n",
            "Elapsed time: 42.685 sec\n",
            "Train f1 Score: [0.95871636 0.94291423 0.83009337 0.72073721 0.86042856 0.68659091\n",
            " 0.89366999 0.88201451 0.79300939 0.77068639]\n",
            "Test f1 Score: [0.958      0.95945369 0.83289589 0.73338608 0.88425236 0.70628887\n",
            " 0.88544549 0.87474333 0.79854809 0.79594937]\n",
            "Train f1 Score: 0.8338860920882112\n",
            "Test f1 Score: 0.842896316671828\n",
            "Now predicting labels for unlabeled data...\n",
            "95 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3968 unlabelled instances remained to be predict in next iteration\n",
            "132 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 403\n",
            "36200 new labelled data is training...\n",
            "Epoch 1/100\n",
            "566/566 [==============================] - 3s 5ms/step - loss: 0.0091 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 2/100\n",
            "566/566 [==============================] - 3s 5ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 3/100\n",
            "566/566 [==============================] - 3s 5ms/step - loss: 0.0066 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 4/100\n",
            "566/566 [==============================] - 3s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 5/100\n",
            "566/566 [==============================] - 3s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 6/100\n",
            "566/566 [==============================] - 3s 6ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 7/100\n",
            "566/566 [==============================] - 3s 6ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 8/100\n",
            "566/566 [==============================] - 3s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 9/100\n",
            "566/566 [==============================] - 3s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 10/100\n",
            "566/566 [==============================] - 3s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 11/100\n",
            "566/566 [==============================] - 3s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 12/100\n",
            "566/566 [==============================] - 4s 7ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 13/100\n",
            "566/566 [==============================] - 3s 5ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 14/100\n",
            "566/566 [==============================] - 3s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 15/100\n",
            "566/566 [==============================] - 3s 5ms/step - loss: 0.0093 - sparse_categorical_accuracy: 0.9966\n",
            "Epoch 00015: early stopping\n",
            "Elapsed time: 43.772 sec\n",
            "Train f1 Score: [0.958483   0.94270425 0.83183942 0.72051717 0.85967235 0.68765572\n",
            " 0.89294296 0.88317524 0.79002837 0.77015851]\n",
            "Test f1 Score: [0.958      0.95904437 0.83260298 0.73222749 0.88293651 0.70887818\n",
            " 0.88642659 0.8766001  0.79417122 0.79471545]\n",
            "Train f1 Score: 0.8337176990426679\n",
            "Test f1 Score: 0.8425602890360142\n",
            "Now predicting labels for unlabeled data...\n",
            "94 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3974 unlabelled instances remained to be predict in next iteration\n",
            "126 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 404\n",
            "36300 new labelled data is training...\n",
            "Epoch 1/100\n",
            "568/568 [==============================] - 3s 5ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 2/100\n",
            "568/568 [==============================] - 3s 6ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9967\n",
            "Epoch 3/100\n",
            "568/568 [==============================] - 3s 6ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 4/100\n",
            "568/568 [==============================] - 3s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 5/100\n",
            "568/568 [==============================] - 3s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 6/100\n",
            "568/568 [==============================] - 3s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9977\n",
            "Epoch 7/100\n",
            "568/568 [==============================] - 3s 5ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 8/100\n",
            "568/568 [==============================] - 4s 6ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 9/100\n",
            "568/568 [==============================] - 3s 5ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 10/100\n",
            "568/568 [==============================] - 3s 5ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 11/100\n",
            "568/568 [==============================] - 3s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9968\n",
            "Epoch 12/100\n",
            "568/568 [==============================] - 3s 5ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 13/100\n",
            "568/568 [==============================] - 3s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 14/100\n",
            "568/568 [==============================] - 3s 6ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9975\n",
            "Epoch 15/100\n",
            "568/568 [==============================] - 3s 5ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 16/100\n",
            "568/568 [==============================] - 3s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 17/100\n",
            "568/568 [==============================] - 3s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 18/100\n",
            "568/568 [==============================] - 3s 5ms/step - loss: 0.0082 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 19/100\n",
            "568/568 [==============================] - 3s 6ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 20/100\n",
            "568/568 [==============================] - 3s 6ms/step - loss: 0.0083 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 21/100\n",
            "568/568 [==============================] - 3s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9976\n",
            "Epoch 22/100\n",
            "568/568 [==============================] - 3s 5ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 23/100\n",
            "568/568 [==============================] - 3s 5ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 24/100\n",
            "568/568 [==============================] - 3s 5ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 00024: early stopping\n",
            "Elapsed time: 69.572 sec\n",
            "Train f1 Score: [0.95991296 0.94153671 0.83000077 0.72019338 0.85917591 0.6874504\n",
            " 0.89302906 0.88123694 0.78995341 0.77011298]\n",
            "Test f1 Score: [0.95891784 0.95863539 0.83187391 0.73272799 0.88282026 0.70758621\n",
            " 0.88580931 0.87390633 0.79709267 0.7959596 ]\n",
            "Train f1 Score: 0.8332602511780376\n",
            "Test f1 Score: 0.8425329501294453\n",
            "Now predicting labels for unlabeled data...\n",
            "94 high-probability unlabelled predictions is labelled and added to next train dataset.\n",
            "3980 unlabelled instances remained to be predict in next iteration\n",
            "120 labelled instances are going to be added to train dataset in next iteration.\n",
            "Iteration: 405\n",
            "36400 new labelled data is training...\n",
            "Epoch 1/100\n",
            "569/569 [==============================] - 3s 5ms/step - loss: 0.0080 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 2/100\n",
            "569/569 [==============================] - 3s 5ms/step - loss: 0.0090 - sparse_categorical_accuracy: 0.9971\n",
            "Epoch 3/100\n",
            "569/569 [==============================] - 3s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 4/100\n",
            " 34/569 [>.............................] - ETA: 2s - loss: 0.0012 - sparse_categorical_accuracy: 0.9995"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fy9jba9xtRr-"
      },
      "source": [
        "#call plot_result() here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz5thBovmWsj"
      },
      "source": [
        "#HyperParams\n",
        "batch_size = 16\n",
        "epochs = 100 \n",
        "num_pseudo = 50\n",
        "y_test, y_test_pred, test_f1s, test_f1s_avg, pseudo_labels, epoch = self_train_with_pretrain('CNN', num_pseudo, batch_size, num_iterations, confidence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znYLT3LgtRsA"
      },
      "source": [
        "#call plot_result() here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJK_tqmu-HN1"
      },
      "source": [
        "#HyperParams\n",
        "batch_size = 16\n",
        "epochs = 100 \n",
        "num_pseudo = 30\n",
        "y_test, y_test_pred, test_f1s, test_f1s_avg, pseudo_labels, epoch = self_train_with_pretrain('CNN', num_pseudo, batch_size, num_iterations, confidence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bO8TR2W-MXt"
      },
      "source": [
        "#call plot_result() here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3D56mb6pZvTb",
        "outputId": "eec99e9f-2f5e-4af3-fc64-b96be275d11b"
      },
      "source": [
        "%cd drive/MyDrive/Projects/ssl-mnist"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Projects/ssl-mnist\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOmjUVzLZq04"
      },
      "source": [
        "!git add ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRt50RmPad1x"
      },
      "source": [
        "!git config --global user.name redmusketeer\n",
        "!git config --global user.email \"rasatechcom@gmail.com\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWn70BAlZsat",
        "outputId": "472af29b-1a8e-41c3-b811-e0e165be99bb"
      },
      "source": [
        "!git commit -m \"ssl cnn with 600 number is calculated and 100 number is intrupted\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On branch main\n",
            "Your branch is ahead of 'origin/main' by 1 commit.\n",
            "  (use \"git push\" to publish your local commits)\n",
            "\n",
            "Changes not staged for commit:\n",
            "\t\u001b[31mmodified:   src/Notebooks/ssl_train_cnn.ipynb\u001b[m\n",
            "\n",
            "no changes added to commit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ovWrtVGbb0r",
        "outputId": "27d73090-1d32-46ab-9a34-28f91c61c41a"
      },
      "source": [
        "!git remote add origin https://{redmusketeer}:{R1a2S3a4}@github.com/{redmusketeer}/ssl_mnist.git"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: remote origin already exists.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbuGJhtKacfF",
        "outputId": "39bfdfa2-0b75-412e-c2d8-696f89542d34"
      },
      "source": [
        "!git push"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQVjKQjTareY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}